{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d6n47ueeqbXb"
   },
   "source": [
    "## Personalized Learning (Localized Learning?)\n",
    "\n",
    "#### This notebook includes the following online models;\n",
    "1. A single global model with all data\n",
    "2. Multiple local models (starting from a single global model)\n",
    "   1. that are updated with new data\n",
    "   2. that exchanges data in clusters\n",
    "   3. that exchanges parameters in clusters\n",
    "\n",
    "  \n",
    "#### The dataset that is used for this project is [CIFAR-100 dataset][1]\n",
    "* Has 100 classes containing 600 images each\n",
    "\n",
    "#### New data are fed by the following rules;\n",
    "1. Distributed, according to superclasses\n",
    "  * Clusters will only be updated with data that belongs to a specific superclass\n",
    "  * We update the NN by\n",
    "    1. Changing all parameters of the NN\n",
    "    2. Only changing the last few layers, as in many MTL models\n",
    "2. Randomly (why?)\n",
    "\n",
    "#### We expect to find an answer to the following research questions with this project;\n",
    "1. If models are updated with data (or parameters) that are shared within a cluster, can the model perform good enough with the labels that count?\n",
    "  * For example, the performance of the cluster that are updated with \"Vehicles\" superclass is only assessed with the labels that corresponds to the superclass.\n",
    "  \n",
    "[1]: https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oji0BTfoqbXc"
   },
   "source": [
    "#### Questions\n",
    "\n",
    "Retraining: how does it work <br>\n",
    "How do we compare these models?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mr4-uY0LqbXd"
   },
   "source": [
    "### Implementation with Custom Neural Network and MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tGoXLnOyqbXe",
    "outputId": "9ccd7215-80bf-4a0a-b852-8896b17c38f1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.lines as mlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E2faBs1yqbXj"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QXfylSWLqbXl"
   },
   "source": [
    "#### Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "V7iMvdGXqbXm",
    "outputId": "875da8c3-28b0-48cc-da41-b2d91add5cb3"
   },
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1 = x_train[-30000:]\n",
    "y_train1 = y_train[-30000:]\n",
    "x_train2 = x_train[:-30000]\n",
    "y_train2 = y_train[:-30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve 10,000 samples for validation\n",
    "x_val1 = x_train1[-5000:]\n",
    "y_val1 = y_train1[-5000:]\n",
    "x_train1 = x_train1[:-5000]\n",
    "y_train1 = y_train1[:-5000]\n",
    "\n",
    "x_val2 = x_train2[-5000:]\n",
    "y_val2 = y_train2[-5000:]\n",
    "x_train2 = x_train2[:-5000]\n",
    "y_train2 = y_train2[:-5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (25000, 28, 28, 1)\n",
      "25000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train1.shape)\n",
    "print(x_train1.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train1 = keras.utils.to_categorical(y_train1, num_classes)\n",
    "y_val1 = keras.utils.to_categorical(y_val1, num_classes)\n",
    "y_train2 = keras.utils.to_categorical(y_train2, num_classes)\n",
    "y_val2 = keras.utils.to_categorical(y_val2, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models and compile & fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):  \n",
    "    # initiate SGD optimizer\n",
    "    opt = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model_lr(model):  \n",
    "    # initiate SGD optimizer\n",
    "    opt = keras.optimizers.SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model1(model, epochs):\n",
    "    now = datetime.datetime.now()\n",
    "    print (\"Training date and time : \")\n",
    "    print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    return model.fit(x_train1, y_train1,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      validation_data=(x_val1, y_val1),\n",
    "                      shuffle=True, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model2(model, epochs):\n",
    "    now = datetime.datetime.now()\n",
    "    print (\"Training date and time : \")\n",
    "    print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    return model.fit(x_train2, y_train2,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      validation_data=(x_val2, y_val2),\n",
    "                      shuffle=True, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = custom_model()\n",
    "model2 = tf.keras.models.clone_model(model1)\n",
    "model2.set_weights(model1.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training date and time : \n",
      "2020-03-04 13:44:36\n",
      "Train on 25000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 21s 837us/sample - loss: 0.0886 - accuracy: 0.2436 - val_loss: 0.0853 - val_accuracy: 0.4654\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 23s 901us/sample - loss: 0.0673 - accuracy: 0.5952 - val_loss: 0.0353 - val_accuracy: 0.7848\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 24s 952us/sample - loss: 0.0262 - accuracy: 0.8368 - val_loss: 0.0139 - val_accuracy: 0.9192\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 23s 936us/sample - loss: 0.0170 - accuracy: 0.8912 - val_loss: 0.0113 - val_accuracy: 0.9284\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 21s 851us/sample - loss: 0.0150 - accuracy: 0.9042 - val_loss: 0.0106 - val_accuracy: 0.9310\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 21s 858us/sample - loss: 0.0137 - accuracy: 0.9116 - val_loss: 0.0095 - val_accuracy: 0.9368\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 22s 864us/sample - loss: 0.0127 - accuracy: 0.9172 - val_loss: 0.0091 - val_accuracy: 0.9420\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 21s 849us/sample - loss: 0.0119 - accuracy: 0.9233 - val_loss: 0.0087 - val_accuracy: 0.9448\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 22s 863us/sample - loss: 0.0112 - accuracy: 0.9294 - val_loss: 0.0079 - val_accuracy: 0.9494\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 23s 902us/sample - loss: 0.0106 - accuracy: 0.9328 - val_loss: 0.0078 - val_accuracy: 0.9496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1671870b8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compile_model(model1)\n",
    "fit_model1(model1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training date and time : \n",
      "2020-03-04 13:48:16\n",
      "Train on 25000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 22s 864us/sample - loss: 0.0885 - accuracy: 0.2449 - val_loss: 0.0852 - val_accuracy: 0.4118\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 21s 827us/sample - loss: 0.0649 - accuracy: 0.5993 - val_loss: 0.0378 - val_accuracy: 0.7532\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 20s 809us/sample - loss: 0.0244 - accuracy: 0.8503 - val_loss: 0.0180 - val_accuracy: 0.8878\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 21s 840us/sample - loss: 0.0161 - accuracy: 0.8990 - val_loss: 0.0154 - val_accuracy: 0.9020\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 21s 854us/sample - loss: 0.0140 - accuracy: 0.9112 - val_loss: 0.0138 - val_accuracy: 0.9094\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 21s 847us/sample - loss: 0.0127 - accuracy: 0.9185 - val_loss: 0.0130 - val_accuracy: 0.9144\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 21s 843us/sample - loss: 0.0119 - accuracy: 0.9249 - val_loss: 0.0125 - val_accuracy: 0.9168\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 22s 865us/sample - loss: 0.0112 - accuracy: 0.9295 - val_loss: 0.0118 - val_accuracy: 0.9220\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 21s 847us/sample - loss: 0.0106 - accuracy: 0.9328 - val_loss: 0.0114 - val_accuracy: 0.9252\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 21s 825us/sample - loss: 0.0100 - accuracy: 0.9363 - val_loss: 0.0111 - val_accuracy: 0.9258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1650500b8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compile_model(model2)\n",
    "fit_model2(model2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "theta_list = list(np.arange(0, 1.05, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_weights = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [model1.get_weights(), model2.get_weights()]\n",
    "agg_weights_list = list()\n",
    "for theta in theta_list:\n",
    "    agg_weights = list()\n",
    "    for weights_list_tuple in zip(*weights):\n",
    "        agg_weights.append(np.array([np.average(np.array(w), axis=0, weights=[1. - theta, theta]) for w in zip(*weights_list_tuple)]))\n",
    "    agg_weights_list.append(agg_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 154us/sample - loss: 0.0099 - accuracy: 0.9378\n",
      "10000/10000 [==============================] - 1s 147us/sample - loss: 0.0098 - accuracy: 0.9379\n",
      "10000/10000 [==============================] - 2s 160us/sample - loss: 0.0098 - accuracy: 0.9382\n",
      "10000/10000 [==============================] - 2s 154us/sample - loss: 0.0097 - accuracy: 0.9379\n",
      "10000/10000 [==============================] - 1s 147us/sample - loss: 0.0097 - accuracy: 0.9378\n",
      "10000/10000 [==============================] - 1s 149us/sample - loss: 0.0097 - accuracy: 0.9379\n",
      "10000/10000 [==============================] - 2s 154us/sample - loss: 0.0096 - accuracy: 0.9379\n",
      "10000/10000 [==============================] - 2s 156us/sample - loss: 0.0096 - accuracy: 0.9380\n",
      "10000/10000 [==============================] - 2s 160us/sample - loss: 0.0096 - accuracy: 0.9382\n",
      "10000/10000 [==============================] - 2s 167us/sample - loss: 0.0096 - accuracy: 0.9384\n",
      "10000/10000 [==============================] - 2s 166us/sample - loss: 0.0096 - accuracy: 0.9388\n",
      "10000/10000 [==============================] - 2s 162us/sample - loss: 0.0096 - accuracy: 0.9384\n",
      "10000/10000 [==============================] - 2s 166us/sample - loss: 0.0096 - accuracy: 0.9382\n",
      "10000/10000 [==============================] - 2s 156us/sample - loss: 0.0096 - accuracy: 0.9385\n",
      "10000/10000 [==============================] - 2s 158us/sample - loss: 0.0096 - accuracy: 0.9387\n",
      "10000/10000 [==============================] - 2s 160us/sample - loss: 0.0097 - accuracy: 0.9383\n",
      "10000/10000 [==============================] - 2s 164us/sample - loss: 0.0097 - accuracy: 0.9377\n",
      "10000/10000 [==============================] - 2s 163us/sample - loss: 0.0098 - accuracy: 0.9378\n",
      "10000/10000 [==============================] - 2s 164us/sample - loss: 0.0098 - accuracy: 0.9379\n",
      "10000/10000 [==============================] - 2s 153us/sample - loss: 0.0099 - accuracy: 0.9373\n",
      "10000/10000 [==============================] - 2s 159us/sample - loss: 0.0100 - accuracy: 0.9374\n"
     ]
    }
   ],
   "source": [
    "scores = list()\n",
    "for agg_weights in agg_weights_list:\n",
    "    aggr_model = keras.models.clone_model(model1)\n",
    "    aggr_model.set_weights(agg_weights)\n",
    "    compile_model(aggr_model)\n",
    "    scores.append(aggr_model.evaluate(x_test, y_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.009890898557472974, 0.9378],\n",
       " [0.009834034765185788, 0.9379],\n",
       " [0.009783718757657335, 0.9382],\n",
       " [0.00974072741267737, 0.9379],\n",
       " [0.00970450523546897, 0.9378],\n",
       " [0.00967449641682906, 0.9379],\n",
       " [0.009649169192684348, 0.9379],\n",
       " [0.009628829794190824, 0.938],\n",
       " [0.009614439655048773, 0.9382],\n",
       " [0.00960684694951633, 0.9384],\n",
       " [0.00960380956933368, 0.9388],\n",
       " [0.009605669262364972, 0.9384],\n",
       " [0.009612580286897718, 0.9382],\n",
       " [0.009625677241734229, 0.9385],\n",
       " [0.009645618424343411, 0.9387],\n",
       " [0.009672319525270723, 0.9383],\n",
       " [0.009709714310162236, 0.9377],\n",
       " [0.009757346639316529, 0.9378],\n",
       " [0.009815173924923875, 0.9379],\n",
       " [0.009882935781846755, 0.9373],\n",
       " [0.009961150336975698, 0.9374]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(theta_list, [score[0] for score in scores])\n",
    "plt.xlabel(r'$\\theta$ for model-1')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### backup results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## @TODO Experiment with pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model1 = tf.keras.models.clone_model(model1)\n",
    "pretrained_model2 = tf.keras.models.clone_model(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sufficiently over-parameterized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input size must be at least 32x32; got `input_shape=(28, 28, 1)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-f64423c8ada9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvgg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/applications/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras_applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m                                       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                                       \u001b[0mrequire_flatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                                       weights=weights)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras_applications/imagenet_utils.py\u001b[0m in \u001b[0;36m_obtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[1;32m    320\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'x'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                                      \u001b[0;34m'; got `input_shape='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m                                      str(input_shape) + '`')\n\u001b[0m\u001b[1;32m    323\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrequire_flatten\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input size must be at least 32x32; got `input_shape=(28, 28, 1)`"
     ]
    }
   ],
   "source": [
    "vgg1 = keras.applications.vgg16.VGG16(include_top=False, weights=None, input_tensor=None, input_shape=(28,28,1), pooling=None, classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wvZdbWQhqbXs"
   },
   "source": [
    "#### We use 30000 samples to train global model and 30000 samples to simulate data being updated locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g-ufefq5GM0J"
   },
   "outputs": [],
   "source": [
    "global_sample_num = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-CWfYPxcqbXv"
   },
   "outputs": [],
   "source": [
    "# it seems like the training data is already in random order\n",
    "x_train_global = x_train[:global_sample_num]\n",
    "x_train_local = x_train[global_sample_num:]\n",
    "y_train_global = y_train[:global_sample_num]\n",
    "y_train_local = y_train[global_sample_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_local_data(num):\n",
    "    # if unable to split into same number of datasets,\n",
    "    # drop last few data\n",
    "    last_index = 30000 - (30000 % num) \n",
    "    x_local = np.split(x_train_local[:last_index], num)\n",
    "    y_local = np.split(y_train_local[:last_index], num)\n",
    "    return x_local, y_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_global(model, epochs):\n",
    "    now = datetime.datetime.now()\n",
    "    print (\"Training date and time : \")\n",
    "    print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    return model.fit(x_train_global, y_train_global,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      validation_data=(x_test, y_test_cat),\n",
    "                      shuffle=True, callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A few helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model_rms(model):  \n",
    "    # initiate RMSprop optimizer\n",
    "    opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_datetime():\n",
    "    now = datetime.datetime.now()\n",
    "    print (\"Training date and time : \")\n",
    "    print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with global model : Tune parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LvZKfgFKrh0p"
   },
   "source": [
    "## RQ1: Serial vs. Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serial\n",
    "30k - 10k - 10k - 10k \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "colab_type": "code",
    "id": "WExnApjkrvnt",
    "outputId": "a9d2ca77-66af-47d3-ba3a-f80095b2e154",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_datetime()\n",
    "\n",
    "serial_model = custom_model()\n",
    "compile_model(serial_model)\n",
    "history_serial = serial_model.fit(x_train_global, y_train_global,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = serial_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_serial.history['val_acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serial_model.save(\"30k_pretrain.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serial_model = keras.models.load_model('30k_pretrain.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(serial_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "local_serial_hist = []\n",
    "split_num = 10\n",
    "\n",
    "(x_local, y_local) = split_local_data(split_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(split_num):\n",
    "    print(\"Local training #%d\" %(i+1))\n",
    "    serial_model.fit(x_local[i], y_local[i],\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serial_model.save(\"serial_split_10.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallel\n",
    "<pre>\n",
    "       | 10k | \n",
    "30k -> | 10k | -> res\n",
    "       | 10k | \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model = []\n",
    "for i in range(split_num):\n",
    "    parallel_model.append(keras.models.load_model('30k_pretrain.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(split_num):\n",
    "    print(\"Local training (parallel) #%d\" %(i+1))\n",
    "    parallel_model[i].fit(x_local[i], y_local[i],\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [m.get_weights() for m in parallel_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Federated Aggregation\n",
    "new_weights = list()\n",
    "\n",
    "for weights_list_tuple in zip(*weights):\n",
    "    new_weights.append(\n",
    "        [np.array(weights_).mean(axis=0)\\\n",
    "            for weights_ in zip(*weights_list_tuple)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = keras.models.load_model('30k_pretrain.h5')\n",
    "aggr_model = keras.models.clone_model(pretrained_model)\n",
    "aggr_model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partial aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compile_model(aggr_model)\n",
    "aggr_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_model.save(\"parallel_split_10.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "serial vs. parallel by devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_by_device(lower, upper):\n",
    "    # Hyperparameter\n",
    "    lr = 0.001\n",
    "    \n",
    "    serial_res = np.zeros(upper - lower + 1)\n",
    "    parallel_res = np.zeros(upper - lower + 1)\n",
    "    serial_res[0] = 0.9563\n",
    "    parallel_res[0] = 0.9563\n",
    "    for split_num in range(lower, upper):\n",
    "        print(\"<=======   Learning with %d devices   =======>\" %split_num)\n",
    "        start_time = datetime.datetime.now() \n",
    "        \n",
    "        #split dataset\n",
    "        (x_local, y_local) = split_local_data(split_num)\n",
    "        \n",
    "        # run serial model\n",
    "        serial = keras.models.load_model('30k_pretrain.h5')\n",
    "        for layer in serial.layers[:2]:\n",
    "            layer.trainable=False\n",
    "        for layer in serial.layers[2:]:\n",
    "            layer.trainable=True\n",
    "        \n",
    "        compile_model_lr(serial, lr)\n",
    "        \n",
    "        for i in range(split_num):\n",
    "            print(\"%d devices: Local training (serial) #%d\" %(split_num, i+1))\n",
    "            serial_hist = serial.fit(x_local[i], y_local[i],\n",
    "                              batch_size=batch_size,\n",
    "                              epochs=epochs,\n",
    "                              verbose=1,\n",
    "                              validation_data=(x_test, y_test))\n",
    "        serial_res[split_num - lower + 1] = serial_hist.history['val_acc'][-1]\n",
    "#         serial.save(\"bd_serial_split_\" + str(split_num) + \".h5\")\n",
    "        \n",
    "        # run parallel model\n",
    "        parallel = [keras.models.load_model('30k_pretrain.h5') for _ in range(split_num)]\n",
    "        for p in parallel:\n",
    "            for layer in p.layers[:2]:\n",
    "                layer.trainable=False\n",
    "            for layer in p.layers[2:]:\n",
    "                layer.trainable=True\n",
    "            compile_model_lr(p, lr)\n",
    "            \n",
    "        for i in range(split_num):\n",
    "            print(\"%d devices: Local training (parallel) #%d\" %(split_num, i+1))\n",
    "            parallel[i].fit(x_local[i], y_local[i],\n",
    "                          batch_size=batch_size,\n",
    "                          epochs=epochs,\n",
    "                          verbose=1,\n",
    "                          validation_data=(x_test, y_test))\n",
    "        weights = [m.get_weights() for m in parallel]\n",
    "        # Federated Aggregation\n",
    "        new_weights = list()\n",
    "        for weights_list_tuple in zip(*weights):\n",
    "            new_weights.append(\n",
    "                [np.array(weights_).mean(axis=0)\\\n",
    "                    for weights_ in zip(*weights_list_tuple)])\n",
    "            \n",
    "        pretrained_model = keras.models.load_model('30k_pretrain.h5')\n",
    "        aggr_model = keras.models.clone_model(pretrained_model)\n",
    "        aggr_model.set_weights(new_weights)\n",
    "        compile_model(aggr_model)\n",
    "        aggr_score = aggr_model.evaluate(x_test, y_test)\n",
    "#         aggr_model.save(\"bd_parallel_split_\" + str(split_num) + \".h5\")\n",
    "        parallel_res[split_num - lower + 1] = aggr_score[1]\n",
    "        \n",
    "        end_time = datetime.datetime.now() \n",
    "        elasped_time = end_time - start_time\n",
    "        et = divmod(elasped_time.days * 86400 + elasped_time.seconds, 60)\n",
    "        print(\"Elasped Time for %d devices: %d minutes, %d seconds\" %(split_num, et[0], et[1]))\n",
    "    return serial_res, parallel_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lower = 2\n",
    "upper = 12\n",
    "(sr_2, pr_2) = compare_by_device(lower,upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(1,12)\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.axis([0.5, 11, 0.9380, 0.96])\n",
    "plt.plot(x, sr_2, label='serial')\n",
    "plt.plot(x, pr_2, label='parallel')\n",
    "# line for \n",
    "l = mlines.Line2D([-0.5,11], [0.9399,0.9399], c='red', label='base')\n",
    "ax = plt.gca()\n",
    "ax.add_line(l)\n",
    "ax.legend()\n",
    "plt.suptitle('SGD, Fixed, Learning rate: ' + str(0.001))\n",
    "plt.xlabel('num_devices')\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.savefig('SGD_lr001_fixed.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed Model \n",
    "#### 90% one class, 10% noise (non-iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_local = y_train_noncat[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train_local.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_skewed = x_train_local[:27000]\n",
    "x_train_noise = x_train_local[27000:]\n",
    "y_train_skewed = y_train_local[:27000]\n",
    "y_train_noise = y_train_local[27000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make placeholders for datas\n",
    "x_data_split = [np.empty([0,28,28,1]) for _ in range(num_users)]\n",
    "y_data_split = [np.empty([0], dtype='uint8') for _ in range(num_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data based on class\n",
    "for i in range(y_train_skewed.shape[0]):\n",
    "    if (i%1000 == 0):\n",
    "        print(\"%d complete\" %i)\n",
    "    user_num = (int) (y_train_skewed[i]) # user_num is from 0 to 9, depends on class\n",
    "    x_data_split[user_num] = \\\n",
    "        np.concatenate((x_data_split[user_num], np.expand_dims(x_train_skewed[i], axis=0)), axis=0)\n",
    "    y_data_split[user_num] = \\\n",
    "        np.concatenate((y_data_split[user_num], np.expand_dims(y_train_skewed[i], axis=0)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_noise_split = np.split(x_train_noise, num_users)\n",
    "y_noise_split = np.split(y_train_noise, num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_users):\n",
    "    x_data_split[i] = np.concatenate((x_data_split[i], x_noise_split[i]), axis=0)\n",
    "    y_data_split[i] = np.concatenate((y_data_split[i], y_noise_split[i]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(x_data_split[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_split_cat = []\n",
    "for yd in y_data_split:\n",
    "    y_data_split_cat.append(keras.utils.to_categorical(yd, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model = []\n",
    "for i in range(10):\n",
    "    parallel_model.append(keras.models.load_model('30k_pretrain.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(\"Local training (parallel) #%d\" %(i+1))\n",
    "    parallel_model[i].fit(x_data_split[i], y_data_split_cat[i],\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models that are fed with certain class more than others will distinguish that class with others better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when we are showing 1 class more than the others, are we just increasing tendency of the model to classify as that class, or are we actually helping it to learn more?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "confusion matrix, "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "personalized.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
