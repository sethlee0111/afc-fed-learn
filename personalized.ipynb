{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d6n47ueeqbXb"
   },
   "source": [
    "## Personalized Learning (Localized Learning?)\n",
    "\n",
    "#### This notebook includes the following online models;\n",
    "1. A single global model with all data\n",
    "2. Multiple local models (starting from a single global model)\n",
    "   1. that are updated with new data\n",
    "   2. that exchanges data in clusters\n",
    "   3. that exchanges parameters in clusters\n",
    "\n",
    "  \n",
    "#### The dataset that is used for this project is [CIFAR-100 dataset][1]\n",
    "* Has 100 classes containing 600 images each\n",
    "\n",
    "#### New data are fed by the following rules;\n",
    "1. Distributed, according to superclasses\n",
    "  * Clusters will only be updated with data that belongs to a specific superclass\n",
    "  * We update the NN by\n",
    "    1. Changing all parameters of the NN\n",
    "    2. Only changing the last few layers, as in many MTL models\n",
    "2. Randomly (why?)\n",
    "\n",
    "#### We expect to find an answer to the following research questions with this project;\n",
    "1. If models are updated with data (or parameters) that are shared within a cluster, can the model perform good enough with the labels that count?\n",
    "  * For example, the performance of the cluster that are updated with \"Vehicles\" superclass is only assessed with the labels that corresponds to the superclass.\n",
    "  \n",
    "[1]: https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oji0BTfoqbXc"
   },
   "source": [
    "#### Questions\n",
    "\n",
    "Retraining: how does it work <br>\n",
    "How do we compare these models?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mr4-uY0LqbXd"
   },
   "source": [
    "### Implementation with [MobileNet][2]\n",
    "\n",
    "[2]: https://arxiv.org/abs/1704.04861"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tGoXLnOyqbXe",
    "outputId": "9ccd7215-80bf-4a0a-b852-8896b17c38f1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "import datetime\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar100\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.applications import MobileNet\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JteNZLv1qbXh"
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E2faBs1yqbXj"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "num_classes = 100\n",
    "epochs = 30\n",
    "data_augmentation = True\n",
    "num_predictions = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QXfylSWLqbXl"
   },
   "source": [
    "#### Load CIFAR-100 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "V7iMvdGXqbXm",
    "outputId": "875da8c3-28b0-48cc-da41-b2d91add5cb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UlpBNC-vqbXq"
   },
   "outputs": [],
   "source": [
    "y_train_cat = keras.utils.to_categorical(\n",
    "    y_train,\n",
    "    num_classes=None,\n",
    "    dtype='float32'\n",
    ")\n",
    "y_test_cat = keras.utils.to_categorical(\n",
    "    y_test,\n",
    "    num_classes=None,\n",
    "    dtype='float32'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wvZdbWQhqbXs"
   },
   "source": [
    "#### We use 35000 samples to train global model and 15000 samples to simulate data being updated locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g-ufefq5GM0J"
   },
   "outputs": [],
   "source": [
    "global_sample_num = 35000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-CWfYPxcqbXv"
   },
   "outputs": [],
   "source": [
    "# it seems like the training data is already in random order\n",
    "x_train_global = x_train[:global_sample_num]\n",
    "x_train_local = x_train[global_sample_num:]\n",
    "y_train_global = y_train_cat[:global_sample_num]\n",
    "y_train_local = y_train_cat[global_sample_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_local_notcat = y_train[global_sample_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_global(model, epochs):\n",
    "    now = datetime.datetime.now()\n",
    "    print (\"Training date and time : \")\n",
    "    print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    return model.fit(x_train_global, y_train_global,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      validation_data=(x_test, y_test_cat),\n",
    "                      shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A few helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):  \n",
    "    # initiate SGD optimizer\n",
    "    opt = keras.optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model_rms(model):  \n",
    "    # initiate RMSprop optimizer\n",
    "    opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_datetime():\n",
    "    now = datetime.datetime.now()\n",
    "    print (\"Training date and time : \")\n",
    "    print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ibr_vzEqbX3"
   },
   "source": [
    "#### Build custom MobileNet model with additional dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "gXapwzyhqbX4",
    "outputId": "a46e27ef-fd0b-4098-9e73-33645676f096"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0801 01:19:32.668441 139671577802496 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0801 01:19:32.702611 139671577802496 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0801 01:19:32.716075 139671577802496 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0801 01:19:32.746716 139671577802496 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0801 01:19:32.747569 139671577802496 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:184: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0801 01:19:37.114187 139671577802496 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNet(weights=None, input_shape=x_train.shape[1:], include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "# @TODO maybe try initializing weights by weights='imagenet'?\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024,activation='relu')(x) # we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x = Dense(1024,activation='relu')(x) # dense layer 2\n",
    "x = Dense(512,activation='relu')(x) # dense layer 3\n",
    "preds = Dense(y_train_cat.shape[1],activation='softmax')(x) # final layer with softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c90clgrsqbX6"
   },
   "outputs": [],
   "source": [
    "model=Model(inputs=base_model.input,outputs=preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "FAvT5wx-qbX9",
    "outputId": "29993715-5d4f-4f9d-e42f-aaf0606635bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0801 01:19:39.753719 139671577802496 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sgd = keras.optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "compile_model(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LvZKfgFKrh0p"
   },
   "source": [
    "#### Global (1) Train globally on all 50k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idea) set batch_size differently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "colab_type": "code",
    "id": "WExnApjkrvnt",
    "outputId": "a9d2ca77-66af-47d3-ba3a-f80095b2e154",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training date and time : \n",
      "2019-07-28 21:29:18\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 49s 981us/step - loss: 0.0099 - acc: 0.0126 - val_loss: 0.0099 - val_acc: 0.0140\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 44s 883us/step - loss: 0.0099 - acc: 0.0156 - val_loss: 0.0099 - val_acc: 0.0193\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 44s 876us/step - loss: 0.0099 - acc: 0.0188 - val_loss: 0.0099 - val_acc: 0.0165\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 44s 875us/step - loss: 0.0099 - acc: 0.0192 - val_loss: 0.0099 - val_acc: 0.0182\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 44s 873us/step - loss: 0.0099 - acc: 0.0206 - val_loss: 0.0099 - val_acc: 0.0206\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 43s 869us/step - loss: 0.0099 - acc: 0.0208 - val_loss: 0.0099 - val_acc: 0.0229\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 44s 870us/step - loss: 0.0099 - acc: 0.0234 - val_loss: 0.0099 - val_acc: 0.0225\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 44s 873us/step - loss: 0.0099 - acc: 0.0240 - val_loss: 0.0098 - val_acc: 0.0267\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 44s 874us/step - loss: 0.0098 - acc: 0.0261 - val_loss: 0.0098 - val_acc: 0.0286\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 44s 872us/step - loss: 0.0098 - acc: 0.0270 - val_loss: 0.0098 - val_acc: 0.0305\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 44s 872us/step - loss: 0.0098 - acc: 0.0275 - val_loss: 0.0098 - val_acc: 0.0295\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 44s 881us/step - loss: 0.0098 - acc: 0.0291 - val_loss: 0.0098 - val_acc: 0.0315\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 44s 879us/step - loss: 0.0098 - acc: 0.0339 - val_loss: 0.0098 - val_acc: 0.0361\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 44s 880us/step - loss: 0.0098 - acc: 0.0367 - val_loss: 0.0098 - val_acc: 0.0402\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 44s 876us/step - loss: 0.0098 - acc: 0.0423 - val_loss: 0.0098 - val_acc: 0.0489\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 44s 874us/step - loss: 0.0098 - acc: 0.0455 - val_loss: 0.0098 - val_acc: 0.0465\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 44s 880us/step - loss: 0.0097 - acc: 0.0505 - val_loss: 0.0097 - val_acc: 0.0555\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 44s 875us/step - loss: 0.0097 - acc: 0.0546 - val_loss: 0.0097 - val_acc: 0.0563\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 44s 871us/step - loss: 0.0097 - acc: 0.0595 - val_loss: 0.0097 - val_acc: 0.0598\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 44s 873us/step - loss: 0.0097 - acc: 0.0630 - val_loss: 0.0097 - val_acc: 0.0614\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 44s 877us/step - loss: 0.0097 - acc: 0.0670 - val_loss: 0.0097 - val_acc: 0.0706\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 44s 878us/step - loss: 0.0096 - acc: 0.0711 - val_loss: 0.0096 - val_acc: 0.0704\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 44s 871us/step - loss: 0.0096 - acc: 0.0773 - val_loss: 0.0096 - val_acc: 0.0804\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 44s 878us/step - loss: 0.0096 - acc: 0.0793 - val_loss: 0.0096 - val_acc: 0.0827\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 44s 878us/step - loss: 0.0096 - acc: 0.0850 - val_loss: 0.0095 - val_acc: 0.0902\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 44s 879us/step - loss: 0.0095 - acc: 0.0915 - val_loss: 0.0095 - val_acc: 0.0957\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 44s 872us/step - loss: 0.0095 - acc: 0.0977 - val_loss: 0.0095 - val_acc: 0.0970\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 44s 872us/step - loss: 0.0095 - acc: 0.1007 - val_loss: 0.0095 - val_acc: 0.1020\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 44s 874us/step - loss: 0.0094 - acc: 0.1054 - val_loss: 0.0095 - val_acc: 0.1048\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 44s 875us/step - loss: 0.0094 - acc: 0.1129 - val_loss: 0.0094 - val_acc: 0.1151\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "print (\"Training date and time : \")\n",
    "print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "history_G1 = model.fit(x_train, y_train_cat,\n",
    "              batch_size=32,\n",
    "              epochs=30,\n",
    "              validation_data=(x_test, y_test_cat),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_G1_sgd.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "\n",
    "with CustomObjectScope({'relu6': keras.applications.mobilenet.relu6,'DepthwiseConv2D': keras.applications.mobilenet.DepthwiseConv2D}):\n",
    "    model = keras.models.load_model(\"model_G1_epoch_30_keras_downgraded.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 414us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.372575284194946, 0.2468]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Why does the accuracy drop?</span>\n",
    "<br> it's not dropping. we should check the validation accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bd3kFfCNO9pG"
   },
   "source": [
    "#### Global (2): Train Globally on 15K + fix layers, continue on remaining 35K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_G2 = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNet(weights=None, input_shape=x_train.shape[1:], include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "# @TODO maybe try initializing weights by weights='imagenet'?\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024,activation='relu')(x) # we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x = Dense(1024,activation='relu')(x) # dense layer 2\n",
    "x = Dense(512,activation='relu')(x) # dense layer 3\n",
    "preds = Dense(y_train_cat.shape[1],activation='softmax')(x) # final layer with softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xHdmHuqQOmmx",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training date and time : \n",
      "2019-07-28 21:57:47\n",
      "Train on 35000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "35000/35000 [==============================] - 37s 1ms/step - loss: 0.0099 - acc: 0.0117 - val_loss: 0.0099 - val_acc: 0.0158\n",
      "Epoch 2/30\n",
      "35000/35000 [==============================] - 31s 892us/step - loss: 0.0099 - acc: 0.0151 - val_loss: 0.0099 - val_acc: 0.0157\n",
      "Epoch 3/30\n",
      "35000/35000 [==============================] - 31s 891us/step - loss: 0.0099 - acc: 0.0149 - val_loss: 0.0099 - val_acc: 0.0164\n",
      "Epoch 4/30\n",
      "35000/35000 [==============================] - 31s 891us/step - loss: 0.0099 - acc: 0.0150 - val_loss: 0.0099 - val_acc: 0.0176\n",
      "Epoch 5/30\n",
      "35000/35000 [==============================] - 31s 889us/step - loss: 0.0099 - acc: 0.0166 - val_loss: 0.0099 - val_acc: 0.0192\n",
      "Epoch 6/30\n",
      "35000/35000 [==============================] - 31s 889us/step - loss: 0.0099 - acc: 0.0212 - val_loss: 0.0099 - val_acc: 0.0246\n",
      "Epoch 7/30\n",
      "35000/35000 [==============================] - 31s 892us/step - loss: 0.0099 - acc: 0.0257 - val_loss: 0.0099 - val_acc: 0.0270\n",
      "Epoch 8/30\n",
      "35000/35000 [==============================] - 31s 890us/step - loss: 0.0099 - acc: 0.0271 - val_loss: 0.0099 - val_acc: 0.0250\n",
      "Epoch 9/30\n",
      "35000/35000 [==============================] - 31s 890us/step - loss: 0.0098 - acc: 0.0302 - val_loss: 0.0098 - val_acc: 0.0311\n",
      "Epoch 10/30\n",
      "35000/35000 [==============================] - 31s 894us/step - loss: 0.0098 - acc: 0.0308 - val_loss: 0.0098 - val_acc: 0.0326\n",
      "Epoch 11/30\n",
      "35000/35000 [==============================] - 31s 889us/step - loss: 0.0098 - acc: 0.0317 - val_loss: 0.0098 - val_acc: 0.0352\n",
      "Epoch 12/30\n",
      "35000/35000 [==============================] - 31s 887us/step - loss: 0.0098 - acc: 0.0341 - val_loss: 0.0098 - val_acc: 0.0355\n",
      "Epoch 13/30\n",
      "35000/35000 [==============================] - 31s 892us/step - loss: 0.0098 - acc: 0.0357 - val_loss: 0.0098 - val_acc: 0.0401\n",
      "Epoch 14/30\n",
      "35000/35000 [==============================] - 31s 889us/step - loss: 0.0098 - acc: 0.0423 - val_loss: 0.0098 - val_acc: 0.0374\n",
      "Epoch 15/30\n",
      "35000/35000 [==============================] - 31s 894us/step - loss: 0.0098 - acc: 0.0415 - val_loss: 0.0098 - val_acc: 0.0457\n",
      "Epoch 16/30\n",
      "35000/35000 [==============================] - 31s 893us/step - loss: 0.0098 - acc: 0.0431 - val_loss: 0.0098 - val_acc: 0.0416\n",
      "Epoch 17/30\n",
      "35000/35000 [==============================] - 31s 889us/step - loss: 0.0098 - acc: 0.0456 - val_loss: 0.0098 - val_acc: 0.0454\n",
      "Epoch 18/30\n",
      "35000/35000 [==============================] - 31s 886us/step - loss: 0.0098 - acc: 0.0457 - val_loss: 0.0097 - val_acc: 0.0463\n",
      "Epoch 19/30\n",
      "35000/35000 [==============================] - 31s 889us/step - loss: 0.0097 - acc: 0.0487 - val_loss: 0.0098 - val_acc: 0.0491\n",
      "Epoch 20/30\n",
      "35000/35000 [==============================] - 31s 889us/step - loss: 0.0097 - acc: 0.0502 - val_loss: 0.0097 - val_acc: 0.0524\n",
      "Epoch 21/30\n",
      "35000/35000 [==============================] - 31s 894us/step - loss: 0.0097 - acc: 0.0519 - val_loss: 0.0097 - val_acc: 0.0536\n",
      "Epoch 22/30\n",
      "35000/35000 [==============================] - 31s 890us/step - loss: 0.0097 - acc: 0.0530 - val_loss: 0.0097 - val_acc: 0.0544\n",
      "Epoch 23/30\n",
      "35000/35000 [==============================] - 31s 891us/step - loss: 0.0097 - acc: 0.0570 - val_loss: 0.0097 - val_acc: 0.0555\n",
      "Epoch 24/30\n",
      "35000/35000 [==============================] - 31s 885us/step - loss: 0.0097 - acc: 0.0575 - val_loss: 0.0097 - val_acc: 0.0559\n",
      "Epoch 25/30\n",
      "35000/35000 [==============================] - 31s 888us/step - loss: 0.0097 - acc: 0.0581 - val_loss: 0.0097 - val_acc: 0.0615\n",
      "Epoch 26/30\n",
      "35000/35000 [==============================] - 31s 889us/step - loss: 0.0097 - acc: 0.0599 - val_loss: 0.0097 - val_acc: 0.0624\n",
      "Epoch 27/30\n",
      "35000/35000 [==============================] - 31s 892us/step - loss: 0.0096 - acc: 0.0621 - val_loss: 0.0097 - val_acc: 0.0644\n",
      "Epoch 28/30\n",
      "35000/35000 [==============================] - 31s 891us/step - loss: 0.0096 - acc: 0.0628 - val_loss: 0.0097 - val_acc: 0.0598\n",
      "Epoch 29/30\n",
      "35000/35000 [==============================] - 31s 886us/step - loss: 0.0096 - acc: 0.0627 - val_loss: 0.0097 - val_acc: 0.0635\n",
      "Epoch 30/30\n",
      "35000/35000 [==============================] - 31s 889us/step - loss: 0.0096 - acc: 0.0650 - val_loss: 0.0097 - val_acc: 0.0676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f53fc0e2b00>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_G2=Model(inputs=base_model.input,outputs=preds)\n",
    "\n",
    "compile_model(model_G2)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "print (\"Training date and time : \")\n",
    "print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "model_G2.fit(x_train_global, y_train_global,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test_cat),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When trained with 100 epochs, the accuracy of the G1 was better than the G2, which was really weird..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_G2.save(\"model_G2_35k_sgd.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0728 19:49:50.543153 139699900229376 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0728 19:49:50.596954 139699900229376 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0728 19:49:50.629657 139699900229376 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0728 19:49:50.630287 139699900229376 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0728 19:49:50.630892 139699900229376 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:184: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0728 19:49:55.003440 139699900229376 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0728 19:49:59.583490 139699900229376 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0728 19:49:59.709908 139699900229376 deprecation.py:323] From /home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model_G2 = keras.models.load_model('model_G2_15k.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fix layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_G2.layers[:20]:\n",
    "    layer.trainable=False\n",
    "for layer in model_G2.layers[20:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain with 15K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_model(model_G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "  160/15000 [..............................] - ETA: 16s - loss: 0.0097 - acc: 0.0688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 15s 970us/step - loss: 0.0097 - acc: 0.0618 - val_loss: 0.0096 - val_acc: 0.0638\n",
      "Epoch 2/30\n",
      "15000/15000 [==============================] - 14s 963us/step - loss: 0.0097 - acc: 0.0633 - val_loss: 0.0096 - val_acc: 0.0629\n",
      "Epoch 3/30\n",
      "15000/15000 [==============================] - 14s 959us/step - loss: 0.0096 - acc: 0.0665 - val_loss: 0.0097 - val_acc: 0.0680\n",
      "Epoch 4/30\n",
      "15000/15000 [==============================] - 14s 965us/step - loss: 0.0096 - acc: 0.0667 - val_loss: 0.0097 - val_acc: 0.0638\n",
      "Epoch 5/30\n",
      "15000/15000 [==============================] - 14s 958us/step - loss: 0.0096 - acc: 0.0691 - val_loss: 0.0096 - val_acc: 0.0676\n",
      "Epoch 6/30\n",
      "15000/15000 [==============================] - 14s 959us/step - loss: 0.0096 - acc: 0.0726 - val_loss: 0.0097 - val_acc: 0.0664\n",
      "Epoch 7/30\n",
      "15000/15000 [==============================] - 14s 959us/step - loss: 0.0096 - acc: 0.0752 - val_loss: 0.0097 - val_acc: 0.0681\n",
      "Epoch 8/30\n",
      "15000/15000 [==============================] - 14s 953us/step - loss: 0.0096 - acc: 0.0755 - val_loss: 0.0096 - val_acc: 0.0684\n",
      "Epoch 9/30\n",
      "15000/15000 [==============================] - 14s 963us/step - loss: 0.0095 - acc: 0.0808 - val_loss: 0.0096 - val_acc: 0.0686\n",
      "Epoch 10/30\n",
      "15000/15000 [==============================] - 14s 961us/step - loss: 0.0096 - acc: 0.0767 - val_loss: 0.0096 - val_acc: 0.0725\n",
      "Epoch 11/30\n",
      "15000/15000 [==============================] - 14s 964us/step - loss: 0.0095 - acc: 0.0815 - val_loss: 0.0096 - val_acc: 0.0708\n",
      "Epoch 12/30\n",
      "15000/15000 [==============================] - 14s 961us/step - loss: 0.0095 - acc: 0.0801 - val_loss: 0.0097 - val_acc: 0.0684\n",
      "Epoch 13/30\n",
      "15000/15000 [==============================] - 14s 960us/step - loss: 0.0095 - acc: 0.0834 - val_loss: 0.0097 - val_acc: 0.0706\n",
      "Epoch 14/30\n",
      "15000/15000 [==============================] - 14s 956us/step - loss: 0.0095 - acc: 0.0834 - val_loss: 0.0096 - val_acc: 0.0691\n",
      "Epoch 15/30\n",
      "15000/15000 [==============================] - 14s 959us/step - loss: 0.0095 - acc: 0.0845 - val_loss: 0.0097 - val_acc: 0.0672\n",
      "Epoch 16/30\n",
      "15000/15000 [==============================] - 14s 958us/step - loss: 0.0095 - acc: 0.0865 - val_loss: 0.0097 - val_acc: 0.0698\n",
      "Epoch 17/30\n",
      "15000/15000 [==============================] - 14s 965us/step - loss: 0.0095 - acc: 0.0873 - val_loss: 0.0097 - val_acc: 0.0722\n",
      "Epoch 18/30\n",
      "15000/15000 [==============================] - 14s 958us/step - loss: 0.0095 - acc: 0.0875 - val_loss: 0.0097 - val_acc: 0.0758\n",
      "Epoch 19/30\n",
      "15000/15000 [==============================] - 14s 957us/step - loss: 0.0095 - acc: 0.0907 - val_loss: 0.0096 - val_acc: 0.0722\n",
      "Epoch 20/30\n",
      "15000/15000 [==============================] - 14s 957us/step - loss: 0.0095 - acc: 0.0943 - val_loss: 0.0097 - val_acc: 0.0670\n",
      "Epoch 21/30\n",
      "15000/15000 [==============================] - 14s 965us/step - loss: 0.0094 - acc: 0.0911 - val_loss: 0.0097 - val_acc: 0.0737\n",
      "Epoch 22/30\n",
      "15000/15000 [==============================] - 14s 956us/step - loss: 0.0094 - acc: 0.0919 - val_loss: 0.0097 - val_acc: 0.0686\n",
      "Epoch 23/30\n",
      "15000/15000 [==============================] - 14s 962us/step - loss: 0.0095 - acc: 0.0898 - val_loss: 0.0097 - val_acc: 0.0716\n",
      "Epoch 24/30\n",
      "15000/15000 [==============================] - 14s 957us/step - loss: 0.0094 - acc: 0.0965 - val_loss: 0.0097 - val_acc: 0.0710\n",
      "Epoch 25/30\n",
      "15000/15000 [==============================] - 14s 958us/step - loss: 0.0094 - acc: 0.0996 - val_loss: 0.0097 - val_acc: 0.0753\n",
      "Epoch 26/30\n",
      "15000/15000 [==============================] - 14s 958us/step - loss: 0.0094 - acc: 0.0969 - val_loss: 0.0096 - val_acc: 0.0747\n",
      "Epoch 27/30\n",
      "15000/15000 [==============================] - 14s 965us/step - loss: 0.0094 - acc: 0.0978 - val_loss: 0.0097 - val_acc: 0.0786\n",
      "Epoch 28/30\n",
      "15000/15000 [==============================] - 14s 961us/step - loss: 0.0094 - acc: 0.1015 - val_loss: 0.0096 - val_acc: 0.0702\n",
      "Epoch 29/30\n",
      "15000/15000 [==============================] - 14s 961us/step - loss: 0.0093 - acc: 0.1046 - val_loss: 0.0097 - val_acc: 0.0789\n",
      "Epoch 30/30\n",
      "15000/15000 [==============================] - 14s 962us/step - loss: 0.0093 - acc: 0.1049 - val_loss: 0.0096 - val_acc: 0.0795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f53e094b518>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_G2.fit(x_train_local, y_train_local,\n",
    "              batch_size=batch_size,\n",
    "              epochs=30,\n",
    "              validation_data=(x_test, y_test_cat),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_G2.save(\"model_G2_35k_15k_sgd.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity Test: If layer not fixed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_G2_layer_not_fixed = keras.models.load_model(\"model_G2_epoch_30.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_G2_layer_not_fixed.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_G2_layer_not_fixed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0149b8d6a1a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model_G2_layer_not_fixed.fit(x_train_local, y_train_local,\n\u001b[0m\u001b[1;32m      2\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               shuffle=True)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_G2_layer_not_fixed' is not defined"
     ]
    }
   ],
   "source": [
    "model_G2_layer_not_fixed.fit(x_train_local, y_train_local,\n",
    "              batch_size=batch_size,\n",
    "              epochs=30,\n",
    "              validation_data=(x_test, y_test_cat),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only a small change..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why a sudden decrease in accuaracy when training started?\n",
    "It wasn't fair for G2 to go through 60 epochs total(first training 30 + the second 30)? \n",
    "G1 and G2 have to go through the same number of mini batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mMJDPXn9PWAd"
   },
   "source": [
    "#### Global (3): Train globally on 35K + fix layers + distribute 15K randomly + train & aggregate (Federated Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N4SyCoN-OyPC"
   },
   "outputs": [],
   "source": [
    "# FL Setting\n",
    "num_users=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of split data\n",
    "x_data_split = np.split(x_train_local, num_users)\n",
    "y_data_split = np.split(y_train_local, num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "pretrained_model = keras.models.load_model('model_G2_35k_sgd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate users with models\n",
    "users_models = [keras.models.clone_model(pretrained_model) for i in range(num_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in users_models:\n",
    "    m.set_weights(pretrained_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for m in users_models:\n",
    "    compile_model(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 29s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.009655948668718339, 0.0676]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_models[0].evaluate(x_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting 1th model\n",
      "Train on 7500 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "7500/7500 [==============================] - 41s 5ms/step - loss: 0.0097 - acc: 0.0597 - val_loss: 0.0096 - val_acc: 0.0653\n",
      "Epoch 2/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0097 - acc: 0.0621 - val_loss: 0.0096 - val_acc: 0.0651\n",
      "Epoch 3/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0096 - acc: 0.0668 - val_loss: 0.0096 - val_acc: 0.0676\n",
      "Epoch 4/30\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.0096 - acc: 0.0693 - val_loss: 0.0097 - val_acc: 0.0648\n",
      "Epoch 5/30\n",
      "7500/7500 [==============================] - 14s 2ms/step - loss: 0.0096 - acc: 0.0696 - val_loss: 0.0097 - val_acc: 0.0558\n",
      "Epoch 6/30\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.0096 - acc: 0.0717 - val_loss: 0.0097 - val_acc: 0.0629\n",
      "Epoch 7/30\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.0095 - acc: 0.0737 - val_loss: 0.0097 - val_acc: 0.0622\n",
      "Epoch 8/30\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.0095 - acc: 0.0748 - val_loss: 0.0097 - val_acc: 0.0627\n",
      "Epoch 9/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0095 - acc: 0.0807 - val_loss: 0.0097 - val_acc: 0.0631\n",
      "Epoch 10/30\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.0095 - acc: 0.0813 - val_loss: 0.0097 - val_acc: 0.0616\n",
      "Epoch 11/30\n",
      "7500/7500 [==============================] - 14s 2ms/step - loss: 0.0095 - acc: 0.0819 - val_loss: 0.0097 - val_acc: 0.0644\n",
      "Epoch 12/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0095 - acc: 0.0803 - val_loss: 0.0097 - val_acc: 0.0639\n",
      "Epoch 13/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0095 - acc: 0.0825 - val_loss: 0.0097 - val_acc: 0.0612\n",
      "Epoch 14/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0095 - acc: 0.0836 - val_loss: 0.0097 - val_acc: 0.0637\n",
      "Epoch 15/30\n",
      "7500/7500 [==============================] - 14s 2ms/step - loss: 0.0094 - acc: 0.0873 - val_loss: 0.0097 - val_acc: 0.0647\n",
      "Epoch 16/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0094 - acc: 0.0872 - val_loss: 0.0097 - val_acc: 0.0641\n",
      "Epoch 17/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0094 - acc: 0.0907 - val_loss: 0.0097 - val_acc: 0.0667\n",
      "Epoch 18/30\n",
      "7500/7500 [==============================] - 14s 2ms/step - loss: 0.0094 - acc: 0.0896 - val_loss: 0.0097 - val_acc: 0.0643\n",
      "Epoch 19/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0094 - acc: 0.0909 - val_loss: 0.0097 - val_acc: 0.0635\n",
      "Epoch 20/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0094 - acc: 0.0925 - val_loss: 0.0098 - val_acc: 0.0549\n",
      "Epoch 21/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0094 - acc: 0.0939 - val_loss: 0.0097 - val_acc: 0.0605\n",
      "Epoch 22/30\n",
      "7500/7500 [==============================] - 14s 2ms/step - loss: 0.0094 - acc: 0.0944 - val_loss: 0.0098 - val_acc: 0.0655\n",
      "Epoch 23/30\n",
      "7500/7500 [==============================] - 15s 2ms/step - loss: 0.0094 - acc: 0.0920 - val_loss: 0.0098 - val_acc: 0.0682\n",
      "Epoch 24/30\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.0093 - acc: 0.0964 - val_loss: 0.0097 - val_acc: 0.0636\n",
      "Epoch 25/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0094 - acc: 0.0964 - val_loss: 0.0098 - val_acc: 0.0652\n",
      "Epoch 26/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0094 - acc: 0.0968 - val_loss: 0.0097 - val_acc: 0.0626\n",
      "Epoch 27/30\n",
      "7500/7500 [==============================] - 13s 2ms/step - loss: 0.0094 - acc: 0.1000 - val_loss: 0.0097 - val_acc: 0.0641\n",
      "Epoch 28/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0093 - acc: 0.0965 - val_loss: 0.0098 - val_acc: 0.0612\n",
      "Epoch 29/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0093 - acc: 0.0981 - val_loss: 0.0097 - val_acc: 0.0666\n",
      "Epoch 30/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0093 - acc: 0.1031 - val_loss: 0.0097 - val_acc: 0.0678\n",
      "fitting 2th model\n",
      "Train on 7500 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "7500/7500 [==============================] - 45s 6ms/step - loss: 0.0097 - acc: 0.0601 - val_loss: 0.0097 - val_acc: 0.0639\n",
      "Epoch 2/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0097 - acc: 0.0613 - val_loss: 0.0096 - val_acc: 0.0661\n",
      "Epoch 3/30\n",
      "7500/7500 [==============================] - 14s 2ms/step - loss: 0.0096 - acc: 0.0659 - val_loss: 0.0097 - val_acc: 0.0633\n",
      "Epoch 4/30\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.0096 - acc: 0.0708 - val_loss: 0.0097 - val_acc: 0.0651\n",
      "Epoch 5/30\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.0096 - acc: 0.0717 - val_loss: 0.0097 - val_acc: 0.0614\n",
      "Epoch 6/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0095 - acc: 0.0745 - val_loss: 0.0097 - val_acc: 0.0644\n",
      "Epoch 7/30\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.0095 - acc: 0.0707 - val_loss: 0.0097 - val_acc: 0.0653\n",
      "Epoch 8/30\n",
      "7500/7500 [==============================] - 14s 2ms/step - loss: 0.0095 - acc: 0.0781 - val_loss: 0.0097 - val_acc: 0.0606\n",
      "Epoch 9/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0095 - acc: 0.0787 - val_loss: 0.0097 - val_acc: 0.0619\n",
      "Epoch 10/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0095 - acc: 0.0789 - val_loss: 0.0097 - val_acc: 0.0643\n",
      "Epoch 11/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0095 - acc: 0.0819 - val_loss: 0.0097 - val_acc: 0.0637\n",
      "Epoch 12/30\n",
      "7500/7500 [==============================] - 13s 2ms/step - loss: 0.0095 - acc: 0.0819 - val_loss: 0.0098 - val_acc: 0.0596\n",
      "Epoch 13/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0095 - acc: 0.0831 - val_loss: 0.0097 - val_acc: 0.0578\n",
      "Epoch 14/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0094 - acc: 0.0880 - val_loss: 0.0097 - val_acc: 0.0668\n",
      "Epoch 15/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0094 - acc: 0.0857 - val_loss: 0.0097 - val_acc: 0.0666\n",
      "Epoch 16/30\n",
      "7500/7500 [==============================] - 14s 2ms/step - loss: 0.0094 - acc: 0.0901 - val_loss: 0.0097 - val_acc: 0.0633\n",
      "Epoch 17/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0094 - acc: 0.0829 - val_loss: 0.0098 - val_acc: 0.0656\n",
      "Epoch 18/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0094 - acc: 0.0843 - val_loss: 0.0097 - val_acc: 0.0648\n",
      "Epoch 19/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0094 - acc: 0.0880 - val_loss: 0.0097 - val_acc: 0.0632\n",
      "Epoch 20/30\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.0094 - acc: 0.0924 - val_loss: 0.0097 - val_acc: 0.0648\n",
      "Epoch 21/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0094 - acc: 0.0961 - val_loss: 0.0098 - val_acc: 0.0630\n",
      "Epoch 22/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0094 - acc: 0.0963 - val_loss: 0.0098 - val_acc: 0.0619\n",
      "Epoch 23/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0093 - acc: 0.0964 - val_loss: 0.0098 - val_acc: 0.0605\n",
      "Epoch 24/30\n",
      "7500/7500 [==============================] - 13s 2ms/step - loss: 0.0094 - acc: 0.0975 - val_loss: 0.0097 - val_acc: 0.0625\n",
      "Epoch 25/30\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.0093 - acc: 0.0976 - val_loss: 0.0099 - val_acc: 0.0627\n",
      "Epoch 26/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0094 - acc: 0.0944 - val_loss: 0.0097 - val_acc: 0.0646\n",
      "Epoch 27/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0093 - acc: 0.1025 - val_loss: 0.0097 - val_acc: 0.0621\n",
      "Epoch 28/30\n",
      "7500/7500 [==============================] - 11s 2ms/step - loss: 0.0093 - acc: 0.1017 - val_loss: 0.0097 - val_acc: 0.0619\n",
      "Epoch 29/30\n",
      "7500/7500 [==============================] - 11s 2ms/step - loss: 0.0093 - acc: 0.1036 - val_loss: 0.0097 - val_acc: 0.0640\n",
      "Epoch 30/30\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.0093 - acc: 0.1013 - val_loss: 0.0098 - val_acc: 0.0657\n"
     ]
    }
   ],
   "source": [
    "local_update_history = []\n",
    "for i, m in enumerate(users_models):\n",
    "    print(\"fitting %dth model\" %(i+1))\n",
    "    local_update_history.append(\n",
    "        m.fit(x_data_split[i], y_data_split[i],\n",
    "              batch_size=32,\n",
    "              epochs=30,\n",
    "              validation_data=(x_test, y_test_cat),\n",
    "              shuffle=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [m.get_weights() for m in users_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FederatedAggregation\n",
    "new_weights = list()\n",
    "\n",
    "for weights_list_tuple in zip(*weights):\n",
    "    new_weights.append(\n",
    "        [np.array(weights_).mean(axis=0)\\\n",
    "            for weights_ in zip(*weights_list_tuple)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_model = keras.models.clone_model(pretrained_model)\n",
    "aggr_model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partial aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 24s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00967746299803257, 0.0609]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compile_model(aggr_model)\n",
    "aggr_model.evaluate(x_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_model.save(\"model_G3_users_2(1).h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_local_test = keras.models.load_model(\"model_G3_users_2(1).h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 26s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00967746299803257, 0.0609]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compile_model(model_local_test)\n",
    "model_local_test.evaluate(x_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mMJDPXn9PWAd"
   },
   "source": [
    "#### Global (4): Train globally on 35K + fix layers + distribute 15K NON-randomly + train & aggregate (Federated Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N4SyCoN-OyPC"
   },
   "outputs": [],
   "source": [
    "# FL Setting\n",
    "num_users=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Users get datasets corresponding to (num_class/num_users) classes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_local[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 100)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_local.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_split = [np.empty([0,32,32,3]) for _ in range(num_users)]\n",
    "y_data_split = [np.empty([0,100]) for _ in range(num_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 complete\n",
      "1000 complete\n",
      "2000 complete\n",
      "3000 complete\n",
      "4000 complete\n",
      "5000 complete\n",
      "6000 complete\n",
      "7000 complete\n",
      "8000 complete\n",
      "9000 complete\n",
      "10000 complete\n",
      "11000 complete\n",
      "12000 complete\n",
      "13000 complete\n",
      "14000 complete\n"
     ]
    }
   ],
   "source": [
    "for i in range(y_train_local.shape[0]):\n",
    "    if (i%1000 == 0):\n",
    "        print(\"%d complete\" %i)\n",
    "    user_num = (int) (y_train_local_notcat[i][0] / (100 / num_users))\n",
    "    x_data_split[user_num] = \\\n",
    "        np.concatenate((x_data_split[user_num], np.expand_dims(x_train_local[i], axis=0)), axis=0)\n",
    "    y_data_split[user_num] = \\\n",
    "        np.concatenate((y_data_split[user_num], np.expand_dims(y_train_local[i], axis=0)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "pretrained_model = keras.models.load_model('model_G2_35k_sgd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate users with models\n",
    "users_models = [keras.models.clone_model(pretrained_model) for i in range(num_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in users_models:\n",
    "    m.set_weights(pretrained_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for m in users_models:\n",
    "    compile_model(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 20s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.009655948668718339, 0.0676]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_models[0].evaluate(x_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training date and time : \n",
      "2019-08-02 17:49:49\n",
      "model #1\n",
      "augmenting dataset\n",
      "Train on 4527 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "4527/4527 [==============================] - 25s 6ms/step - loss: 0.0096 - acc: 0.0769 - val_loss: 0.0097 - val_acc: 0.0580\n",
      "Epoch 2/30\n",
      "4527/4527 [==============================] - 7s 2ms/step - loss: 0.0095 - acc: 0.0987 - val_loss: 0.0097 - val_acc: 0.0556\n",
      "Epoch 3/30\n",
      "4527/4527 [==============================] - 7s 2ms/step - loss: 0.0094 - acc: 0.1124 - val_loss: 0.0097 - val_acc: 0.0559\n",
      "Epoch 4/30\n",
      "4527/4527 [==============================] - 7s 2ms/step - loss: 0.0094 - acc: 0.1257 - val_loss: 0.0097 - val_acc: 0.0557\n",
      "Epoch 5/30\n",
      "4527/4527 [==============================] - 10s 2ms/step - loss: 0.0093 - acc: 0.1387 - val_loss: 0.0097 - val_acc: 0.0561\n",
      "Epoch 6/30\n",
      "4527/4527 [==============================] - 10s 2ms/step - loss: 0.0093 - acc: 0.1498 - val_loss: 0.0098 - val_acc: 0.0561\n",
      "Epoch 7/30\n",
      "4527/4527 [==============================] - 9s 2ms/step - loss: 0.0092 - acc: 0.1482 - val_loss: 0.0098 - val_acc: 0.0546\n",
      "Epoch 8/30\n",
      "4527/4527 [==============================] - 8s 2ms/step - loss: 0.0092 - acc: 0.1504 - val_loss: 0.0098 - val_acc: 0.0525\n",
      "Epoch 9/30\n",
      "4527/4527 [==============================] - 7s 2ms/step - loss: 0.0092 - acc: 0.1533 - val_loss: 0.0098 - val_acc: 0.0484\n",
      "Epoch 10/30\n",
      "4527/4527 [==============================] - 7s 2ms/step - loss: 0.0091 - acc: 0.1588 - val_loss: 0.0098 - val_acc: 0.0510\n",
      "Epoch 11/30\n",
      "4527/4527 [==============================] - 7s 2ms/step - loss: 0.0091 - acc: 0.1615 - val_loss: 0.0098 - val_acc: 0.0505\n",
      "Epoch 12/30\n",
      "4527/4527 [==============================] - 7s 2ms/step - loss: 0.0090 - acc: 0.1652 - val_loss: 0.0098 - val_acc: 0.0570\n",
      "Epoch 13/30\n",
      "4527/4527 [==============================] - 7s 2ms/step - loss: 0.0090 - acc: 0.1683 - val_loss: 0.0098 - val_acc: 0.0524\n",
      "Epoch 14/30\n",
      "4527/4527 [==============================] - 7s 2ms/step - loss: 0.0090 - acc: 0.1769 - val_loss: 0.0098 - val_acc: 0.0500\n",
      "Epoch 15/30\n",
      "4527/4527 [==============================] - 9s 2ms/step - loss: 0.0090 - acc: 0.1776 - val_loss: 0.0100 - val_acc: 0.0504\n",
      "Epoch 16/30\n",
      "4527/4527 [==============================] - 10s 2ms/step - loss: 0.0089 - acc: 0.1833 - val_loss: 0.0099 - val_acc: 0.0533\n",
      "Epoch 17/30\n",
      "4527/4527 [==============================] - 9s 2ms/step - loss: 0.0089 - acc: 0.1836 - val_loss: 0.0100 - val_acc: 0.0576\n",
      "Epoch 18/30\n",
      "4527/4527 [==============================] - 7s 2ms/step - loss: 0.0089 - acc: 0.1909 - val_loss: 0.0100 - val_acc: 0.0536\n",
      "Epoch 19/30\n",
      "4527/4527 [==============================] - 9s 2ms/step - loss: 0.0089 - acc: 0.1898 - val_loss: 0.0099 - val_acc: 0.0499\n",
      "Epoch 20/30\n",
      "4527/4527 [==============================] - 10s 2ms/step - loss: 0.0088 - acc: 0.1944 - val_loss: 0.0100 - val_acc: 0.0498\n",
      "Epoch 21/30\n",
      "4527/4527 [==============================] - 9s 2ms/step - loss: 0.0088 - acc: 0.2039 - val_loss: 0.0099 - val_acc: 0.0529\n",
      "Epoch 22/30\n",
      "4527/4527 [==============================] - 7s 2ms/step - loss: 0.0088 - acc: 0.1992 - val_loss: 0.0100 - val_acc: 0.0469\n",
      "Epoch 23/30\n",
      "4527/4527 [==============================] - 8s 2ms/step - loss: 0.0087 - acc: 0.2043 - val_loss: 0.0100 - val_acc: 0.0571\n",
      "Epoch 24/30\n",
      "4527/4527 [==============================] - 9s 2ms/step - loss: 0.0087 - acc: 0.2125 - val_loss: 0.0100 - val_acc: 0.0588\n",
      "Epoch 25/30\n",
      "4527/4527 [==============================] - 10s 2ms/step - loss: 0.0086 - acc: 0.2238 - val_loss: 0.0101 - val_acc: 0.0544\n",
      "Epoch 26/30\n",
      "4527/4527 [==============================] - 8s 2ms/step - loss: 0.0087 - acc: 0.2189 - val_loss: 0.0101 - val_acc: 0.0525\n",
      "Epoch 27/30\n",
      "4527/4527 [==============================] - 7s 2ms/step - loss: 0.0086 - acc: 0.2282 - val_loss: 0.0101 - val_acc: 0.0577\n",
      "Epoch 28/30\n",
      "4527/4527 [==============================] - 7s 2ms/step - loss: 0.0086 - acc: 0.2300 - val_loss: 0.0102 - val_acc: 0.0530\n",
      "Epoch 29/30\n",
      "4527/4527 [==============================] - 7s 2ms/step - loss: 0.0085 - acc: 0.2381 - val_loss: 0.0100 - val_acc: 0.0542\n",
      "Epoch 30/30\n",
      "4527/4527 [==============================] - 7s 2ms/step - loss: 0.0085 - acc: 0.2328 - val_loss: 0.0101 - val_acc: 0.0506\n",
      "model #2\n",
      "augmenting dataset\n",
      "Train on 1505 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "1505/1505 [==============================] - 27s 18ms/step - loss: 0.0099 - acc: 0.0405 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 2/30\n",
      "1505/1505 [==============================] - 6s 4ms/step - loss: 0.0097 - acc: 0.1043 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 3/30\n",
      "1505/1505 [==============================] - 5s 3ms/step - loss: 0.0095 - acc: 0.1522 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 4/30\n",
      "1505/1505 [==============================] - 5s 3ms/step - loss: 0.0094 - acc: 0.1993 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 5/30\n",
      "1505/1505 [==============================] - 5s 3ms/step - loss: 0.0093 - acc: 0.2000 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 6/30\n",
      "1505/1505 [==============================] - 5s 3ms/step - loss: 0.0091 - acc: 0.2219 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 7/30\n",
      "1505/1505 [==============================] - 5s 3ms/step - loss: 0.0090 - acc: 0.2266 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 8/30\n",
      "1505/1505 [==============================] - 5s 3ms/step - loss: 0.0088 - acc: 0.2379 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 9/30\n",
      "1505/1505 [==============================] - 5s 3ms/step - loss: 0.0086 - acc: 0.2385 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 10/30\n",
      "1505/1505 [==============================] - 5s 3ms/step - loss: 0.0084 - acc: 0.2691 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 11/30\n",
      "1505/1505 [==============================] - 5s 3ms/step - loss: 0.0083 - acc: 0.2698 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 12/30\n",
      "1505/1505 [==============================] - 5s 3ms/step - loss: 0.0082 - acc: 0.2837 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 13/30\n",
      "1505/1505 [==============================] - 5s 3ms/step - loss: 0.0080 - acc: 0.2917 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 14/30\n",
      "1505/1505 [==============================] - 6s 4ms/step - loss: 0.0078 - acc: 0.3143 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 15/30\n",
      "1505/1505 [==============================] - 6s 4ms/step - loss: 0.0077 - acc: 0.3455 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 16/30\n",
      "1505/1505 [==============================] - 7s 5ms/step - loss: 0.0077 - acc: 0.3355 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 17/30\n",
      "1505/1505 [==============================] - 5s 4ms/step - loss: 0.0075 - acc: 0.3741 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 18/30\n",
      "1505/1505 [==============================] - 5s 3ms/step - loss: 0.0074 - acc: 0.3794 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 19/30\n",
      "1505/1505 [==============================] - 5s 3ms/step - loss: 0.0075 - acc: 0.3674 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 20/30\n",
      "1505/1505 [==============================] - 5s 3ms/step - loss: 0.0073 - acc: 0.3973 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 21/30\n",
      "1505/1505 [==============================] - 5s 3ms/step - loss: 0.0071 - acc: 0.4166 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 22/30\n",
      "1505/1505 [==============================] - 5s 3ms/step - loss: 0.0071 - acc: 0.4073 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 23/30\n",
      "1505/1505 [==============================] - 5s 3ms/step - loss: 0.0068 - acc: 0.4611 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 24/30\n",
      "1505/1505 [==============================] - 5s 3ms/step - loss: 0.0068 - acc: 0.4425 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 25/30\n",
      "1505/1505 [==============================] - 5s 3ms/step - loss: 0.0069 - acc: 0.4286 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 26/30\n",
      "1505/1505 [==============================] - 5s 3ms/step - loss: 0.0065 - acc: 0.4970 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 27/30\n",
      "1505/1505 [==============================] - 5s 3ms/step - loss: 0.0065 - acc: 0.4777 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 28/30\n",
      "1505/1505 [==============================] - 5s 3ms/step - loss: 0.0064 - acc: 0.5043 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 29/30\n",
      "1505/1505 [==============================] - 5s 3ms/step - loss: 0.0063 - acc: 0.4990 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "Epoch 30/30\n",
      "1505/1505 [==============================] - 5s 3ms/step - loss: 0.0062 - acc: 0.5216 - val_loss: 0.0099 - val_acc: 0.0100\n",
      "model #3\n",
      "augmenting dataset\n",
      "Train on 1553 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "1553/1553 [==============================] - 27s 17ms/step - loss: 0.0095 - acc: 0.0992 - val_loss: 0.0097 - val_acc: 0.0564\n",
      "Epoch 2/30\n",
      "1553/1553 [==============================] - 5s 3ms/step - loss: 0.0092 - acc: 0.1487 - val_loss: 0.0097 - val_acc: 0.0590\n",
      "Epoch 3/30\n",
      "1553/1553 [==============================] - 6s 4ms/step - loss: 0.0091 - acc: 0.1854 - val_loss: 0.0097 - val_acc: 0.0539\n",
      "Epoch 4/30\n",
      "1553/1553 [==============================] - 6s 4ms/step - loss: 0.0089 - acc: 0.2267 - val_loss: 0.0098 - val_acc: 0.0463\n",
      "Epoch 5/30\n",
      "1553/1553 [==============================] - 6s 4ms/step - loss: 0.0088 - acc: 0.2466 - val_loss: 0.0099 - val_acc: 0.0330\n",
      "Epoch 6/30\n",
      "1553/1553 [==============================] - 6s 4ms/step - loss: 0.0086 - acc: 0.2659 - val_loss: 0.0100 - val_acc: 0.0271\n",
      "Epoch 7/30\n",
      "1553/1553 [==============================] - 5s 3ms/step - loss: 0.0084 - acc: 0.2704 - val_loss: 0.0103 - val_acc: 0.0218\n",
      "Epoch 8/30\n",
      "1553/1553 [==============================] - 5s 3ms/step - loss: 0.0082 - acc: 0.2988 - val_loss: 0.0104 - val_acc: 0.0241\n",
      "Epoch 9/30\n",
      "1553/1553 [==============================] - 5s 3ms/step - loss: 0.0081 - acc: 0.3033 - val_loss: 0.0106 - val_acc: 0.0271\n",
      "Epoch 10/30\n",
      "1553/1553 [==============================] - 5s 3ms/step - loss: 0.0079 - acc: 0.3052 - val_loss: 0.0107 - val_acc: 0.0239\n",
      "Epoch 11/30\n",
      "1553/1553 [==============================] - 5s 3ms/step - loss: 0.0078 - acc: 0.3175 - val_loss: 0.0107 - val_acc: 0.0288\n",
      "Epoch 12/30\n",
      "1553/1553 [==============================] - 5s 3ms/step - loss: 0.0077 - acc: 0.3477 - val_loss: 0.0111 - val_acc: 0.0225\n",
      "Epoch 13/30\n",
      "1553/1553 [==============================] - 5s 3ms/step - loss: 0.0074 - acc: 0.3677 - val_loss: 0.0114 - val_acc: 0.0249\n",
      "Epoch 14/30\n",
      "1553/1553 [==============================] - 7s 4ms/step - loss: 0.0072 - acc: 0.4018 - val_loss: 0.0115 - val_acc: 0.0267\n",
      "Epoch 15/30\n",
      "1553/1553 [==============================] - 6s 4ms/step - loss: 0.0071 - acc: 0.4082 - val_loss: 0.0114 - val_acc: 0.0255\n",
      "Epoch 16/30\n",
      "1553/1553 [==============================] - 7s 4ms/step - loss: 0.0069 - acc: 0.4288 - val_loss: 0.0115 - val_acc: 0.0327\n",
      "Epoch 17/30\n",
      "1553/1553 [==============================] - 5s 3ms/step - loss: 0.0068 - acc: 0.4404 - val_loss: 0.0130 - val_acc: 0.0216\n",
      "Epoch 18/30\n",
      "1553/1553 [==============================] - 5s 3ms/step - loss: 0.0071 - acc: 0.3863 - val_loss: 0.0140 - val_acc: 0.0158\n",
      "Epoch 19/30\n",
      "1553/1553 [==============================] - 5s 3ms/step - loss: 0.0070 - acc: 0.4179 - val_loss: 0.0119 - val_acc: 0.0286\n",
      "Epoch 20/30\n",
      "1553/1553 [==============================] - 5s 3ms/step - loss: 0.0069 - acc: 0.4443 - val_loss: 0.0121 - val_acc: 0.0327\n",
      "Epoch 21/30\n",
      "1553/1553 [==============================] - 6s 4ms/step - loss: 0.0068 - acc: 0.4404 - val_loss: 0.0117 - val_acc: 0.0297\n",
      "Epoch 22/30\n",
      "1553/1553 [==============================] - 6s 4ms/step - loss: 0.0067 - acc: 0.4552 - val_loss: 0.0120 - val_acc: 0.0304\n",
      "Epoch 23/30\n",
      "1553/1553 [==============================] - 7s 4ms/step - loss: 0.0066 - acc: 0.4598 - val_loss: 0.0119 - val_acc: 0.0327\n",
      "Epoch 24/30\n",
      "1553/1553 [==============================] - 6s 4ms/step - loss: 0.0065 - acc: 0.4868 - val_loss: 0.0119 - val_acc: 0.0350\n",
      "Epoch 25/30\n",
      "1553/1553 [==============================] - 5s 3ms/step - loss: 0.0061 - acc: 0.5158 - val_loss: 0.0120 - val_acc: 0.0348\n",
      "Epoch 26/30\n",
      "1553/1553 [==============================] - 5s 3ms/step - loss: 0.0061 - acc: 0.5306 - val_loss: 0.0121 - val_acc: 0.0387\n",
      "Epoch 27/30\n",
      "1553/1553 [==============================] - 5s 3ms/step - loss: 0.0060 - acc: 0.5293 - val_loss: 0.0121 - val_acc: 0.0383\n",
      "Epoch 28/30\n",
      "1553/1553 [==============================] - 5s 3ms/step - loss: 0.0060 - acc: 0.5145 - val_loss: 0.0122 - val_acc: 0.0395\n",
      "Epoch 29/30\n",
      "1553/1553 [==============================] - 5s 3ms/step - loss: 0.0060 - acc: 0.5299 - val_loss: 0.0123 - val_acc: 0.0359\n",
      "Epoch 30/30\n",
      "1553/1553 [==============================] - 5s 3ms/step - loss: 0.0059 - acc: 0.5460 - val_loss: 0.0124 - val_acc: 0.0354\n",
      "model #4\n",
      "augmenting dataset\n",
      "Train on 1454 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "1454/1454 [==============================] - 26s 18ms/step - loss: 0.0100 - acc: 0.0392 - val_loss: 0.0097 - val_acc: 0.0640\n",
      "Epoch 2/30\n",
      "1454/1454 [==============================] - 7s 5ms/step - loss: 0.0098 - acc: 0.0928 - val_loss: 0.0097 - val_acc: 0.0564\n",
      "Epoch 3/30\n",
      "1454/1454 [==============================] - 5s 4ms/step - loss: 0.0097 - acc: 0.1424 - val_loss: 0.0099 - val_acc: 0.0361\n",
      "Epoch 4/30\n",
      "1454/1454 [==============================] - 5s 4ms/step - loss: 0.0095 - acc: 0.1671 - val_loss: 0.0102 - val_acc: 0.0225\n",
      "Epoch 5/30\n",
      "1454/1454 [==============================] - 7s 4ms/step - loss: 0.0093 - acc: 0.1905 - val_loss: 0.0105 - val_acc: 0.0219\n",
      "Epoch 6/30\n",
      "1454/1454 [==============================] - 5s 4ms/step - loss: 0.0091 - acc: 0.2263 - val_loss: 0.0107 - val_acc: 0.0206\n",
      "Epoch 7/30\n",
      "1454/1454 [==============================] - 7s 5ms/step - loss: 0.0089 - acc: 0.2228 - val_loss: 0.0107 - val_acc: 0.0204\n",
      "Epoch 8/30\n",
      "1454/1454 [==============================] - 6s 4ms/step - loss: 0.0086 - acc: 0.2469 - val_loss: 0.0109 - val_acc: 0.0210\n",
      "Epoch 9/30\n",
      "1454/1454 [==============================] - 5s 3ms/step - loss: 0.0084 - acc: 0.2600 - val_loss: 0.0112 - val_acc: 0.0202\n",
      "Epoch 10/30\n",
      "1454/1454 [==============================] - 6s 4ms/step - loss: 0.0082 - acc: 0.2730 - val_loss: 0.0111 - val_acc: 0.0210\n",
      "Epoch 11/30\n",
      "1454/1454 [==============================] - 5s 4ms/step - loss: 0.0081 - acc: 0.2847 - val_loss: 0.0115 - val_acc: 0.0235\n",
      "Epoch 12/30\n",
      "1454/1454 [==============================] - 7s 5ms/step - loss: 0.0080 - acc: 0.3116 - val_loss: 0.0114 - val_acc: 0.0259\n",
      "Epoch 13/30\n",
      "1454/1454 [==============================] - 5s 4ms/step - loss: 0.0077 - acc: 0.3336 - val_loss: 0.0114 - val_acc: 0.0266\n",
      "Epoch 14/30\n",
      "1454/1454 [==============================] - 5s 3ms/step - loss: 0.0076 - acc: 0.3459 - val_loss: 0.0111 - val_acc: 0.0266\n",
      "Epoch 15/30\n",
      "1454/1454 [==============================] - 6s 4ms/step - loss: 0.0075 - acc: 0.3680 - val_loss: 0.0116 - val_acc: 0.0301\n",
      "Epoch 16/30\n",
      "1454/1454 [==============================] - 6s 4ms/step - loss: 0.0074 - acc: 0.3769 - val_loss: 0.0116 - val_acc: 0.0279\n",
      "Epoch 17/30\n",
      "1454/1454 [==============================] - 6s 4ms/step - loss: 0.0072 - acc: 0.4044 - val_loss: 0.0125 - val_acc: 0.0284\n",
      "Epoch 18/30\n",
      "1454/1454 [==============================] - 5s 3ms/step - loss: 0.0071 - acc: 0.4092 - val_loss: 0.0124 - val_acc: 0.0269\n",
      "Epoch 19/30\n",
      "1454/1454 [==============================] - 6s 4ms/step - loss: 0.0071 - acc: 0.3975 - val_loss: 0.0126 - val_acc: 0.0298\n",
      "Epoch 20/30\n",
      "1454/1454 [==============================] - 5s 4ms/step - loss: 0.0071 - acc: 0.4085 - val_loss: 0.0119 - val_acc: 0.0310\n",
      "Epoch 21/30\n",
      "1454/1454 [==============================] - 7s 5ms/step - loss: 0.0072 - acc: 0.3975 - val_loss: 0.0119 - val_acc: 0.0261\n",
      "Epoch 22/30\n",
      "1454/1454 [==============================] - 6s 4ms/step - loss: 0.0071 - acc: 0.4230 - val_loss: 0.0120 - val_acc: 0.0278\n",
      "Epoch 23/30\n",
      "1454/1454 [==============================] - 5s 3ms/step - loss: 0.0069 - acc: 0.4168 - val_loss: 0.0121 - val_acc: 0.0301\n",
      "Epoch 24/30\n",
      "1454/1454 [==============================] - 6s 4ms/step - loss: 0.0067 - acc: 0.4608 - val_loss: 0.0125 - val_acc: 0.0242\n",
      "Epoch 25/30\n",
      "1454/1454 [==============================] - 5s 4ms/step - loss: 0.0066 - acc: 0.4622 - val_loss: 0.0124 - val_acc: 0.0315\n",
      "Epoch 26/30\n",
      "1454/1454 [==============================] - 6s 4ms/step - loss: 0.0065 - acc: 0.4821 - val_loss: 0.0124 - val_acc: 0.0315\n",
      "Epoch 27/30\n",
      "1454/1454 [==============================] - 5s 3ms/step - loss: 0.0064 - acc: 0.4904 - val_loss: 0.0122 - val_acc: 0.0348\n",
      "Epoch 28/30\n",
      "1454/1454 [==============================] - 6s 4ms/step - loss: 0.0062 - acc: 0.5275 - val_loss: 0.0127 - val_acc: 0.0335\n",
      "Epoch 29/30\n",
      "1454/1454 [==============================] - 5s 4ms/step - loss: 0.0063 - acc: 0.5069 - val_loss: 0.0123 - val_acc: 0.0350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "1454/1454 [==============================] - 7s 5ms/step - loss: 0.0059 - acc: 0.5420 - val_loss: 0.0127 - val_acc: 0.0344\n",
      "model #5\n",
      "augmenting dataset\n",
      "Train on 1503 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "1503/1503 [==============================] - 27s 18ms/step - loss: 0.0096 - acc: 0.0705 - val_loss: 0.0097 - val_acc: 0.0609\n",
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0094 - acc: 0.1457 - val_loss: 0.0098 - val_acc: 0.0365\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 0.0093 - acc: 0.1956 - val_loss: 0.0101 - val_acc: 0.0261\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 0.0092 - acc: 0.2122 - val_loss: 0.0101 - val_acc: 0.0216\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 7s 4ms/step - loss: 0.0091 - acc: 0.2236 - val_loss: 0.0101 - val_acc: 0.0193\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 0.0090 - acc: 0.2249 - val_loss: 0.0100 - val_acc: 0.0212\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0088 - acc: 0.2369 - val_loss: 0.0101 - val_acc: 0.0198\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 0.0086 - acc: 0.2488 - val_loss: 0.0103 - val_acc: 0.0189\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 7s 4ms/step - loss: 0.0084 - acc: 0.2635 - val_loss: 0.0103 - val_acc: 0.0200\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0082 - acc: 0.2908 - val_loss: 0.0105 - val_acc: 0.0207\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 0.0081 - acc: 0.2934 - val_loss: 0.0106 - val_acc: 0.0233\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 0.0078 - acc: 0.3194 - val_loss: 0.0111 - val_acc: 0.0268\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 5s 4ms/step - loss: 0.0076 - acc: 0.3573 - val_loss: 0.0114 - val_acc: 0.0276\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0073 - acc: 0.4059 - val_loss: 0.0118 - val_acc: 0.0284\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 0.0071 - acc: 0.3912 - val_loss: 0.0115 - val_acc: 0.0320\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 0.0072 - acc: 0.3985 - val_loss: 0.0116 - val_acc: 0.0312\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0069 - acc: 0.4318 - val_loss: 0.0117 - val_acc: 0.0314\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 0.0067 - acc: 0.4511 - val_loss: 0.0117 - val_acc: 0.0311\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 0.0067 - acc: 0.4464 - val_loss: 0.0121 - val_acc: 0.0320\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 0.0064 - acc: 0.4717 - val_loss: 0.0121 - val_acc: 0.0291\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 0.0065 - acc: 0.4717 - val_loss: 0.0124 - val_acc: 0.0311\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 5s 4ms/step - loss: 0.0066 - acc: 0.4657 - val_loss: 0.0126 - val_acc: 0.0272\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0065 - acc: 0.4731 - val_loss: 0.0126 - val_acc: 0.0342\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 0.0064 - acc: 0.4777 - val_loss: 0.0127 - val_acc: 0.0327\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 7s 4ms/step - loss: 0.0062 - acc: 0.5037 - val_loss: 0.0120 - val_acc: 0.0344\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 5s 3ms/step - loss: 0.0062 - acc: 0.5116 - val_loss: 0.0124 - val_acc: 0.0388\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 0.0060 - acc: 0.5323 - val_loss: 0.0124 - val_acc: 0.0343\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 0.0062 - acc: 0.5163 - val_loss: 0.0128 - val_acc: 0.0313\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 0.0059 - acc: 0.5556 - val_loss: 0.0133 - val_acc: 0.0328\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 0.0061 - acc: 0.5183 - val_loss: 0.0138 - val_acc: 0.0191\n",
      "model #6\n",
      "augmenting dataset\n",
      "Train on 1523 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "1523/1523 [==============================] - 27s 18ms/step - loss: 0.0095 - acc: 0.0880 - val_loss: 0.0099 - val_acc: 0.0400\n",
      "Epoch 2/30\n",
      "1523/1523 [==============================] - 5s 3ms/step - loss: 0.0091 - acc: 0.1766 - val_loss: 0.0100 - val_acc: 0.0298\n",
      "Epoch 3/30\n",
      "1523/1523 [==============================] - 5s 3ms/step - loss: 0.0088 - acc: 0.2397 - val_loss: 0.0102 - val_acc: 0.0294\n",
      "Epoch 4/30\n",
      "1523/1523 [==============================] - 5s 3ms/step - loss: 0.0086 - acc: 0.2580 - val_loss: 0.0104 - val_acc: 0.0270\n",
      "Epoch 5/30\n",
      "1523/1523 [==============================] - 5s 3ms/step - loss: 0.0084 - acc: 0.2830 - val_loss: 0.0103 - val_acc: 0.0271\n",
      "Epoch 6/30\n",
      "1523/1523 [==============================] - 5s 4ms/step - loss: 0.0083 - acc: 0.2902 - val_loss: 0.0101 - val_acc: 0.0263\n",
      "Epoch 7/30\n",
      "1523/1523 [==============================] - 6s 4ms/step - loss: 0.0082 - acc: 0.3106 - val_loss: 0.0102 - val_acc: 0.0277\n",
      "Epoch 8/30\n",
      "1523/1523 [==============================] - 6s 4ms/step - loss: 0.0081 - acc: 0.3093 - val_loss: 0.0102 - val_acc: 0.0276\n",
      "Epoch 9/30\n",
      "1523/1523 [==============================] - 7s 4ms/step - loss: 0.0079 - acc: 0.3316 - val_loss: 0.0103 - val_acc: 0.0277\n",
      "Epoch 10/30\n",
      "1523/1523 [==============================] - 6s 4ms/step - loss: 0.0078 - acc: 0.3336 - val_loss: 0.0106 - val_acc: 0.0280\n",
      "Epoch 11/30\n",
      "1523/1523 [==============================] - 5s 3ms/step - loss: 0.0076 - acc: 0.3290 - val_loss: 0.0106 - val_acc: 0.0274\n",
      "Epoch 12/30\n",
      "1523/1523 [==============================] - 5s 4ms/step - loss: 0.0075 - acc: 0.3401 - val_loss: 0.0110 - val_acc: 0.0287\n",
      "Epoch 13/30\n",
      "1523/1523 [==============================] - 6s 4ms/step - loss: 0.0073 - acc: 0.3618 - val_loss: 0.0108 - val_acc: 0.0295\n",
      "Epoch 14/30\n",
      "1523/1523 [==============================] - 7s 4ms/step - loss: 0.0072 - acc: 0.3848 - val_loss: 0.0107 - val_acc: 0.0295\n",
      "Epoch 15/30\n",
      "1523/1523 [==============================] - 5s 3ms/step - loss: 0.0070 - acc: 0.4058 - val_loss: 0.0110 - val_acc: 0.0319\n",
      "Epoch 16/30\n",
      "1523/1523 [==============================] - 6s 4ms/step - loss: 0.0070 - acc: 0.4110 - val_loss: 0.0109 - val_acc: 0.0329\n",
      "Epoch 17/30\n",
      "1523/1523 [==============================] - 6s 4ms/step - loss: 0.0068 - acc: 0.4235 - val_loss: 0.0112 - val_acc: 0.0363\n",
      "Epoch 18/30\n",
      "1523/1523 [==============================] - 6s 4ms/step - loss: 0.0067 - acc: 0.4353 - val_loss: 0.0117 - val_acc: 0.0343\n",
      "Epoch 19/30\n",
      "1523/1523 [==============================] - 5s 3ms/step - loss: 0.0067 - acc: 0.4550 - val_loss: 0.0116 - val_acc: 0.0347\n",
      "Epoch 20/30\n",
      "1523/1523 [==============================] - 6s 4ms/step - loss: 0.0066 - acc: 0.4425 - val_loss: 0.0124 - val_acc: 0.0322\n",
      "Epoch 21/30\n",
      "1523/1523 [==============================] - 5s 3ms/step - loss: 0.0065 - acc: 0.4485 - val_loss: 0.0117 - val_acc: 0.0376\n",
      "Epoch 22/30\n",
      "1523/1523 [==============================] - 7s 5ms/step - loss: 0.0062 - acc: 0.4938 - val_loss: 0.0125 - val_acc: 0.0323\n",
      "Epoch 23/30\n",
      "1523/1523 [==============================] - 6s 4ms/step - loss: 0.0065 - acc: 0.4675 - val_loss: 0.0124 - val_acc: 0.0362\n",
      "Epoch 24/30\n",
      "1523/1523 [==============================] - 5s 3ms/step - loss: 0.0064 - acc: 0.4931 - val_loss: 0.0116 - val_acc: 0.0359\n",
      "Epoch 25/30\n",
      "1523/1523 [==============================] - 6s 4ms/step - loss: 0.0063 - acc: 0.4970 - val_loss: 0.0122 - val_acc: 0.0324\n",
      "Epoch 26/30\n",
      "1523/1523 [==============================] - 7s 4ms/step - loss: 0.0061 - acc: 0.5128 - val_loss: 0.0118 - val_acc: 0.0353\n",
      "Epoch 27/30\n",
      "1523/1523 [==============================] - 5s 3ms/step - loss: 0.0063 - acc: 0.4957 - val_loss: 0.0123 - val_acc: 0.0422\n",
      "Epoch 28/30\n",
      "1523/1523 [==============================] - 5s 3ms/step - loss: 0.0060 - acc: 0.5299 - val_loss: 0.0120 - val_acc: 0.0429\n",
      "Epoch 29/30\n",
      "1523/1523 [==============================] - 5s 3ms/step - loss: 0.0056 - acc: 0.5620 - val_loss: 0.0123 - val_acc: 0.0395\n",
      "Epoch 30/30\n",
      "1523/1523 [==============================] - 5s 3ms/step - loss: 0.0057 - acc: 0.5555 - val_loss: 0.0122 - val_acc: 0.0393\n",
      "model #7\n",
      "augmenting dataset\n",
      "Train on 1416 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "1416/1416 [==============================] - 28s 20ms/step - loss: 0.0096 - acc: 0.0607 - val_loss: 0.0098 - val_acc: 0.0570\n",
      "Epoch 2/30\n",
      "1416/1416 [==============================] - 5s 3ms/step - loss: 0.0094 - acc: 0.1215 - val_loss: 0.0100 - val_acc: 0.0417\n",
      "Epoch 3/30\n",
      "1416/1416 [==============================] - 5s 3ms/step - loss: 0.0092 - acc: 0.1688 - val_loss: 0.0101 - val_acc: 0.0424\n",
      "Epoch 4/30\n",
      "1416/1416 [==============================] - 5s 3ms/step - loss: 0.0091 - acc: 0.2013 - val_loss: 0.0100 - val_acc: 0.0393\n",
      "Epoch 5/30\n",
      "1416/1416 [==============================] - 5s 3ms/step - loss: 0.0091 - acc: 0.2380 - val_loss: 0.0103 - val_acc: 0.0278\n",
      "Epoch 6/30\n",
      "1416/1416 [==============================] - 5s 3ms/step - loss: 0.0089 - acc: 0.2429 - val_loss: 0.0105 - val_acc: 0.0263\n",
      "Epoch 7/30\n",
      "1416/1416 [==============================] - 5s 3ms/step - loss: 0.0087 - acc: 0.2429 - val_loss: 0.0103 - val_acc: 0.0266\n",
      "Epoch 8/30\n",
      "1416/1416 [==============================] - 5s 3ms/step - loss: 0.0086 - acc: 0.2542 - val_loss: 0.0104 - val_acc: 0.0254\n",
      "Epoch 9/30\n",
      "1416/1416 [==============================] - 5s 3ms/step - loss: 0.0085 - acc: 0.2542 - val_loss: 0.0105 - val_acc: 0.0247\n",
      "Epoch 10/30\n",
      "1416/1416 [==============================] - 5s 3ms/step - loss: 0.0083 - acc: 0.2549 - val_loss: 0.0103 - val_acc: 0.0238\n",
      "Epoch 11/30\n",
      "1416/1416 [==============================] - 5s 3ms/step - loss: 0.0082 - acc: 0.2747 - val_loss: 0.0104 - val_acc: 0.0228\n",
      "Epoch 12/30\n",
      "1416/1416 [==============================] - 7s 5ms/step - loss: 0.0079 - acc: 0.3086 - val_loss: 0.0108 - val_acc: 0.0246\n",
      "Epoch 13/30\n",
      "1416/1416 [==============================] - 6s 4ms/step - loss: 0.0077 - acc: 0.3305 - val_loss: 0.0108 - val_acc: 0.0284\n",
      "Epoch 14/30\n",
      "1416/1416 [==============================] - 7s 5ms/step - loss: 0.0075 - acc: 0.3694 - val_loss: 0.0109 - val_acc: 0.0262\n",
      "Epoch 15/30\n",
      "1416/1416 [==============================] - 5s 4ms/step - loss: 0.0074 - acc: 0.3694 - val_loss: 0.0110 - val_acc: 0.0283\n",
      "Epoch 16/30\n",
      "1416/1416 [==============================] - 5s 3ms/step - loss: 0.0072 - acc: 0.3990 - val_loss: 0.0113 - val_acc: 0.0334\n",
      "Epoch 17/30\n",
      "1416/1416 [==============================] - 5s 3ms/step - loss: 0.0071 - acc: 0.4082 - val_loss: 0.0119 - val_acc: 0.0309\n",
      "Epoch 18/30\n",
      "1416/1416 [==============================] - 5s 3ms/step - loss: 0.0070 - acc: 0.4117 - val_loss: 0.0116 - val_acc: 0.0311\n",
      "Epoch 19/30\n",
      "1416/1416 [==============================] - 5s 3ms/step - loss: 0.0070 - acc: 0.4202 - val_loss: 0.0115 - val_acc: 0.0307\n",
      "Epoch 20/30\n",
      "1416/1416 [==============================] - 5s 3ms/step - loss: 0.0068 - acc: 0.4414 - val_loss: 0.0119 - val_acc: 0.0345\n",
      "Epoch 21/30\n",
      "1416/1416 [==============================] - 5s 3ms/step - loss: 0.0066 - acc: 0.4633 - val_loss: 0.0118 - val_acc: 0.0324\n",
      "Epoch 22/30\n",
      "1416/1416 [==============================] - 5s 3ms/step - loss: 0.0065 - acc: 0.4725 - val_loss: 0.0125 - val_acc: 0.0301\n",
      "Epoch 23/30\n",
      "1416/1416 [==============================] - 5s 3ms/step - loss: 0.0065 - acc: 0.4640 - val_loss: 0.0122 - val_acc: 0.0329\n",
      "Epoch 24/30\n",
      "1416/1416 [==============================] - 5s 3ms/step - loss: 0.0063 - acc: 0.4809 - val_loss: 0.0123 - val_acc: 0.0350\n",
      "Epoch 25/30\n",
      "1416/1416 [==============================] - 5s 3ms/step - loss: 0.0061 - acc: 0.5247 - val_loss: 0.0125 - val_acc: 0.0389\n",
      "Epoch 26/30\n",
      "1416/1416 [==============================] - 5s 3ms/step - loss: 0.0059 - acc: 0.5403 - val_loss: 0.0128 - val_acc: 0.0378\n",
      "Epoch 27/30\n",
      "1416/1416 [==============================] - 7s 5ms/step - loss: 0.0059 - acc: 0.5339 - val_loss: 0.0126 - val_acc: 0.0412\n",
      "Epoch 28/30\n",
      "1416/1416 [==============================] - 5s 4ms/step - loss: 0.0057 - acc: 0.5431 - val_loss: 0.0142 - val_acc: 0.0218\n",
      "Epoch 29/30\n",
      "1416/1416 [==============================] - 7s 5ms/step - loss: 0.0057 - acc: 0.5290 - val_loss: 0.0135 - val_acc: 0.0270\n",
      "Epoch 30/30\n",
      "1416/1416 [==============================] - 5s 4ms/step - loss: 0.0055 - acc: 0.5706 - val_loss: 0.0127 - val_acc: 0.0382\n",
      "model #8\n",
      "augmenting dataset\n",
      "Train on 1475 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "1475/1475 [==============================] - 30s 20ms/step - loss: 0.0096 - acc: 0.0712 - val_loss: 0.0099 - val_acc: 0.0503\n",
      "Epoch 2/30\n",
      "1475/1475 [==============================] - 6s 4ms/step - loss: 0.0093 - acc: 0.1336 - val_loss: 0.0104 - val_acc: 0.0320\n",
      "Epoch 3/30\n",
      "1475/1475 [==============================] - 5s 3ms/step - loss: 0.0093 - acc: 0.1668 - val_loss: 0.0103 - val_acc: 0.0288\n",
      "Epoch 4/30\n",
      "1475/1475 [==============================] - 5s 3ms/step - loss: 0.0092 - acc: 0.1810 - val_loss: 0.0101 - val_acc: 0.0321\n",
      "Epoch 5/30\n",
      "1475/1475 [==============================] - 5s 3ms/step - loss: 0.0091 - acc: 0.1824 - val_loss: 0.0101 - val_acc: 0.0320\n",
      "Epoch 6/30\n",
      "1475/1475 [==============================] - 5s 3ms/step - loss: 0.0090 - acc: 0.1980 - val_loss: 0.0102 - val_acc: 0.0261\n",
      "Epoch 7/30\n",
      "1475/1475 [==============================] - 5s 3ms/step - loss: 0.0089 - acc: 0.2014 - val_loss: 0.0103 - val_acc: 0.0193\n",
      "Epoch 8/30\n",
      "1475/1475 [==============================] - 5s 3ms/step - loss: 0.0086 - acc: 0.2020 - val_loss: 0.0104 - val_acc: 0.0196\n",
      "Epoch 9/30\n",
      "1475/1475 [==============================] - 5s 3ms/step - loss: 0.0085 - acc: 0.2393 - val_loss: 0.0107 - val_acc: 0.0205\n",
      "Epoch 10/30\n",
      "1475/1475 [==============================] - 5s 3ms/step - loss: 0.0083 - acc: 0.2481 - val_loss: 0.0109 - val_acc: 0.0253\n",
      "Epoch 11/30\n",
      "1475/1475 [==============================] - 5s 3ms/step - loss: 0.0083 - acc: 0.2671 - val_loss: 0.0110 - val_acc: 0.0239\n",
      "Epoch 12/30\n",
      "1475/1475 [==============================] - 5s 3ms/step - loss: 0.0082 - acc: 0.2671 - val_loss: 0.0118 - val_acc: 0.0234\n",
      "Epoch 13/30\n",
      "1475/1475 [==============================] - 5s 3ms/step - loss: 0.0080 - acc: 0.3098 - val_loss: 0.0119 - val_acc: 0.0181\n",
      "Epoch 14/30\n",
      "1475/1475 [==============================] - 5s 3ms/step - loss: 0.0078 - acc: 0.3139 - val_loss: 0.0126 - val_acc: 0.0183\n",
      "Epoch 15/30\n",
      "1475/1475 [==============================] - 5s 3ms/step - loss: 0.0078 - acc: 0.3037 - val_loss: 0.0126 - val_acc: 0.0242\n",
      "Epoch 16/30\n",
      "1475/1475 [==============================] - 7s 5ms/step - loss: 0.0076 - acc: 0.3397 - val_loss: 0.0120 - val_acc: 0.0276\n",
      "Epoch 17/30\n",
      "1475/1475 [==============================] - 5s 4ms/step - loss: 0.0076 - acc: 0.3329 - val_loss: 0.0130 - val_acc: 0.0232\n",
      "Epoch 18/30\n",
      "1475/1475 [==============================] - 7s 5ms/step - loss: 0.0075 - acc: 0.3458 - val_loss: 0.0128 - val_acc: 0.0204\n",
      "Epoch 19/30\n",
      "1475/1475 [==============================] - 6s 4ms/step - loss: 0.0074 - acc: 0.3756 - val_loss: 0.0124 - val_acc: 0.0303\n",
      "Epoch 20/30\n",
      "1475/1475 [==============================] - 5s 4ms/step - loss: 0.0072 - acc: 0.3844 - val_loss: 0.0112 - val_acc: 0.0337\n",
      "Epoch 21/30\n",
      "1475/1475 [==============================] - 6s 4ms/step - loss: 0.0071 - acc: 0.3871 - val_loss: 0.0115 - val_acc: 0.0362\n",
      "Epoch 22/30\n",
      "1475/1475 [==============================] - 6s 4ms/step - loss: 0.0073 - acc: 0.3715 - val_loss: 0.0127 - val_acc: 0.0323\n",
      "Epoch 23/30\n",
      "1475/1475 [==============================] - 6s 4ms/step - loss: 0.0073 - acc: 0.3756 - val_loss: 0.0123 - val_acc: 0.0284\n",
      "Epoch 24/30\n",
      "1475/1475 [==============================] - 6s 4ms/step - loss: 0.0073 - acc: 0.3627 - val_loss: 0.0114 - val_acc: 0.0342\n",
      "Epoch 25/30\n",
      "1475/1475 [==============================] - 5s 4ms/step - loss: 0.0071 - acc: 0.4027 - val_loss: 0.0120 - val_acc: 0.0323\n",
      "Epoch 26/30\n",
      "1475/1475 [==============================] - 5s 3ms/step - loss: 0.0073 - acc: 0.3715 - val_loss: 0.0133 - val_acc: 0.0247\n",
      "Epoch 27/30\n",
      "1475/1475 [==============================] - 5s 3ms/step - loss: 0.0071 - acc: 0.3844 - val_loss: 0.0124 - val_acc: 0.0321\n",
      "Epoch 28/30\n",
      "1475/1475 [==============================] - 5s 3ms/step - loss: 0.0069 - acc: 0.4149 - val_loss: 0.0122 - val_acc: 0.0367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "1475/1475 [==============================] - 5s 3ms/step - loss: 0.0069 - acc: 0.4176 - val_loss: 0.0118 - val_acc: 0.0344\n",
      "Epoch 30/30\n",
      "1475/1475 [==============================] - 5s 3ms/step - loss: 0.0068 - acc: 0.4380 - val_loss: 0.0122 - val_acc: 0.0349\n",
      "model #9\n",
      "augmenting dataset\n",
      "Train on 1496 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "1496/1496 [==============================] - 28s 19ms/step - loss: 0.0093 - acc: 0.1384 - val_loss: 0.0100 - val_acc: 0.0432\n",
      "Epoch 2/30\n",
      "1496/1496 [==============================] - 7s 5ms/step - loss: 0.0088 - acc: 0.2039 - val_loss: 0.0102 - val_acc: 0.0334\n",
      "Epoch 3/30\n",
      "1496/1496 [==============================] - 6s 4ms/step - loss: 0.0085 - acc: 0.2400 - val_loss: 0.0101 - val_acc: 0.0325\n",
      "Epoch 4/30\n",
      "1496/1496 [==============================] - 6s 4ms/step - loss: 0.0083 - acc: 0.2894 - val_loss: 0.0101 - val_acc: 0.0319\n",
      "Epoch 5/30\n",
      "1496/1496 [==============================] - 5s 3ms/step - loss: 0.0082 - acc: 0.3041 - val_loss: 0.0103 - val_acc: 0.0285\n",
      "Epoch 6/30\n",
      "1496/1496 [==============================] - 5s 3ms/step - loss: 0.0082 - acc: 0.2975 - val_loss: 0.0102 - val_acc: 0.0295\n",
      "Epoch 7/30\n",
      "1496/1496 [==============================] - 5s 3ms/step - loss: 0.0080 - acc: 0.3182 - val_loss: 0.0103 - val_acc: 0.0308\n",
      "Epoch 8/30\n",
      "1496/1496 [==============================] - 5s 3ms/step - loss: 0.0078 - acc: 0.3242 - val_loss: 0.0108 - val_acc: 0.0271\n",
      "Epoch 9/30\n",
      "1496/1496 [==============================] - 5s 3ms/step - loss: 0.0078 - acc: 0.3222 - val_loss: 0.0104 - val_acc: 0.0280\n",
      "Epoch 10/30\n",
      "1496/1496 [==============================] - 5s 3ms/step - loss: 0.0076 - acc: 0.3275 - val_loss: 0.0105 - val_acc: 0.0303\n",
      "Epoch 11/30\n",
      "1496/1496 [==============================] - 5s 3ms/step - loss: 0.0075 - acc: 0.3316 - val_loss: 0.0106 - val_acc: 0.0288\n",
      "Epoch 12/30\n",
      "1496/1496 [==============================] - 5s 4ms/step - loss: 0.0074 - acc: 0.3409 - val_loss: 0.0107 - val_acc: 0.0302\n",
      "Epoch 13/30\n",
      "1496/1496 [==============================] - 6s 4ms/step - loss: 0.0073 - acc: 0.3549 - val_loss: 0.0110 - val_acc: 0.0293\n",
      "Epoch 14/30\n",
      "1496/1496 [==============================] - 6s 4ms/step - loss: 0.0070 - acc: 0.3750 - val_loss: 0.0116 - val_acc: 0.0299\n",
      "Epoch 15/30\n",
      "1496/1496 [==============================] - 6s 4ms/step - loss: 0.0069 - acc: 0.3991 - val_loss: 0.0116 - val_acc: 0.0315\n",
      "Epoch 16/30\n",
      "1496/1496 [==============================] - 6s 4ms/step - loss: 0.0069 - acc: 0.3984 - val_loss: 0.0113 - val_acc: 0.0347\n",
      "Epoch 17/30\n",
      "1496/1496 [==============================] - 5s 3ms/step - loss: 0.0068 - acc: 0.4158 - val_loss: 0.0113 - val_acc: 0.0305\n",
      "Epoch 18/30\n",
      "1496/1496 [==============================] - 5s 3ms/step - loss: 0.0068 - acc: 0.4198 - val_loss: 0.0115 - val_acc: 0.0329\n",
      "Epoch 19/30\n",
      "1496/1496 [==============================] - 5s 3ms/step - loss: 0.0068 - acc: 0.4131 - val_loss: 0.0120 - val_acc: 0.0328\n",
      "Epoch 20/30\n",
      "1496/1496 [==============================] - 5s 3ms/step - loss: 0.0069 - acc: 0.4205 - val_loss: 0.0119 - val_acc: 0.0330\n",
      "Epoch 21/30\n",
      "1496/1496 [==============================] - 5s 3ms/step - loss: 0.0066 - acc: 0.4465 - val_loss: 0.0119 - val_acc: 0.0344\n",
      "Epoch 22/30\n",
      "1496/1496 [==============================] - 5s 3ms/step - loss: 0.0066 - acc: 0.4579 - val_loss: 0.0121 - val_acc: 0.0325\n",
      "Epoch 23/30\n",
      "1496/1496 [==============================] - 5s 3ms/step - loss: 0.0066 - acc: 0.4539 - val_loss: 0.0121 - val_acc: 0.0334\n",
      "Epoch 24/30\n",
      "1496/1496 [==============================] - 5s 3ms/step - loss: 0.0063 - acc: 0.4860 - val_loss: 0.0122 - val_acc: 0.0323\n",
      "Epoch 25/30\n",
      "1496/1496 [==============================] - 5s 3ms/step - loss: 0.0062 - acc: 0.4866 - val_loss: 0.0121 - val_acc: 0.0352\n",
      "Epoch 26/30\n",
      "1496/1496 [==============================] - 5s 3ms/step - loss: 0.0063 - acc: 0.4826 - val_loss: 0.0123 - val_acc: 0.0315\n",
      "Epoch 27/30\n",
      "1496/1496 [==============================] - 6s 4ms/step - loss: 0.0062 - acc: 0.5087 - val_loss: 0.0127 - val_acc: 0.0359\n",
      "Epoch 28/30\n",
      "1496/1496 [==============================] - 6s 4ms/step - loss: 0.0062 - acc: 0.4840 - val_loss: 0.0124 - val_acc: 0.0356\n",
      "Epoch 29/30\n",
      "1496/1496 [==============================] - 7s 4ms/step - loss: 0.0061 - acc: 0.5154 - val_loss: 0.0124 - val_acc: 0.0389\n",
      "Epoch 30/30\n",
      "1496/1496 [==============================] - 6s 4ms/step - loss: 0.0061 - acc: 0.5114 - val_loss: 0.0125 - val_acc: 0.0381\n",
      "model #10\n",
      "augmenting dataset\n",
      "Train on 1548 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "1548/1548 [==============================] - 30s 20ms/step - loss: 0.0095 - acc: 0.0917 - val_loss: 0.0100 - val_acc: 0.0443\n",
      "Epoch 2/30\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 0.0092 - acc: 0.1163 - val_loss: 0.0101 - val_acc: 0.0412\n",
      "Epoch 3/30\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 0.0091 - acc: 0.1557 - val_loss: 0.0100 - val_acc: 0.0411\n",
      "Epoch 4/30\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 0.0089 - acc: 0.1977 - val_loss: 0.0102 - val_acc: 0.0267\n",
      "Epoch 5/30\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 0.0087 - acc: 0.2093 - val_loss: 0.0102 - val_acc: 0.0238\n",
      "Epoch 6/30\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 0.0086 - acc: 0.2261 - val_loss: 0.0102 - val_acc: 0.0235\n",
      "Epoch 7/30\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 0.0086 - acc: 0.2287 - val_loss: 0.0103 - val_acc: 0.0226\n",
      "Epoch 8/30\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 0.0084 - acc: 0.2500 - val_loss: 0.0103 - val_acc: 0.0233\n",
      "Epoch 9/30\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 0.0082 - acc: 0.2778 - val_loss: 0.0104 - val_acc: 0.0250\n",
      "Epoch 10/30\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 0.0081 - acc: 0.2894 - val_loss: 0.0105 - val_acc: 0.0245\n",
      "Epoch 11/30\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 0.0079 - acc: 0.3049 - val_loss: 0.0106 - val_acc: 0.0244\n",
      "Epoch 12/30\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 0.0078 - acc: 0.3230 - val_loss: 0.0112 - val_acc: 0.0248\n",
      "Epoch 13/30\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 0.0078 - acc: 0.3256 - val_loss: 0.0115 - val_acc: 0.0228\n",
      "Epoch 14/30\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 0.0075 - acc: 0.3404 - val_loss: 0.0116 - val_acc: 0.0277\n",
      "Epoch 15/30\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 0.0073 - acc: 0.3547 - val_loss: 0.0116 - val_acc: 0.0295\n",
      "Epoch 16/30\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 0.0071 - acc: 0.3966 - val_loss: 0.0118 - val_acc: 0.0295\n",
      "Epoch 17/30\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 0.0070 - acc: 0.4070 - val_loss: 0.0122 - val_acc: 0.0310\n",
      "Epoch 18/30\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 0.0070 - acc: 0.4128 - val_loss: 0.0113 - val_acc: 0.0343\n",
      "Epoch 19/30\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 0.0068 - acc: 0.4386 - val_loss: 0.0118 - val_acc: 0.0355\n",
      "Epoch 20/30\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 0.0067 - acc: 0.4464 - val_loss: 0.0121 - val_acc: 0.0352\n",
      "Epoch 21/30\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 0.0065 - acc: 0.4509 - val_loss: 0.0122 - val_acc: 0.0324\n",
      "Epoch 22/30\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 0.0065 - acc: 0.4677 - val_loss: 0.0118 - val_acc: 0.0340\n",
      "Epoch 23/30\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 0.0064 - acc: 0.4774 - val_loss: 0.0118 - val_acc: 0.0378\n",
      "Epoch 24/30\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 0.0062 - acc: 0.5116 - val_loss: 0.0119 - val_acc: 0.0334\n",
      "Epoch 25/30\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 0.0062 - acc: 0.5032 - val_loss: 0.0121 - val_acc: 0.0398\n",
      "Epoch 26/30\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 0.0062 - acc: 0.5116 - val_loss: 0.0123 - val_acc: 0.0375\n",
      "Epoch 27/30\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 0.0061 - acc: 0.5097 - val_loss: 0.0127 - val_acc: 0.0373\n",
      "Epoch 28/30\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 0.0060 - acc: 0.5329 - val_loss: 0.0125 - val_acc: 0.0358\n",
      "Epoch 29/30\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 0.0060 - acc: 0.5368 - val_loss: 0.0125 - val_acc: 0.0398\n",
      "Epoch 30/30\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 0.0059 - acc: 0.5420 - val_loss: 0.0126 - val_acc: 0.0383\n"
     ]
    }
   ],
   "source": [
    "local_update_history = []\n",
    "\n",
    "print_datetime()\n",
    "\n",
    "for i, m in enumerate(users_models):\n",
    "    print(\"model #%d\" %(i+1))\n",
    "    local_update_history.append(\n",
    "        m.fit(x_data_split[i], y_data_split[i],\n",
    "              batch_size=32,\n",
    "              epochs=30,\n",
    "              validation_data=(x_test, y_test_cat),\n",
    "              shuffle=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [m.get_weights() for m in users_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FederatedAggregation\n",
    "new_weights = list()\n",
    "\n",
    "for weights_list_tuple in zip(*weights):\n",
    "    new_weights.append(\n",
    "        [np.array(weights_).mean(axis=0)\\\n",
    "            for weights_ in zip(*weights_list_tuple)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_model = keras.models.clone_model(pretrained_model)\n",
    "aggr_model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partial aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 23s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.009900018228590489, 0.01]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compile_model(aggr_model)\n",
    "aggr_model.evaluate(x_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_model.save(\"model_G4_users_10.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_local_test = keras.models.load_model(\"model_G4_users_10.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 23s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.009900018228590489, 0.01]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compile_model(model_local_test)\n",
    "model_local_test.evaluate(x_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-f94bd2ee365f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mlocal_update_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"update_history_G4_users_10.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__getstate__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickle_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mpickle_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0m_serialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_serialize_model\u001b[0;34m(model, f, include_optimizer)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 'optimizer_config': {\n\u001b[1;32m    131\u001b[0m                     \u001b[0;34m'class_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                     \u001b[0;34m'config'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                 },\n\u001b[1;32m    134\u001b[0m                 \u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         config = {'lr': float(K.get_value(self.lr)),\n\u001b[0;32m--> 213\u001b[0;31m                   \u001b[0;34m'momentum'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m                   \u001b[0;34m'decay'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                   'nesterov': self.nesterov}\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2405\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mNumpy\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2406\u001b[0m     \"\"\"\n\u001b[0;32m-> 2407\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m   1907\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m     \"\"\"\n\u001b[0;32m-> 1909\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1911\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \"\"\"\n\u001b[0;32m--> 731\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5577\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5578\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5579\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pickle.dump( local_update_history, open( \"update_history_G4_users_10.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mMJDPXn9PWAd"
   },
   "source": [
    "\n",
    "### Global (4): Train globally on 35K + fix layers + distribute 15K NON-randomly + train & aggregate (Federated Learning)\n",
    "#### 2 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N4SyCoN-OyPC"
   },
   "outputs": [],
   "source": [
    "# FL Setting\n",
    "num_users = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Users get datasets corresponding to (num_class/num_users) classes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_local[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 100)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_local.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_split = [np.empty([0,32,32,3]) for _ in range(num_users)]\n",
    "y_data_split = [np.empty([0,100]) for _ in range(num_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 complete\n",
      "1000 complete\n",
      "2000 complete\n",
      "3000 complete\n",
      "4000 complete\n",
      "5000 complete\n",
      "6000 complete\n",
      "7000 complete\n",
      "8000 complete\n",
      "9000 complete\n",
      "10000 complete\n",
      "11000 complete\n",
      "12000 complete\n",
      "13000 complete\n"
     ]
    }
   ],
   "source": [
    "for i in range(y_train_local.shape[0]):\n",
    "    if (i%1000 == 0):\n",
    "        print(\"%d complete\" %i)\n",
    "    user_num = (int) (y_train_local_notcat[i][0] / (100 / num_users))\n",
    "    x_data_split[user_num] = \\\n",
    "        np.concatenate((x_data_split[user_num], np.expand_dims(x_train_local[i], axis=0)), axis=0)\n",
    "    y_data_split[user_num] = \\\n",
    "        np.concatenate((y_data_split[user_num], np.expand_dims(y_train_local[i], axis=0)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "pretrained_model = keras.models.load_model('model_G2_35k_sgd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate users with models\n",
    "users_models = [keras.models.clone_model(pretrained_model) for i in range(num_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in users_models:\n",
    "    m.set_weights(pretrained_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for m in users_models:\n",
    "    compile_model(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_models[0].evaluate(x_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "local_update_history = []\n",
    "\n",
    "print_datetime()\n",
    "\n",
    "for i, m in enumerate(users_models):\n",
    "    print(\"model #%d\" %(i+1))\n",
    "    local_update_history.append(\n",
    "        m.fit(x_data_split[i], y_data_split[i],\n",
    "              batch_size=32,\n",
    "              epochs=30,\n",
    "              validation_data=(x_test, y_test_cat),\n",
    "              shuffle=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [m.get_weights() for m in users_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FederatedAggregation\n",
    "new_weights = list()\n",
    "\n",
    "for weights_list_tuple in zip(*weights):\n",
    "    new_weights.append(\n",
    "        [np.array(weights_).mean(axis=0)\\\n",
    "            for weights_ in zip(*weights_list_tuple)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_model = keras.models.clone_model(pretrained_model)\n",
    "aggr_model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partial aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_model(aggr_model)\n",
    "aggr_model.evaluate(x_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_model.save(\"model_G4_users_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_local_test = keras.models.load_model(\"model_G4_users_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_model(model_local_test)\n",
    "model_local_test.evaluate(x_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( local_update_history, open( \"update_history_G4_users_2.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "personalized.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
