{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d6n47ueeqbXb"
   },
   "source": [
    "## Personalized Learning (Localized Learning?)\n",
    "\n",
    "#### This notebook includes the following online models;\n",
    "1. A single global model with all data\n",
    "2. Multiple local models (starting from a single global model)\n",
    "   1. that are updated with new data\n",
    "   2. that exchanges data in clusters\n",
    "   3. that exchanges parameters in clusters\n",
    "\n",
    "  \n",
    "#### The dataset that is used for this project is [CIFAR-100 dataset][1]\n",
    "* Has 100 classes containing 600 images each\n",
    "\n",
    "#### New data are fed by the following rules;\n",
    "1. Distributed, according to superclasses\n",
    "  * Clusters will only be updated with data that belongs to a specific superclass\n",
    "  * We update the NN by\n",
    "    1. Changing all parameters of the NN\n",
    "    2. Only changing the last few layers, as in many MTL models\n",
    "2. Randomly (why?)\n",
    "\n",
    "#### We expect to find an answer to the following research questions with this project;\n",
    "1. If models are updated with data (or parameters) that are shared within a cluster, can the model perform good enough with the labels that count?\n",
    "  * For example, the performance of the cluster that are updated with \"Vehicles\" superclass is only assessed with the labels that corresponds to the superclass.\n",
    "  \n",
    "[1]: https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oji0BTfoqbXc"
   },
   "source": [
    "#### Questions\n",
    "\n",
    "Retraining: how does it work <br>\n",
    "How do we compare these models?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mr4-uY0LqbXd"
   },
   "source": [
    "### Implementation with Custom Neural Network and EMNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tGoXLnOyqbXe",
    "outputId": "9ccd7215-80bf-4a0a-b852-8896b17c38f1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.lines as mlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E2faBs1yqbXj"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 50\n",
    "epochs = 20\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QXfylSWLqbXl"
   },
   "source": [
    "#### Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_dataset_size = 6000\n",
    "local_dataset_size = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_global = x_train[-global_dataset_size:]\n",
    "Y_global = y_train[-global_dataset_size:]\n",
    "X_local = x_train[:-global_dataset_size]\n",
    "Y_local = y_train[:-global_dataset_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/seth/projects/fed-learn-experiment/utils.py'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_local_list, Y_local_list = utils.split_training_set(4000, 10, X_local, Y_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4154, 28, 28, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_local_list[8].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "num_classes = 10\n",
    "Y_global = keras.utils.to_categorical(Y_global, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models and compile & fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_model():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=input_shape))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):  \n",
    "    # initiate SGD optimizer\n",
    "    opt = keras.optimizers.SGD(lr=0.1)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model_lr(model):  \n",
    "    # initiate SGD optimizer\n",
    "    opt = keras.optimizers.SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_global(model, epochs):\n",
    "    now = datetime.datetime.now()\n",
    "    print (\"Training date and time : \")\n",
    "    print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    return model.fit(X_global, Y_global,\n",
    "                      batch_size=100,\n",
    "                      epochs=40,\n",
    "                      shuffle=True, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_with_datasets(model, epochs, x_train, y_train):\n",
    "    now = datetime.datetime.now()\n",
    "    print (\"Training date and time : \")\n",
    "    print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    return model.fit(x_train, y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      shuffle=True, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/seth/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Training date and time : \n",
      "2020-05-18 10:32:59\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "5400/5400 [==============================] - 1s 94us/sample - loss: 0.0882 - acc: 0.2176 - val_loss: 0.0859 - val_acc: 0.3600\n",
      "Epoch 2/30\n",
      "5400/5400 [==============================] - 0s 35us/sample - loss: 0.0838 - acc: 0.3628 - val_loss: 0.0806 - val_acc: 0.4250\n",
      "Epoch 3/30\n",
      "5400/5400 [==============================] - 0s 35us/sample - loss: 0.0782 - acc: 0.4670 - val_loss: 0.0738 - val_acc: 0.4967\n",
      "Epoch 4/30\n",
      "5400/5400 [==============================] - 0s 30us/sample - loss: 0.0711 - acc: 0.5467 - val_loss: 0.0654 - val_acc: 0.5650\n",
      "Epoch 5/30\n",
      "5400/5400 [==============================] - 0s 29us/sample - loss: 0.0625 - acc: 0.6291 - val_loss: 0.0561 - val_acc: 0.6850\n",
      "Epoch 6/30\n",
      "5400/5400 [==============================] - 0s 32us/sample - loss: 0.0533 - acc: 0.7167 - val_loss: 0.0469 - val_acc: 0.7533\n",
      "Epoch 7/30\n",
      "5400/5400 [==============================] - 0s 34us/sample - loss: 0.0444 - acc: 0.7793 - val_loss: 0.0382 - val_acc: 0.8000\n",
      "Epoch 8/30\n",
      "5400/5400 [==============================] - 0s 35us/sample - loss: 0.0367 - acc: 0.8200 - val_loss: 0.0314 - val_acc: 0.8500\n",
      "Epoch 9/30\n",
      "5400/5400 [==============================] - 0s 34us/sample - loss: 0.0309 - acc: 0.8594 - val_loss: 0.0264 - val_acc: 0.8783\n",
      "Epoch 10/30\n",
      "5400/5400 [==============================] - 0s 35us/sample - loss: 0.0267 - acc: 0.8746 - val_loss: 0.0230 - val_acc: 0.8883\n",
      "Epoch 11/30\n",
      "5400/5400 [==============================] - 0s 34us/sample - loss: 0.0239 - acc: 0.8804 - val_loss: 0.0209 - val_acc: 0.8983\n",
      "Epoch 12/30\n",
      "5400/5400 [==============================] - 0s 34us/sample - loss: 0.0217 - acc: 0.8900 - val_loss: 0.0191 - val_acc: 0.8983\n",
      "Epoch 13/30\n",
      "5400/5400 [==============================] - 0s 34us/sample - loss: 0.0201 - acc: 0.8952 - val_loss: 0.0181 - val_acc: 0.9017\n",
      "Epoch 14/30\n",
      "5400/5400 [==============================] - 0s 34us/sample - loss: 0.0188 - acc: 0.8985 - val_loss: 0.0170 - val_acc: 0.9117\n",
      "Epoch 15/30\n",
      "5400/5400 [==============================] - 0s 32us/sample - loss: 0.0177 - acc: 0.9024 - val_loss: 0.0161 - val_acc: 0.9150\n",
      "Epoch 16/30\n",
      "5400/5400 [==============================] - 0s 29us/sample - loss: 0.0169 - acc: 0.9044 - val_loss: 0.0157 - val_acc: 0.9150\n",
      "Epoch 17/30\n",
      "5400/5400 [==============================] - 0s 32us/sample - loss: 0.0161 - acc: 0.9078 - val_loss: 0.0149 - val_acc: 0.9183\n",
      "Epoch 18/30\n",
      "5400/5400 [==============================] - 0s 35us/sample - loss: 0.0155 - acc: 0.9115 - val_loss: 0.0147 - val_acc: 0.9117\n",
      "Epoch 19/30\n",
      "5400/5400 [==============================] - 0s 34us/sample - loss: 0.0149 - acc: 0.9157 - val_loss: 0.0144 - val_acc: 0.9167\n",
      "Epoch 20/30\n",
      "5400/5400 [==============================] - 0s 34us/sample - loss: 0.0144 - acc: 0.9148 - val_loss: 0.0141 - val_acc: 0.9133\n",
      "Epoch 21/30\n",
      "5400/5400 [==============================] - 0s 35us/sample - loss: 0.0140 - acc: 0.9200 - val_loss: 0.0139 - val_acc: 0.9150\n",
      "Epoch 22/30\n",
      "5400/5400 [==============================] - 0s 35us/sample - loss: 0.0135 - acc: 0.9224 - val_loss: 0.0135 - val_acc: 0.9183\n",
      "Epoch 23/30\n",
      "5400/5400 [==============================] - 0s 35us/sample - loss: 0.0132 - acc: 0.9263 - val_loss: 0.0133 - val_acc: 0.9200\n",
      "Epoch 24/30\n",
      "5400/5400 [==============================] - 0s 35us/sample - loss: 0.0128 - acc: 0.9263 - val_loss: 0.0131 - val_acc: 0.9217\n",
      "Epoch 25/30\n",
      "5400/5400 [==============================] - 0s 34us/sample - loss: 0.0125 - acc: 0.9291 - val_loss: 0.0130 - val_acc: 0.9217\n",
      "Epoch 26/30\n",
      "5400/5400 [==============================] - 0s 31us/sample - loss: 0.0122 - acc: 0.9289 - val_loss: 0.0125 - val_acc: 0.9200\n",
      "Epoch 27/30\n",
      "5400/5400 [==============================] - 0s 30us/sample - loss: 0.0119 - acc: 0.9322 - val_loss: 0.0125 - val_acc: 0.9217\n",
      "Epoch 28/30\n",
      "5400/5400 [==============================] - 0s 33us/sample - loss: 0.0116 - acc: 0.9346 - val_loss: 0.0129 - val_acc: 0.9167\n",
      "Epoch 29/30\n",
      "5400/5400 [==============================] - 0s 33us/sample - loss: 0.0114 - acc: 0.9337 - val_loss: 0.0124 - val_acc: 0.9217\n",
      "Epoch 30/30\n",
      "5400/5400 [==============================] - 0s 34us/sample - loss: 0.0112 - acc: 0.9367 - val_loss: 0.0122 - val_acc: 0.9200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efb695c1320>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = custom_model()\n",
    "compile_model(model1)\n",
    "fit_model_with_datasets(model1, 30, X_global, Y_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/seth/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/seth/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model_list = list()\n",
    "for _ in range(15):\n",
    "    model_list.append(tf.keras.models.clone_model(model1)) \n",
    "    model_list[_].set_weights(model1.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_model = tf.keras.models.clone_model(model1)\n",
    "standard_model.set_weights(model1.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'semantic_drift' from '/home/seth/projects/fed-learn-experiment/semantic_drift.py'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(semantic_drift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct transfer learning in local models using different datasets & epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training date and time : \n",
      "2020-05-18 10:33:37\n",
      "Train on 3738 samples, validate on 416 samples\n",
      "Epoch 1/10\n",
      "3738/3738 [==============================] - 0s 58us/sample - loss: 0.0159 - acc: 0.8994 - val_loss: 0.0132 - val_acc: 0.9255\n",
      "Epoch 2/10\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0154 - acc: 0.9037 - val_loss: 0.0133 - val_acc: 0.9231\n",
      "Epoch 3/10\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0149 - acc: 0.9053 - val_loss: 0.0130 - val_acc: 0.9303\n",
      "Epoch 4/10\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0145 - acc: 0.9098 - val_loss: 0.0129 - val_acc: 0.9279\n",
      "Epoch 5/10\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0142 - acc: 0.9141 - val_loss: 0.0128 - val_acc: 0.9303\n",
      "Epoch 6/10\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0139 - acc: 0.9168 - val_loss: 0.0128 - val_acc: 0.9351\n",
      "Epoch 7/10\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0136 - acc: 0.9181 - val_loss: 0.0127 - val_acc: 0.9327\n",
      "Epoch 8/10\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0133 - acc: 0.9192 - val_loss: 0.0125 - val_acc: 0.9303\n",
      "Epoch 9/10\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0131 - acc: 0.9219 - val_loss: 0.0126 - val_acc: 0.9303\n",
      "Epoch 10/10\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0129 - acc: 0.9224 - val_loss: 0.0122 - val_acc: 0.9303\n",
      "Training date and time : \n",
      "2020-05-18 10:33:39\n",
      "Train on 3738 samples, validate on 416 samples\n",
      "Epoch 1/20\n",
      "3738/3738 [==============================] - 0s 57us/sample - loss: 0.0159 - acc: 0.8991 - val_loss: 0.0134 - val_acc: 0.9207\n",
      "Epoch 2/20\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0154 - acc: 0.9026 - val_loss: 0.0132 - val_acc: 0.9231\n",
      "Epoch 3/20\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0149 - acc: 0.9072 - val_loss: 0.0130 - val_acc: 0.9279\n",
      "Epoch 4/20\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0145 - acc: 0.9123 - val_loss: 0.0130 - val_acc: 0.9231\n",
      "Epoch 5/20\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0142 - acc: 0.9131 - val_loss: 0.0128 - val_acc: 0.9279\n",
      "Epoch 6/20\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0139 - acc: 0.9155 - val_loss: 0.0127 - val_acc: 0.9303\n",
      "Epoch 7/20\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0136 - acc: 0.9168 - val_loss: 0.0126 - val_acc: 0.9351\n",
      "Epoch 8/20\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0133 - acc: 0.9205 - val_loss: 0.0125 - val_acc: 0.9375\n",
      "Epoch 9/20\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0131 - acc: 0.9205 - val_loss: 0.0124 - val_acc: 0.9351\n",
      "Epoch 10/20\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0128 - acc: 0.9243 - val_loss: 0.0125 - val_acc: 0.9375\n",
      "Epoch 11/20\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0127 - acc: 0.9230 - val_loss: 0.0121 - val_acc: 0.9327\n",
      "Epoch 12/20\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0124 - acc: 0.9256 - val_loss: 0.0121 - val_acc: 0.9327\n",
      "Epoch 13/20\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0122 - acc: 0.9275 - val_loss: 0.0121 - val_acc: 0.9327\n",
      "Epoch 14/20\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0120 - acc: 0.9307 - val_loss: 0.0118 - val_acc: 0.9399\n",
      "Epoch 15/20\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0119 - acc: 0.9307 - val_loss: 0.0118 - val_acc: 0.9351\n",
      "Epoch 16/20\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0117 - acc: 0.9318 - val_loss: 0.0117 - val_acc: 0.9375\n",
      "Epoch 17/20\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0115 - acc: 0.9323 - val_loss: 0.0117 - val_acc: 0.9423\n",
      "Epoch 18/20\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0114 - acc: 0.9329 - val_loss: 0.0115 - val_acc: 0.9375\n",
      "Epoch 19/20\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0112 - acc: 0.9342 - val_loss: 0.0116 - val_acc: 0.9375\n",
      "Epoch 20/20\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0111 - acc: 0.9347 - val_loss: 0.0116 - val_acc: 0.9375\n",
      "Training date and time : \n",
      "2020-05-18 10:33:42\n",
      "Train on 3738 samples, validate on 416 samples\n",
      "Epoch 1/30\n",
      "3738/3738 [==============================] - 0s 63us/sample - loss: 0.0159 - acc: 0.8994 - val_loss: 0.0135 - val_acc: 0.9231\n",
      "Epoch 2/30\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0153 - acc: 0.9034 - val_loss: 0.0133 - val_acc: 0.9231\n",
      "Epoch 3/30\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0149 - acc: 0.9085 - val_loss: 0.0131 - val_acc: 0.9279\n",
      "Epoch 4/30\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0145 - acc: 0.9098 - val_loss: 0.0128 - val_acc: 0.9231\n",
      "Epoch 5/30\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0142 - acc: 0.9133 - val_loss: 0.0128 - val_acc: 0.9303\n",
      "Epoch 6/30\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0139 - acc: 0.9165 - val_loss: 0.0126 - val_acc: 0.9327\n",
      "Epoch 7/30\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0136 - acc: 0.9171 - val_loss: 0.0126 - val_acc: 0.9351\n",
      "Epoch 8/30\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0133 - acc: 0.9200 - val_loss: 0.0124 - val_acc: 0.9327\n",
      "Epoch 9/30\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0131 - acc: 0.9211 - val_loss: 0.0122 - val_acc: 0.9303\n",
      "Epoch 10/30\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0129 - acc: 0.9232 - val_loss: 0.0122 - val_acc: 0.9351\n",
      "Epoch 11/30\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0126 - acc: 0.9243 - val_loss: 0.0122 - val_acc: 0.9327\n",
      "Epoch 12/30\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0124 - acc: 0.9251 - val_loss: 0.0120 - val_acc: 0.9327\n",
      "Epoch 13/30\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0122 - acc: 0.9256 - val_loss: 0.0120 - val_acc: 0.9351\n",
      "Epoch 14/30\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0120 - acc: 0.9302 - val_loss: 0.0119 - val_acc: 0.9399\n",
      "Epoch 15/30\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0119 - acc: 0.9312 - val_loss: 0.0121 - val_acc: 0.9375\n",
      "Epoch 16/30\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0117 - acc: 0.9318 - val_loss: 0.0119 - val_acc: 0.9351\n",
      "Epoch 17/30\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0115 - acc: 0.9334 - val_loss: 0.0118 - val_acc: 0.9399\n",
      "Epoch 18/30\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0114 - acc: 0.9334 - val_loss: 0.0117 - val_acc: 0.9399\n",
      "Epoch 19/30\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0112 - acc: 0.9339 - val_loss: 0.0116 - val_acc: 0.9423\n",
      "Epoch 20/30\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0111 - acc: 0.9345 - val_loss: 0.0115 - val_acc: 0.9375\n",
      "Epoch 21/30\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0109 - acc: 0.9361 - val_loss: 0.0115 - val_acc: 0.9375\n",
      "Epoch 22/30\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0108 - acc: 0.9377 - val_loss: 0.0114 - val_acc: 0.9375\n",
      "Epoch 23/30\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0106 - acc: 0.9385 - val_loss: 0.0113 - val_acc: 0.9375\n",
      "Epoch 24/30\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0105 - acc: 0.9387 - val_loss: 0.0114 - val_acc: 0.9375\n",
      "Epoch 25/30\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0104 - acc: 0.9406 - val_loss: 0.0114 - val_acc: 0.9375\n",
      "Epoch 26/30\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0102 - acc: 0.9425 - val_loss: 0.0114 - val_acc: 0.9375\n",
      "Epoch 27/30\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0101 - acc: 0.9419 - val_loss: 0.0112 - val_acc: 0.9375\n",
      "Epoch 28/30\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0100 - acc: 0.9438 - val_loss: 0.0113 - val_acc: 0.9375\n",
      "Epoch 29/30\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0099 - acc: 0.9444 - val_loss: 0.0113 - val_acc: 0.9375\n",
      "Epoch 30/30\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0098 - acc: 0.9449 - val_loss: 0.0111 - val_acc: 0.9399\n",
      "Training date and time : \n",
      "2020-05-18 10:33:46\n",
      "Train on 3738 samples, validate on 416 samples\n",
      "Epoch 1/40\n",
      "3738/3738 [==============================] - 0s 61us/sample - loss: 0.0159 - acc: 0.9007 - val_loss: 0.0134 - val_acc: 0.9231\n",
      "Epoch 2/40\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0153 - acc: 0.9021 - val_loss: 0.0134 - val_acc: 0.9255\n",
      "Epoch 3/40\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0149 - acc: 0.9077 - val_loss: 0.0129 - val_acc: 0.9255\n",
      "Epoch 4/40\n",
      "3738/3738 [==============================] - 0s 27us/sample - loss: 0.0145 - acc: 0.9098 - val_loss: 0.0129 - val_acc: 0.9327\n",
      "Epoch 5/40\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0142 - acc: 0.9141 - val_loss: 0.0127 - val_acc: 0.9255\n",
      "Epoch 6/40\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0139 - acc: 0.9149 - val_loss: 0.0126 - val_acc: 0.9303\n",
      "Epoch 7/40\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0136 - acc: 0.9173 - val_loss: 0.0125 - val_acc: 0.9375\n",
      "Epoch 8/40\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0134 - acc: 0.9197 - val_loss: 0.0124 - val_acc: 0.9327\n",
      "Epoch 9/40\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0131 - acc: 0.9211 - val_loss: 0.0124 - val_acc: 0.9279\n",
      "Epoch 10/40\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0129 - acc: 0.9230 - val_loss: 0.0122 - val_acc: 0.9303\n",
      "Epoch 11/40\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0126 - acc: 0.9246 - val_loss: 0.0123 - val_acc: 0.9303\n",
      "Epoch 12/40\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0124 - acc: 0.9256 - val_loss: 0.0122 - val_acc: 0.9399\n",
      "Epoch 13/40\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0122 - acc: 0.9264 - val_loss: 0.0121 - val_acc: 0.9375\n",
      "Epoch 14/40\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0120 - acc: 0.9310 - val_loss: 0.0120 - val_acc: 0.9351\n",
      "Epoch 15/40\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0118 - acc: 0.9296 - val_loss: 0.0118 - val_acc: 0.9399\n",
      "Epoch 16/40\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0117 - acc: 0.9310 - val_loss: 0.0117 - val_acc: 0.9375\n",
      "Epoch 17/40\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0115 - acc: 0.9329 - val_loss: 0.0117 - val_acc: 0.9399\n",
      "Epoch 18/40\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0113 - acc: 0.9331 - val_loss: 0.0116 - val_acc: 0.9399\n",
      "Epoch 19/40\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0112 - acc: 0.9353 - val_loss: 0.0117 - val_acc: 0.9399\n",
      "Epoch 20/40\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0110 - acc: 0.9371 - val_loss: 0.0116 - val_acc: 0.9375\n",
      "Epoch 21/40\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0109 - acc: 0.9350 - val_loss: 0.0114 - val_acc: 0.9399\n",
      "Epoch 22/40\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0108 - acc: 0.9382 - val_loss: 0.0115 - val_acc: 0.9375\n",
      "Epoch 23/40\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0106 - acc: 0.9390 - val_loss: 0.0116 - val_acc: 0.9375\n",
      "Epoch 24/40\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0105 - acc: 0.9390 - val_loss: 0.0113 - val_acc: 0.9423\n",
      "Epoch 25/40\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0104 - acc: 0.9411 - val_loss: 0.0113 - val_acc: 0.9375\n",
      "Epoch 26/40\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0103 - acc: 0.9433 - val_loss: 0.0112 - val_acc: 0.9423\n",
      "Epoch 27/40\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0101 - acc: 0.9411 - val_loss: 0.0112 - val_acc: 0.9399\n",
      "Epoch 28/40\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0100 - acc: 0.9433 - val_loss: 0.0113 - val_acc: 0.9375\n",
      "Epoch 29/40\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0099 - acc: 0.9462 - val_loss: 0.0111 - val_acc: 0.9375\n",
      "Epoch 30/40\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0098 - acc: 0.9454 - val_loss: 0.0111 - val_acc: 0.9375\n",
      "Epoch 31/40\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0097 - acc: 0.9449 - val_loss: 0.0111 - val_acc: 0.9375\n",
      "Epoch 32/40\n",
      "3738/3738 [==============================] - 0s 28us/sample - loss: 0.0096 - acc: 0.9465 - val_loss: 0.0111 - val_acc: 0.9399\n",
      "Epoch 33/40\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0095 - acc: 0.9481 - val_loss: 0.0111 - val_acc: 0.9423\n",
      "Epoch 34/40\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0094 - acc: 0.9486 - val_loss: 0.0109 - val_acc: 0.9423\n",
      "Epoch 35/40\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0093 - acc: 0.9500 - val_loss: 0.0110 - val_acc: 0.9399\n",
      "Epoch 36/40\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0092 - acc: 0.9486 - val_loss: 0.0110 - val_acc: 0.9423\n",
      "Epoch 37/40\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0091 - acc: 0.9502 - val_loss: 0.0113 - val_acc: 0.9375\n",
      "Epoch 38/40\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0090 - acc: 0.9505 - val_loss: 0.0110 - val_acc: 0.9399\n",
      "Epoch 39/40\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0089 - acc: 0.9524 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 40/40\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0088 - acc: 0.9521 - val_loss: 0.0110 - val_acc: 0.9375\n",
      "Training date and time : \n",
      "2020-05-18 10:33:51\n",
      "Train on 3738 samples, validate on 416 samples\n",
      "Epoch 1/50\n",
      "3738/3738 [==============================] - 0s 61us/sample - loss: 0.0159 - acc: 0.8962 - val_loss: 0.0133 - val_acc: 0.9207\n",
      "Epoch 2/50\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0154 - acc: 0.9042 - val_loss: 0.0133 - val_acc: 0.9279\n",
      "Epoch 3/50\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0149 - acc: 0.9056 - val_loss: 0.0130 - val_acc: 0.9279\n",
      "Epoch 4/50\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0145 - acc: 0.9090 - val_loss: 0.0129 - val_acc: 0.9279\n",
      "Epoch 5/50\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0142 - acc: 0.9133 - val_loss: 0.0127 - val_acc: 0.9327\n",
      "Epoch 6/50\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0139 - acc: 0.9160 - val_loss: 0.0126 - val_acc: 0.9303\n",
      "Epoch 7/50\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0136 - acc: 0.9181 - val_loss: 0.0126 - val_acc: 0.9279\n",
      "Epoch 8/50\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0133 - acc: 0.9195 - val_loss: 0.0126 - val_acc: 0.9327\n",
      "Epoch 9/50\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0131 - acc: 0.9219 - val_loss: 0.0125 - val_acc: 0.9327\n",
      "Epoch 10/50\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0129 - acc: 0.9230 - val_loss: 0.0123 - val_acc: 0.9351\n",
      "Epoch 11/50\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0126 - acc: 0.9238 - val_loss: 0.0125 - val_acc: 0.9351\n",
      "Epoch 12/50\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0124 - acc: 0.9254 - val_loss: 0.0121 - val_acc: 0.9399\n",
      "Epoch 13/50\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0122 - acc: 0.9299 - val_loss: 0.0122 - val_acc: 0.9303\n",
      "Epoch 14/50\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0121 - acc: 0.9267 - val_loss: 0.0119 - val_acc: 0.9375\n",
      "Epoch 15/50\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0119 - acc: 0.9291 - val_loss: 0.0118 - val_acc: 0.9447\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0117 - acc: 0.9312 - val_loss: 0.0119 - val_acc: 0.9423\n",
      "Epoch 17/50\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0115 - acc: 0.9329 - val_loss: 0.0118 - val_acc: 0.9375\n",
      "Epoch 18/50\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0113 - acc: 0.9334 - val_loss: 0.0119 - val_acc: 0.9447\n",
      "Epoch 19/50\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0112 - acc: 0.9329 - val_loss: 0.0117 - val_acc: 0.9351\n",
      "Epoch 20/50\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0111 - acc: 0.9355 - val_loss: 0.0115 - val_acc: 0.9375\n",
      "Epoch 21/50\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0109 - acc: 0.9361 - val_loss: 0.0116 - val_acc: 0.9375\n",
      "Epoch 22/50\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0108 - acc: 0.9387 - val_loss: 0.0114 - val_acc: 0.9375\n",
      "Epoch 23/50\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0106 - acc: 0.9387 - val_loss: 0.0115 - val_acc: 0.9399\n",
      "Epoch 24/50\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0105 - acc: 0.9382 - val_loss: 0.0113 - val_acc: 0.9375\n",
      "Epoch 25/50\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0104 - acc: 0.9395 - val_loss: 0.0112 - val_acc: 0.9375\n",
      "Epoch 26/50\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0103 - acc: 0.9422 - val_loss: 0.0113 - val_acc: 0.9375\n",
      "Epoch 27/50\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0102 - acc: 0.9422 - val_loss: 0.0112 - val_acc: 0.9375\n",
      "Epoch 28/50\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0100 - acc: 0.9411 - val_loss: 0.0112 - val_acc: 0.9399\n",
      "Epoch 29/50\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0099 - acc: 0.9449 - val_loss: 0.0112 - val_acc: 0.9375\n",
      "Epoch 30/50\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0098 - acc: 0.9457 - val_loss: 0.0112 - val_acc: 0.9399\n",
      "Epoch 31/50\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0097 - acc: 0.9465 - val_loss: 0.0113 - val_acc: 0.9375\n",
      "Epoch 32/50\n",
      "3738/3738 [==============================] - 0s 28us/sample - loss: 0.0096 - acc: 0.9460 - val_loss: 0.0112 - val_acc: 0.9399\n",
      "Epoch 33/50\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0095 - acc: 0.9494 - val_loss: 0.0113 - val_acc: 0.9351\n",
      "Epoch 34/50\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0094 - acc: 0.9486 - val_loss: 0.0110 - val_acc: 0.9375\n",
      "Epoch 35/50\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0093 - acc: 0.9484 - val_loss: 0.0109 - val_acc: 0.9375\n",
      "Epoch 36/50\n",
      "3738/3738 [==============================] - 0s 28us/sample - loss: 0.0092 - acc: 0.9500 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 37/50\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0091 - acc: 0.9494 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 38/50\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0090 - acc: 0.9521 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 39/50\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0089 - acc: 0.9518 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 40/50\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0088 - acc: 0.9524 - val_loss: 0.0108 - val_acc: 0.9399\n",
      "Epoch 41/50\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0087 - acc: 0.9537 - val_loss: 0.0109 - val_acc: 0.9375\n",
      "Epoch 42/50\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0086 - acc: 0.9537 - val_loss: 0.0108 - val_acc: 0.9423\n",
      "Epoch 43/50\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0086 - acc: 0.9535 - val_loss: 0.0109 - val_acc: 0.9375\n",
      "Epoch 44/50\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0085 - acc: 0.9537 - val_loss: 0.0108 - val_acc: 0.9399\n",
      "Epoch 45/50\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0084 - acc: 0.9553 - val_loss: 0.0108 - val_acc: 0.9423\n",
      "Epoch 46/50\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0083 - acc: 0.9564 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 47/50\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0082 - acc: 0.9559 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 48/50\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0082 - acc: 0.9572 - val_loss: 0.0107 - val_acc: 0.9447\n",
      "Epoch 49/50\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0081 - acc: 0.9569 - val_loss: 0.0107 - val_acc: 0.9447\n",
      "Epoch 50/50\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0080 - acc: 0.9572 - val_loss: 0.0107 - val_acc: 0.9399\n",
      "Training date and time : \n",
      "2020-05-18 10:33:57\n",
      "Train on 3738 samples, validate on 416 samples\n",
      "Epoch 1/60\n",
      "3738/3738 [==============================] - 0s 65us/sample - loss: 0.0159 - acc: 0.8997 - val_loss: 0.0134 - val_acc: 0.9255\n",
      "Epoch 2/60\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0153 - acc: 0.9040 - val_loss: 0.0131 - val_acc: 0.9255\n",
      "Epoch 3/60\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0149 - acc: 0.9096 - val_loss: 0.0129 - val_acc: 0.9255\n",
      "Epoch 4/60\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0145 - acc: 0.9114 - val_loss: 0.0130 - val_acc: 0.9303\n",
      "Epoch 5/60\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0142 - acc: 0.9133 - val_loss: 0.0130 - val_acc: 0.9279\n",
      "Epoch 6/60\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0139 - acc: 0.9152 - val_loss: 0.0125 - val_acc: 0.9351\n",
      "Epoch 7/60\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0136 - acc: 0.9189 - val_loss: 0.0126 - val_acc: 0.9255\n",
      "Epoch 8/60\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0133 - acc: 0.9208 - val_loss: 0.0125 - val_acc: 0.9327\n",
      "Epoch 9/60\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0131 - acc: 0.9187 - val_loss: 0.0123 - val_acc: 0.9327\n",
      "Epoch 10/60\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0128 - acc: 0.9216 - val_loss: 0.0124 - val_acc: 0.9375\n",
      "Epoch 11/60\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0126 - acc: 0.9227 - val_loss: 0.0122 - val_acc: 0.9351\n",
      "Epoch 12/60\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0124 - acc: 0.9264 - val_loss: 0.0121 - val_acc: 0.9327\n",
      "Epoch 13/60\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0122 - acc: 0.9283 - val_loss: 0.0120 - val_acc: 0.9375\n",
      "Epoch 14/60\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0120 - acc: 0.9286 - val_loss: 0.0121 - val_acc: 0.9375\n",
      "Epoch 15/60\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0119 - acc: 0.9296 - val_loss: 0.0118 - val_acc: 0.9399\n",
      "Epoch 16/60\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0117 - acc: 0.9310 - val_loss: 0.0117 - val_acc: 0.9375\n",
      "Epoch 17/60\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0115 - acc: 0.9323 - val_loss: 0.0118 - val_acc: 0.9399\n",
      "Epoch 18/60\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0114 - acc: 0.9331 - val_loss: 0.0116 - val_acc: 0.9375\n",
      "Epoch 19/60\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0112 - acc: 0.9345 - val_loss: 0.0117 - val_acc: 0.9351\n",
      "Epoch 20/60\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0110 - acc: 0.9350 - val_loss: 0.0116 - val_acc: 0.9375\n",
      "Epoch 21/60\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0109 - acc: 0.9371 - val_loss: 0.0115 - val_acc: 0.9399\n",
      "Epoch 22/60\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0108 - acc: 0.9371 - val_loss: 0.0115 - val_acc: 0.9351\n",
      "Epoch 23/60\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0107 - acc: 0.9385 - val_loss: 0.0115 - val_acc: 0.9375\n",
      "Epoch 24/60\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0105 - acc: 0.9387 - val_loss: 0.0114 - val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/60\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0104 - acc: 0.9417 - val_loss: 0.0114 - val_acc: 0.9375\n",
      "Epoch 26/60\n",
      "3738/3738 [==============================] - 0s 27us/sample - loss: 0.0102 - acc: 0.9419 - val_loss: 0.0114 - val_acc: 0.9375\n",
      "Epoch 27/60\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0101 - acc: 0.9411 - val_loss: 0.0111 - val_acc: 0.9423\n",
      "Epoch 28/60\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0100 - acc: 0.9438 - val_loss: 0.0111 - val_acc: 0.9399\n",
      "Epoch 29/60\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0099 - acc: 0.9422 - val_loss: 0.0112 - val_acc: 0.9375\n",
      "Epoch 30/60\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0098 - acc: 0.9449 - val_loss: 0.0112 - val_acc: 0.9375\n",
      "Epoch 31/60\n",
      "3738/3738 [==============================] - 0s 42us/sample - loss: 0.0097 - acc: 0.9465 - val_loss: 0.0111 - val_acc: 0.9375\n",
      "Epoch 32/60\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0096 - acc: 0.9452 - val_loss: 0.0112 - val_acc: 0.9375\n",
      "Epoch 33/60\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0095 - acc: 0.9484 - val_loss: 0.0111 - val_acc: 0.9375\n",
      "Epoch 34/60\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0094 - acc: 0.9478 - val_loss: 0.0110 - val_acc: 0.9399\n",
      "Epoch 35/60\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0093 - acc: 0.9481 - val_loss: 0.0109 - val_acc: 0.9423\n",
      "Epoch 36/60\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0092 - acc: 0.9497 - val_loss: 0.0110 - val_acc: 0.9375\n",
      "Epoch 37/60\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0091 - acc: 0.9510 - val_loss: 0.0109 - val_acc: 0.9375\n",
      "Epoch 38/60\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0090 - acc: 0.9508 - val_loss: 0.0111 - val_acc: 0.9375\n",
      "Epoch 39/60\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0089 - acc: 0.9521 - val_loss: 0.0109 - val_acc: 0.9423\n",
      "Epoch 40/60\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0088 - acc: 0.9521 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 41/60\n",
      "3738/3738 [==============================] - 0s 42us/sample - loss: 0.0087 - acc: 0.9540 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 42/60\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0087 - acc: 0.9543 - val_loss: 0.0108 - val_acc: 0.9399\n",
      "Epoch 43/60\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0086 - acc: 0.9537 - val_loss: 0.0108 - val_acc: 0.9423\n",
      "Epoch 44/60\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0085 - acc: 0.9540 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 45/60\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0084 - acc: 0.9553 - val_loss: 0.0107 - val_acc: 0.9447\n",
      "Epoch 46/60\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0083 - acc: 0.9567 - val_loss: 0.0107 - val_acc: 0.9399\n",
      "Epoch 47/60\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0082 - acc: 0.9567 - val_loss: 0.0106 - val_acc: 0.9399\n",
      "Epoch 48/60\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0082 - acc: 0.9567 - val_loss: 0.0106 - val_acc: 0.9447\n",
      "Epoch 49/60\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0081 - acc: 0.9561 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 50/60\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0080 - acc: 0.9577 - val_loss: 0.0107 - val_acc: 0.9447\n",
      "Epoch 51/60\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0079 - acc: 0.9596 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 52/60\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0079 - acc: 0.9585 - val_loss: 0.0106 - val_acc: 0.9399\n",
      "Epoch 53/60\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0078 - acc: 0.9599 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 54/60\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0077 - acc: 0.9596 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 55/60\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0077 - acc: 0.9599 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 56/60\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0076 - acc: 0.9604 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 57/60\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0075 - acc: 0.9612 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 58/60\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0075 - acc: 0.9615 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 59/60\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0074 - acc: 0.9612 - val_loss: 0.0106 - val_acc: 0.9399\n",
      "Epoch 60/60\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0074 - acc: 0.9612 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Training date and time : \n",
      "2020-05-18 10:34:05\n",
      "Train on 3738 samples, validate on 416 samples\n",
      "Epoch 1/70\n",
      "3738/3738 [==============================] - 0s 76us/sample - loss: 0.0159 - acc: 0.8991 - val_loss: 0.0135 - val_acc: 0.9231\n",
      "Epoch 2/70\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0153 - acc: 0.9037 - val_loss: 0.0133 - val_acc: 0.9303\n",
      "Epoch 3/70\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0149 - acc: 0.9098 - val_loss: 0.0130 - val_acc: 0.9303\n",
      "Epoch 4/70\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0145 - acc: 0.9109 - val_loss: 0.0131 - val_acc: 0.9303\n",
      "Epoch 5/70\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0142 - acc: 0.9133 - val_loss: 0.0127 - val_acc: 0.9327\n",
      "Epoch 6/70\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0139 - acc: 0.9163 - val_loss: 0.0128 - val_acc: 0.9255\n",
      "Epoch 7/70\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0136 - acc: 0.9181 - val_loss: 0.0125 - val_acc: 0.9351\n",
      "Epoch 8/70\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0133 - acc: 0.9192 - val_loss: 0.0124 - val_acc: 0.9351\n",
      "Epoch 9/70\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0131 - acc: 0.9208 - val_loss: 0.0124 - val_acc: 0.9327\n",
      "Epoch 10/70\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0129 - acc: 0.9213 - val_loss: 0.0123 - val_acc: 0.9327\n",
      "Epoch 11/70\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0126 - acc: 0.9248 - val_loss: 0.0122 - val_acc: 0.9399\n",
      "Epoch 12/70\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0124 - acc: 0.9243 - val_loss: 0.0122 - val_acc: 0.9399\n",
      "Epoch 13/70\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0122 - acc: 0.9280 - val_loss: 0.0120 - val_acc: 0.9399\n",
      "Epoch 14/70\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0120 - acc: 0.9310 - val_loss: 0.0123 - val_acc: 0.9399\n",
      "Epoch 15/70\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0119 - acc: 0.9296 - val_loss: 0.0120 - val_acc: 0.9351\n",
      "Epoch 16/70\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0117 - acc: 0.9304 - val_loss: 0.0117 - val_acc: 0.9399\n",
      "Epoch 17/70\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0115 - acc: 0.9334 - val_loss: 0.0117 - val_acc: 0.9447\n",
      "Epoch 18/70\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0114 - acc: 0.9342 - val_loss: 0.0117 - val_acc: 0.9375\n",
      "Epoch 19/70\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0112 - acc: 0.9358 - val_loss: 0.0115 - val_acc: 0.9399\n",
      "Epoch 20/70\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0111 - acc: 0.9355 - val_loss: 0.0116 - val_acc: 0.9375\n",
      "Epoch 21/70\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0109 - acc: 0.9369 - val_loss: 0.0116 - val_acc: 0.9351\n",
      "Epoch 22/70\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0108 - acc: 0.9363 - val_loss: 0.0116 - val_acc: 0.9375\n",
      "Epoch 23/70\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0107 - acc: 0.9382 - val_loss: 0.0115 - val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/70\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0105 - acc: 0.9401 - val_loss: 0.0113 - val_acc: 0.9375\n",
      "Epoch 25/70\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0104 - acc: 0.9382 - val_loss: 0.0112 - val_acc: 0.9399\n",
      "Epoch 26/70\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0103 - acc: 0.9395 - val_loss: 0.0113 - val_acc: 0.9375\n",
      "Epoch 27/70\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0101 - acc: 0.9419 - val_loss: 0.0113 - val_acc: 0.9375\n",
      "Epoch 28/70\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0100 - acc: 0.9441 - val_loss: 0.0111 - val_acc: 0.9399\n",
      "Epoch 29/70\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0099 - acc: 0.9436 - val_loss: 0.0111 - val_acc: 0.9375\n",
      "Epoch 30/70\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0098 - acc: 0.9457 - val_loss: 0.0113 - val_acc: 0.9375\n",
      "Epoch 31/70\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0097 - acc: 0.9457 - val_loss: 0.0110 - val_acc: 0.9399\n",
      "Epoch 32/70\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0096 - acc: 0.9457 - val_loss: 0.0110 - val_acc: 0.9399\n",
      "Epoch 33/70\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0095 - acc: 0.9465 - val_loss: 0.0110 - val_acc: 0.9423\n",
      "Epoch 34/70\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0094 - acc: 0.9486 - val_loss: 0.0110 - val_acc: 0.9375\n",
      "Epoch 35/70\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0093 - acc: 0.9492 - val_loss: 0.0111 - val_acc: 0.9375\n",
      "Epoch 36/70\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0092 - acc: 0.9489 - val_loss: 0.0110 - val_acc: 0.9375\n",
      "Epoch 37/70\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0091 - acc: 0.9500 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 38/70\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0090 - acc: 0.9513 - val_loss: 0.0110 - val_acc: 0.9375\n",
      "Epoch 39/70\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0089 - acc: 0.9529 - val_loss: 0.0110 - val_acc: 0.9375\n",
      "Epoch 40/70\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0088 - acc: 0.9526 - val_loss: 0.0111 - val_acc: 0.9375\n",
      "Epoch 41/70\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0087 - acc: 0.9532 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 42/70\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0087 - acc: 0.9537 - val_loss: 0.0107 - val_acc: 0.9447\n",
      "Epoch 43/70\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0086 - acc: 0.9543 - val_loss: 0.0108 - val_acc: 0.9399\n",
      "Epoch 44/70\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0085 - acc: 0.9537 - val_loss: 0.0108 - val_acc: 0.9447\n",
      "Epoch 45/70\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0084 - acc: 0.9561 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 46/70\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0083 - acc: 0.9564 - val_loss: 0.0108 - val_acc: 0.9423\n",
      "Epoch 47/70\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0083 - acc: 0.9564 - val_loss: 0.0108 - val_acc: 0.9399\n",
      "Epoch 48/70\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0081 - acc: 0.9572 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 49/70\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0081 - acc: 0.9569 - val_loss: 0.0106 - val_acc: 0.9447\n",
      "Epoch 50/70\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0080 - acc: 0.9580 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 51/70\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0079 - acc: 0.9575 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 52/70\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0079 - acc: 0.9588 - val_loss: 0.0106 - val_acc: 0.9399\n",
      "Epoch 53/70\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0078 - acc: 0.9593 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 54/70\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0077 - acc: 0.9596 - val_loss: 0.0107 - val_acc: 0.9447\n",
      "Epoch 55/70\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0077 - acc: 0.9607 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 56/70\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0076 - acc: 0.9593 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 57/70\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0075 - acc: 0.9593 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 58/70\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0075 - acc: 0.9607 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 59/70\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0074 - acc: 0.9612 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 60/70\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0073 - acc: 0.9615 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 61/70\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0073 - acc: 0.9617 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 62/70\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0072 - acc: 0.9642 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 63/70\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0072 - acc: 0.9631 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 64/70\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0071 - acc: 0.9633 - val_loss: 0.0106 - val_acc: 0.9399\n",
      "Epoch 65/70\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0070 - acc: 0.9650 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 66/70\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0070 - acc: 0.9644 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 67/70\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0069 - acc: 0.9655 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 68/70\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0069 - acc: 0.9658 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 69/70\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0068 - acc: 0.9655 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 70/70\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0067 - acc: 0.9663 - val_loss: 0.0103 - val_acc: 0.9423\n",
      "Training date and time : \n",
      "2020-05-18 10:34:14\n",
      "Train on 3738 samples, validate on 416 samples\n",
      "Epoch 1/80\n",
      "3738/3738 [==============================] - 0s 60us/sample - loss: 0.0159 - acc: 0.8981 - val_loss: 0.0134 - val_acc: 0.9255\n",
      "Epoch 2/80\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0154 - acc: 0.9024 - val_loss: 0.0134 - val_acc: 0.9231\n",
      "Epoch 3/80\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0149 - acc: 0.9082 - val_loss: 0.0130 - val_acc: 0.9279\n",
      "Epoch 4/80\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0145 - acc: 0.9117 - val_loss: 0.0129 - val_acc: 0.9327\n",
      "Epoch 5/80\n",
      "3738/3738 [==============================] - 0s 28us/sample - loss: 0.0142 - acc: 0.9120 - val_loss: 0.0128 - val_acc: 0.9303\n",
      "Epoch 6/80\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0139 - acc: 0.9176 - val_loss: 0.0125 - val_acc: 0.9327\n",
      "Epoch 7/80\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0136 - acc: 0.9168 - val_loss: 0.0127 - val_acc: 0.9279\n",
      "Epoch 8/80\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0133 - acc: 0.9205 - val_loss: 0.0125 - val_acc: 0.9327\n",
      "Epoch 9/80\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0131 - acc: 0.9200 - val_loss: 0.0123 - val_acc: 0.9351\n",
      "Epoch 10/80\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0128 - acc: 0.9224 - val_loss: 0.0123 - val_acc: 0.9375\n",
      "Epoch 11/80\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0126 - acc: 0.9246 - val_loss: 0.0123 - val_acc: 0.9327\n",
      "Epoch 12/80\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0124 - acc: 0.9243 - val_loss: 0.0121 - val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/80\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0122 - acc: 0.9259 - val_loss: 0.0123 - val_acc: 0.9423\n",
      "Epoch 14/80\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0120 - acc: 0.9291 - val_loss: 0.0119 - val_acc: 0.9327\n",
      "Epoch 15/80\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0119 - acc: 0.9288 - val_loss: 0.0120 - val_acc: 0.9351\n",
      "Epoch 16/80\n",
      "3738/3738 [==============================] - 0s 29us/sample - loss: 0.0117 - acc: 0.9326 - val_loss: 0.0118 - val_acc: 0.9423\n",
      "Epoch 17/80\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0115 - acc: 0.9323 - val_loss: 0.0118 - val_acc: 0.9399\n",
      "Epoch 18/80\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0114 - acc: 0.9326 - val_loss: 0.0118 - val_acc: 0.9399\n",
      "Epoch 19/80\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0112 - acc: 0.9358 - val_loss: 0.0118 - val_acc: 0.9375\n",
      "Epoch 20/80\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0111 - acc: 0.9342 - val_loss: 0.0116 - val_acc: 0.9375\n",
      "Epoch 21/80\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0109 - acc: 0.9361 - val_loss: 0.0114 - val_acc: 0.9375\n",
      "Epoch 22/80\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0108 - acc: 0.9377 - val_loss: 0.0116 - val_acc: 0.9447\n",
      "Epoch 23/80\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0106 - acc: 0.9395 - val_loss: 0.0116 - val_acc: 0.9375\n",
      "Epoch 24/80\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0105 - acc: 0.9393 - val_loss: 0.0113 - val_acc: 0.9375\n",
      "Epoch 25/80\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0104 - acc: 0.9411 - val_loss: 0.0114 - val_acc: 0.9423\n",
      "Epoch 26/80\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0102 - acc: 0.9406 - val_loss: 0.0115 - val_acc: 0.9399\n",
      "Epoch 27/80\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0102 - acc: 0.9417 - val_loss: 0.0113 - val_acc: 0.9375\n",
      "Epoch 28/80\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0100 - acc: 0.9438 - val_loss: 0.0113 - val_acc: 0.9399\n",
      "Epoch 29/80\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0099 - acc: 0.9444 - val_loss: 0.0112 - val_acc: 0.9375\n",
      "Epoch 30/80\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0098 - acc: 0.9465 - val_loss: 0.0111 - val_acc: 0.9399\n",
      "Epoch 31/80\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0097 - acc: 0.9457 - val_loss: 0.0111 - val_acc: 0.9351\n",
      "Epoch 32/80\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0096 - acc: 0.9462 - val_loss: 0.0111 - val_acc: 0.9399\n",
      "Epoch 33/80\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0095 - acc: 0.9470 - val_loss: 0.0110 - val_acc: 0.9399\n",
      "Epoch 34/80\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0093 - acc: 0.9486 - val_loss: 0.0112 - val_acc: 0.9375\n",
      "Epoch 35/80\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0093 - acc: 0.9497 - val_loss: 0.0112 - val_acc: 0.9375\n",
      "Epoch 36/80\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0092 - acc: 0.9508 - val_loss: 0.0111 - val_acc: 0.9375\n",
      "Epoch 37/80\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0091 - acc: 0.9510 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 38/80\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0090 - acc: 0.9518 - val_loss: 0.0109 - val_acc: 0.9423\n",
      "Epoch 39/80\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0089 - acc: 0.9508 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 40/80\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0088 - acc: 0.9524 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 41/80\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0087 - acc: 0.9529 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 42/80\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0086 - acc: 0.9543 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 43/80\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0086 - acc: 0.9548 - val_loss: 0.0106 - val_acc: 0.9399\n",
      "Epoch 44/80\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0085 - acc: 0.9537 - val_loss: 0.0109 - val_acc: 0.9375\n",
      "Epoch 45/80\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0084 - acc: 0.9551 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 46/80\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0083 - acc: 0.9564 - val_loss: 0.0109 - val_acc: 0.9423\n",
      "Epoch 47/80\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0082 - acc: 0.9559 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 48/80\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0082 - acc: 0.9575 - val_loss: 0.0108 - val_acc: 0.9447\n",
      "Epoch 49/80\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0081 - acc: 0.9569 - val_loss: 0.0107 - val_acc: 0.9399\n",
      "Epoch 50/80\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0080 - acc: 0.9577 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 51/80\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0079 - acc: 0.9580 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 52/80\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0079 - acc: 0.9580 - val_loss: 0.0106 - val_acc: 0.9399\n",
      "Epoch 53/80\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0078 - acc: 0.9599 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 54/80\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0077 - acc: 0.9601 - val_loss: 0.0106 - val_acc: 0.9399\n",
      "Epoch 55/80\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0077 - acc: 0.9593 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 56/80\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0076 - acc: 0.9596 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 57/80\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0076 - acc: 0.9604 - val_loss: 0.0107 - val_acc: 0.9399\n",
      "Epoch 58/80\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0075 - acc: 0.9607 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 59/80\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0074 - acc: 0.9612 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 60/80\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0074 - acc: 0.9625 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 61/80\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0073 - acc: 0.9617 - val_loss: 0.0106 - val_acc: 0.9399\n",
      "Epoch 62/80\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0072 - acc: 0.9620 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 63/80\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0072 - acc: 0.9623 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 64/80\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0071 - acc: 0.9631 - val_loss: 0.0105 - val_acc: 0.9399\n",
      "Epoch 65/80\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0071 - acc: 0.9633 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 66/80\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0070 - acc: 0.9644 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 67/80\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0069 - acc: 0.9639 - val_loss: 0.0106 - val_acc: 0.9399\n",
      "Epoch 68/80\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0069 - acc: 0.9660 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 69/80\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0068 - acc: 0.9652 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 70/80\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0068 - acc: 0.9650 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 71/80\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0067 - acc: 0.9650 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 72/80\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0066 - acc: 0.9663 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 73/80\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0066 - acc: 0.9658 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 74/80\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0065 - acc: 0.9658 - val_loss: 0.0103 - val_acc: 0.9423\n",
      "Epoch 75/80\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0065 - acc: 0.9658 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 76/80\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0064 - acc: 0.9676 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 77/80\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0064 - acc: 0.9682 - val_loss: 0.0105 - val_acc: 0.9399\n",
      "Epoch 78/80\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0063 - acc: 0.9676 - val_loss: 0.0105 - val_acc: 0.9399\n",
      "Epoch 79/80\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0063 - acc: 0.9684 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 80/80\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0062 - acc: 0.9692 - val_loss: 0.0105 - val_acc: 0.9399\n",
      "Training date and time : \n",
      "2020-05-18 10:34:24\n",
      "Train on 3738 samples, validate on 416 samples\n",
      "Epoch 1/90\n",
      "3738/3738 [==============================] - 0s 65us/sample - loss: 0.0159 - acc: 0.9021 - val_loss: 0.0133 - val_acc: 0.9231\n",
      "Epoch 2/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0153 - acc: 0.9064 - val_loss: 0.0134 - val_acc: 0.9255\n",
      "Epoch 3/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0149 - acc: 0.9058 - val_loss: 0.0131 - val_acc: 0.9255\n",
      "Epoch 4/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0145 - acc: 0.9106 - val_loss: 0.0129 - val_acc: 0.9303\n",
      "Epoch 5/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0142 - acc: 0.9125 - val_loss: 0.0129 - val_acc: 0.9279\n",
      "Epoch 6/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0139 - acc: 0.9144 - val_loss: 0.0125 - val_acc: 0.9327\n",
      "Epoch 7/90\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0136 - acc: 0.9171 - val_loss: 0.0125 - val_acc: 0.9279\n",
      "Epoch 8/90\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0133 - acc: 0.9192 - val_loss: 0.0125 - val_acc: 0.9303\n",
      "Epoch 9/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0131 - acc: 0.9216 - val_loss: 0.0125 - val_acc: 0.9303\n",
      "Epoch 10/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0129 - acc: 0.9232 - val_loss: 0.0124 - val_acc: 0.9351\n",
      "Epoch 11/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0126 - acc: 0.9232 - val_loss: 0.0121 - val_acc: 0.9351\n",
      "Epoch 12/90\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0124 - acc: 0.9275 - val_loss: 0.0121 - val_acc: 0.9303\n",
      "Epoch 13/90\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0122 - acc: 0.9267 - val_loss: 0.0120 - val_acc: 0.9375\n",
      "Epoch 14/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0120 - acc: 0.9291 - val_loss: 0.0120 - val_acc: 0.9375\n",
      "Epoch 15/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0118 - acc: 0.9318 - val_loss: 0.0119 - val_acc: 0.9375\n",
      "Epoch 16/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0117 - acc: 0.9326 - val_loss: 0.0119 - val_acc: 0.9375\n",
      "Epoch 17/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0115 - acc: 0.9310 - val_loss: 0.0116 - val_acc: 0.9351\n",
      "Epoch 18/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0114 - acc: 0.9342 - val_loss: 0.0116 - val_acc: 0.9375\n",
      "Epoch 19/90\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0112 - acc: 0.9350 - val_loss: 0.0117 - val_acc: 0.9375\n",
      "Epoch 20/90\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0110 - acc: 0.9363 - val_loss: 0.0116 - val_acc: 0.9375\n",
      "Epoch 21/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0109 - acc: 0.9374 - val_loss: 0.0116 - val_acc: 0.9399\n",
      "Epoch 22/90\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0108 - acc: 0.9377 - val_loss: 0.0115 - val_acc: 0.9423\n",
      "Epoch 23/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0106 - acc: 0.9377 - val_loss: 0.0115 - val_acc: 0.9375\n",
      "Epoch 24/90\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0105 - acc: 0.9390 - val_loss: 0.0114 - val_acc: 0.9399\n",
      "Epoch 25/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0104 - acc: 0.9398 - val_loss: 0.0115 - val_acc: 0.9399\n",
      "Epoch 26/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0103 - acc: 0.9406 - val_loss: 0.0112 - val_acc: 0.9399\n",
      "Epoch 27/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0101 - acc: 0.9433 - val_loss: 0.0112 - val_acc: 0.9423\n",
      "Epoch 28/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0100 - acc: 0.9436 - val_loss: 0.0111 - val_acc: 0.9399\n",
      "Epoch 29/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0099 - acc: 0.9428 - val_loss: 0.0112 - val_acc: 0.9375\n",
      "Epoch 30/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0098 - acc: 0.9470 - val_loss: 0.0112 - val_acc: 0.9399\n",
      "Epoch 31/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0097 - acc: 0.9454 - val_loss: 0.0111 - val_acc: 0.9399\n",
      "Epoch 32/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0095 - acc: 0.9476 - val_loss: 0.0111 - val_acc: 0.9399\n",
      "Epoch 33/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0095 - acc: 0.9486 - val_loss: 0.0111 - val_acc: 0.9375\n",
      "Epoch 34/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0094 - acc: 0.9481 - val_loss: 0.0110 - val_acc: 0.9375\n",
      "Epoch 35/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0093 - acc: 0.9494 - val_loss: 0.0110 - val_acc: 0.9423\n",
      "Epoch 36/90\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0092 - acc: 0.9497 - val_loss: 0.0110 - val_acc: 0.9399\n",
      "Epoch 37/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0091 - acc: 0.9500 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 38/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0090 - acc: 0.9510 - val_loss: 0.0111 - val_acc: 0.9375\n",
      "Epoch 39/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0089 - acc: 0.9518 - val_loss: 0.0110 - val_acc: 0.9399\n",
      "Epoch 40/90\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0088 - acc: 0.9526 - val_loss: 0.0109 - val_acc: 0.9423\n",
      "Epoch 41/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0087 - acc: 0.9526 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 42/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0086 - acc: 0.9529 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 43/90\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0086 - acc: 0.9540 - val_loss: 0.0109 - val_acc: 0.9375\n",
      "Epoch 44/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0085 - acc: 0.9537 - val_loss: 0.0107 - val_acc: 0.9399\n",
      "Epoch 45/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0084 - acc: 0.9564 - val_loss: 0.0109 - val_acc: 0.9423\n",
      "Epoch 46/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0083 - acc: 0.9548 - val_loss: 0.0107 - val_acc: 0.9399\n",
      "Epoch 47/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0082 - acc: 0.9567 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 48/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0082 - acc: 0.9575 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 49/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0081 - acc: 0.9580 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 50/90\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0080 - acc: 0.9572 - val_loss: 0.0106 - val_acc: 0.9399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0079 - acc: 0.9580 - val_loss: 0.0106 - val_acc: 0.9399\n",
      "Epoch 52/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0079 - acc: 0.9583 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 53/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0078 - acc: 0.9599 - val_loss: 0.0108 - val_acc: 0.9399\n",
      "Epoch 54/90\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0077 - acc: 0.9599 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 55/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0077 - acc: 0.9601 - val_loss: 0.0107 - val_acc: 0.9399\n",
      "Epoch 56/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0076 - acc: 0.9601 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 57/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0075 - acc: 0.9601 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 58/90\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0075 - acc: 0.9609 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 59/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0074 - acc: 0.9628 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 60/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0074 - acc: 0.9615 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 61/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0073 - acc: 0.9612 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 62/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0072 - acc: 0.9633 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 63/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0072 - acc: 0.9631 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 64/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0071 - acc: 0.9636 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 65/90\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0070 - acc: 0.9631 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 66/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0070 - acc: 0.9644 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 67/90\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0069 - acc: 0.9647 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 68/90\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0069 - acc: 0.9658 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 69/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0068 - acc: 0.9663 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 70/90\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0068 - acc: 0.9652 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 71/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0067 - acc: 0.9668 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 72/90\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0067 - acc: 0.9663 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 73/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0066 - acc: 0.9666 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 74/90\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0065 - acc: 0.9666 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 75/90\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0065 - acc: 0.9674 - val_loss: 0.0103 - val_acc: 0.9423\n",
      "Epoch 76/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0064 - acc: 0.9676 - val_loss: 0.0103 - val_acc: 0.9399\n",
      "Epoch 77/90\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0064 - acc: 0.9676 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 78/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0063 - acc: 0.9690 - val_loss: 0.0104 - val_acc: 0.9375\n",
      "Epoch 79/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0063 - acc: 0.9682 - val_loss: 0.0103 - val_acc: 0.9423\n",
      "Epoch 80/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0062 - acc: 0.9682 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 81/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0062 - acc: 0.9690 - val_loss: 0.0105 - val_acc: 0.9351\n",
      "Epoch 82/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0061 - acc: 0.9682 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 83/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0061 - acc: 0.9692 - val_loss: 0.0105 - val_acc: 0.9399\n",
      "Epoch 84/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0060 - acc: 0.9687 - val_loss: 0.0103 - val_acc: 0.9423\n",
      "Epoch 85/90\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0060 - acc: 0.9698 - val_loss: 0.0105 - val_acc: 0.9399\n",
      "Epoch 86/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0060 - acc: 0.9695 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 87/90\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0059 - acc: 0.9698 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 88/90\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0059 - acc: 0.9703 - val_loss: 0.0103 - val_acc: 0.9399\n",
      "Epoch 89/90\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0058 - acc: 0.9703 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 90/90\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0058 - acc: 0.9706 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Training date and time : \n",
      "2020-05-18 10:34:36\n",
      "Train on 3738 samples, validate on 416 samples\n",
      "Epoch 1/100\n",
      "3738/3738 [==============================] - 0s 64us/sample - loss: 0.0158 - acc: 0.9018 - val_loss: 0.0133 - val_acc: 0.9231\n",
      "Epoch 2/100\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0154 - acc: 0.9045 - val_loss: 0.0132 - val_acc: 0.9255\n",
      "Epoch 3/100\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0149 - acc: 0.9058 - val_loss: 0.0131 - val_acc: 0.9279\n",
      "Epoch 4/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0145 - acc: 0.9101 - val_loss: 0.0128 - val_acc: 0.9327\n",
      "Epoch 5/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0142 - acc: 0.9149 - val_loss: 0.0127 - val_acc: 0.9279\n",
      "Epoch 6/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0138 - acc: 0.9163 - val_loss: 0.0125 - val_acc: 0.9303\n",
      "Epoch 7/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0136 - acc: 0.9179 - val_loss: 0.0126 - val_acc: 0.9327\n",
      "Epoch 8/100\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0133 - acc: 0.9200 - val_loss: 0.0125 - val_acc: 0.9303\n",
      "Epoch 9/100\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0130 - acc: 0.9208 - val_loss: 0.0123 - val_acc: 0.9327\n",
      "Epoch 10/100\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0129 - acc: 0.9238 - val_loss: 0.0123 - val_acc: 0.9327\n",
      "Epoch 11/100\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0127 - acc: 0.9254 - val_loss: 0.0123 - val_acc: 0.9351\n",
      "Epoch 12/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0124 - acc: 0.9254 - val_loss: 0.0120 - val_acc: 0.9351\n",
      "Epoch 13/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0122 - acc: 0.9267 - val_loss: 0.0120 - val_acc: 0.9351\n",
      "Epoch 14/100\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0120 - acc: 0.9302 - val_loss: 0.0120 - val_acc: 0.9351\n",
      "Epoch 15/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0119 - acc: 0.9315 - val_loss: 0.0119 - val_acc: 0.9351\n",
      "Epoch 16/100\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0117 - acc: 0.9323 - val_loss: 0.0118 - val_acc: 0.9351\n",
      "Epoch 17/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0115 - acc: 0.9334 - val_loss: 0.0117 - val_acc: 0.9447\n",
      "Epoch 18/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0114 - acc: 0.9334 - val_loss: 0.0116 - val_acc: 0.9399\n",
      "Epoch 19/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0112 - acc: 0.9353 - val_loss: 0.0115 - val_acc: 0.9399\n",
      "Epoch 20/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0111 - acc: 0.9371 - val_loss: 0.0115 - val_acc: 0.9375\n",
      "Epoch 21/100\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0109 - acc: 0.9382 - val_loss: 0.0115 - val_acc: 0.9375\n",
      "Epoch 22/100\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0108 - acc: 0.9382 - val_loss: 0.0116 - val_acc: 0.9351\n",
      "Epoch 23/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0106 - acc: 0.9387 - val_loss: 0.0115 - val_acc: 0.9375\n",
      "Epoch 24/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0105 - acc: 0.9403 - val_loss: 0.0114 - val_acc: 0.9375\n",
      "Epoch 25/100\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0103 - acc: 0.9406 - val_loss: 0.0115 - val_acc: 0.9375\n",
      "Epoch 26/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0103 - acc: 0.9403 - val_loss: 0.0113 - val_acc: 0.9375\n",
      "Epoch 27/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0101 - acc: 0.9436 - val_loss: 0.0111 - val_acc: 0.9399\n",
      "Epoch 28/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0100 - acc: 0.9430 - val_loss: 0.0112 - val_acc: 0.9423\n",
      "Epoch 29/100\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0099 - acc: 0.9444 - val_loss: 0.0111 - val_acc: 0.9375\n",
      "Epoch 30/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0098 - acc: 0.9441 - val_loss: 0.0111 - val_acc: 0.9423\n",
      "Epoch 31/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0097 - acc: 0.9470 - val_loss: 0.0112 - val_acc: 0.9375\n",
      "Epoch 32/100\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0096 - acc: 0.9465 - val_loss: 0.0110 - val_acc: 0.9399\n",
      "Epoch 33/100\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0095 - acc: 0.9473 - val_loss: 0.0111 - val_acc: 0.9399\n",
      "Epoch 34/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0094 - acc: 0.9476 - val_loss: 0.0110 - val_acc: 0.9423\n",
      "Epoch 35/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0093 - acc: 0.9486 - val_loss: 0.0112 - val_acc: 0.9399\n",
      "Epoch 36/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0092 - acc: 0.9508 - val_loss: 0.0111 - val_acc: 0.9423\n",
      "Epoch 37/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0091 - acc: 0.9505 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 38/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0090 - acc: 0.9521 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 39/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0089 - acc: 0.9510 - val_loss: 0.0109 - val_acc: 0.9375\n",
      "Epoch 40/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0088 - acc: 0.9524 - val_loss: 0.0108 - val_acc: 0.9423\n",
      "Epoch 41/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0087 - acc: 0.9532 - val_loss: 0.0110 - val_acc: 0.9375\n",
      "Epoch 42/100\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0086 - acc: 0.9540 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 43/100\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0086 - acc: 0.9548 - val_loss: 0.0108 - val_acc: 0.9375\n",
      "Epoch 44/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0085 - acc: 0.9532 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 45/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0084 - acc: 0.9551 - val_loss: 0.0108 - val_acc: 0.9399\n",
      "Epoch 46/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0083 - acc: 0.9553 - val_loss: 0.0108 - val_acc: 0.9423\n",
      "Epoch 47/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0083 - acc: 0.9559 - val_loss: 0.0108 - val_acc: 0.9423\n",
      "Epoch 48/100\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0082 - acc: 0.9575 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 49/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0081 - acc: 0.9569 - val_loss: 0.0107 - val_acc: 0.9447\n",
      "Epoch 50/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0080 - acc: 0.9583 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 51/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0080 - acc: 0.9580 - val_loss: 0.0107 - val_acc: 0.9399\n",
      "Epoch 52/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0079 - acc: 0.9588 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 53/100\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0078 - acc: 0.9599 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 54/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0078 - acc: 0.9591 - val_loss: 0.0106 - val_acc: 0.9399\n",
      "Epoch 55/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0077 - acc: 0.9607 - val_loss: 0.0106 - val_acc: 0.9399\n",
      "Epoch 56/100\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0076 - acc: 0.9601 - val_loss: 0.0108 - val_acc: 0.9375\n",
      "Epoch 57/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0076 - acc: 0.9604 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 58/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0075 - acc: 0.9607 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 59/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0074 - acc: 0.9609 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 60/100\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0073 - acc: 0.9612 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 61/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0073 - acc: 0.9617 - val_loss: 0.0107 - val_acc: 0.9399\n",
      "Epoch 62/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0072 - acc: 0.9620 - val_loss: 0.0107 - val_acc: 0.9399\n",
      "Epoch 63/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0072 - acc: 0.9636 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 64/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0071 - acc: 0.9644 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 65/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0071 - acc: 0.9636 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 66/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0070 - acc: 0.9639 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 67/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0070 - acc: 0.9650 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 68/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0069 - acc: 0.9658 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 69/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0068 - acc: 0.9642 - val_loss: 0.0106 - val_acc: 0.9399\n",
      "Epoch 70/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0068 - acc: 0.9650 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 71/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0067 - acc: 0.9660 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 72/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0066 - acc: 0.9666 - val_loss: 0.0107 - val_acc: 0.9375\n",
      "Epoch 73/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0066 - acc: 0.9671 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 74/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0065 - acc: 0.9666 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 75/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0065 - acc: 0.9674 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 76/100\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0064 - acc: 0.9668 - val_loss: 0.0103 - val_acc: 0.9423\n",
      "Epoch 77/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0064 - acc: 0.9676 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0063 - acc: 0.9674 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 79/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0063 - acc: 0.9679 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 80/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0062 - acc: 0.9682 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 81/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0062 - acc: 0.9695 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 82/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0061 - acc: 0.9682 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 83/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0061 - acc: 0.9690 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 84/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0060 - acc: 0.9695 - val_loss: 0.0103 - val_acc: 0.9423\n",
      "Epoch 85/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0060 - acc: 0.9690 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 86/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0060 - acc: 0.9700 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 87/100\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0059 - acc: 0.9695 - val_loss: 0.0103 - val_acc: 0.9399\n",
      "Epoch 88/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0059 - acc: 0.9706 - val_loss: 0.0103 - val_acc: 0.9399\n",
      "Epoch 89/100\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0058 - acc: 0.9700 - val_loss: 0.0103 - val_acc: 0.9399\n",
      "Epoch 90/100\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0058 - acc: 0.9714 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 91/100\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0057 - acc: 0.9703 - val_loss: 0.0103 - val_acc: 0.9375\n",
      "Epoch 92/100\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0057 - acc: 0.9719 - val_loss: 0.0103 - val_acc: 0.9375\n",
      "Epoch 93/100\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0057 - acc: 0.9714 - val_loss: 0.0102 - val_acc: 0.9375\n",
      "Epoch 94/100\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0056 - acc: 0.9714 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 95/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0056 - acc: 0.9714 - val_loss: 0.0103 - val_acc: 0.9351\n",
      "Epoch 96/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0055 - acc: 0.9722 - val_loss: 0.0102 - val_acc: 0.9447\n",
      "Epoch 97/100\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0055 - acc: 0.9730 - val_loss: 0.0102 - val_acc: 0.9399\n",
      "Epoch 98/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0055 - acc: 0.9722 - val_loss: 0.0102 - val_acc: 0.9447\n",
      "Epoch 99/100\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0054 - acc: 0.9730 - val_loss: 0.0103 - val_acc: 0.9399\n",
      "Epoch 100/100\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0054 - acc: 0.9730 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Training date and time : \n",
      "2020-05-18 10:34:48\n",
      "Train on 3738 samples, validate on 416 samples\n",
      "Epoch 1/110\n",
      "3738/3738 [==============================] - 0s 68us/sample - loss: 0.0159 - acc: 0.9010 - val_loss: 0.0134 - val_acc: 0.9255\n",
      "Epoch 2/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0153 - acc: 0.9048 - val_loss: 0.0133 - val_acc: 0.9255\n",
      "Epoch 3/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0149 - acc: 0.9088 - val_loss: 0.0129 - val_acc: 0.9231\n",
      "Epoch 4/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0146 - acc: 0.9098 - val_loss: 0.0128 - val_acc: 0.9279\n",
      "Epoch 5/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0142 - acc: 0.9136 - val_loss: 0.0127 - val_acc: 0.9327\n",
      "Epoch 6/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0139 - acc: 0.9165 - val_loss: 0.0128 - val_acc: 0.9327\n",
      "Epoch 7/110\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0136 - acc: 0.9179 - val_loss: 0.0125 - val_acc: 0.9351\n",
      "Epoch 8/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0133 - acc: 0.9192 - val_loss: 0.0125 - val_acc: 0.9327\n",
      "Epoch 9/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0130 - acc: 0.9222 - val_loss: 0.0124 - val_acc: 0.9423\n",
      "Epoch 10/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0129 - acc: 0.9219 - val_loss: 0.0121 - val_acc: 0.9327\n",
      "Epoch 11/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0126 - acc: 0.9259 - val_loss: 0.0121 - val_acc: 0.9375\n",
      "Epoch 12/110\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0124 - acc: 0.9251 - val_loss: 0.0120 - val_acc: 0.9375\n",
      "Epoch 13/110\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0122 - acc: 0.9286 - val_loss: 0.0119 - val_acc: 0.9423\n",
      "Epoch 14/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0120 - acc: 0.9286 - val_loss: 0.0120 - val_acc: 0.9375\n",
      "Epoch 15/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0118 - acc: 0.9315 - val_loss: 0.0120 - val_acc: 0.9399\n",
      "Epoch 16/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0117 - acc: 0.9320 - val_loss: 0.0120 - val_acc: 0.9351\n",
      "Epoch 17/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0115 - acc: 0.9323 - val_loss: 0.0118 - val_acc: 0.9351\n",
      "Epoch 18/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0114 - acc: 0.9323 - val_loss: 0.0118 - val_acc: 0.9375\n",
      "Epoch 19/110\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0112 - acc: 0.9353 - val_loss: 0.0115 - val_acc: 0.9375\n",
      "Epoch 20/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0111 - acc: 0.9355 - val_loss: 0.0114 - val_acc: 0.9423\n",
      "Epoch 21/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0109 - acc: 0.9369 - val_loss: 0.0113 - val_acc: 0.9375\n",
      "Epoch 22/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0108 - acc: 0.9387 - val_loss: 0.0114 - val_acc: 0.9375\n",
      "Epoch 23/110\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0107 - acc: 0.9374 - val_loss: 0.0113 - val_acc: 0.9399\n",
      "Epoch 24/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0105 - acc: 0.9401 - val_loss: 0.0115 - val_acc: 0.9423\n",
      "Epoch 25/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0104 - acc: 0.9411 - val_loss: 0.0115 - val_acc: 0.9399\n",
      "Epoch 26/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0103 - acc: 0.9411 - val_loss: 0.0112 - val_acc: 0.9423\n",
      "Epoch 27/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0101 - acc: 0.9436 - val_loss: 0.0112 - val_acc: 0.9447\n",
      "Epoch 28/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0100 - acc: 0.9436 - val_loss: 0.0113 - val_acc: 0.9399\n",
      "Epoch 29/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0099 - acc: 0.9441 - val_loss: 0.0112 - val_acc: 0.9375\n",
      "Epoch 30/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0098 - acc: 0.9436 - val_loss: 0.0111 - val_acc: 0.9375\n",
      "Epoch 31/110\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0097 - acc: 0.9481 - val_loss: 0.0111 - val_acc: 0.9423\n",
      "Epoch 32/110\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0096 - acc: 0.9457 - val_loss: 0.0111 - val_acc: 0.9375\n",
      "Epoch 33/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0095 - acc: 0.9470 - val_loss: 0.0112 - val_acc: 0.9375\n",
      "Epoch 34/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0094 - acc: 0.9497 - val_loss: 0.0110 - val_acc: 0.9375\n",
      "Epoch 35/110\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0093 - acc: 0.9489 - val_loss: 0.0111 - val_acc: 0.9375\n",
      "Epoch 36/110\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0092 - acc: 0.9500 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 37/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0091 - acc: 0.9505 - val_loss: 0.0109 - val_acc: 0.9423\n",
      "Epoch 38/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0090 - acc: 0.9524 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 39/110\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0089 - acc: 0.9524 - val_loss: 0.0109 - val_acc: 0.9423\n",
      "Epoch 40/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0088 - acc: 0.9526 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 41/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0087 - acc: 0.9524 - val_loss: 0.0108 - val_acc: 0.9423\n",
      "Epoch 42/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0086 - acc: 0.9540 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 43/110\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0085 - acc: 0.9529 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 44/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0085 - acc: 0.9543 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 45/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0084 - acc: 0.9551 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 46/110\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0083 - acc: 0.9559 - val_loss: 0.0107 - val_acc: 0.9447\n",
      "Epoch 47/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0082 - acc: 0.9564 - val_loss: 0.0108 - val_acc: 0.9375\n",
      "Epoch 48/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0082 - acc: 0.9567 - val_loss: 0.0108 - val_acc: 0.9423\n",
      "Epoch 49/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0081 - acc: 0.9583 - val_loss: 0.0108 - val_acc: 0.9375\n",
      "Epoch 50/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0080 - acc: 0.9575 - val_loss: 0.0107 - val_acc: 0.9399\n",
      "Epoch 51/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0079 - acc: 0.9572 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 52/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0078 - acc: 0.9591 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 53/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0078 - acc: 0.9591 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 54/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0077 - acc: 0.9596 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 55/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0077 - acc: 0.9601 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 56/110\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0076 - acc: 0.9596 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 57/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0075 - acc: 0.9599 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 58/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0075 - acc: 0.9617 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 59/110\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0074 - acc: 0.9612 - val_loss: 0.0105 - val_acc: 0.9399\n",
      "Epoch 60/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0073 - acc: 0.9609 - val_loss: 0.0106 - val_acc: 0.9447\n",
      "Epoch 61/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0073 - acc: 0.9609 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 62/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0072 - acc: 0.9633 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 63/110\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0072 - acc: 0.9631 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 64/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0071 - acc: 0.9628 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 65/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0071 - acc: 0.9639 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 66/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0070 - acc: 0.9639 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 67/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0069 - acc: 0.9642 - val_loss: 0.0103 - val_acc: 0.9423\n",
      "Epoch 68/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0069 - acc: 0.9650 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 69/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0068 - acc: 0.9655 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 70/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0067 - acc: 0.9650 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 71/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0067 - acc: 0.9655 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 72/110\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0067 - acc: 0.9655 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 73/110\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0066 - acc: 0.9658 - val_loss: 0.0105 - val_acc: 0.9399\n",
      "Epoch 74/110\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0065 - acc: 0.9666 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 75/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0065 - acc: 0.9679 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 76/110\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0064 - acc: 0.9671 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 77/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0064 - acc: 0.9674 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 78/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0063 - acc: 0.9679 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 79/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0063 - acc: 0.9679 - val_loss: 0.0103 - val_acc: 0.9423\n",
      "Epoch 80/110\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0062 - acc: 0.9682 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 81/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0062 - acc: 0.9684 - val_loss: 0.0103 - val_acc: 0.9423\n",
      "Epoch 82/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0061 - acc: 0.9692 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 83/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0061 - acc: 0.9698 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 84/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0060 - acc: 0.9692 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 85/110\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0060 - acc: 0.9698 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 86/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0060 - acc: 0.9706 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 87/110\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0059 - acc: 0.9700 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 88/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0059 - acc: 0.9711 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 89/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0058 - acc: 0.9711 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 90/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0058 - acc: 0.9711 - val_loss: 0.0103 - val_acc: 0.9399\n",
      "Epoch 91/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0057 - acc: 0.9703 - val_loss: 0.0103 - val_acc: 0.9423\n",
      "Epoch 92/110\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0057 - acc: 0.9714 - val_loss: 0.0103 - val_acc: 0.9423\n",
      "Epoch 93/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0057 - acc: 0.9716 - val_loss: 0.0103 - val_acc: 0.9423\n",
      "Epoch 94/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0056 - acc: 0.9724 - val_loss: 0.0101 - val_acc: 0.9447\n",
      "Epoch 95/110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0056 - acc: 0.9716 - val_loss: 0.0103 - val_acc: 0.9399\n",
      "Epoch 96/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0055 - acc: 0.9722 - val_loss: 0.0103 - val_acc: 0.9399\n",
      "Epoch 97/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0055 - acc: 0.9727 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 98/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0055 - acc: 0.9735 - val_loss: 0.0102 - val_acc: 0.9447\n",
      "Epoch 99/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0054 - acc: 0.9735 - val_loss: 0.0102 - val_acc: 0.9447\n",
      "Epoch 100/110\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0054 - acc: 0.9732 - val_loss: 0.0101 - val_acc: 0.9447\n",
      "Epoch 101/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0054 - acc: 0.9741 - val_loss: 0.0102 - val_acc: 0.9399\n",
      "Epoch 102/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0053 - acc: 0.9738 - val_loss: 0.0102 - val_acc: 0.9399\n",
      "Epoch 103/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0053 - acc: 0.9730 - val_loss: 0.0103 - val_acc: 0.9399\n",
      "Epoch 104/110\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0053 - acc: 0.9735 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 105/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0052 - acc: 0.9743 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 106/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0052 - acc: 0.9746 - val_loss: 0.0101 - val_acc: 0.9447\n",
      "Epoch 107/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0052 - acc: 0.9746 - val_loss: 0.0102 - val_acc: 0.9399\n",
      "Epoch 108/110\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0051 - acc: 0.9749 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 109/110\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0051 - acc: 0.9751 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 110/110\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0051 - acc: 0.9754 - val_loss: 0.0102 - val_acc: 0.9399\n",
      "Training date and time : \n",
      "2020-05-18 10:35:02\n",
      "Train on 3738 samples, validate on 416 samples\n",
      "Epoch 1/120\n",
      "3738/3738 [==============================] - 0s 69us/sample - loss: 0.0159 - acc: 0.8989 - val_loss: 0.0134 - val_acc: 0.9231\n",
      "Epoch 2/120\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0153 - acc: 0.9010 - val_loss: 0.0132 - val_acc: 0.9255\n",
      "Epoch 3/120\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0149 - acc: 0.9064 - val_loss: 0.0131 - val_acc: 0.9327\n",
      "Epoch 4/120\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0146 - acc: 0.9120 - val_loss: 0.0129 - val_acc: 0.9303\n",
      "Epoch 5/120\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0142 - acc: 0.9155 - val_loss: 0.0128 - val_acc: 0.9303\n",
      "Epoch 6/120\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0139 - acc: 0.9155 - val_loss: 0.0127 - val_acc: 0.9327\n",
      "Epoch 7/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0135 - acc: 0.9173 - val_loss: 0.0126 - val_acc: 0.9327\n",
      "Epoch 8/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0133 - acc: 0.9192 - val_loss: 0.0124 - val_acc: 0.9351\n",
      "Epoch 9/120\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0131 - acc: 0.9208 - val_loss: 0.0124 - val_acc: 0.9303\n",
      "Epoch 10/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0128 - acc: 0.9235 - val_loss: 0.0124 - val_acc: 0.9375\n",
      "Epoch 11/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0126 - acc: 0.9248 - val_loss: 0.0122 - val_acc: 0.9327\n",
      "Epoch 12/120\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0124 - acc: 0.9254 - val_loss: 0.0123 - val_acc: 0.9327\n",
      "Epoch 13/120\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0122 - acc: 0.9280 - val_loss: 0.0119 - val_acc: 0.9399\n",
      "Epoch 14/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0121 - acc: 0.9275 - val_loss: 0.0118 - val_acc: 0.9423\n",
      "Epoch 15/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0119 - acc: 0.9283 - val_loss: 0.0119 - val_acc: 0.9375\n",
      "Epoch 16/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0117 - acc: 0.9320 - val_loss: 0.0121 - val_acc: 0.9423\n",
      "Epoch 17/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0115 - acc: 0.9337 - val_loss: 0.0118 - val_acc: 0.9375\n",
      "Epoch 18/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0113 - acc: 0.9323 - val_loss: 0.0116 - val_acc: 0.9399\n",
      "Epoch 19/120\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0112 - acc: 0.9353 - val_loss: 0.0117 - val_acc: 0.9351\n",
      "Epoch 20/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0111 - acc: 0.9353 - val_loss: 0.0116 - val_acc: 0.9351\n",
      "Epoch 21/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0109 - acc: 0.9363 - val_loss: 0.0114 - val_acc: 0.9351\n",
      "Epoch 22/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0107 - acc: 0.9377 - val_loss: 0.0116 - val_acc: 0.9375\n",
      "Epoch 23/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0107 - acc: 0.9371 - val_loss: 0.0114 - val_acc: 0.9375\n",
      "Epoch 24/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0105 - acc: 0.9409 - val_loss: 0.0115 - val_acc: 0.9399\n",
      "Epoch 25/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0104 - acc: 0.9401 - val_loss: 0.0113 - val_acc: 0.9375\n",
      "Epoch 26/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0103 - acc: 0.9422 - val_loss: 0.0114 - val_acc: 0.9375\n",
      "Epoch 27/120\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0101 - acc: 0.9433 - val_loss: 0.0114 - val_acc: 0.9375\n",
      "Epoch 28/120\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0100 - acc: 0.9441 - val_loss: 0.0113 - val_acc: 0.9399\n",
      "Epoch 29/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0099 - acc: 0.9444 - val_loss: 0.0112 - val_acc: 0.9375\n",
      "Epoch 30/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0098 - acc: 0.9446 - val_loss: 0.0113 - val_acc: 0.9375\n",
      "Epoch 31/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0097 - acc: 0.9460 - val_loss: 0.0111 - val_acc: 0.9399\n",
      "Epoch 32/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0096 - acc: 0.9460 - val_loss: 0.0110 - val_acc: 0.9399\n",
      "Epoch 33/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0095 - acc: 0.9473 - val_loss: 0.0110 - val_acc: 0.9399\n",
      "Epoch 34/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0094 - acc: 0.9478 - val_loss: 0.0111 - val_acc: 0.9375\n",
      "Epoch 35/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0093 - acc: 0.9484 - val_loss: 0.0111 - val_acc: 0.9399\n",
      "Epoch 36/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0092 - acc: 0.9505 - val_loss: 0.0109 - val_acc: 0.9375\n",
      "Epoch 37/120\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0091 - acc: 0.9508 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 38/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0090 - acc: 0.9518 - val_loss: 0.0109 - val_acc: 0.9375\n",
      "Epoch 39/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0089 - acc: 0.9510 - val_loss: 0.0109 - val_acc: 0.9375\n",
      "Epoch 40/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0088 - acc: 0.9526 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 41/120\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0087 - acc: 0.9526 - val_loss: 0.0108 - val_acc: 0.9399\n",
      "Epoch 42/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0086 - acc: 0.9540 - val_loss: 0.0108 - val_acc: 0.9399\n",
      "Epoch 43/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0085 - acc: 0.9556 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 44/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0085 - acc: 0.9553 - val_loss: 0.0109 - val_acc: 0.9423\n",
      "Epoch 45/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0084 - acc: 0.9551 - val_loss: 0.0108 - val_acc: 0.9375\n",
      "Epoch 46/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0083 - acc: 0.9551 - val_loss: 0.0107 - val_acc: 0.9399\n",
      "Epoch 47/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0082 - acc: 0.9569 - val_loss: 0.0107 - val_acc: 0.9399\n",
      "Epoch 48/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0082 - acc: 0.9577 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 49/120\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0081 - acc: 0.9575 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 50/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0080 - acc: 0.9583 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 51/120\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0080 - acc: 0.9575 - val_loss: 0.0106 - val_acc: 0.9447\n",
      "Epoch 52/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0079 - acc: 0.9585 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 53/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0078 - acc: 0.9601 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 54/120\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0077 - acc: 0.9593 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 55/120\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0077 - acc: 0.9604 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 56/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0076 - acc: 0.9599 - val_loss: 0.0106 - val_acc: 0.9375\n",
      "Epoch 57/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0075 - acc: 0.9604 - val_loss: 0.0106 - val_acc: 0.9399\n",
      "Epoch 58/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0075 - acc: 0.9604 - val_loss: 0.0105 - val_acc: 0.9471\n",
      "Epoch 59/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0074 - acc: 0.9615 - val_loss: 0.0106 - val_acc: 0.9399\n",
      "Epoch 60/120\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0073 - acc: 0.9615 - val_loss: 0.0105 - val_acc: 0.9399\n",
      "Epoch 61/120\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0073 - acc: 0.9623 - val_loss: 0.0107 - val_acc: 0.9399\n",
      "Epoch 62/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0072 - acc: 0.9639 - val_loss: 0.0106 - val_acc: 0.9447\n",
      "Epoch 63/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0071 - acc: 0.9625 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 64/120\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0071 - acc: 0.9631 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 65/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0071 - acc: 0.9631 - val_loss: 0.0105 - val_acc: 0.9399\n",
      "Epoch 66/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0070 - acc: 0.9636 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 67/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0069 - acc: 0.9647 - val_loss: 0.0106 - val_acc: 0.9399\n",
      "Epoch 68/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0069 - acc: 0.9644 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 69/120\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0068 - acc: 0.9650 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 70/120\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0068 - acc: 0.9652 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 71/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0067 - acc: 0.9652 - val_loss: 0.0105 - val_acc: 0.9399\n",
      "Epoch 72/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0066 - acc: 0.9668 - val_loss: 0.0106 - val_acc: 0.9399\n",
      "Epoch 73/120\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0066 - acc: 0.9660 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 74/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0065 - acc: 0.9666 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 75/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0065 - acc: 0.9668 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 76/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0064 - acc: 0.9674 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 77/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0064 - acc: 0.9684 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 78/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0063 - acc: 0.9676 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 79/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0063 - acc: 0.9687 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 80/120\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0062 - acc: 0.9687 - val_loss: 0.0105 - val_acc: 0.9375\n",
      "Epoch 81/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0062 - acc: 0.9692 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 82/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0061 - acc: 0.9690 - val_loss: 0.0103 - val_acc: 0.9423\n",
      "Epoch 83/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0061 - acc: 0.9700 - val_loss: 0.0105 - val_acc: 0.9399\n",
      "Epoch 84/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0060 - acc: 0.9692 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 85/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0060 - acc: 0.9706 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 86/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0059 - acc: 0.9695 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 87/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0059 - acc: 0.9703 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 88/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0059 - acc: 0.9703 - val_loss: 0.0102 - val_acc: 0.9447\n",
      "Epoch 89/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0058 - acc: 0.9706 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 90/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0058 - acc: 0.9708 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 91/120\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0057 - acc: 0.9711 - val_loss: 0.0103 - val_acc: 0.9399\n",
      "Epoch 92/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0057 - acc: 0.9716 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 93/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0057 - acc: 0.9716 - val_loss: 0.0103 - val_acc: 0.9423\n",
      "Epoch 94/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0056 - acc: 0.9727 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 95/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0056 - acc: 0.9730 - val_loss: 0.0102 - val_acc: 0.9399\n",
      "Epoch 96/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0055 - acc: 0.9730 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 97/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0055 - acc: 0.9722 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 98/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0054 - acc: 0.9730 - val_loss: 0.0101 - val_acc: 0.9423\n",
      "Epoch 99/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0054 - acc: 0.9735 - val_loss: 0.0105 - val_acc: 0.9351\n",
      "Epoch 100/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0054 - acc: 0.9735 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 101/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0054 - acc: 0.9741 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 102/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0053 - acc: 0.9741 - val_loss: 0.0103 - val_acc: 0.9423\n",
      "Epoch 103/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0053 - acc: 0.9741 - val_loss: 0.0102 - val_acc: 0.9447\n",
      "Epoch 104/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0053 - acc: 0.9743 - val_loss: 0.0105 - val_acc: 0.9399\n",
      "Epoch 105/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0052 - acc: 0.9743 - val_loss: 0.0102 - val_acc: 0.9399\n",
      "Epoch 106/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0052 - acc: 0.9746 - val_loss: 0.0101 - val_acc: 0.9423\n",
      "Epoch 107/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0052 - acc: 0.9749 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 108/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0051 - acc: 0.9743 - val_loss: 0.0101 - val_acc: 0.9423\n",
      "Epoch 109/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0051 - acc: 0.9757 - val_loss: 0.0102 - val_acc: 0.9399\n",
      "Epoch 110/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0051 - acc: 0.9751 - val_loss: 0.0101 - val_acc: 0.9447\n",
      "Epoch 111/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0050 - acc: 0.9757 - val_loss: 0.0100 - val_acc: 0.9423\n",
      "Epoch 112/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0050 - acc: 0.9765 - val_loss: 0.0101 - val_acc: 0.9423\n",
      "Epoch 113/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0050 - acc: 0.9759 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 114/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0050 - acc: 0.9765 - val_loss: 0.0101 - val_acc: 0.9423\n",
      "Epoch 115/120\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0049 - acc: 0.9762 - val_loss: 0.0100 - val_acc: 0.9447\n",
      "Epoch 116/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0049 - acc: 0.9762 - val_loss: 0.0100 - val_acc: 0.9423\n",
      "Epoch 117/120\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0049 - acc: 0.9757 - val_loss: 0.0101 - val_acc: 0.9423\n",
      "Epoch 118/120\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0048 - acc: 0.9762 - val_loss: 0.0100 - val_acc: 0.9447\n",
      "Epoch 119/120\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0048 - acc: 0.9773 - val_loss: 0.0101 - val_acc: 0.9423\n",
      "Epoch 120/120\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0048 - acc: 0.9765 - val_loss: 0.0101 - val_acc: 0.9399\n",
      "Training date and time : \n",
      "2020-05-18 10:35:17\n",
      "Train on 3738 samples, validate on 416 samples\n",
      "Epoch 1/130\n",
      "3738/3738 [==============================] - 0s 70us/sample - loss: 0.0159 - acc: 0.8997 - val_loss: 0.0133 - val_acc: 0.9255\n",
      "Epoch 2/130\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0154 - acc: 0.9048 - val_loss: 0.0132 - val_acc: 0.9255\n",
      "Epoch 3/130\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0149 - acc: 0.9058 - val_loss: 0.0130 - val_acc: 0.9303\n",
      "Epoch 4/130\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0145 - acc: 0.9109 - val_loss: 0.0129 - val_acc: 0.9255\n",
      "Epoch 5/130\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0142 - acc: 0.9123 - val_loss: 0.0129 - val_acc: 0.9279\n",
      "Epoch 6/130\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0139 - acc: 0.9155 - val_loss: 0.0128 - val_acc: 0.9327\n",
      "Epoch 7/130\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0136 - acc: 0.9171 - val_loss: 0.0124 - val_acc: 0.9327\n",
      "Epoch 8/130\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0134 - acc: 0.9187 - val_loss: 0.0124 - val_acc: 0.9279\n",
      "Epoch 9/130\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0131 - acc: 0.9235 - val_loss: 0.0125 - val_acc: 0.9279\n",
      "Epoch 10/130\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0129 - acc: 0.9222 - val_loss: 0.0123 - val_acc: 0.9351\n",
      "Epoch 11/130\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0126 - acc: 0.9227 - val_loss: 0.0123 - val_acc: 0.9351\n",
      "Epoch 12/130\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0124 - acc: 0.9264 - val_loss: 0.0121 - val_acc: 0.9327\n",
      "Epoch 13/130\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0122 - acc: 0.9288 - val_loss: 0.0120 - val_acc: 0.9351\n",
      "Epoch 14/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0120 - acc: 0.9299 - val_loss: 0.0119 - val_acc: 0.9399\n",
      "Epoch 15/130\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0118 - acc: 0.9310 - val_loss: 0.0118 - val_acc: 0.9375\n",
      "Epoch 16/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0117 - acc: 0.9299 - val_loss: 0.0118 - val_acc: 0.9375\n",
      "Epoch 17/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0115 - acc: 0.9331 - val_loss: 0.0118 - val_acc: 0.9375\n",
      "Epoch 18/130\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0114 - acc: 0.9339 - val_loss: 0.0116 - val_acc: 0.9399\n",
      "Epoch 19/130\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0112 - acc: 0.9326 - val_loss: 0.0116 - val_acc: 0.9375\n",
      "Epoch 20/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0110 - acc: 0.9366 - val_loss: 0.0115 - val_acc: 0.9375\n",
      "Epoch 21/130\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0109 - acc: 0.9366 - val_loss: 0.0115 - val_acc: 0.9399\n",
      "Epoch 22/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0108 - acc: 0.9374 - val_loss: 0.0113 - val_acc: 0.9375\n",
      "Epoch 23/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0107 - acc: 0.9385 - val_loss: 0.0114 - val_acc: 0.9399\n",
      "Epoch 24/130\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0105 - acc: 0.9395 - val_loss: 0.0114 - val_acc: 0.9375\n",
      "Epoch 25/130\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0104 - acc: 0.9393 - val_loss: 0.0114 - val_acc: 0.9399\n",
      "Epoch 26/130\n",
      "3738/3738 [==============================] - 0s 41us/sample - loss: 0.0103 - acc: 0.9414 - val_loss: 0.0113 - val_acc: 0.9375\n",
      "Epoch 27/130\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0101 - acc: 0.9422 - val_loss: 0.0111 - val_acc: 0.9423\n",
      "Epoch 28/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0100 - acc: 0.9430 - val_loss: 0.0112 - val_acc: 0.9375\n",
      "Epoch 29/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0099 - acc: 0.9460 - val_loss: 0.0111 - val_acc: 0.9399\n",
      "Epoch 30/130\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0098 - acc: 0.9457 - val_loss: 0.0110 - val_acc: 0.9399\n",
      "Epoch 31/130\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0097 - acc: 0.9452 - val_loss: 0.0110 - val_acc: 0.9423\n",
      "Epoch 32/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0096 - acc: 0.9473 - val_loss: 0.0113 - val_acc: 0.9375\n",
      "Epoch 33/130\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0095 - acc: 0.9478 - val_loss: 0.0112 - val_acc: 0.9375\n",
      "Epoch 34/130\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0094 - acc: 0.9473 - val_loss: 0.0112 - val_acc: 0.9375\n",
      "Epoch 35/130\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0093 - acc: 0.9494 - val_loss: 0.0110 - val_acc: 0.9375\n",
      "Epoch 36/130\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0092 - acc: 0.9500 - val_loss: 0.0110 - val_acc: 0.9399\n",
      "Epoch 37/130\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0091 - acc: 0.9513 - val_loss: 0.0110 - val_acc: 0.9375\n",
      "Epoch 38/130\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0090 - acc: 0.9513 - val_loss: 0.0110 - val_acc: 0.9375\n",
      "Epoch 39/130\n",
      "3738/3738 [==============================] - 0s 41us/sample - loss: 0.0089 - acc: 0.9502 - val_loss: 0.0110 - val_acc: 0.9399\n",
      "Epoch 40/130\n",
      "3738/3738 [==============================] - 0s 41us/sample - loss: 0.0088 - acc: 0.9524 - val_loss: 0.0110 - val_acc: 0.9375\n",
      "Epoch 41/130\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0087 - acc: 0.9529 - val_loss: 0.0110 - val_acc: 0.9375\n",
      "Epoch 42/130\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0087 - acc: 0.9535 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 43/130\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0086 - acc: 0.9532 - val_loss: 0.0108 - val_acc: 0.9423\n",
      "Epoch 44/130\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0085 - acc: 0.9545 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 45/130\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0084 - acc: 0.9569 - val_loss: 0.0108 - val_acc: 0.9375\n",
      "Epoch 46/130\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0083 - acc: 0.9551 - val_loss: 0.0107 - val_acc: 0.9399\n",
      "Epoch 47/130\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0082 - acc: 0.9564 - val_loss: 0.0108 - val_acc: 0.9399\n",
      "Epoch 48/130\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0082 - acc: 0.9564 - val_loss: 0.0107 - val_acc: 0.9447\n",
      "Epoch 49/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0081 - acc: 0.9580 - val_loss: 0.0107 - val_acc: 0.9399\n",
      "Epoch 50/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0080 - acc: 0.9569 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 51/130\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0080 - acc: 0.9577 - val_loss: 0.0106 - val_acc: 0.9447\n",
      "Epoch 52/130\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0079 - acc: 0.9577 - val_loss: 0.0107 - val_acc: 0.9447\n",
      "Epoch 53/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0078 - acc: 0.9601 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 54/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0077 - acc: 0.9585 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 55/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0077 - acc: 0.9601 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 56/130\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0076 - acc: 0.9599 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 57/130\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0075 - acc: 0.9599 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 58/130\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0075 - acc: 0.9601 - val_loss: 0.0107 - val_acc: 0.9399\n",
      "Epoch 59/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0074 - acc: 0.9612 - val_loss: 0.0106 - val_acc: 0.9399\n",
      "Epoch 60/130\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0074 - acc: 0.9617 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 61/130\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0073 - acc: 0.9617 - val_loss: 0.0106 - val_acc: 0.9399\n",
      "Epoch 62/130\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0072 - acc: 0.9631 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 63/130\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0072 - acc: 0.9628 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 64/130\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0071 - acc: 0.9633 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 65/130\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0071 - acc: 0.9628 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 66/130\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0070 - acc: 0.9642 - val_loss: 0.0105 - val_acc: 0.9399\n",
      "Epoch 67/130\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0069 - acc: 0.9647 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 68/130\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0069 - acc: 0.9655 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 69/130\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0068 - acc: 0.9636 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 70/130\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0068 - acc: 0.9652 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 71/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0067 - acc: 0.9668 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 72/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0067 - acc: 0.9663 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 73/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0066 - acc: 0.9671 - val_loss: 0.0106 - val_acc: 0.9399\n",
      "Epoch 74/130\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0065 - acc: 0.9666 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 75/130\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0065 - acc: 0.9663 - val_loss: 0.0105 - val_acc: 0.9399\n",
      "Epoch 76/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0065 - acc: 0.9666 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 77/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0064 - acc: 0.9682 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 78/130\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0063 - acc: 0.9674 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 79/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0063 - acc: 0.9682 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 80/130\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0062 - acc: 0.9687 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 81/130\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0062 - acc: 0.9687 - val_loss: 0.0106 - val_acc: 0.9399\n",
      "Epoch 82/130\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0061 - acc: 0.9684 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 83/130\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0061 - acc: 0.9687 - val_loss: 0.0103 - val_acc: 0.9423\n",
      "Epoch 84/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0060 - acc: 0.9700 - val_loss: 0.0103 - val_acc: 0.9423\n",
      "Epoch 85/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0060 - acc: 0.9692 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 86/130\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0060 - acc: 0.9695 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 87/130\n",
      "3738/3738 [==============================] - 0s 41us/sample - loss: 0.0059 - acc: 0.9692 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 88/130\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0059 - acc: 0.9703 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 89/130\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0058 - acc: 0.9706 - val_loss: 0.0103 - val_acc: 0.9399\n",
      "Epoch 90/130\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0058 - acc: 0.9711 - val_loss: 0.0103 - val_acc: 0.9423\n",
      "Epoch 91/130\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0057 - acc: 0.9711 - val_loss: 0.0103 - val_acc: 0.9423\n",
      "Epoch 92/130\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0057 - acc: 0.9708 - val_loss: 0.0103 - val_acc: 0.9375\n",
      "Epoch 93/130\n",
      "3738/3738 [==============================] - 0s 41us/sample - loss: 0.0057 - acc: 0.9711 - val_loss: 0.0103 - val_acc: 0.9399\n",
      "Epoch 94/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0056 - acc: 0.9714 - val_loss: 0.0103 - val_acc: 0.9399\n",
      "Epoch 95/130\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0056 - acc: 0.9722 - val_loss: 0.0104 - val_acc: 0.9351\n",
      "Epoch 96/130\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0056 - acc: 0.9724 - val_loss: 0.0102 - val_acc: 0.9447\n",
      "Epoch 97/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0055 - acc: 0.9727 - val_loss: 0.0103 - val_acc: 0.9423\n",
      "Epoch 98/130\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0055 - acc: 0.9730 - val_loss: 0.0102 - val_acc: 0.9399\n",
      "Epoch 99/130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0054 - acc: 0.9743 - val_loss: 0.0103 - val_acc: 0.9399\n",
      "Epoch 100/130\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0054 - acc: 0.9730 - val_loss: 0.0102 - val_acc: 0.9447\n",
      "Epoch 101/130\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0054 - acc: 0.9730 - val_loss: 0.0102 - val_acc: 0.9447\n",
      "Epoch 102/130\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0053 - acc: 0.9741 - val_loss: 0.0101 - val_acc: 0.9447\n",
      "Epoch 103/130\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0053 - acc: 0.9741 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 104/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0053 - acc: 0.9749 - val_loss: 0.0102 - val_acc: 0.9399\n",
      "Epoch 105/130\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0052 - acc: 0.9746 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 106/130\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0052 - acc: 0.9746 - val_loss: 0.0101 - val_acc: 0.9423\n",
      "Epoch 107/130\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0052 - acc: 0.9754 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 108/130\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0051 - acc: 0.9759 - val_loss: 0.0102 - val_acc: 0.9399\n",
      "Epoch 109/130\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0051 - acc: 0.9757 - val_loss: 0.0101 - val_acc: 0.9423\n",
      "Epoch 110/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0051 - acc: 0.9754 - val_loss: 0.0101 - val_acc: 0.9423\n",
      "Epoch 111/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0050 - acc: 0.9757 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 112/130\n",
      "3738/3738 [==============================] - 0s 41us/sample - loss: 0.0050 - acc: 0.9757 - val_loss: 0.0100 - val_acc: 0.9423\n",
      "Epoch 113/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0050 - acc: 0.9754 - val_loss: 0.0101 - val_acc: 0.9423\n",
      "Epoch 114/130\n",
      "3738/3738 [==============================] - 0s 41us/sample - loss: 0.0049 - acc: 0.9754 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 115/130\n",
      "3738/3738 [==============================] - 0s 41us/sample - loss: 0.0049 - acc: 0.9762 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 116/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0049 - acc: 0.9762 - val_loss: 0.0100 - val_acc: 0.9423\n",
      "Epoch 117/130\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0049 - acc: 0.9762 - val_loss: 0.0101 - val_acc: 0.9399\n",
      "Epoch 118/130\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0048 - acc: 0.9770 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 119/130\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0048 - acc: 0.9767 - val_loss: 0.0100 - val_acc: 0.9423\n",
      "Epoch 120/130\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0048 - acc: 0.9767 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 121/130\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0048 - acc: 0.9773 - val_loss: 0.0101 - val_acc: 0.9423\n",
      "Epoch 122/130\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0047 - acc: 0.9770 - val_loss: 0.0101 - val_acc: 0.9423\n",
      "Epoch 123/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0047 - acc: 0.9773 - val_loss: 0.0100 - val_acc: 0.9423\n",
      "Epoch 124/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0047 - acc: 0.9775 - val_loss: 0.0100 - val_acc: 0.9423\n",
      "Epoch 125/130\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0047 - acc: 0.9781 - val_loss: 0.0100 - val_acc: 0.9423\n",
      "Epoch 126/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0046 - acc: 0.9786 - val_loss: 0.0100 - val_acc: 0.9423\n",
      "Epoch 127/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0046 - acc: 0.9783 - val_loss: 0.0100 - val_acc: 0.9423\n",
      "Epoch 128/130\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0046 - acc: 0.9778 - val_loss: 0.0100 - val_acc: 0.9423\n",
      "Epoch 129/130\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0046 - acc: 0.9783 - val_loss: 0.0099 - val_acc: 0.9423\n",
      "Epoch 130/130\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0045 - acc: 0.9778 - val_loss: 0.0100 - val_acc: 0.9423\n",
      "Training date and time : \n",
      "2020-05-18 10:35:36\n",
      "Train on 3738 samples, validate on 416 samples\n",
      "Epoch 1/140\n",
      "3738/3738 [==============================] - 0s 84us/sample - loss: 0.0159 - acc: 0.8999 - val_loss: 0.0134 - val_acc: 0.9231\n",
      "Epoch 2/140\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0154 - acc: 0.9032 - val_loss: 0.0133 - val_acc: 0.9231\n",
      "Epoch 3/140\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0149 - acc: 0.9082 - val_loss: 0.0132 - val_acc: 0.9303\n",
      "Epoch 4/140\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0145 - acc: 0.9117 - val_loss: 0.0129 - val_acc: 0.9279\n",
      "Epoch 5/140\n",
      "3738/3738 [==============================] - 0s 41us/sample - loss: 0.0142 - acc: 0.9117 - val_loss: 0.0126 - val_acc: 0.9303\n",
      "Epoch 6/140\n",
      "3738/3738 [==============================] - 0s 41us/sample - loss: 0.0139 - acc: 0.9168 - val_loss: 0.0128 - val_acc: 0.9327\n",
      "Epoch 7/140\n",
      "3738/3738 [==============================] - 0s 42us/sample - loss: 0.0136 - acc: 0.9187 - val_loss: 0.0125 - val_acc: 0.9279\n",
      "Epoch 8/140\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0133 - acc: 0.9216 - val_loss: 0.0125 - val_acc: 0.9327\n",
      "Epoch 9/140\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0131 - acc: 0.9213 - val_loss: 0.0123 - val_acc: 0.9327\n",
      "Epoch 10/140\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0129 - acc: 0.9230 - val_loss: 0.0122 - val_acc: 0.9351\n",
      "Epoch 11/140\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0126 - acc: 0.9246 - val_loss: 0.0121 - val_acc: 0.9351\n",
      "Epoch 12/140\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0124 - acc: 0.9267 - val_loss: 0.0120 - val_acc: 0.9303\n",
      "Epoch 13/140\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0122 - acc: 0.9272 - val_loss: 0.0121 - val_acc: 0.9303\n",
      "Epoch 14/140\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0121 - acc: 0.9299 - val_loss: 0.0119 - val_acc: 0.9423\n",
      "Epoch 15/140\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0119 - acc: 0.9294 - val_loss: 0.0118 - val_acc: 0.9351\n",
      "Epoch 16/140\n",
      "3738/3738 [==============================] - 0s 41us/sample - loss: 0.0117 - acc: 0.9337 - val_loss: 0.0119 - val_acc: 0.9375\n",
      "Epoch 17/140\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0115 - acc: 0.9320 - val_loss: 0.0118 - val_acc: 0.9375\n",
      "Epoch 18/140\n",
      "3738/3738 [==============================] - 0s 43us/sample - loss: 0.0114 - acc: 0.9337 - val_loss: 0.0117 - val_acc: 0.9375\n",
      "Epoch 19/140\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0112 - acc: 0.9347 - val_loss: 0.0118 - val_acc: 0.9375\n",
      "Epoch 20/140\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0111 - acc: 0.9342 - val_loss: 0.0116 - val_acc: 0.9375\n",
      "Epoch 21/140\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0109 - acc: 0.9363 - val_loss: 0.0115 - val_acc: 0.9399\n",
      "Epoch 22/140\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0108 - acc: 0.9385 - val_loss: 0.0113 - val_acc: 0.9423\n",
      "Epoch 23/140\n",
      "3738/3738 [==============================] - 0s 43us/sample - loss: 0.0106 - acc: 0.9387 - val_loss: 0.0116 - val_acc: 0.9423\n",
      "Epoch 24/140\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0105 - acc: 0.9387 - val_loss: 0.0114 - val_acc: 0.9375\n",
      "Epoch 25/140\n",
      "3738/3738 [==============================] - 0s 41us/sample - loss: 0.0104 - acc: 0.9401 - val_loss: 0.0113 - val_acc: 0.9399\n",
      "Epoch 26/140\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0102 - acc: 0.9430 - val_loss: 0.0113 - val_acc: 0.9375\n",
      "Epoch 27/140\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0101 - acc: 0.9428 - val_loss: 0.0114 - val_acc: 0.9375\n",
      "Epoch 28/140\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0100 - acc: 0.9444 - val_loss: 0.0112 - val_acc: 0.9423\n",
      "Epoch 29/140\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0099 - acc: 0.9433 - val_loss: 0.0112 - val_acc: 0.9375\n",
      "Epoch 30/140\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0098 - acc: 0.9454 - val_loss: 0.0112 - val_acc: 0.9375\n",
      "Epoch 31/140\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0097 - acc: 0.9465 - val_loss: 0.0110 - val_acc: 0.9423\n",
      "Epoch 32/140\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0096 - acc: 0.9460 - val_loss: 0.0111 - val_acc: 0.9375\n",
      "Epoch 33/140\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0095 - acc: 0.9473 - val_loss: 0.0111 - val_acc: 0.9375\n",
      "Epoch 34/140\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0094 - acc: 0.9492 - val_loss: 0.0111 - val_acc: 0.9375\n",
      "Epoch 35/140\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0092 - acc: 0.9502 - val_loss: 0.0108 - val_acc: 0.9423\n",
      "Epoch 36/140\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0092 - acc: 0.9494 - val_loss: 0.0109 - val_acc: 0.9423\n",
      "Epoch 37/140\n",
      "3738/3738 [==============================] - 0s 41us/sample - loss: 0.0091 - acc: 0.9500 - val_loss: 0.0111 - val_acc: 0.9375\n",
      "Epoch 38/140\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0090 - acc: 0.9502 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 39/140\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0089 - acc: 0.9502 - val_loss: 0.0109 - val_acc: 0.9423\n",
      "Epoch 40/140\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0088 - acc: 0.9518 - val_loss: 0.0108 - val_acc: 0.9423\n",
      "Epoch 41/140\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0087 - acc: 0.9532 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 42/140\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0087 - acc: 0.9532 - val_loss: 0.0109 - val_acc: 0.9375\n",
      "Epoch 43/140\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0086 - acc: 0.9532 - val_loss: 0.0107 - val_acc: 0.9447\n",
      "Epoch 44/140\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0085 - acc: 0.9543 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 45/140\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0084 - acc: 0.9564 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 46/140\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0083 - acc: 0.9564 - val_loss: 0.0108 - val_acc: 0.9399\n",
      "Epoch 47/140\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0082 - acc: 0.9561 - val_loss: 0.0108 - val_acc: 0.9399\n",
      "Epoch 48/140\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0081 - acc: 0.9575 - val_loss: 0.0107 - val_acc: 0.9399\n",
      "Epoch 49/140\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0081 - acc: 0.9575 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 50/140\n",
      "3738/3738 [==============================] - 0s 41us/sample - loss: 0.0080 - acc: 0.9583 - val_loss: 0.0107 - val_acc: 0.9447\n",
      "Epoch 51/140\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0079 - acc: 0.9577 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 52/140\n",
      "3738/3738 [==============================] - 0s 41us/sample - loss: 0.0079 - acc: 0.9591 - val_loss: 0.0105 - val_acc: 0.9399\n",
      "Epoch 53/140\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0078 - acc: 0.9596 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 54/140\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0077 - acc: 0.9607 - val_loss: 0.0106 - val_acc: 0.9399\n",
      "Epoch 55/140\n",
      "3738/3738 [==============================] - 0s 42us/sample - loss: 0.0077 - acc: 0.9599 - val_loss: 0.0106 - val_acc: 0.9447\n",
      "Epoch 56/140\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0076 - acc: 0.9593 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 57/140\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0075 - acc: 0.9617 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 58/140\n",
      "3738/3738 [==============================] - 0s 41us/sample - loss: 0.0075 - acc: 0.9607 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 59/140\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0074 - acc: 0.9612 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 60/140\n",
      "3738/3738 [==============================] - 0s 41us/sample - loss: 0.0073 - acc: 0.9617 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 61/140\n",
      "3738/3738 [==============================] - 0s 41us/sample - loss: 0.0073 - acc: 0.9623 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 62/140\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0072 - acc: 0.9623 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 63/140\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0072 - acc: 0.9625 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 64/140\n",
      "3738/3738 [==============================] - 0s 41us/sample - loss: 0.0071 - acc: 0.9644 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 65/140\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0070 - acc: 0.9636 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 66/140\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0070 - acc: 0.9639 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 67/140\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0069 - acc: 0.9644 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 68/140\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0069 - acc: 0.9658 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 69/140\n",
      "3738/3738 [==============================] - 0s 41us/sample - loss: 0.0068 - acc: 0.9660 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 70/140\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0068 - acc: 0.9655 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 71/140\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0067 - acc: 0.9658 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 72/140\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0066 - acc: 0.9655 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 73/140\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0066 - acc: 0.9668 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 74/140\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0065 - acc: 0.9671 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 75/140\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0065 - acc: 0.9668 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 76/140\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0064 - acc: 0.9671 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 77/140\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0063 - acc: 0.9687 - val_loss: 0.0105 - val_acc: 0.9399\n",
      "Epoch 78/140\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0063 - acc: 0.9679 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 79/140\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0063 - acc: 0.9687 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 80/140\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0062 - acc: 0.9684 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 81/140\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0062 - acc: 0.9690 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 82/140\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0061 - acc: 0.9692 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 83/140\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0060 - acc: 0.9695 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 84/140\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0060 - acc: 0.9700 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 85/140\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0060 - acc: 0.9695 - val_loss: 0.0103 - val_acc: 0.9423\n",
      "Epoch 86/140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0059 - acc: 0.9703 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 87/140\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0059 - acc: 0.9698 - val_loss: 0.0102 - val_acc: 0.9447\n",
      "Epoch 88/140\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0058 - acc: 0.9708 - val_loss: 0.0102 - val_acc: 0.9399\n",
      "Epoch 89/140\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0058 - acc: 0.9700 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 90/140\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0058 - acc: 0.9703 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 91/140\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0057 - acc: 0.9708 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 92/140\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0057 - acc: 0.9711 - val_loss: 0.0102 - val_acc: 0.9447\n",
      "Epoch 93/140\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0056 - acc: 0.9722 - val_loss: 0.0101 - val_acc: 0.9447\n",
      "Epoch 94/140\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0056 - acc: 0.9722 - val_loss: 0.0101 - val_acc: 0.9447\n",
      "Epoch 95/140\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0056 - acc: 0.9716 - val_loss: 0.0101 - val_acc: 0.9447\n",
      "Epoch 96/140\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0055 - acc: 0.9722 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 97/140\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0055 - acc: 0.9724 - val_loss: 0.0102 - val_acc: 0.9399\n",
      "Epoch 98/140\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0055 - acc: 0.9732 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 99/140\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0054 - acc: 0.9727 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 100/140\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0054 - acc: 0.9741 - val_loss: 0.0101 - val_acc: 0.9423\n",
      "Epoch 101/140\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0054 - acc: 0.9738 - val_loss: 0.0102 - val_acc: 0.9447\n",
      "Epoch 102/140\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0053 - acc: 0.9741 - val_loss: 0.0100 - val_acc: 0.9423\n",
      "Epoch 103/140\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0053 - acc: 0.9738 - val_loss: 0.0102 - val_acc: 0.9399\n",
      "Epoch 104/140\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0053 - acc: 0.9741 - val_loss: 0.0101 - val_acc: 0.9423\n",
      "Epoch 105/140\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0052 - acc: 0.9746 - val_loss: 0.0101 - val_acc: 0.9423\n",
      "Epoch 106/140\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0052 - acc: 0.9746 - val_loss: 0.0101 - val_acc: 0.9447\n",
      "Epoch 107/140\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0052 - acc: 0.9746 - val_loss: 0.0101 - val_acc: 0.9423\n",
      "Epoch 108/140\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0051 - acc: 0.9751 - val_loss: 0.0101 - val_acc: 0.9423\n",
      "Epoch 109/140\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0051 - acc: 0.9754 - val_loss: 0.0101 - val_acc: 0.9399\n",
      "Epoch 110/140\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0051 - acc: 0.9759 - val_loss: 0.0101 - val_acc: 0.9399\n",
      "Epoch 111/140\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0050 - acc: 0.9757 - val_loss: 0.0100 - val_acc: 0.9447\n",
      "Epoch 112/140\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0050 - acc: 0.9759 - val_loss: 0.0099 - val_acc: 0.9447\n",
      "Epoch 113/140\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0050 - acc: 0.9759 - val_loss: 0.0100 - val_acc: 0.9399\n",
      "Epoch 114/140\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0049 - acc: 0.9762 - val_loss: 0.0101 - val_acc: 0.9423\n",
      "Epoch 115/140\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0049 - acc: 0.9767 - val_loss: 0.0099 - val_acc: 0.9423\n",
      "Epoch 116/140\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0049 - acc: 0.9762 - val_loss: 0.0099 - val_acc: 0.9423\n",
      "Epoch 117/140\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0049 - acc: 0.9762 - val_loss: 0.0099 - val_acc: 0.9399\n",
      "Epoch 118/140\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0048 - acc: 0.9762 - val_loss: 0.0099 - val_acc: 0.9423\n",
      "Epoch 119/140\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0048 - acc: 0.9770 - val_loss: 0.0099 - val_acc: 0.9399\n",
      "Epoch 120/140\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0048 - acc: 0.9765 - val_loss: 0.0099 - val_acc: 0.9423\n",
      "Epoch 121/140\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0047 - acc: 0.9773 - val_loss: 0.0099 - val_acc: 0.9447\n",
      "Epoch 122/140\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0047 - acc: 0.9775 - val_loss: 0.0099 - val_acc: 0.9423\n",
      "Epoch 123/140\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0047 - acc: 0.9773 - val_loss: 0.0099 - val_acc: 0.9423\n",
      "Epoch 124/140\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0047 - acc: 0.9773 - val_loss: 0.0099 - val_acc: 0.9423\n",
      "Epoch 125/140\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0047 - acc: 0.9775 - val_loss: 0.0099 - val_acc: 0.9423\n",
      "Epoch 126/140\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0046 - acc: 0.9781 - val_loss: 0.0099 - val_acc: 0.9423\n",
      "Epoch 127/140\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0046 - acc: 0.9783 - val_loss: 0.0099 - val_acc: 0.9399\n",
      "Epoch 128/140\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0046 - acc: 0.9783 - val_loss: 0.0100 - val_acc: 0.9399\n",
      "Epoch 129/140\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0045 - acc: 0.9781 - val_loss: 0.0098 - val_acc: 0.9423\n",
      "Epoch 130/140\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0045 - acc: 0.9781 - val_loss: 0.0099 - val_acc: 0.9423\n",
      "Epoch 131/140\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0045 - acc: 0.9781 - val_loss: 0.0098 - val_acc: 0.9423\n",
      "Epoch 132/140\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0045 - acc: 0.9789 - val_loss: 0.0098 - val_acc: 0.9423\n",
      "Epoch 133/140\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0045 - acc: 0.9786 - val_loss: 0.0097 - val_acc: 0.9447\n",
      "Epoch 134/140\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0044 - acc: 0.9786 - val_loss: 0.0098 - val_acc: 0.9423\n",
      "Epoch 135/140\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0044 - acc: 0.9786 - val_loss: 0.0098 - val_acc: 0.9423\n",
      "Epoch 136/140\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0044 - acc: 0.9786 - val_loss: 0.0098 - val_acc: 0.9423\n",
      "Epoch 137/140\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0044 - acc: 0.9789 - val_loss: 0.0099 - val_acc: 0.9399\n",
      "Epoch 138/140\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0043 - acc: 0.9789 - val_loss: 0.0098 - val_acc: 0.9423\n",
      "Epoch 139/140\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0043 - acc: 0.9789 - val_loss: 0.0098 - val_acc: 0.9423\n",
      "Epoch 140/140\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0043 - acc: 0.9789 - val_loss: 0.0098 - val_acc: 0.9423\n",
      "Training date and time : \n",
      "2020-05-18 10:35:56\n",
      "Train on 3738 samples, validate on 416 samples\n",
      "Epoch 1/150\n",
      "3738/3738 [==============================] - 0s 73us/sample - loss: 0.0159 - acc: 0.8999 - val_loss: 0.0135 - val_acc: 0.9255\n",
      "Epoch 2/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0153 - acc: 0.9037 - val_loss: 0.0131 - val_acc: 0.9327\n",
      "Epoch 3/150\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0149 - acc: 0.9072 - val_loss: 0.0131 - val_acc: 0.9255\n",
      "Epoch 4/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0145 - acc: 0.9093 - val_loss: 0.0130 - val_acc: 0.9303\n",
      "Epoch 5/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0142 - acc: 0.9155 - val_loss: 0.0128 - val_acc: 0.9303\n",
      "Epoch 6/150\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0139 - acc: 0.9168 - val_loss: 0.0126 - val_acc: 0.9303\n",
      "Epoch 7/150\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0136 - acc: 0.9168 - val_loss: 0.0127 - val_acc: 0.9303\n",
      "Epoch 8/150\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0133 - acc: 0.9205 - val_loss: 0.0126 - val_acc: 0.9327\n",
      "Epoch 9/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0131 - acc: 0.9205 - val_loss: 0.0123 - val_acc: 0.9351\n",
      "Epoch 10/150\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0128 - acc: 0.9211 - val_loss: 0.0123 - val_acc: 0.9351\n",
      "Epoch 11/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0126 - acc: 0.9246 - val_loss: 0.0121 - val_acc: 0.9303\n",
      "Epoch 12/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0124 - acc: 0.9248 - val_loss: 0.0121 - val_acc: 0.9327\n",
      "Epoch 13/150\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0122 - acc: 0.9278 - val_loss: 0.0122 - val_acc: 0.9327\n",
      "Epoch 14/150\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0121 - acc: 0.9296 - val_loss: 0.0121 - val_acc: 0.9351\n",
      "Epoch 15/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0119 - acc: 0.9291 - val_loss: 0.0118 - val_acc: 0.9375\n",
      "Epoch 16/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0117 - acc: 0.9320 - val_loss: 0.0118 - val_acc: 0.9423\n",
      "Epoch 17/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0115 - acc: 0.9323 - val_loss: 0.0120 - val_acc: 0.9375\n",
      "Epoch 18/150\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0114 - acc: 0.9342 - val_loss: 0.0115 - val_acc: 0.9351\n",
      "Epoch 19/150\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0112 - acc: 0.9337 - val_loss: 0.0115 - val_acc: 0.9399\n",
      "Epoch 20/150\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0110 - acc: 0.9361 - val_loss: 0.0118 - val_acc: 0.9375\n",
      "Epoch 21/150\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0109 - acc: 0.9361 - val_loss: 0.0114 - val_acc: 0.9375\n",
      "Epoch 22/150\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0108 - acc: 0.9363 - val_loss: 0.0115 - val_acc: 0.9375\n",
      "Epoch 23/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0106 - acc: 0.9395 - val_loss: 0.0114 - val_acc: 0.9375\n",
      "Epoch 24/150\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0105 - acc: 0.9387 - val_loss: 0.0114 - val_acc: 0.9375\n",
      "Epoch 25/150\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0104 - acc: 0.9417 - val_loss: 0.0113 - val_acc: 0.9375\n",
      "Epoch 26/150\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0102 - acc: 0.9438 - val_loss: 0.0114 - val_acc: 0.9375\n",
      "Epoch 27/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0102 - acc: 0.9419 - val_loss: 0.0112 - val_acc: 0.9423\n",
      "Epoch 28/150\n",
      "3738/3738 [==============================] - 0s 30us/sample - loss: 0.0100 - acc: 0.9422 - val_loss: 0.0114 - val_acc: 0.9399\n",
      "Epoch 29/150\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0099 - acc: 0.9449 - val_loss: 0.0112 - val_acc: 0.9399\n",
      "Epoch 30/150\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0098 - acc: 0.9454 - val_loss: 0.0111 - val_acc: 0.9399\n",
      "Epoch 31/150\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0097 - acc: 0.9449 - val_loss: 0.0111 - val_acc: 0.9399\n",
      "Epoch 32/150\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0096 - acc: 0.9465 - val_loss: 0.0110 - val_acc: 0.9423\n",
      "Epoch 33/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0095 - acc: 0.9476 - val_loss: 0.0110 - val_acc: 0.9423\n",
      "Epoch 34/150\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0094 - acc: 0.9478 - val_loss: 0.0110 - val_acc: 0.9423\n",
      "Epoch 35/150\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0093 - acc: 0.9502 - val_loss: 0.0112 - val_acc: 0.9375\n",
      "Epoch 36/150\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0092 - acc: 0.9494 - val_loss: 0.0111 - val_acc: 0.9375\n",
      "Epoch 37/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0091 - acc: 0.9502 - val_loss: 0.0109 - val_acc: 0.9423\n",
      "Epoch 38/150\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0090 - acc: 0.9521 - val_loss: 0.0109 - val_acc: 0.9375\n",
      "Epoch 39/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0089 - acc: 0.9526 - val_loss: 0.0108 - val_acc: 0.9399\n",
      "Epoch 40/150\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0088 - acc: 0.9524 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 41/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0087 - acc: 0.9540 - val_loss: 0.0109 - val_acc: 0.9375\n",
      "Epoch 42/150\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0086 - acc: 0.9521 - val_loss: 0.0109 - val_acc: 0.9399\n",
      "Epoch 43/150\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0085 - acc: 0.9543 - val_loss: 0.0108 - val_acc: 0.9399\n",
      "Epoch 44/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0085 - acc: 0.9545 - val_loss: 0.0109 - val_acc: 0.9351\n",
      "Epoch 45/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0084 - acc: 0.9545 - val_loss: 0.0108 - val_acc: 0.9423\n",
      "Epoch 46/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0083 - acc: 0.9559 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 47/150\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0082 - acc: 0.9567 - val_loss: 0.0107 - val_acc: 0.9399\n",
      "Epoch 48/150\n",
      "3738/3738 [==============================] - 0s 31us/sample - loss: 0.0082 - acc: 0.9567 - val_loss: 0.0107 - val_acc: 0.9399\n",
      "Epoch 49/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0081 - acc: 0.9575 - val_loss: 0.0107 - val_acc: 0.9399\n",
      "Epoch 50/150\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0080 - acc: 0.9567 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 51/150\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0080 - acc: 0.9599 - val_loss: 0.0107 - val_acc: 0.9399\n",
      "Epoch 52/150\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0079 - acc: 0.9585 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 53/150\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0078 - acc: 0.9588 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 54/150\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0078 - acc: 0.9593 - val_loss: 0.0107 - val_acc: 0.9399\n",
      "Epoch 55/150\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0077 - acc: 0.9596 - val_loss: 0.0106 - val_acc: 0.9423\n",
      "Epoch 56/150\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0076 - acc: 0.9609 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 57/150\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0075 - acc: 0.9612 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 58/150\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0075 - acc: 0.9612 - val_loss: 0.0107 - val_acc: 0.9399\n",
      "Epoch 59/150\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0074 - acc: 0.9617 - val_loss: 0.0107 - val_acc: 0.9423\n",
      "Epoch 60/150\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0074 - acc: 0.9617 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 61/150\n",
      "3738/3738 [==============================] - 0s 42us/sample - loss: 0.0073 - acc: 0.9631 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 62/150\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0072 - acc: 0.9628 - val_loss: 0.0105 - val_acc: 0.9399\n",
      "Epoch 63/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0072 - acc: 0.9620 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 64/150\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0071 - acc: 0.9636 - val_loss: 0.0105 - val_acc: 0.9423\n",
      "Epoch 65/150\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0070 - acc: 0.9633 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 66/150\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0070 - acc: 0.9647 - val_loss: 0.0105 - val_acc: 0.9447\n",
      "Epoch 67/150\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0069 - acc: 0.9650 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 68/150\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0069 - acc: 0.9650 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 69/150\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0068 - acc: 0.9666 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 70/150\n",
      "3738/3738 [==============================] - 0s 41us/sample - loss: 0.0068 - acc: 0.9655 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 71/150\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0067 - acc: 0.9652 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 72/150\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0066 - acc: 0.9676 - val_loss: 0.0104 - val_acc: 0.9375\n",
      "Epoch 73/150\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0066 - acc: 0.9671 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 74/150\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0065 - acc: 0.9679 - val_loss: 0.0105 - val_acc: 0.9399\n",
      "Epoch 75/150\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0065 - acc: 0.9671 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 76/150\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0064 - acc: 0.9666 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 77/150\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0064 - acc: 0.9682 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 78/150\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0063 - acc: 0.9684 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 79/150\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0063 - acc: 0.9674 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 80/150\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0062 - acc: 0.9687 - val_loss: 0.0105 - val_acc: 0.9399\n",
      "Epoch 81/150\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0062 - acc: 0.9684 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 82/150\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0061 - acc: 0.9692 - val_loss: 0.0104 - val_acc: 0.9447\n",
      "Epoch 83/150\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0061 - acc: 0.9690 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 84/150\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0060 - acc: 0.9695 - val_loss: 0.0104 - val_acc: 0.9375\n",
      "Epoch 85/150\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0060 - acc: 0.9690 - val_loss: 0.0102 - val_acc: 0.9447\n",
      "Epoch 86/150\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0059 - acc: 0.9708 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 87/150\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0059 - acc: 0.9703 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 88/150\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0059 - acc: 0.9703 - val_loss: 0.0102 - val_acc: 0.9447\n",
      "Epoch 89/150\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0058 - acc: 0.9703 - val_loss: 0.0102 - val_acc: 0.9447\n",
      "Epoch 90/150\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0058 - acc: 0.9706 - val_loss: 0.0101 - val_acc: 0.9447\n",
      "Epoch 91/150\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0057 - acc: 0.9708 - val_loss: 0.0103 - val_acc: 0.9447\n",
      "Epoch 92/150\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0057 - acc: 0.9716 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 93/150\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0057 - acc: 0.9714 - val_loss: 0.0104 - val_acc: 0.9399\n",
      "Epoch 94/150\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0056 - acc: 0.9722 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 95/150\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0056 - acc: 0.9719 - val_loss: 0.0103 - val_acc: 0.9399\n",
      "Epoch 96/150\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0055 - acc: 0.9722 - val_loss: 0.0103 - val_acc: 0.9423\n",
      "Epoch 97/150\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0055 - acc: 0.9722 - val_loss: 0.0103 - val_acc: 0.9399\n",
      "Epoch 98/150\n",
      "3738/3738 [==============================] - 0s 36us/sample - loss: 0.0055 - acc: 0.9735 - val_loss: 0.0102 - val_acc: 0.9399\n",
      "Epoch 99/150\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0054 - acc: 0.9727 - val_loss: 0.0101 - val_acc: 0.9423\n",
      "Epoch 100/150\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0054 - acc: 0.9730 - val_loss: 0.0101 - val_acc: 0.9423\n",
      "Epoch 101/150\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0053 - acc: 0.9738 - val_loss: 0.0102 - val_acc: 0.9423\n",
      "Epoch 102/150\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0053 - acc: 0.9746 - val_loss: 0.0101 - val_acc: 0.9447\n",
      "Epoch 103/150\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0053 - acc: 0.9735 - val_loss: 0.0101 - val_acc: 0.9447\n",
      "Epoch 104/150\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0052 - acc: 0.9746 - val_loss: 0.0101 - val_acc: 0.9423\n",
      "Epoch 105/150\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0052 - acc: 0.9743 - val_loss: 0.0101 - val_acc: 0.9375\n",
      "Epoch 106/150\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0052 - acc: 0.9746 - val_loss: 0.0101 - val_acc: 0.9423\n",
      "Epoch 107/150\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0052 - acc: 0.9749 - val_loss: 0.0100 - val_acc: 0.9399\n",
      "Epoch 108/150\n",
      "3738/3738 [==============================] - 0s 37us/sample - loss: 0.0051 - acc: 0.9746 - val_loss: 0.0101 - val_acc: 0.9399\n",
      "Epoch 109/150\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0051 - acc: 0.9754 - val_loss: 0.0100 - val_acc: 0.9423\n",
      "Epoch 110/150\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0051 - acc: 0.9757 - val_loss: 0.0100 - val_acc: 0.9423\n",
      "Epoch 111/150\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0050 - acc: 0.9757 - val_loss: 0.0100 - val_acc: 0.9423\n",
      "Epoch 112/150\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0050 - acc: 0.9762 - val_loss: 0.0100 - val_acc: 0.9423\n",
      "Epoch 113/150\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0050 - acc: 0.9759 - val_loss: 0.0100 - val_acc: 0.9423\n",
      "Epoch 114/150\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0049 - acc: 0.9759 - val_loss: 0.0100 - val_acc: 0.9423\n",
      "Epoch 115/150\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0049 - acc: 0.9762 - val_loss: 0.0099 - val_acc: 0.9423\n",
      "Epoch 116/150\n",
      "3738/3738 [==============================] - 0s 39us/sample - loss: 0.0049 - acc: 0.9765 - val_loss: 0.0100 - val_acc: 0.9423\n",
      "Epoch 117/150\n",
      "3738/3738 [==============================] - 0s 38us/sample - loss: 0.0049 - acc: 0.9765 - val_loss: 0.0100 - val_acc: 0.9423\n",
      "Epoch 118/150\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0048 - acc: 0.9767 - val_loss: 0.0100 - val_acc: 0.9423\n",
      "Epoch 119/150\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0048 - acc: 0.9765 - val_loss: 0.0101 - val_acc: 0.9423\n",
      "Epoch 120/150\n",
      "3738/3738 [==============================] - 0s 40us/sample - loss: 0.0048 - acc: 0.9770 - val_loss: 0.0100 - val_acc: 0.9399\n",
      "Epoch 121/150\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0047 - acc: 0.9773 - val_loss: 0.0100 - val_acc: 0.9447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/150\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0047 - acc: 0.9770 - val_loss: 0.0099 - val_acc: 0.9423\n",
      "Epoch 123/150\n",
      "3738/3738 [==============================] - 0s 35us/sample - loss: 0.0047 - acc: 0.9773 - val_loss: 0.0099 - val_acc: 0.9399\n",
      "Epoch 124/150\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0047 - acc: 0.9770 - val_loss: 0.0099 - val_acc: 0.9399\n",
      "Epoch 125/150\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0046 - acc: 0.9778 - val_loss: 0.0099 - val_acc: 0.9399\n",
      "Epoch 126/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0046 - acc: 0.9778 - val_loss: 0.0098 - val_acc: 0.9423\n",
      "Epoch 127/150\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0046 - acc: 0.9783 - val_loss: 0.0099 - val_acc: 0.9423\n",
      "Epoch 128/150\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0046 - acc: 0.9775 - val_loss: 0.0099 - val_acc: 0.9423\n",
      "Epoch 129/150\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0045 - acc: 0.9783 - val_loss: 0.0098 - val_acc: 0.9423\n",
      "Epoch 130/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0045 - acc: 0.9783 - val_loss: 0.0099 - val_acc: 0.9375\n",
      "Epoch 131/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0045 - acc: 0.9783 - val_loss: 0.0097 - val_acc: 0.9447\n",
      "Epoch 132/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0045 - acc: 0.9786 - val_loss: 0.0099 - val_acc: 0.9423\n",
      "Epoch 133/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0045 - acc: 0.9781 - val_loss: 0.0098 - val_acc: 0.9423\n",
      "Epoch 134/150\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0044 - acc: 0.9786 - val_loss: 0.0099 - val_acc: 0.9399\n",
      "Epoch 135/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0044 - acc: 0.9786 - val_loss: 0.0098 - val_acc: 0.9423\n",
      "Epoch 136/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0044 - acc: 0.9789 - val_loss: 0.0097 - val_acc: 0.9399\n",
      "Epoch 137/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0044 - acc: 0.9789 - val_loss: 0.0098 - val_acc: 0.9423\n",
      "Epoch 138/150\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0043 - acc: 0.9789 - val_loss: 0.0098 - val_acc: 0.9423\n",
      "Epoch 139/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0043 - acc: 0.9789 - val_loss: 0.0097 - val_acc: 0.9423\n",
      "Epoch 140/150\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0043 - acc: 0.9789 - val_loss: 0.0097 - val_acc: 0.9423\n",
      "Epoch 141/150\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0043 - acc: 0.9786 - val_loss: 0.0098 - val_acc: 0.9423\n",
      "Epoch 142/150\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0043 - acc: 0.9786 - val_loss: 0.0098 - val_acc: 0.9423\n",
      "Epoch 143/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0042 - acc: 0.9789 - val_loss: 0.0098 - val_acc: 0.9423\n",
      "Epoch 144/150\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0042 - acc: 0.9791 - val_loss: 0.0097 - val_acc: 0.9423\n",
      "Epoch 145/150\n",
      "3738/3738 [==============================] - 0s 34us/sample - loss: 0.0042 - acc: 0.9789 - val_loss: 0.0097 - val_acc: 0.9423\n",
      "Epoch 146/150\n",
      "3738/3738 [==============================] - 0s 32us/sample - loss: 0.0042 - acc: 0.9791 - val_loss: 0.0096 - val_acc: 0.9423\n",
      "Epoch 147/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0041 - acc: 0.9791 - val_loss: 0.0097 - val_acc: 0.9423\n",
      "Epoch 148/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0041 - acc: 0.9797 - val_loss: 0.0097 - val_acc: 0.9423\n",
      "Epoch 149/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0041 - acc: 0.9799 - val_loss: 0.0097 - val_acc: 0.9423\n",
      "Epoch 150/150\n",
      "3738/3738 [==============================] - 0s 33us/sample - loss: 0.0041 - acc: 0.9797 - val_loss: 0.0096 - val_acc: 0.9423\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(model_list)):\n",
    "    compile_model(model_list[i])\n",
    "    fit_model_with_datasets(model_list[i], (i+1)*10, X_local_list[0], Y_local_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see how these models are different from each other, compared to the base model(before training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49092203, 0.8314665, 1.1135027, 1.3575116, 1.574934, 1.7718439, 1.9546021, 2.1236625, 2.2770913, 2.4207997, 2.5532637, 2.674287, 2.786849, 2.892571, 2.9939706]\n"
     ]
    }
   ],
   "source": [
    "dists = [semantic_drift.l2_distance(standard_model, m) for m in model_list]\n",
    "print(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(5, (len(dists)+2)*5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_combs(model_list, model_dists):\n",
    "    combs = list()\n",
    "    dists = list()\n",
    "    l = len(model_list)\n",
    "    for i in range(l):\n",
    "        for j in range(l):\n",
    "            if i > j:\n",
    "                combs.append([model_list[i], model_list[j]])\n",
    "                dists.append(np.abs(model_dists[i]-model_dists[j]))\n",
    "    combs_sorted = [x for _,x in sorted(zip(dists, combs))]\n",
    "    return combs_sorted, sorted(dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The l2-distance increases in respect to epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(5, (len(dists)+1)*5, 5), np.array(dists))\n",
    "plt.ylabel(\"l2 distance\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get model combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "combs, model_dists = model_combs(model_list, dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_list = [0, 0.6, 1]\n",
    "agg_weights_list_per_pi = list()\n",
    "cross_dists = list()\n",
    "\n",
    "for comb in combs:\n",
    "    weights = [comb[0].get_weights(), comb[1].get_weights()]\n",
    "    agg_weights_list = list()\n",
    "    for theta in theta_list:\n",
    "        agg_weights = list()\n",
    "        for weights_list_tuple in zip(*weights):\n",
    "            agg_weights.append(np.array([np.average(np.array(w), axis=0, weights=[1. - theta, theta]) for w in zip(*weights_list_tuple)]))\n",
    "        agg_weights_list.append(agg_weights)\n",
    "    cross_dists.append(semantic_drift.l2_distance(comb[0], comb[1]))\n",
    "    agg_weights_list_per_pi.append(agg_weights_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th iteration\n",
      "20th iteration\n",
      "30th iteration\n",
      "40th iteration\n",
      "50th iteration\n",
      "60th iteration\n",
      "70th iteration\n",
      "80th iteration\n",
      "90th iteration\n",
      "100th iteration\n"
     ]
    }
   ],
   "source": [
    "B = np.zeros(len(agg_weights_list_per_pi))\n",
    "\n",
    "i = 0\n",
    "for agg_weights_list in agg_weights_list_per_pi:\n",
    "\n",
    "    aggr_model = keras.models.clone_model(model1)\n",
    "    aggr_model.set_weights(agg_weights_list[1])\n",
    "    compile_model(aggr_model)\n",
    "    score = aggr_model.evaluate(x=x_test, y=y_test, verbose=0)\n",
    "\n",
    "    aggr_model = keras.models.clone_model(model1)\n",
    "    aggr_model.set_weights(agg_weights_list[0])\n",
    "    compile_model(aggr_model)\n",
    "    comp_score1 = aggr_model.evaluate(x=x_test, y=y_test, verbose=0)\n",
    "\n",
    "    aggr_model = keras.models.clone_model(model1)\n",
    "    aggr_model.set_weights(agg_weights_list[2])\n",
    "    compile_model(aggr_model)\n",
    "    comp_score2 = aggr_model.evaluate(x=x_test, y=y_test, verbose=0)\n",
    "\n",
    "    B[i] = min(comp_score1[0], comp_score2[0]) - score[0]\n",
    "    K.clear_session() #prevent memory leak https://github.com/keras-team/keras/issues/13118\n",
    "    i += 1\n",
    "    if i % 10 == 0:\n",
    "        print(\"{}th iteration\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.array(model_dists), np.array(B), s=np.array(cross_dists)*10)\n",
    "plt.ylabel(\"aggregation benefit in loss\")\n",
    "plt.xlabel(\"l2 distance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Fetch argument <tf.Variable 'dense_17/kernel:0' shape=(784, 200) dtype=float32> cannot be interpreted as a Tensor. (Tensor Tensor(\"dense_17/kernel/Read/ReadVariableOp:0\", shape=(784, 200), dtype=float32) is not an element of this graph.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    304\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 305\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    306\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3606\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3607\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3685\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3686\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3687\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"dense_17/kernel/Read/ReadVariableOp:0\", shape=(784, 200), dtype=float32) is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-80c6914a95c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mget_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mget_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \"\"\"\n\u001b[1;32m   1351\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_updates_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m   3183\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get value inside Tensorflow graph function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3184\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3185\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3186\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3187\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1165\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \"\"\"\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections_abc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \"\"\"\n\u001b[1;32m    374\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \"\"\"\n\u001b[1;32m    374\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    310\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[0;32m--> 312\u001b[0;31m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[1;32m    313\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mValueError\u001b[0m: Fetch argument <tf.Variable 'dense_17/kernel:0' shape=(784, 200) dtype=float32> cannot be interpreted as a Tensor. (Tensor Tensor(\"dense_17/kernel/Read/ReadVariableOp:0\", shape=(784, 200), dtype=float32) is not an element of this graph.)"
     ]
    }
   ],
   "source": [
    "ws = combs[0][0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change THETA_AS_VARIABLE to true to get a 3D graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "THETA_AS_VARIABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not THETA_AS_VARIABLE:\n",
    "    theta_list = [0, 0.6, 1]\n",
    "    agg_weights_list_per_pi = list()\n",
    "    dist_list = list()\n",
    "\n",
    "    for model in model_list:\n",
    "        weights = [model1.get_weights(), model.get_weights()]\n",
    "        agg_weights_list = list()\n",
    "        for theta in theta_list:\n",
    "            agg_weights = list()\n",
    "            for weights_list_tuple in zip(*weights):\n",
    "                agg_weights.append(np.array([np.average(np.array(w), axis=0, weights=[1. - theta, theta]) for w in zip(*weights_list_tuple)]))\n",
    "            agg_weights_list.append(agg_weights)\n",
    "        dist_list.append(semantic_drift.l2_distance(model1, model))\n",
    "        agg_weights_list_per_pi.append(agg_weights_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "if THETA_AS_VARIABLE:\n",
    "    theta_list = list(np.arange(0, 1.05, 0.05))\n",
    "    agg_weights_list_per_pi = list()    # \\pi for perturbations\n",
    "    dist_list = list()\n",
    "    for model in model_list:\n",
    "        weights = [model1.get_weights(), model.get_weights()]\n",
    "        agg_weights_list = list()\n",
    "        for theta in theta_list:\n",
    "            agg_weights = list()\n",
    "            for weights_list_tuple in zip(*weights):\n",
    "                agg_weights.append(np.array([np.average(np.array(w), axis=0, weights=[1. - theta, theta]) for w in zip(*weights_list_tuple)]))\n",
    "            agg_weights_list.append(agg_weights)\n",
    "        dist_list.append(semantic_drift.l2_distance(model1, model))\n",
    "        agg_weights_list_per_pi.append(agg_weights_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (np.diff(dist_list)>0).all():\n",
    "    print(\"The dist list does not monotonically increase!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th iteration\n",
      "20th iteration\n",
      "30th iteration\n",
      "40th iteration\n"
     ]
    }
   ],
   "source": [
    "if not THETA_AS_VARIABLE:\n",
    "    B = np.zeros(len(agg_weights_list_per_pi))\n",
    "\n",
    "    i = 0\n",
    "    for agg_weights_list in agg_weights_list_per_pi:\n",
    "\n",
    "        aggr_model = keras.models.clone_model(model1)\n",
    "        aggr_model.set_weights(agg_weights_list[1])\n",
    "        compile_model(aggr_model)\n",
    "        score = aggr_model.evaluate(x=x_test, y=y_test, verbose=0)\n",
    "        \n",
    "        aggr_model = keras.models.clone_model(model1)\n",
    "        aggr_model.set_weights(agg_weights_list[0])\n",
    "        compile_model(aggr_model)\n",
    "        comp_score1 = aggr_model.evaluate(x=x_test, y=y_test, verbose=0)\n",
    "        \n",
    "        aggr_model = keras.models.clone_model(model1)\n",
    "        aggr_model.set_weights(agg_weights_list[2])\n",
    "        compile_model(aggr_model)\n",
    "        comp_score2 = aggr_model.evaluate(x=x_test, y=y_test, verbose=0)\n",
    "        \n",
    "        B[i] = score[0] - min(comp_score1[0], comp_score2[0])\n",
    "        K.clear_session() #prevent memory leak https://github.com/keras-team/keras/issues/13118\n",
    "        i += 1\n",
    "        if i % 10 == 0:\n",
    "            print(\"{}th iteration\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEGCAYAAACtqQjWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd3hUZfr/8fedTiAFQqgBQocAIhC6soiiFAXXxVXXVbAsropr2++q6+r+1C26lt21Y0PFgooNhSwWEAWkhBq6oQdCLwkl/f79MQc3G1MmMJMzydyv65orJ2fOzHzmwMyd85znPI+oKsYYY4wvhLgdwBhjTN1hRcUYY4zPWFExxhjjM1ZUjDHG+IwVFWOMMT4T5naAmtC4cWNNTk52O4YxxtQqy5YtO6CqidV5TFAUleTkZNLT092OYYwxtYqIbK/uY6z5yxhjjM9YUTHGGOMzVlSMMcb4jBUVY4wxPmNFxRhjjM9YUTHGGOMzVlSMMcb4TFBcp2KCS2FxCbl5ReTmFZJzsoicvEJyThaSm+dZzi8q4aJuTenQJMbtqMbUOVZUTMBTVZZsPcTm/cd/LBA5eU6ROFlIjvPzVNE4UVBc5XM+Pnsj53ZszPWD2/KzTomEhEgNvBNj6j4rKiagrdudw19nrWNB5sEf14WFCLH1womNCiMmKpzYemE0iWlAbFQ4MVFhP94XWy/cc/+pdfU89+cXljBtyQ6mLtrOda8vpV3j+owflMy4PknUj7SPhDFnQoJh5sfU1FS1YVpql705eTz5xUY+WJZFXL1w7ji/IyO6NyeuXjhR4SGInPmRRUFRCWlrsnltwTZW7TxCTGQYv+zbigmDkmnVKNoH78KY2k1ElqlqarUeY0XFBJITBUW8/O1WXpy3maKSEiYMSmbSeR2Jiw736+su33GYKQu2kZaRTYkqF3RtynWD2zKgXSOfFDBjaqPTKSp2rG8CQkmJ8tGKXTw+ewN7c/IZ1aMZ94zoQpuE+jXy+r1bN6R364bsGdWVqYu28c7iHXyxbi9dmsVw/eC2jDm7BVHhoTWSxZjazI5UjOsWbj7AX2euZ+3uHHq2iueB0V1JTW7kaqa8wmI+XbmLKQu2sWFPLo3qR/Crfq25ZmAbmsZGuZrNmJpizV8VsKISmDbvP8bfZ23gq/V7aRlfjz+M6MwlZ7UIqJ5Yqsr3Ww4yZcE2vlq/l1ARxvRswc1D29OxqXVJNnWbNX+ZWuHQ8QKe/voH3lq0najwUP4wojPXD24bkM1LIsKg9o0Z1L4xOw6e4PWF23h3yQ4+WrGLi7o15ZahHejZKt7tmMYEDDtSMTUmv6iYNxZu45k5mRzPL+JX/VtzxwWdaNwg0u1o1XLoeAGvL9zG6wu2kpNXxLkdG3PL0A52Ut/UOdb8VQErKu5SVWZl7OHR/6xn56GTnNc5kT+O6lrrm4+O5Rfx9qLtvPzdVg4cy6d363huPa8Dw7o0seJi6gQrKhWwouKe5TsO89eZ61m2/TBdmsVw/+iunNuxWlNeB7y8wmI+WJbF5HmbyTp8ki7NYrh5aHtG92hOWKgNr2dqLysqFbCiUvN2HjrBP2Zv5LNVu0mMieTu4Z24PLUVoQF0Et7XCotL+GzVbp7/ZjOZ+47RJiGa3/6sPZf1bklkWOCdLzKmKlZUKmBFpebk5BXy/NzNvLZgKyECE89tx00/ax9Uw5+UlChfrNvL899ksjrrKM1io7hzeEfG9anbRdXUPVZUKmBFxf+Kikt4d8kO/vnVDxw6XsBlvVvyfxd1pnlcPbejuUZVmZ95gH9+uYnlO47QvWUsD17cjX5t3b0GxxhvWVGpgBUV/9qy/xgTpy4jc98xBrRrxJ9Gp9C9ZZzbsQKGqjJj1W4eTdtA9tE8Rp/VnPtGdiGpoY0vZgKbXadiapyqcv/Ha9ifm89L1/RheEpT6/lUhogw9uyWXJjSjBfnbWbyt5v5at1ebhrSjt8ObU90hH0MTd1hXVPMGZm9di/fbznI3Rd24sJuzaygVKJeRCh3Du/EnLuHclG3Zjw9J5NhT8zj4xVZlJTU/RYDExysqJjTlldYzF9nraNT0wb8ql9rt+PUGi3i6/H0Vb348OaBNImN5M73VvGLFxeycucRt6MZc8asqJjT9tqCrew8dJIHL+5m12Ochj5tGvHJLYN54vKeZB0+yaXPLeCu91Zy6HiB29GMOW32TWBOy76cPJ6bk8kFXZtyTsfGbseptUJChHF9kpj7+6HcMrQ9n6/O5upXFnP0RKHb0Yw5LVZUzGl5fPZGCopLuH90V7ej1AkNIsP4w4guvDI+lc37jnHd60s4nl/kdixjqs2Kiqm2jKyjTF+exXWD29K2cc1MohUshnRK5OmrzmblziPcNHUZeYXFbkcyplqsqJhqUVUe+mwtjaIjmDSsg9tx6qQR3Zvzj3E9mZ95gN+9u4Ki4hK3IxnjNSsqplo+X51N+vbD/P6izsRG+Xfe+GA2rk8SD43pxhfr9vKH6auty7GpNeyqK+O1vMJiHk3bQNfmsfwytZXbceq88YOSyc0r5IkvNlE/MoyHx3az64BMwPPrkYqIjBCRjSKSKSL3lnN/pIi859y/WESSnfUJIjJXRI6JyLMVPPcMEVnjz/zmf7307RZ2HTnJny9JsYERa8it53XgpiHtmLpoO4/P3uh2HGOq5LcjFREJBZ4DhgNZwFIRmaGq60ptdgNwWFU7iMiVwGPAFUAe8ADQ3bmVfe7LgGP+ym5+as/RPF74ZjMjuzdjQLsEt+MEDRHh3pFdyM0v4vlvNhMTFc7NQ9u7HcuYCvnzSKUfkKmqW1S1AJgGjC2zzVjgDWd5OnC+iIiqHlfV+XiKy/8QkQbAXcBf/BfdlPXYfzZQrMofR1kX4pomIjwytjtjz27BY//ZwNRF292OZEyF/HlOpSWws9TvWUD/irZR1SIROQokAAcqed5HgCeBE5W9uIhMBCYCtG5tQ4icieU7DvPxil3cMrQ9rRrZyLpuCA0Rnri8J8fzi3jw0zXERIZxaa+Wbscy5idqVe8vETkbaK+qH1e1raq+pKqpqpqamFi3pq+tSSUlysOfraNJTCS3nGddiN0UHhrCs7/qzYC2Cdz9wSrmbNjrdiRjfsKfRWUXULqLUJKzrtxtRCQMiAMOVvKcA4FUEdkGzAc6icg3PspryvHpql2s3HmEP4zoQoMgmr0xUEWFh/Ly+FRSmscy6Z0VrNl11O1IxvwPfxaVpUBHEWkrIhHAlcCMMtvMAMY7y+OAOVrJrGGq+oKqtlDVZOAcYJOqDvV5cgPAiYIiHkvbSM+kOC6zppaA0SAyjFfHp9IwOoLrX1/K7iMn3Y5kzI/8VlRUtQiYBMwG1gPvq+paEXlYRMY4m70KJIhIJp6T7z92O3aORp4CJohIloik+CurKd+L32xmT04eD16SQoh1IQ4oTWKjeG1CX04WFHP960vJzbMBKE1gsOmETbmyDp/g/CfneSaTuqqX23FMBeb/cIAJU5YwsH0Cr03oS7hNQWB86HSmE7b/gaZcf0/bgAjcO7KL21FMJc7p2Ji//bwH3/1wgAc+WUMw/JFoApudeTU/sWTrIWauzub28zvSIr6e23FMFX7ZtxU7Dp3g2bmZtE6I5pah1kvPuMeKivkfJSXKw5+vpXlcFL/9mV25XVvcfWEndh4+wT/+s5GkhtGM6dnC7UgmSFnzl/kf05dlsWZXDveO7EK9iFC34xgviQj/GHcW/ZIb8fsPVrF02yG3I5kgZUXF/Cg3r5B/zN5I79bx9pduLRQZFspL1/YhKb4ev3kzna0HjrsdyQQhKyrmR8/N3cyBY/n8+RIbYr22io+OYMp1fQkR4bopS9ib85Ph84zxKysqBoDtB4/z2vytXNa7JT1bxbsdx5yBNgn1efnaVPbl5nPxM/NZtv2w25FMELGiYgD426z1hIUK94ywLsR1QZ82Dfn4lsHUCw/lqpcW8d7SHW5HMkHCioph4eYDzF67l1vP60DT2Ci34xgf6dwshhmTBtO/XSPu+TCDBz5ZQ6HNd2/8zIpKkCt2RiFOaliPG85p63Yc42Px0RFMmdCX35zblqmLtnP1K4s5cCzf7VimDrOiEuSmLd3Bhj25/HFUV6LCrQtxXRQWGsL9o1P41xVns2rnEcY8M99GNzZ+Y0UliB09WciTX2yiX9tGjOzezO04xs8u7dWS6b8dBMAvXljIpyvLzkRhzJmzohLEnvn6Bw6fKODBi1OsC3GQ6JEUx4zbzqFnUjy3T1vJnz7J4ERBkduxTB1iRSVIbdl/jNcXbuOK1FZ0bxnndhxTgxo3iOStG/vzm3Pb8vbiHYz693cs32Hdjo1vWFEJUn+duZ6o8FDuvrCz21GMCyLCPOdZ3rlxAIXFyrgXFvLE7I0UFFnvMHNmrKgEoXmb9vP1hn3cNqwDiTGRbscxLhrYPoH/3HEul/VO4tm5mfz8+QVs2pvrdixTi1lRCTKFxSU88vk62iREM2FwsttxTACIiQrnict7MvmaPuw5msfFz8znle+2UFJic7OY6quyqIjIY96sM7XD24u2k7nvGPeP6kpkmHUhNv91UbdmzL5zCEM6JvKXmesZP2WJXSxpqs2bI5Xh5awb6esgxv8OHy/gn1/9wOAOCQxPaep2HBOAGjeI5OVr+/DI2G5898MB/vnlJrcjmVqmwkm6RORm4BagnYisLnVXDLDA38GM7/3rq03k5hXy4MU2CrGpmIhwzcBk1u7O4YV5mzm3YyID2ye4HcvUEpUdqbwDXALMcH6euvVR1V/XQDbjQ5v25vLW4h1c3b8NnZvFuB3H1AIPXpJC24T63PneSo6cKHA7jqklKisqqqrbgFuB3FI3RKSR/6MZX1FVHvl8HfUjQrlzeCe345haIjoijH9f2YuDx/O576MMVO3EvalaVUcqAMuAdOfnslK/m1pizoZ9fPfDAe64oBON6ke4HcfUIj2S4rj7ws6krdnD++k73Y5jaoEKz6kAjzo/u6qqTR9XSxUUlfCXmetpn1ifawa2cTuOqYUmntuObzft5//NWEff5Ea0S2zgdiQTwCo7Uvm383NhTQQx/vHm99vYeuA4f7o4hfBQuyzJVF9IiPDUL88mMjyE26ettKvuTaUq+5YpFJGXgCQRebrsraYCmtN38Fg+//76B4Z2TuS8zk3cjmNqsWZxUTx62Vlk7DrKU9bN2FSisuavi4ELgIvwnEcxtcyTX27iZEExfxqd4nYUUweM6N6Mq/q1YvK3mxnSqTGD2jd2O5IJQBUWFVU9AEwTkfWquqoGMxkfWJ+dw7QlOxg/KJkOTawN3PjGAxensHjrIX737kreurEfXZrFuh3JBBhvGtlPisjXIrIGQETOEpE/+TmXOQOqnimC4+qFc8f51oXY+E50RBgvXdOHsBDh8he+5/vNB92OZAKMN0XlZeA+oBBAVVcDV/ozlDkzs9fu5fstB7lreCfiosPdjmPqmA5NYvjolkE0i4ti/GtLmLk62+1IJoB4U1SiVXVJmXU2VVyAyiss5m+z1tO5aQxX9WvtdhxTR7WIr8cHvx1Iz1ZxTHp3OVMWbHU7kgkQ3hSVAyLSHlAAERkH2J8mAeq1BVvZcegED16SQph1ITZ+FB8dwdQb+nNhSlMe+mwdf09bb8PlG6+Kyq3AZKCLiOwC7gBu9msqc1r25eTx3JxMhqc0ZXAH65lj/C8qPJTnr+7DNQPaMHneFu7+YJVdxxLkqiwqqrpFVS8AEoEuqnqOMyZYlURkhIhsFJFMEbm3nPsjReQ95/7FIpLsrE8QkbkickxEni21fbSIzBSRDSKyVkQeLfucwezx2RspKC7h/lFd3Y5igkhoiPDw2G78/sJOfLxiF/d+tNrGCQtilV2nAni++IFfAMlA2Kkh01X14SoeFwo8h2c+lixgqYjMUNV1pTa7ATisqh1E5ErgMeAKIA94AOju3Ep7QlXnikgE8LWIjFTVtCrfaR2XkXWU6cuzmHhuO5Ib13c7jgkyIsKkYR0pLoF/frWJlOax3HhuO7djGRd40/z1KTAWz8n546VuVekHZDpHOgXANOd5ShsLvOEsTwfOFxFR1eOqOh9PcfmRqp5Q1bnOcgGwHEjyIkudpqo89NlaEupHMGlYB7fjmCB227AOjOzejL/NWs+8TfvdjmNcUOWRCpCkqiNO47lbAqWHNc0C+le0jaoWichRIAE4UNWTi0g8nvld/l3B/ROBiQCtW9ftXlCfr84mffthHr2sBzFR1oXYuCckRHjylz3Z9sIJJr2znE9vHWwDUAYZb45UFopID78nqQYRCQPeBZ5W1S3lbaOqL6lqqqqmJiYm1mzAGpRXWMyjaRtIaR7L5amt3I5jDNERYbx8bR/CQ0O48c10cvIK3Y5kapA3ReUcYJlzwn21iGSUmV64IruA0t9ySc66crdxCkUc4M0lui8BP6jqv7zYtk6blZHNriMnuX90V0JDbIpgExiSGkbzwtW92XHwBL97dwXF1tU4aHhTVEYCHYEL8TQ3Xez8rMpSoKOItHVOql+JZ2ri0mYA453lccAcraLbiIj8BU/xucOLDHXerIxsWsRFMcjmEDcBpn+7BB4a241vNu7nH7M3uB3H1BBvuhRvx3M0McxZPuHl44qAScBsYD3wvqquFZGHRWSMs9mrQIKIZAJ3AT92OxaRbcBTwAQRyRKRFBFJAu4HUoDlIrJSRG70/u3WLTl5hXy76QAjezTnVK88YwLJ1f3b8OsBrZk8bwvTl2W5HcfUAG+6FP8ZSAU6A1OAcOAtYHBVj1XVWcCsMuseLLWcB1xewWOTK4pU1esGiznr91FQXMKoHs3djmJMhf58STe27D/OPR+upn5EKCPt/2ud5k3z18+BMTjdiFV1NxDjz1DGOzMzsmkWG0WvVvFuRzGmQuGhIbx8bSpnt4rntndX8PX6vW5HMn7kTVEpcM5znBr7y66sCwC5eYXM27SfkT2aEWIn6E2Aqx8ZxpTr+pLSIpab31rOt3YNS53lTVF5X0QmA/Ei8hvgKzzD4RsXzdmwj4KiEkZbU4KpJWKjwnnz+n60b9KAiVPTWbTF5mKpi7w54f4EnqvdPwQ6AQ+q6jP+DmYqNysjm6axkfRu3dDtKMZ4LT46grdu6EerhtFc//pSlm0/5HYk42Pejo2eAXwHfOssGxcdzy/im437Gdm9uTV9mVonoUEkb9/Yn6axUUx4bSnrdue4Hcn4UJVFxemyuwS4DM+1JItE5Hp/BzMV+3rDPvKLrNeXqb2axEbxzm/6Uz8yjIlT0zl0vMDtSMZHvDlS+T+gl6pOUNXxQB/gHv/GMpWZtTqbJjGRpLaxpi9TezWPq8fka/qwLzefSe8sp6jY5mGpC7wpKgeB3FK/5+LdUCrGD47nFzF34z5GdrdeX6b269kqnr9e2p2Fmw/yaJpddV8XVHjxo4jc5SxmAotF5FM83YrHAt6M/WX8YO5GT9OXXUBm6orLU1uxdncOr8zfSreWsfy8V9DPZlGrVXZF/akLHDc7t1M+9V8cU5VZGdk0bhBJ3+RGbkcxxmfuH92V9dk53PthBh2bxNC9ZZzbkcxpqrCoqOpDNRnEVO1EQRFzNuzj8j6tbERiU6eEh4bw3NW9GfPMfCa+mc6M286hcYNIt2OZ0+Btl2ITAL7ZuJ+8whJG9mjmdhRjfK5xg0gmX5PKweMFXDH5e/6zJpsSGzK/1rGiUovMzMimcYMI+re1Ye5N3dQjKY6Xrk1FFX771nJGPzOf2Wv3UMWMGCaAWFGpJU4WFDNn/T4u6tbMmr5MnfazTol8cecQnvplT04WFHHT1GVc/Mx8Gy+slvBm6PtE4DdAcuntVdUugKxB8zbt42RhsY31ZYJCWGgIl/VOYkzPFnyycjfPzPmBCVOW8Mr4VIZ1aep2PFMJb45UPsUz0+JXwMxSN1ODZmbsoVH9CPq1tV5fJniEhYYwrk8SabefS0qLWG57ZwXrs21Yl0DmTVGJVtV7VPV9Vf3w1M3vycyP8gqL+Xr9Xi7q1oywUGuxNMEnOiKMV8f3JSYqnBteX8q+nDy3I5kKePMN9bmIjPJ7ElOhbzbu50SBNX2Z4NY0NopXJ6Ry5GQhN76ZzsmCYrcjmXJ4U1Rux1NY8kQk17nZ8WcNSluTTcPocAa0s6YvE9y6tYjj6St7kbHrKHe9v9K6HAcgb+ZTiVHVEFWNcpZjVDW2JsKZU01f+6zpyxjHBSlNuX9UV9LW7OGx2Rusu3GAqbL3F4CIjAGGOL9+o6qf+y+SKe3bTfs5ll9kw9wbU8oN57Rl28HjTJ63BVW4b2QXRKyrfSDwpkvxo0Bf4G1n1e0iMlhV7/NrMgN4xvqKjw5nYHu74NGYU0SEh8d0J0SEl77dwvH8Ih4Z291G7g4A3hypjALOVtUSABF5A1gBWFHxs/yiYr5av49RPZoRbk1fxvyPkBDhoTHdiI4I48V5mzlZUMw/xp1lzcQu86r5C4gHTk0mbcOH1pDvNh2wpi9jKiEi3DuyCzFRYTw+eyMnC4v595W9iAizwuIWb4rK34EVIjIXEDznVu71ayoDeJq+4uqFM7hDY7ejGBPQbj2vA/XCQ3n483XseH4Bj1zand6tbWZUN3jT++tdYADwEfAhMFBV3/N3sGCXX1TMl+v2cmFKU2v6MsYL15/TlsnX9OHgsQIue34h9364msPHC9yOFXQq/LYSkS7Oz95AcyDLubVw1hk/WpB5gFxr+jKmWi7q1oyv7v4ZE4e0Y/qyLM578hs+SN/pdqygUlnz113ARODJcu5TYJhfEhkAZq7eQ2xUmDV9GVNNDSLD+OOorozrk8SfPl7D/01fTcPoCC5IsYEoa0KFRyqqOtFZHKmq55W+4ekRZvykoKiEL9ftYXhKMzvhaMxp6tQ0hqk39qNr81ju+XA1+3Pz3Y4UFLz5xlro5TrjIwsyD5CTV8Tos2yGR2PORGRYKP++8mxy84u458PVdvV9DajsnEozEekD1BORXiLS27kNBaJrLGEQmpWRTUykNX0Z4wudmsZw38guzNmwj7cX73A7Tp1X2TmVi4AJQBLwVKn1ucAf/ZgpqBUWl/DFur0MT2lKZFio23GMqRPGD0xmzoZ9/GXmOga2T6B9YgO3I9VZlZ1TecM5fzKhzDmVMar6UQ1mDCoLMg9w9GSh9foyxodCQoQnLu9JVHgod0xbSUFRiduR6ixvrlP5UERGi8gfROTBUzdvnlxERojIRhHJFJGfXDApIpEi8p5z/2IRSXbWJ4jIXBE5JiLPlnlMHxHJcB7ztNSxUeTSMvbQIDKMczpa05cxvtQ0NopHL+tBxq6j3PL2MpuPxU+qLCoi8iJwBXAbnivqLwfaePG4UOA5YCSQAlwlIillNrsBOKyqHYB/Ao856/OAB4Dfl/PULwC/ATo6txFVZaktCotLmL1uDxd0bUJUuDV9GeNrI7o35+Gx3fh6wz5+9coiDtnFkT7nTe+vQap6LZ4v/4eAgUAnLx7XD8hU1S2qWgBMA8aW2WYs8IazPB04X0REVY+r6nw8xeVHItIciFXVRerpxvEmcKkXWWqF7zcf5MgJa/oyxp+uHZjMC1f3Yd3uHH7xwkJ2HDzhdqQ6xZuictL5eUJEWgCFeK6wr0pLoPSlrFnOunK3UdUi4ChQ2RjvLZ3nqew5ARCRiSKSLiLp+/fv9yKu+2ZlZFM/IpQhnRLdjmJMnTaiezPevrE/h44XcNkLC1ifbZPZ+oq3c9THA48Dy4FtwLv+DOULqvqSqqaqampiYuB/SRcVlzB77R7O79rUmr6MqQGpyY348OZBhIWEcOMb6Rw4ZhdH+oI3J+ofUdUjqvohnnMpXVT1AS+eexfQqtTvSc66crcRkTA8w+ofrOI5k6p4zlpp0ZZDHLamL2NqVIcmDXj52lQOHMvn5reWWa8wH/DmRP1lp27AaDznPc4XkSZVPHQp0FFE2opIBHAlMKPMNjOA8c7yOGCOVnLJq6pmAzkiMsDp9XUt8GlV76E2mOk0fQ3tHPhHVcbUJT2S4nj88p4s3XaYP89YY1fdnyFv5lO5Ac/J+bnO70OBZUBbEXlYVaeW9yBVLRKRScBsIBR4TVXXisjDQLqqzgBeBaaKSCaeScCuPPV4EdkGxAIRInIpcKGqrgNuAV4H6gFpzq1WO9X0NcyavoxxxZieLdi4J4fn5m6ma/NYrh2Y7HakWsubohIGdFXVvQAi0hRPr6v+wLdAuUUFQFVnAbPKrHuw1HIeni7K5T02uYL16UB3L3LXGku2HuLQ8QJGdbexvoxxy93DO7NxTy4PfbYOEeHKvq1sLqPT4M0ea3WqoDj2OesO4ekJZs7QzIxs6oWHMrRzVS2Kxhh/CQkR/nnF2fRp05AHPlnDBU/N49OVuygpseaw6vCmqHwjIp+LyHgRGY/nPMg3IlIfOOLfeHVfcYk6TV9NqBdhTV/GuCkmKpz3Jg7g1fGp1AsP5fZpKxn57+9YudO+6rzlTVG5FZgCnO3c3gBudS5QPM+f4YLB4q0HOXCsgNHW68uYgCAinN+1KbN+dy5PX9WLY/lFXP7iQl6dv9VO4nuhynMqqqoikg4cVdWvRCQaaIBntGJzhtIy9hAVHmK9vowJMCEhwpieLfhZx0R+P30Vj3y+jkVbDvLEuJ7ERYe7HS9gedOl+Dd4hlCZ7KxqCXziz1DBorhESVuzh2FdmhAd4U2fCWNMTYuLDuela/rwwMUpzN2wj0uenc/RE3Y6uSLeNn8NBnIAVPUHwM4o+8DSbYc4cCzfLng0JsCJCDec05a3b+xP1uETPPnlRrcjBSxvikq+MyAk8OOV79aw6ANpGdlEhoVwnvX6MqZW6N8ugV8PaMNbi7azdvdRt+MEJG+KyjwR+SOeaYWHAx8An/k3Vt1X4jR9nde5CfUjrenLmNri7uGdaRgdwYOfrrXuxuXwpqjcA+wHMoCb8FzM+Cd/hgoG6dsPsy83n1FnWdOXMbVJXHQ494zswrLth/loRZ0YetCnKv0T2Zloa62qdgFerplIwWGW0/Q1rIs1fRlT24zrncS7S3bwaNp6hqc0Ja6e9QY7pdIjFVUtBjaKSOsayhMUPE1f2fysUyINrOnLmFonJER4ZGx3DvDbLUoAABOQSURBVB4v4P/NWEtRsY1ufIo332gNgbUisgQ4fmqlqo7xW6o6bvmOw+zNyWe0NX0ZU2t1bxnHbcM68vTXP7DnaB7P/qoXCQ0i3Y7lOm+Kijdzp5hqmJmRTURYCOd3bep2FGPMGbhreCfaNIrmjx9ncMkz83nxmj6clRTvdixXeXNF/byaCBIsSkqUtIw91vRlTB3xiz5JdG4Ww01TlzHuhe9JTW5Ir9bx9GrVkIHtE4Kud2eV71ZEcvnpdSlHgXTgblXd4o9gddWKnUfYk5PHPT06ux3FGOMj3VvG8dlt5/DMnB9I33aYF+dtobhEaZMQzdTr+9M6IdrtiDXGmxL6LyALeAcQPBNptcczX/1reCbtMl6alZFNRKg1fRlT1zSqH8GfL+kGwMmCYhZuPsDdH6zishcW8sb1fenWIs7lhDXDm+tUxqjqZFXNVdUcVX0JuEhV38NzEt94ydP0lc2QTo2JjbIuiMbUVfUiQjm/a1Om/3YgEaHCFZMXsXDzAbdj1QhvisoJEfmliIQ4t18Cec59djlpNazMOsLuo3mM7G69vowJBh2axDD95kE0j4viuilLyciq+0O7eFNUrgauwTPj415n+dciUg+Y5MdsdU5aRjbhocIFKdb0ZUywaBFfj3cnDqBxg0humprOgWP5bkfyqyqLiqpuUdVLVLWxqiY6y5mqelJV59dEyLpAVZmVsYdzOyba1bfGBJnGDSKZfE0fDh4v4Ja3l1NYhy+W9Kb319PlrD4KpKvqp76PVDetyjrKriMnuXN4J7ejGGNc0L1lHI/94izueG8lf/l8HQ+N7e52JL/wpvdXFNAFz+jEAL8AtgI9ReQ8Vb3DX+HqklNNX8Ot15cxQevSXi1Zu/soL3+3laIS5cFLUogMC3U7lk95U1TOAgY744AhIi8A3wHn4Bm52FRBVZmZkc3gDo1tGlJjgty9I7sSIsLkb7ewdncOL/y6N83j6rkdy2e8OVHfEM+c9KfUBxo5RaZun3HykYxdR8k6fNJmeDTGEBoi3DeqKy9c3Zsf9uYy+un5TFmwtc5MUexNUfkHsFJEpojI68AK4HERqQ985c9wdcXMjGzCQoQLrdeXMcYxskdzPp10Dm0Sonnos3X0+9tX3PXeSvbl5FX94ADmzdhfr4rILKCfs+qPqrrbWf4/vyWrI1Q9Y30N6tCY+OgIt+MYYwJIhyYN+PiWwazdfZRpS3bywbKdbD90gmkTBxAe6s3f/IHH29R5QDZwGOggIkP8F6luWbs7hx2HTjC6RzO3oxhjAlS3FnE8cml3/jGuJ8u2H+aJLza6Hem0edOl+EbgdiAJWAkMAL4Hhvk3Wt0wMyOb0BDhwhQrKsaYyo3p2YLFWw4yed4W+rdtxLAuta/J3JveX7cDfYFFqnqeiHQB/ubfWHWD54LHbAa1T6BhfWv6MsZU7YGLU1ix4wh3vb+Kawa04Vh+EQA3DWlPs7gol9NVzZvmrzxVzQMQkUhV3QDYuO1eWJedw/aDJ6zXlzHGa1HhoTx3dW8iQkN4dm4m09OzmPr9du54bwUlJYE/3KI3RypZIhIPfAJ8KSKHge3+jVU3zHKavi7qZk1fxhjvtW1cn+/vOx8BQkKEaUt2cO9HGby9eDvXDEx2O16lvOn99XNn8f+JyFwgDviPX1PVAafG+hrYLoFG1vRljKmm0BD5cfmKvq2YmZHN39M2MLRzE1o1CtxJv6rVZ01V56nqDFUt8FegumJ9di5bDxxnpPX6MsacIRHh0V+cRYgIf5i+moKiwB2Q0q8doUVkhIhsFJFMEbm3nPsjReQ95/7FIpJc6r77nPUbReSiUuvvFJG1IrJGRN4VkYA8c5W2JpsQwZq+jDE+0TK+Hg9c3JXvtxxk8GNzeObrHzh0PPD+vvdbURGRUOA5YCSQAlwlIillNrsBOKyqHYB/Ao85j03BM21xN2AE8LyIhIpIS+B3QKqqdgdCne0Cyqmxvga0S6Bxg0i34xhj6ogr+rbmzev70bV5LE9+uYlzHpvDq/O3UhxAJ/D9eaTSD8h05mMpAKYBY8tsMxZ4w1meDpwvIuKsn6aq+aq6Fcjkv1f0hwH1RCQMiAZ2E2A27s1ly/7j1uvLGONzQzol8ub1/fjiziH0a9uIRz5fx6XPLeDz1btZnXWEwy4fvfizqLQEdpb6PctZV+42qlqEZ56WhIoeq6q7gCeAHXiu8D+qql+U9+IiMlFE0kUkff/+/T54O96blbHHmr6MMX7VqWkMUyb05dlf9WJPTh6T3lnBmGcX0PsvX/LO4h2u5fKmS3HAEJGGeI5i2gJHgA9E5Neq+lbZbVX1JeAlgNTU1Bo9NpyVkU2/to1IjLGmL2OM/4gIF5/Vggu6NmXz/mNkHT7Jq/O38rdZ6xnWpYkrF0v680hlF9Cq1O9Jzrpyt3Gas+KAg5U89gJgq6ruV9VC4CNgkF/Sn6ZNe3PJ3HeM0db0ZYypIVHhoXRrEcdF3Zrx+LizKCwu4aHP1rqSxZ9FZSnQUUTaikgEnhPqM8psMwMY7yyPA+aoqjrrr3R6h7UFOgJL8DR7DRCRaOfcy/nAej++h2qbuTobEbiouzV9GWNqXpuE+tw2rANpa/YwZ8PeGn99vxUV5xzJJGA2ni/+91V1rYg8LCJjnM1eBRJEJBO4C7jXeexa4H1gHZ4LLW9V1WJVXYznhP5yPLNOhuA0cQWKtDXZ9E1uRJOYgOzpbIwJAhOHtKdDkwY88MlaThQU1ehri+fAoG5LTU3V9PR0v79O5r5cLnjqWx4a043xg5L9/nrGGFORxVsOMnXRdh4Z2/20B7QVkWWqmlqdx9SqE/WBbubqPYjACGv6Msa4rH+7BPq3S6jx162dU4sFqFkZ2aS2aUjTWGv6MsYEJysqPpK57xgb9+baBY/GmKBmRcVH0jKyARjZ3YqKMSZ4WVHxkZlO01dtmJnNGGP8xYqKD2zZf4wNe3IZaU1fxpggZ0XFB9LW7AFglM2dYowJclZUfGDm6mx6t46neVw9t6MYY4yrrKicoW0HjrMuO8d6fRljDFZUztjMU72+rKgYY4wVlTOVtiabs1vF0zLemr6MMcaKyhnYcfAEa3bl2DD3xhjjsKJyBk41fdlYX8YY42FF5QykrcmmZ1IcrRpFux3FGGMCghWV07Tz0AlWZx21Xl/GGFOKFZXTNMtp+rKiYowx/2VF5TTNysimR0tr+jLGmNKsqJyGrMMnWGVNX8YY8xNWVE5DWoZnrC/rSmyMMf/LisppmJmRTfeWsbROsKYvY4wpzYpKNe06cpKVO4/YZFzGGFMOKyrVdGqGR2v6MsaYn7KiUk2zMrJJaR5LcuP6bkcxxpiAY0WlGnYfOcnyHUdsMi5jjKmAFZVq+O8Mj9b0ZYwx5bGiUg1pGdl0aRZDu8QGbkcxxpiAZEXFS3uO5pG+/bCdoDfGmEpYUfFS2hqb4dEYY6piRcVLaRl76Nw0hg5NrOnLGGMqYkXFC/ty8li6/ZCdoDfGmCpYUfFC2po9qMLos6wrsTHGVMaKihdmZmTTsUkDOjSJcTuKMcYENCsqVdiXm8fSbdb0ZYwx3vBrURGRESKyUUQyReTecu6PFJH3nPsXi0hyqfvuc9ZvFJGLSq2PF5HpIrJBRNaLyEB/vofZPzZ9WVExxpiq+K2oiEgo8BwwEkgBrhKRlDKb3QAcVtUOwD+Bx5zHpgBXAt2AEcDzzvMB/Bv4j6p2AXoC6/31HsDT9NU+sT4drdeXMcZUyZ9HKv2ATFXdoqoFwDRgbJltxgJvOMvTgfNFRJz101Q1X1W3AplAPxGJA4YArwKoaoGqHvHXG9ifm8+SrYcY3aM5nljGGGMq48+i0hLYWer3LGdduduoahFwFEio5LFtgf3AFBFZISKviEi5wwWLyEQRSReR9P3795/WG5i9dg8lCqOs6csYY7xS207UhwG9gRdUtRdwHPjJuRoAVX1JVVNVNTUxMfG0XmxWRjbtEuvTuan1+jLGGG/4s6jsAlqV+j3JWVfuNiISBsQBByt5bBaQpaqLnfXT8RQZn1NVujaP5er+bazpyxhjvOTPorIU6CgibUUkAs+J9xlltpkBjHeWxwFzVFWd9Vc6vcPaAh2BJaq6B9gpIp2dx5wPrPNHeBHhgYtTuOGctv54emOMqZPC/PXEqlokIpOA2UAo8JqqrhWRh4F0VZ2B54T7VBHJBA7hKTw4272Pp2AUAbeqarHz1LcBbzuFagtwnb/egzHGmOoRz4FB3Zaamqrp6eluxzDGmFpFRJapamp1HlPbTtQbY4wJYFZUjDHG+IwVFWOMMT5jRcUYY4zPWFExxhjjM1ZUjDHG+ExQdCkWkf3A9mo+rDFwwA9xfMXynRnLd2Ys35mpLfnaqGq1xrkKiqJyOkQkvbr9s2uS5Tszlu/MWL4zU5fzWfOXMcYYn7GiYowxxmesqFTsJbcDVMHynRnLd2Ys35mps/nsnIoxxhifsSMVY4wxPmNFxRhjjM8EfVERkREislFEMkXkJ1MTi8gEEdkvIiud2401mO01EdknImsquF9E5Gkn+2oR8cssmGeQb6iIHC217x6s4XytRGSuiKwTkbUicns527i2D73M59o+FJEoEVkiIqucfA+Vs02kiLzn7L/FIpIcYPlc+/yWyhAqIitE5PNy7nNt/3mZr/r7T1WD9oZn8rDNQDsgAlgFpJTZZgLwrEv5huCZLnlNBfePAtIAAQYAiwMs31Dgcxf/fZsDvZ3lGGBTOf++ru1DL/O5tg+dfdLAWQ4HFgMDymxzC/Cis3wl8F6A5XPt81sqw13AO+X9O7q5/7zMV+39F+xHKv2ATFXdoqoFwDRgrMuZfqSq3+KZEbMiY4E31WMREC8izWsmnVf5XKWq2aq63FnOBdYDLcts5to+9DKfa5x9csz5Ndy5le3ZMxZ4w1meDpwvIhJA+VwlIknAaOCVCjZxbf+BV/mqLdiLSktgZ6nfsyj/Q/0Lp2lkuoi0qploXvE2v5sGOs0TaSLSza0QTrNCLzx/zZYWEPuwknzg4j50mkZWAvuAL1W1wv2nqkXAUSAhgPKBu5/ffwF/AEoquN/V/UfV+aCa+y/Yi4o3PgOSVfUs4Ev++1eFqdpyPGMH9QSeAT5xI4SINAA+BO5Q1Rw3MlSminyu7kNVLVbVs4EkoJ+IdK/J16+KF/lc+/yKyMXAPlVdVlOvWR1e5qv2/gv2orILKF15k5x1P1LVg6qa7/z6CtCnhrJ5o8r8blLVnFPNE6o6CwgXkcY1mUFEwvF8Yb+tqh+Vs4mr+7CqfIGwD53XPgLMBUaUuevH/SciYUAccLBm01Wcz+XP72BgjIhsw9O0PkxE3iqzjZv7r8p8p7P/gr2oLAU6ikhbEYnAc6JsRukNyrSvj8HT7h0oZgDXOj2YBgBHVTXb7VCniEizU+3DItIPz/+3GvvCcV77VWC9qj5VwWau7UNv8rm5D0UkUUTineV6wHBgQ5nNZgDjneVxwBx1zvAGQj43P7+qep+qJqlqMp7vljmq+usym7m2/7zJdzr7L8ynKWsZVS0SkUnAbDw9wV5T1bUi8jCQrqozgN+JyBigCM9J6Qk1lU9E3sXT+6exiGQBf8ZzMhJVfRGYhaf3UiZwAriuprJ5mW8ccLOIFAEngStr6gPjGAxcA2Q47e4AfwRal8ro5j70Jp+b+7A58IaIhOIpZu+r6udlPh+vAlNFJBPP5+PKGsrmbT7XPr8VCaD9V64z3X82TIsxxhifCfbmL2OMMT5kRcUYY4zPWFExxhjjM1ZUjDHG+IwVFWOMMT5jRcWYcojIMefn2SLyvTMK7moRucKLxyaLM3KziKSKyNNVbPsr3yU3xl1BfZ2KMV44AVyrqj+ISAtgmYjMdq7grpKqpgPplWySDPwKzyixxtR6dqRiTCVUdZOq/uAs78YzcGFi2e1EpI8z6OMq4NZS64eemqdCRH5Wal6KFSISAzwKnOusu9M5cvlORJY7t0GlnucbZ1C/DSLydqkr7fuKyELn9ZeISIwz0OLjIrLUOcK6ye87yxjsSMUYrznDpETgmYOnrCnAJFX9VkQer+Apfg/cqqoLnEEk84B7gd+r6sXOa0QDw1U1T0Q6Au8Cqc7jewHdgN3AAmCwiCwB3gOuUNWlIhKL58r7G/AMOdNXRCKBBSLyhapuPeMdYUwl7EjFGC84YyBNBa5T1ZIy98UD8c78MjjblWcB8JSI/M7ZvqicbcKBl0UkA/gASCl13xJVzXJefyWeprPOQLaqLoUfB6AsAi7EM6bZSjzD6ScAHav7vo2pLjtSMaYKzl//M4H7nYm8TouqPioiM/GMNbZARC4qZ7M7gb1ATzx/9OWVui+/1HIxlX9+BbhNVWefbl5jTocdqRhTCWf06o/xzA45vbxtnJP2R0TkHGfV1RU8V3tVzVDVx/CMkN0FyMUzlfApcXiOPErwDDYZWkXEjUBzEenrvEaMeIZQn41nIMpwZ30nEalf9Ts25szYkYoxlfslMARIEJEJzroJqrqyzHbXAa+JiAJfVPBcd4jIeXhm2VsLpDnLxc4J/teB54EPReRa4D/A8crCqWqB0835GWf495PABXjmvkgGljsn9PcDl3r7po05XTZKsTHGGJ+x5i9jjDE+Y0XFGGOMz1hRMcYY4zNWVIwxxviMFRVjjDE+Y0XFGGOMz1hRMcYY4zP/H5GpY2/jsyupAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_list = np.arange(5, (len(dist_list)+1)*5, 5)\n",
    "if not THETA_AS_VARIABLE:\n",
    "    plt.plot(np.array(dist_list), np.array(B))\n",
    "    plt.ylabel(\"aggregation benefit\")\n",
    "    plt.xlabel(\"l2 distance\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th iteration\n",
      "2th iteration\n",
      "3th iteration\n",
      "4th iteration\n",
      "5th iteration\n",
      "6th iteration\n",
      "7th iteration\n",
      "8th iteration\n",
      "9th iteration\n",
      "10th iteration\n",
      "11th iteration\n",
      "12th iteration\n",
      "13th iteration\n",
      "14th iteration\n",
      "15th iteration\n",
      "16th iteration\n",
      "17th iteration\n",
      "18th iteration\n",
      "19th iteration\n",
      "20th iteration\n"
     ]
    }
   ],
   "source": [
    "if THETA_AS_VARIABLE:\n",
    "    X, Y = np.meshgrid(np.array(theta_list), np.array(dist_list))\n",
    "    Z = np.zeros(X.shape)\n",
    "    i = 0\n",
    "    for agg_weights_list in agg_weights_list_per_pi:\n",
    "        j = 0\n",
    "        for agg_weights in agg_weights_list:\n",
    "            aggr_model = keras.models.clone_model(model1)\n",
    "            aggr_model.set_weights(agg_weights)\n",
    "            compile_model(aggr_model)\n",
    "            score = aggr_model.evaluate(x=x_test, y=y_test, verbose=0)\n",
    "            Z[i][j] = score[0]\n",
    "            j += 1\n",
    "            K.clear_session() #prevent memory leak https://github.com/keras-team/keras/issues/13118\n",
    "        i += 1\n",
    "        print(\"{}th iteration\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if THETA_AS_VARIABLE:\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    surf = ax.plot_surface(X, Y, Z, cmap=cm.rainbow,\n",
    "                           linewidth=0, antialiased=False)\n",
    "    ax.set_xlabel('$theta$')\n",
    "    ax.set_ylabel('$distance$')\n",
    "    ax.set_zlabel('$loss$')\n",
    "    # Customize the z axis.\n",
    "    # ax.set_xlim(0.051, 0.054)\n",
    "    # ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "    # ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "    ax.view_init(0, 45)\n",
    "    # ax.view_init(0, 0)\n",
    "    # Add a color bar which maps values to colors.\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "    plt.savefig('fig1.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "personalized.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
