{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib\n",
    "import copy\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as plot\n",
    "import seaborn as sns\n",
    "import matplotlib.lines as mlines\n",
    "import semantic_drift\n",
    "import tensorflow as tf\n",
    "import utils\n",
    "import two_models_exp as tm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist\n",
    "MULTI_NUM = 2\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test_orig) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/seth/projects/fed-learn-experiment/utils.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(tm)\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pretrained model\n",
    "with open('swarm_exp/hist/pretrained_model_2nn_mnist_local_updates_epochs_20_data_600.pickle', 'rb') as handle:\n",
    "    init_weights = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_target, y_target_orig = utils.filter_data_by_labels_with_numbers(x_test,\n",
    "                                             y_test_orig, \n",
    "                                             {2:1000, 3:1000})\n",
    "y_target = keras.utils.to_categorical(y_target_orig, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 33us/sample - loss: 0.0187 - acc: 0.8715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.018669994592666626, 0.8715]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = get_model()\n",
    "my_model.set_weights(init_weights)\n",
    "compile_model(my_model)\n",
    "my_model.evaluate(x_target, y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swarm_exp.data_process as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_conf = {}\n",
    "for i in range(6):\n",
    "    label_conf[i] = 10000\n",
    "x_test, y_test_orig = utils.filter_data_by_labels_with_numbers(x_test,\n",
    "                                             y_test_orig, \n",
    "                                             label_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swarm_exp.data_process as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_occ(arr):\n",
    "    y = np.bincount(arr)\n",
    "    ii = np.nonzero(y)[0]\n",
    "    return dict(zip(ii,y[ii]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_provider = dp.DataProvider(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 5923,\n",
       " 1: 6742,\n",
       " 2: 5958,\n",
       " 3: 6131,\n",
       " 4: 5842,\n",
       " 5: 5421,\n",
       " 6: 5918,\n",
       " 7: 6265,\n",
       " 8: 5851,\n",
       " 9: 5949}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_occ(data_provider.y_train[data_provider.mask_unused])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 500\n",
    "\n",
    "x_train_list = []\n",
    "y_train_list = []\n",
    "x_target, y_target_orig = data_provider.fetch({0:80,1:80})\n",
    "# candidates = np.arange(0,10)\n",
    "# np.random.shuffle(candidates)\n",
    "def append_data(x_train_list, y_train_list, local_data_labels):\n",
    "    label_conf = {}\n",
    "    for j in local_data_labels:\n",
    "        label_conf[j] = 80\n",
    "\n",
    "    x, y = data_provider.fetch(label_conf)\n",
    "    x_train_list.append(x)\n",
    "    y_train_list.append(y)\n",
    "\n",
    "def append_series(x_train_list, y_train_list, num):\n",
    "    for _ in range(num):\n",
    "        for __ in range(10):\n",
    "            append_data(x_train_list, y_train_list, [2,3])\n",
    "        for __ in range(10):\n",
    "            append_data(x_train_list, y_train_list, [4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_series(x_train_list, y_train_list, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list = [keras.utils.to_categorical(y, 10) for y in y_train_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target = keras.utils.to_categorical(y_target_orig, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = keras.utils.to_categorical(y_test_orig, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_conf = {}\n",
    "for i in local_data_labels:\n",
    "    label_conf[i] = 100\n",
    "x_val, y_val_orig = utils.filter_data_by_labels_with_numbers(x_train,\n",
    "                                             y_train, \n",
    "                                             label_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = keras.utils.to_categorical(y_val_orig, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):  \n",
    "    # initiate SGD optimizer\n",
    "    opt = keras.optimizers.SGD(lr=0.1)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model = tm.custom_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_weights_list = []\n",
    "for i in range(20):\n",
    "    new_model = get_model()\n",
    "    new_model.set_weights(init_weights)\n",
    "    compile_model(new_model)\n",
    "#     new_model.fit(x_train_list[i], y_train_list[i], epochs=10, shuffle=True,\n",
    "#                  validation_data=(x_val, y_val))\n",
    "    model_weights_list.append(copy.deepcopy(new_model.get_weights()))\n",
    "    del new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_weights = get_model().get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6030/6030 [==============================] - 0s 42us/sample - loss: 0.0809 - acc: 0.5299\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 415us/sample - loss: 0.0833 - acc: 0.5063\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 129us/sample - loss: 0.0805 - acc: 0.5688\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 117us/sample - loss: 0.0778 - acc: 0.5938\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 111us/sample - loss: 0.0752 - acc: 0.6125\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0777 - acc: 0.4070\n",
      "--------------[0.07774569557031391, 0.40696517]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 287us/sample - loss: 0.0728 - acc: 0.6125\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 55us/sample - loss: 0.0707 - acc: 0.6125\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0688 - acc: 0.6125\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 51us/sample - loss: 0.0670 - acc: 0.6187\n",
      "6030/6030 [==============================] - 0s 20us/sample - loss: 0.0767 - acc: 0.3504\n",
      "--------------[0.07673436100061853, 0.3504146]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 265us/sample - loss: 0.0654 - acc: 0.6187\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 65us/sample - loss: 0.0638 - acc: 0.6187\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 53us/sample - loss: 0.0624 - acc: 0.6187\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 60us/sample - loss: 0.0609 - acc: 0.6125\n",
      "6030/6030 [==============================] - 0s 22us/sample - loss: 0.0771 - acc: 0.3494\n",
      "--------------[0.07709046028690354, 0.34941956]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 262us/sample - loss: 0.0596 - acc: 0.6125\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0583 - acc: 0.6313\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 56us/sample - loss: 0.0572 - acc: 0.6313\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0558 - acc: 0.6313\n",
      "6030/6030 [==============================] - 0s 23us/sample - loss: 0.0796 - acc: 0.3473\n",
      "--------------[0.07958909936162765, 0.3472637]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 426us/sample - loss: 0.0547 - acc: 0.6250\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 119us/sample - loss: 0.0536 - acc: 0.6187\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 67us/sample - loss: 0.0526 - acc: 0.6313\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 108us/sample - loss: 0.0518 - acc: 0.6438\n",
      "6030/6030 [==============================] - 0s 38us/sample - loss: 0.0838 - acc: 0.3401\n",
      "--------------[0.08383057940609222, 0.34013268]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 386us/sample - loss: 0.0509 - acc: 0.6500\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 69us/sample - loss: 0.0501 - acc: 0.6438\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 94us/sample - loss: 0.0495 - acc: 0.6625\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 51us/sample - loss: 0.0488 - acc: 0.6562\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0876 - acc: 0.3285\n",
      "--------------[0.08756064775324184, 0.32852405]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 408us/sample - loss: 0.0481 - acc: 0.6562\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 82us/sample - loss: 0.0476 - acc: 0.6500\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 55us/sample - loss: 0.0467 - acc: 0.6562\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 51us/sample - loss: 0.0461 - acc: 0.6562\n",
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.0900 - acc: 0.3265\n",
      "--------------[0.09002555065833119, 0.326534]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 427us/sample - loss: 0.0457 - acc: 0.6625\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 119us/sample - loss: 0.0453 - acc: 0.6562\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 69us/sample - loss: 0.0444 - acc: 0.6562\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 49us/sample - loss: 0.0440 - acc: 0.6625\n",
      "6030/6030 [==============================] - 0s 29us/sample - loss: 0.0926 - acc: 0.3206\n",
      "--------------[0.09263540111716904, 0.32056385]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 405us/sample - loss: 0.0435 - acc: 0.6625\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 114us/sample - loss: 0.0429 - acc: 0.6687\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 49us/sample - loss: 0.0426 - acc: 0.6562\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 76us/sample - loss: 0.0422 - acc: 0.6687\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0945 - acc: 0.3217\n",
      "--------------[0.09450999060228689, 0.3217247]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 435us/sample - loss: 0.0414 - acc: 0.6687\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 67us/sample - loss: 0.0411 - acc: 0.6812\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 72us/sample - loss: 0.0408 - acc: 0.6812\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 59us/sample - loss: 0.0401 - acc: 0.6938\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0964 - acc: 0.3211\n",
      "--------------[0.09641294720803525, 0.32106137]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 480us/sample - loss: 0.0399 - acc: 0.6938\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0394 - acc: 0.7000\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 76us/sample - loss: 0.0392 - acc: 0.6938\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 86us/sample - loss: 0.0389 - acc: 0.6938\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0985 - acc: 0.3139\n",
      "--------------[0.09845360634141102, 0.31393036]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 378us/sample - loss: 0.0384 - acc: 0.6938\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 98us/sample - loss: 0.0378 - acc: 0.7063\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 67us/sample - loss: 0.0377 - acc: 0.7125\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 85us/sample - loss: 0.0371 - acc: 0.7125\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0999 - acc: 0.3133\n",
      "--------------[0.09988454846452124, 0.313267]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 357us/sample - loss: 0.0370 - acc: 0.7312\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 70us/sample - loss: 0.0366 - acc: 0.7188\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 90us/sample - loss: 0.0363 - acc: 0.7375\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0361 - acc: 0.7563\n",
      "6030/6030 [==============================] - 0s 30us/sample - loss: 0.1011 - acc: 0.3096\n",
      "--------------[0.1010641282223548, 0.30961856]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 391us/sample - loss: 0.0357 - acc: 0.7375\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 118us/sample - loss: 0.0353 - acc: 0.7812\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 62us/sample - loss: 0.0351 - acc: 0.7563\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 86us/sample - loss: 0.0347 - acc: 0.7750\n",
      "6030/6030 [==============================] - 0s 37us/sample - loss: 0.1022 - acc: 0.3017\n",
      "--------------[0.10223572618431515, 0.30165836]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 384us/sample - loss: 0.0346 - acc: 0.7563\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 113us/sample - loss: 0.0343 - acc: 0.7875\n",
      "Epoch 3/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 68us/sample - loss: 0.0339 - acc: 0.7937\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 102us/sample - loss: 0.0340 - acc: 0.7875\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.1033 - acc: 0.2950\n",
      "--------------[0.1032653338898276, 0.29502487]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 402us/sample - loss: 0.0338 - acc: 0.7812\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 100us/sample - loss: 0.0330 - acc: 0.7812\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 58us/sample - loss: 0.0329 - acc: 0.7937\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 96us/sample - loss: 0.0325 - acc: 0.8188\n",
      "6030/6030 [==============================] - 0s 36us/sample - loss: 0.1043 - acc: 0.2881\n",
      "--------------[0.10431457255066529, 0.2880597]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 402us/sample - loss: 0.0324 - acc: 0.7937\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 108us/sample - loss: 0.0323 - acc: 0.8062\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 56us/sample - loss: 0.0317 - acc: 0.8250\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 60us/sample - loss: 0.0317 - acc: 0.8125\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.1051 - acc: 0.2828\n",
      "--------------[0.10514206276653616, 0.2827529]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 437us/sample - loss: 0.0315 - acc: 0.8000\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 75us/sample - loss: 0.0311 - acc: 0.8375\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0308 - acc: 0.8188\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 96us/sample - loss: 0.0308 - acc: 0.8125\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.1057 - acc: 0.2761\n",
      "--------------[0.10568410057086454, 0.2761194]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 421us/sample - loss: 0.0307 - acc: 0.8250\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 95us/sample - loss: 0.0299 - acc: 0.8250\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 67us/sample - loss: 0.0297 - acc: 0.8375\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 95us/sample - loss: 0.0301 - acc: 0.8188\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.1063 - acc: 0.2708\n",
      "--------------[0.10625112210191898, 0.2708126]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 409us/sample - loss: 0.0295 - acc: 0.8250\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 62us/sample - loss: 0.0294 - acc: 0.8313\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0292 - acc: 0.8188\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 112us/sample - loss: 0.0288 - acc: 0.8438\n",
      "6030/6030 [==============================] - 0s 30us/sample - loss: 0.1069 - acc: 0.2643\n",
      "--------------[0.10691277118612878, 0.26434493]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 359us/sample - loss: 0.0283 - acc: 0.8313\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 50us/sample - loss: 0.0280 - acc: 0.8500\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 85us/sample - loss: 0.0279 - acc: 0.8375\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 102us/sample - loss: 0.0279 - acc: 0.8125\n",
      "6030/6030 [==============================] - 0s 37us/sample - loss: 0.1075 - acc: 0.2653\n",
      "--------------[0.10753084570663683, 0.26533997]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 431us/sample - loss: 0.0274 - acc: 0.8313\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 73us/sample - loss: 0.0273 - acc: 0.8375\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 49us/sample - loss: 0.0273 - acc: 0.8375\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 74us/sample - loss: 0.0273 - acc: 0.8313\n",
      "6030/6030 [==============================] - 0s 41us/sample - loss: 0.1081 - acc: 0.2600\n",
      "--------------[0.10806051918226688, 0.26003316]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 382us/sample - loss: 0.0267 - acc: 0.8375\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 105us/sample - loss: 0.0265 - acc: 0.8250\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 71us/sample - loss: 0.0261 - acc: 0.8438\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 53us/sample - loss: 0.0263 - acc: 0.8313\n",
      "6030/6030 [==============================] - 0s 38us/sample - loss: 0.1087 - acc: 0.2570\n",
      "--------------[0.1086642644422169, 0.2570481]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 413us/sample - loss: 0.0266 - acc: 0.8375\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 126us/sample - loss: 0.0256 - acc: 0.8562\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 56us/sample - loss: 0.0256 - acc: 0.8500\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 74us/sample - loss: 0.0252 - acc: 0.8500\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.1098 - acc: 0.2532\n",
      "--------------[0.10975538703734997, 0.25323382]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 413us/sample - loss: 0.0253 - acc: 0.8313\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 64us/sample - loss: 0.0248 - acc: 0.8500\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 52us/sample - loss: 0.0247 - acc: 0.8750\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 107us/sample - loss: 0.0247 - acc: 0.8313\n",
      "6030/6030 [==============================] - ETA: 0s - loss: 0.1097 - acc: 0.254 - 0s 23us/sample - loss: 0.1099 - acc: 0.2527\n",
      "--------------[0.10986559513344693, 0.25273633]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 255us/sample - loss: 0.0241 - acc: 0.8687\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 53us/sample - loss: 0.0240 - acc: 0.8562\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0243 - acc: 0.8687\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0236 - acc: 0.8562\n",
      "6030/6030 [==============================] - 0s 20us/sample - loss: 0.1106 - acc: 0.2483\n",
      "--------------[0.11057429658388024, 0.24825871]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 276us/sample - loss: 0.0237 - acc: 0.8687\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 54us/sample - loss: 0.0233 - acc: 0.8750\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 52us/sample - loss: 0.0233 - acc: 0.8562\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 52us/sample - loss: 0.0232 - acc: 0.8625\n",
      "6030/6030 [==============================] - 0s 21us/sample - loss: 0.1111 - acc: 0.2502\n",
      "--------------[0.11106317231607675, 0.25024876]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 291us/sample - loss: 0.0230 - acc: 0.8625\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 51us/sample - loss: 0.0228 - acc: 0.8687\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0226 - acc: 0.8687\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0223 - acc: 0.8813\n",
      "6030/6030 [==============================] - 0s 22us/sample - loss: 0.1116 - acc: 0.2479\n",
      "--------------[0.11161156741046589, 0.24792702]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 438us/sample - loss: 0.0224 - acc: 0.8687\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 96us/sample - loss: 0.0219 - acc: 0.8687\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 53us/sample - loss: 0.0217 - acc: 0.8813\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 54us/sample - loss: 0.0220 - acc: 0.8687\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.1120 - acc: 0.2448\n",
      "--------------[0.11198599063984395, 0.24477611]\n",
      "fit on others\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 402us/sample - loss: 0.0220 - acc: 0.8750\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 112us/sample - loss: 0.0211 - acc: 0.8813\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 69us/sample - loss: 0.0214 - acc: 0.8938\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 102us/sample - loss: 0.0209 - acc: 0.8875\n",
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.1121 - acc: 0.2483\n",
      "--------------[0.11205110071755167, 0.24825871]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 401us/sample - loss: 0.0209 - acc: 0.8875\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 146us/sample - loss: 0.0209 - acc: 0.8813\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 113us/sample - loss: 0.0211 - acc: 0.8813\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 115us/sample - loss: 0.0205 - acc: 0.8750\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.1127 - acc: 0.2448\n",
      "--------------[0.11266634219865103, 0.24477611]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 463us/sample - loss: 0.0207 - acc: 0.8813\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 66us/sample - loss: 0.0200 - acc: 0.8875\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 102us/sample - loss: 0.0199 - acc: 0.9000\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 75us/sample - loss: 0.0197 - acc: 0.8938\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.1133 - acc: 0.2458\n",
      "--------------[0.11329756410264258, 0.24577114]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 403us/sample - loss: 0.0199 - acc: 0.8813\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 95us/sample - loss: 0.0197 - acc: 0.8938\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 56us/sample - loss: 0.0192 - acc: 0.9062\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 94us/sample - loss: 0.0194 - acc: 0.8938\n",
      "6030/6030 [==============================] - 0s 39us/sample - loss: 0.1137 - acc: 0.2406\n",
      "--------------[0.11371824436421023, 0.24063018]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 383us/sample - loss: 0.0193 - acc: 0.8813\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 111us/sample - loss: 0.0195 - acc: 0.8875\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0187 - acc: 0.9062\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 79us/sample - loss: 0.0189 - acc: 0.8875\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.1143 - acc: 0.2373\n",
      "--------------[0.11429316441020365, 0.23731343]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 365us/sample - loss: 0.0184 - acc: 0.9062\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 108us/sample - loss: 0.0187 - acc: 0.9062\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 78us/sample - loss: 0.0188 - acc: 0.8938\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0182 - acc: 0.8938\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.1148 - acc: 0.2352\n",
      "--------------[0.11479425563741086, 0.23515755]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 448us/sample - loss: 0.0181 - acc: 0.9062\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 71us/sample - loss: 0.0177 - acc: 0.9000\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 89us/sample - loss: 0.0179 - acc: 0.9000\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 53us/sample - loss: 0.0177 - acc: 0.9000\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.1151 - acc: 0.2363\n",
      "--------------[0.11507765191111398, 0.23631841]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 388us/sample - loss: 0.0177 - acc: 0.9250\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 103us/sample - loss: 0.0175 - acc: 0.9125\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0177 - acc: 0.9062\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 70us/sample - loss: 0.0172 - acc: 0.9062\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.1155 - acc: 0.2338\n",
      "--------------[0.11548732315031054, 0.23383084]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 366us/sample - loss: 0.0173 - acc: 0.9000\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 93us/sample - loss: 0.0169 - acc: 0.9125\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 71us/sample - loss: 0.0166 - acc: 0.9312\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 50us/sample - loss: 0.0169 - acc: 0.9062\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.1157 - acc: 0.2348\n",
      "--------------[0.11565106238792983, 0.23482586]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 377us/sample - loss: 0.0165 - acc: 0.9125\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 105us/sample - loss: 0.0168 - acc: 0.9125\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 88us/sample - loss: 0.0164 - acc: 0.9125\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0164 - acc: 0.9250\n",
      "6030/6030 [==============================] - 0s 36us/sample - loss: 0.1159 - acc: 0.2386\n",
      "--------------[0.11588361984362848, 0.23864013]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 438us/sample - loss: 0.0162 - acc: 0.9438\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 61us/sample - loss: 0.0160 - acc: 0.9312\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 83us/sample - loss: 0.0163 - acc: 0.9438\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 111us/sample - loss: 0.0159 - acc: 0.9312\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.1166 - acc: 0.2323\n",
      "--------------[0.11658000052963718, 0.23233831]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 424us/sample - loss: 0.0158 - acc: 0.9250\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0156 - acc: 0.9250\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 96us/sample - loss: 0.0166 - acc: 0.9000\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 128us/sample - loss: 0.0152 - acc: 0.9375\n",
      "6030/6030 [==============================] - 0s 30us/sample - loss: 0.1172 - acc: 0.2317\n",
      "--------------[0.11718583436648841, 0.23167495]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 395us/sample - loss: 0.0151 - acc: 0.9250\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 96us/sample - loss: 0.0151 - acc: 0.9375\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 75us/sample - loss: 0.0150 - acc: 0.9375\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 53us/sample - loss: 0.0149 - acc: 0.9312\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.1172 - acc: 0.2333\n",
      "--------------[0.11723848872912267, 0.23333333]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 411us/sample - loss: 0.0149 - acc: 0.9375\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 121us/sample - loss: 0.0147 - acc: 0.9438\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 47us/sample - loss: 0.0146 - acc: 0.9375\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 146us/sample - loss: 0.0145 - acc: 0.9375\n",
      "6030/6030 [==============================] - 0s 28us/sample - loss: 0.1176 - acc: 0.2325\n",
      "--------------[0.11760839560435186, 0.23250414]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 431us/sample - loss: 0.0147 - acc: 0.9312\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 93us/sample - loss: 0.0146 - acc: 0.9250\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 64us/sample - loss: 0.0141 - acc: 0.9375\n",
      "Epoch 4/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 79us/sample - loss: 0.0143 - acc: 0.9438\n",
      "6030/6030 [==============================] - 0s 30us/sample - loss: 0.1179 - acc: 0.2308\n",
      "--------------[0.11794217283749461, 0.23084576]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 449us/sample - loss: 0.0141 - acc: 0.9312\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 51us/sample - loss: 0.0139 - acc: 0.9375\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 164us/sample - loss: 0.0139 - acc: 0.9500\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 53us/sample - loss: 0.0140 - acc: 0.9375\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.1182 - acc: 0.2343\n",
      "--------------[0.118210769841327, 0.23432836]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 452us/sample - loss: 0.0137 - acc: 0.9438\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0136 - acc: 0.9438\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 77us/sample - loss: 0.0136 - acc: 0.9438\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 91us/sample - loss: 0.0135 - acc: 0.9438\n",
      "6030/6030 [==============================] - 0s 39us/sample - loss: 0.1187 - acc: 0.2292\n",
      "--------------[0.11868940462817007, 0.2291874]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 434us/sample - loss: 0.0133 - acc: 0.9375\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 74us/sample - loss: 0.0138 - acc: 0.9250\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 68us/sample - loss: 0.0134 - acc: 0.9500\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 100us/sample - loss: 0.0132 - acc: 0.9438\n",
      "6030/6030 [==============================] - 0s 36us/sample - loss: 0.1191 - acc: 0.2295\n",
      "--------------[0.11911319927196598, 0.22951907]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 432us/sample - loss: 0.0131 - acc: 0.9500\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 57us/sample - loss: 0.0134 - acc: 0.9375\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 72us/sample - loss: 0.0131 - acc: 0.9438\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 102us/sample - loss: 0.0129 - acc: 0.9438\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.1194 - acc: 0.2305\n",
      "--------------[0.11936627568099431, 0.2305141]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 307us/sample - loss: 0.0126 - acc: 0.9500\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 52us/sample - loss: 0.0126 - acc: 0.9500\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 50us/sample - loss: 0.0125 - acc: 0.9500\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 58us/sample - loss: 0.0124 - acc: 0.9438\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.1194 - acc: 0.2318\n",
      "--------------[0.11940040001722908, 0.23184079]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 273us/sample - loss: 0.0125 - acc: 0.9500\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 38us/sample - loss: 0.0125 - acc: 0.9438\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 50us/sample - loss: 0.0122 - acc: 0.9563\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 52us/sample - loss: 0.0123 - acc: 0.9438\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.1200 - acc: 0.2285\n",
      "--------------[0.11997816929374366, 0.22852404]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 284us/sample - loss: 0.0120 - acc: 0.9563\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 51us/sample - loss: 0.0126 - acc: 0.9438\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0120 - acc: 0.9500\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0119 - acc: 0.9563\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.1198 - acc: 0.2325\n",
      "--------------[0.11976276585711769, 0.23250414]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 409us/sample - loss: 0.0118 - acc: 0.9563\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 86us/sample - loss: 0.0117 - acc: 0.9563\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 49us/sample - loss: 0.0117 - acc: 0.9563\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 96us/sample - loss: 0.0116 - acc: 0.9563\n",
      "6030/6030 [==============================] - 0s 29us/sample - loss: 0.1203 - acc: 0.2302\n",
      "--------------[0.12029597034699487, 0.23018242]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 458us/sample - loss: 0.0116 - acc: 0.9438\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 97us/sample - loss: 0.0116 - acc: 0.9563\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 67us/sample - loss: 0.0118 - acc: 0.9500\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 54us/sample - loss: 0.0116 - acc: 0.9438\n",
      "6030/6030 [==============================] - 0s 37us/sample - loss: 0.1205 - acc: 0.2315\n",
      "--------------[0.12052067200935895, 0.23150912]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 420us/sample - loss: 0.0112 - acc: 0.9563\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 102us/sample - loss: 0.0113 - acc: 0.9625\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 55us/sample - loss: 0.0112 - acc: 0.9625\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 91us/sample - loss: 0.0111 - acc: 0.9625\n",
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.1208 - acc: 0.2308\n",
      "--------------[0.12079867374640002, 0.23084576]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 489us/sample - loss: 0.0111 - acc: 0.9625\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 124us/sample - loss: 0.0111 - acc: 0.9500\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 76us/sample - loss: 0.0110 - acc: 0.9625\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 66us/sample - loss: 0.0112 - acc: 0.9563\n",
      "6030/6030 [==============================] - 0s 29us/sample - loss: 0.1211 - acc: 0.2310\n",
      "--------------[0.12109708037245925, 0.23101161]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 462us/sample - loss: 0.0111 - acc: 0.9625\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 51us/sample - loss: 0.0107 - acc: 0.9625\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 54us/sample - loss: 0.0107 - acc: 0.9563\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 133us/sample - loss: 0.0107 - acc: 0.9625\n",
      "6030/6030 [==============================] - 0s 24us/sample - loss: 0.1214 - acc: 0.2300\n",
      "--------------[0.12139687699267322, 0.23001659]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 465us/sample - loss: 0.0106 - acc: 0.9625\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 92us/sample - loss: 0.0111 - acc: 0.9563\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 71us/sample - loss: 0.0107 - acc: 0.9563\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0107 - acc: 0.9563\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.1215 - acc: 0.2300\n",
      "--------------[0.12152292171916361, 0.23001659]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 459us/sample - loss: 0.0105 - acc: 0.9563\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 55us/sample - loss: 0.0111 - acc: 0.9625\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 76us/sample - loss: 0.0103 - acc: 0.9563\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 90us/sample - loss: 0.0102 - acc: 0.9625\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.1218 - acc: 0.2302\n",
      "--------------[0.12183288501368629, 0.23018242]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 434us/sample - loss: 0.0102 - acc: 0.9563\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 90us/sample - loss: 0.0101 - acc: 0.9625\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 109us/sample - loss: 0.0102 - acc: 0.9500\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 53us/sample - loss: 0.0101 - acc: 0.9563\n",
      "6030/6030 [==============================] - 0s 29us/sample - loss: 0.1222 - acc: 0.2290\n",
      "--------------[0.12219864938587296, 0.22902156]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 456us/sample - loss: 0.0099 - acc: 0.9625\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 64us/sample - loss: 0.0103 - acc: 0.9625\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 52us/sample - loss: 0.0099 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 85us/sample - loss: 0.0097 - acc: 0.9625\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.1223 - acc: 0.2290\n",
      "--------------[0.12233728506968389, 0.22902156]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 411us/sample - loss: 0.0097 - acc: 0.9563\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 70us/sample - loss: 0.0100 - acc: 0.9563\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 54us/sample - loss: 0.0096 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 111us/sample - loss: 0.0095 - acc: 0.9625\n",
      "6030/6030 [==============================] - 0s 30us/sample - loss: 0.1229 - acc: 0.2262\n",
      "--------------[0.12291994621208058, 0.22620232]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 436us/sample - loss: 0.0097 - acc: 0.9625\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 100us/sample - loss: 0.0095 - acc: 0.9625\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 64us/sample - loss: 0.0095 - acc: 0.9563\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0096 - acc: 0.9688\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.1226 - acc: 0.2300\n",
      "--------------[0.12258802211007866, 0.23001659]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 423us/sample - loss: 0.0096 - acc: 0.9688\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 91us/sample - loss: 0.0095 - acc: 0.9688\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 65us/sample - loss: 0.0092 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 121us/sample - loss: 0.0094 - acc: 0.9688\n",
      "6030/6030 [==============================] - 0s 38us/sample - loss: 0.1236 - acc: 0.2235\n",
      "--------------[0.12362871812054174, 0.22354892]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 426us/sample - loss: 0.0093 - acc: 0.9625\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 100us/sample - loss: 0.0091 - acc: 0.9688\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0090 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 79us/sample - loss: 0.0093 - acc: 0.9563\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.1234 - acc: 0.2269\n",
      "--------------[0.12339064012811354, 0.22686568]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 414us/sample - loss: 0.0097 - acc: 0.9625\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 76us/sample - loss: 0.0089 - acc: 0.9625\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0091 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 72us/sample - loss: 0.0088 - acc: 0.9688\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.1233 - acc: 0.2299\n",
      "--------------[0.12326850004951356, 0.22985074]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 467us/sample - loss: 0.0090 - acc: 0.9500\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0089 - acc: 0.9688\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 114us/sample - loss: 0.0086 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 52us/sample - loss: 0.0086 - acc: 0.9688\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.1244 - acc: 0.2222\n",
      "--------------[0.12443010825818253, 0.22222222]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 435us/sample - loss: 0.0087 - acc: 0.9625\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 106us/sample - loss: 0.0086 - acc: 0.9688\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 95us/sample - loss: 0.0085 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 83us/sample - loss: 0.0088 - acc: 0.9625\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.1243 - acc: 0.2234\n",
      "--------------[0.12434360282634621, 0.22338308]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 395us/sample - loss: 0.0085 - acc: 0.9625\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 112us/sample - loss: 0.0084 - acc: 0.9625\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0089 - acc: 0.9625\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 104us/sample - loss: 0.0087 - acc: 0.9625\n",
      "6030/6030 [==============================] - 0s 36us/sample - loss: 0.1241 - acc: 0.2264\n",
      "--------------[0.12406085909994483, 0.22636816]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 456us/sample - loss: 0.0083 - acc: 0.9688\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0083 - acc: 0.9750\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 56us/sample - loss: 0.0086 - acc: 0.9625\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 80us/sample - loss: 0.0082 - acc: 0.9688\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.1243 - acc: 0.2270\n",
      "--------------[0.12426243769391061, 0.22703151]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 479us/sample - loss: 0.0081 - acc: 0.9750\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 64us/sample - loss: 0.0081 - acc: 0.9688\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 106us/sample - loss: 0.0080 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 72us/sample - loss: 0.0080 - acc: 0.9688\n",
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.1250 - acc: 0.2224\n",
      "--------------[0.12504290042825006, 0.22238806]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 290us/sample - loss: 0.0082 - acc: 0.9688\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 50us/sample - loss: 0.0079 - acc: 0.9688\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0080 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 62us/sample - loss: 0.0078 - acc: 0.9688\n",
      "6030/6030 [==============================] - 0s 21us/sample - loss: 0.1251 - acc: 0.2234\n",
      "--------------[0.12508072224916708, 0.22338308]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 292us/sample - loss: 0.0078 - acc: 0.9688\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0079 - acc: 0.9750\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 54us/sample - loss: 0.0078 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 38us/sample - loss: 0.0079 - acc: 0.9688\n",
      "6030/6030 [==============================] - 0s 21us/sample - loss: 0.1251 - acc: 0.2240\n",
      "--------------[0.12508254415459102, 0.22404644]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 268us/sample - loss: 0.0076 - acc: 0.9688\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0076 - acc: 0.9688\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0077 - acc: 0.9625\n",
      "Epoch 4/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0076 - acc: 0.9688\n",
      "6030/6030 [==============================] - 0s 20us/sample - loss: 0.1256 - acc: 0.2216\n",
      "--------------[0.1255875830577183, 0.22155887]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 410us/sample - loss: 0.0076 - acc: 0.9688\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 83us/sample - loss: 0.0075 - acc: 0.9812\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 53us/sample - loss: 0.0074 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 133us/sample - loss: 0.0074 - acc: 0.9688\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.1258 - acc: 0.2221\n",
      "--------------[0.125832062193608, 0.22205639]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 422us/sample - loss: 0.0078 - acc: 0.9750\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 89us/sample - loss: 0.0073 - acc: 0.9750\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0073 - acc: 0.9750\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 125us/sample - loss: 0.0074 - acc: 0.9688\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.1261 - acc: 0.2207\n",
      "--------------[0.12608339717830988, 0.22072968]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 388us/sample - loss: 0.0072 - acc: 0.9688\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 106us/sample - loss: 0.0073 - acc: 0.9750\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 64us/sample - loss: 0.0072 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 129us/sample - loss: 0.0073 - acc: 0.9688\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.1257 - acc: 0.2255\n",
      "--------------[0.12567259808183706, 0.22553897]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 503us/sample - loss: 0.0071 - acc: 0.9688\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 88us/sample - loss: 0.0070 - acc: 0.9688\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 56us/sample - loss: 0.0070 - acc: 0.9750\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0071 - acc: 0.9750\n",
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.1261 - acc: 0.2235\n",
      "--------------[0.12611945643156125, 0.22354892]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 453us/sample - loss: 0.0069 - acc: 0.9688\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0070 - acc: 0.9688\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 81us/sample - loss: 0.0071 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 93us/sample - loss: 0.0070 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.1265 - acc: 0.2216\n",
      "--------------[0.1265418438472558, 0.22155887]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 413us/sample - loss: 0.0068 - acc: 0.9812\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 88us/sample - loss: 0.0069 - acc: 0.9750\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 78us/sample - loss: 0.0068 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 57us/sample - loss: 0.0066 - acc: 0.9875\n",
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.1264 - acc: 0.2245\n",
      "--------------[0.1263695842937055, 0.22454394]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 388us/sample - loss: 0.0067 - acc: 0.9688\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 117us/sample - loss: 0.0068 - acc: 0.9875\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 67us/sample - loss: 0.0067 - acc: 0.9812\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 82us/sample - loss: 0.0066 - acc: 0.9750\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.1267 - acc: 0.2231\n",
      "--------------[0.12671052957846354, 0.22305141]\n"
     ]
    }
   ],
   "source": [
    "# Control Group - ONLY LOCAL\n",
    "assim_epochs = 4\n",
    "coeff = 0.5\n",
    "first_exc_locs = []\n",
    "cur_weights = init_weights\n",
    "eval_hist = [eval_weights(cur_weights)]\n",
    "for i in range(len(y_train_list)):\n",
    "    print(\"fit on others\".format(0, i))\n",
    "    target_model = get_model()\n",
    "    target_model.set_weights(cur_weights)\n",
    "    compile_model(target_model)\n",
    "    target_model.fit(x_target, y_target, epochs=assim_epochs, shuffle=True)\n",
    "#     target_model.fit(x_train_list[0], y_train_list[0], epochs=assim_epochs, shuffle=True)\n",
    "    hist = target_model.evaluate(x_test, y_test)\n",
    "    print(\"--------------{}\".format(hist))\n",
    "    eval_hist.append(copy.deepcopy(hist))\n",
    "    cur_weights = copy.deepcopy(target_model.get_weights())\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.0809 - acc: 0.5299\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 455us/sample - loss: 0.0820 - acc: 0.4875\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 77us/sample - loss: 0.0768 - acc: 0.6062\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 121us/sample - loss: 0.0706 - acc: 0.6687\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0639 - acc: 0.6938\n",
      "6030/6030 [==============================] - 0s 36us/sample - loss: 0.0781 - acc: 0.3373\n",
      "--------------[0.07812939646528728, 0.33731344]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 419us/sample - loss: 0.0590 - acc: 0.7500\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 92us/sample - loss: 0.0530 - acc: 0.8000\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0471 - acc: 0.8250\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 47us/sample - loss: 0.0418 - acc: 0.8750\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0800 - acc: 0.3118\n",
      "--------------[0.080027993478091, 0.31177446]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 400us/sample - loss: 0.0364 - acc: 0.8813\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 71us/sample - loss: 0.0322 - acc: 0.8875\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 95us/sample - loss: 0.0286 - acc: 0.9187\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 63us/sample - loss: 0.0256 - acc: 0.9187\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0841 - acc: 0.3146\n",
      "--------------[0.0841116235648617, 0.3145937]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 458us/sample - loss: 0.0216 - acc: 0.9187\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 90us/sample - loss: 0.0199 - acc: 0.9125\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 114us/sample - loss: 0.0182 - acc: 0.9250\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 85us/sample - loss: 0.0168 - acc: 0.9312\n",
      "6030/6030 [==============================] - 0s 39us/sample - loss: 0.0882 - acc: 0.3164\n",
      "--------------[0.08820164781650698, 0.3164179]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 432us/sample - loss: 0.0153 - acc: 0.9563\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 138us/sample - loss: 0.0140 - acc: 0.9625\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 53us/sample - loss: 0.0129 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 65us/sample - loss: 0.0120 - acc: 0.9688\n",
      "6030/6030 [==============================] - 0s 36us/sample - loss: 0.0908 - acc: 0.3197\n",
      "--------------[0.09079521181275002, 0.31973466]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 459us/sample - loss: 0.0135 - acc: 0.9688\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 49us/sample - loss: 0.0126 - acc: 0.9750\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 72us/sample - loss: 0.0119 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 128us/sample - loss: 0.0111 - acc: 0.9750\n",
      "6030/6030 [==============================] - 0s 36us/sample - loss: 0.0937 - acc: 0.3184\n",
      "--------------[0.09374344857227347, 0.31840795]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 391us/sample - loss: 0.0143 - acc: 0.9312\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 91us/sample - loss: 0.0135 - acc: 0.9250\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0130 - acc: 0.9250\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 75us/sample - loss: 0.0126 - acc: 0.9312\n",
      "6030/6030 [==============================] - 0s 36us/sample - loss: 0.0952 - acc: 0.3235\n",
      "--------------[0.0951818895008829, 0.3235489]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 417us/sample - loss: 0.0087 - acc: 0.9812\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 103us/sample - loss: 0.0079 - acc: 0.9875\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0075 - acc: 0.9875\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 76us/sample - loss: 0.0070 - acc: 0.9875\n",
      "6030/6030 [==============================] - 0s 30us/sample - loss: 0.0964 - acc: 0.3237\n",
      "--------------[0.09644244816864703, 0.32371476]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 438us/sample - loss: 0.0101 - acc: 0.9563\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 128us/sample - loss: 0.0094 - acc: 0.9563\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 60us/sample - loss: 0.0090 - acc: 0.9625\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 85us/sample - loss: 0.0085 - acc: 0.9625\n",
      "6030/6030 [==============================] - 0s 26us/sample - loss: 0.0984 - acc: 0.3232\n",
      "--------------[0.09840513718859671, 0.32321724]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 431us/sample - loss: 0.0098 - acc: 0.9500\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 79us/sample - loss: 0.0094 - acc: 0.9563\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0091 - acc: 0.9563\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 84us/sample - loss: 0.0087 - acc: 0.9563\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0998 - acc: 0.3249\n",
      "--------------[0.09977596529433581, 0.32487562]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 436us/sample - loss: 0.1494 - acc: 0.0000e+00\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.1408 - acc: 0.0000e+00\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 140us/sample - loss: 0.1297 - acc: 0.0000e+00\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 73us/sample - loss: 0.1164 - acc: 0.0000e+00\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0798 - acc: 0.3221\n",
      "--------------[0.07975694828266726, 0.32205638]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 455us/sample - loss: 0.1051 - acc: 0.0312\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 113us/sample - loss: 0.0897 - acc: 0.1875\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 57us/sample - loss: 0.0765 - acc: 0.3250\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 100us/sample - loss: 0.0658 - acc: 0.4750\n",
      "6030/6030 [==============================] - 0s 38us/sample - loss: 0.0653 - acc: 0.5103\n",
      "--------------[0.06532418471243646, 0.5102819]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 282us/sample - loss: 0.0511 - acc: 0.7937\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 50us/sample - loss: 0.0412 - acc: 0.8687\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 68us/sample - loss: 0.0336 - acc: 0.8938\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 72us/sample - loss: 0.0282 - acc: 0.9187\n",
      "6030/6030 [==============================] - 0s 20us/sample - loss: 0.0789 - acc: 0.3645\n",
      "--------------[0.07892844675488733, 0.36451077]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 291us/sample - loss: 0.0319 - acc: 0.8875\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0282 - acc: 0.9062\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 55us/sample - loss: 0.0252 - acc: 0.9250\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 47us/sample - loss: 0.0225 - acc: 0.9500\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0916 - acc: 0.3154\n",
      "--------------[0.09156525432322156, 0.3154229]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 316us/sample - loss: 0.0196 - acc: 0.9563\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 52us/sample - loss: 0.0177 - acc: 0.9750\n",
      "Epoch 3/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 49us/sample - loss: 0.0161 - acc: 0.9750\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0147 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 21us/sample - loss: 0.0986 - acc: 0.3027\n",
      "--------------[0.09861521424592826, 0.3026534]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 450us/sample - loss: 0.0155 - acc: 0.9375\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 78us/sample - loss: 0.0145 - acc: 0.9375\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0136 - acc: 0.9438\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 104us/sample - loss: 0.0128 - acc: 0.9500\n",
      "6030/6030 [==============================] - 0s 29us/sample - loss: 0.1032 - acc: 0.3003\n",
      "--------------[0.10317745592265976, 0.30033168]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 449us/sample - loss: 0.0142 - acc: 0.9563\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 118us/sample - loss: 0.0131 - acc: 0.9563\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0123 - acc: 0.9563\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 70us/sample - loss: 0.0118 - acc: 0.9500\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.1071 - acc: 0.3005\n",
      "--------------[0.10707665127802449, 0.3004975]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 381us/sample - loss: 0.0096 - acc: 0.9625\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 93us/sample - loss: 0.0090 - acc: 0.9750\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 59us/sample - loss: 0.0085 - acc: 0.9812\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 93us/sample - loss: 0.0081 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 36us/sample - loss: 0.1080 - acc: 0.2998\n",
      "--------------[0.10800923057159974, 0.29983416]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 442us/sample - loss: 0.0108 - acc: 0.9688\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 65us/sample - loss: 0.0101 - acc: 0.9688\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 69us/sample - loss: 0.0096 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 111us/sample - loss: 0.0091 - acc: 0.9688\n",
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.1123 - acc: 0.3027\n",
      "--------------[0.1122561368776198, 0.3026534]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 430us/sample - loss: 0.0091 - acc: 0.9750\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 99us/sample - loss: 0.0086 - acc: 0.9812\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 95us/sample - loss: 0.0081 - acc: 0.9812\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 84us/sample - loss: 0.0077 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 36us/sample - loss: 0.1134 - acc: 0.3028\n",
      "--------------[0.11338478874408982, 0.30281925]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 556us/sample - loss: 0.1558 - acc: 0.0125\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 102us/sample - loss: 0.1282 - acc: 0.1250\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 57us/sample - loss: 0.0842 - acc: 0.3812\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 128us/sample - loss: 0.0643 - acc: 0.4750\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0684 - acc: 0.4672\n",
      "--------------[0.06839602819920378, 0.4671642]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 392us/sample - loss: 0.0407 - acc: 0.6750\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 122us/sample - loss: 0.0255 - acc: 0.8750\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 39us/sample - loss: 0.0186 - acc: 0.9125\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0156 - acc: 0.9375\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0685 - acc: 0.4697\n",
      "--------------[0.06853842349540733, 0.46965173]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 461us/sample - loss: 0.0072 - acc: 0.9688\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 68us/sample - loss: 0.0067 - acc: 0.9688\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 54us/sample - loss: 0.0064 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 68us/sample - loss: 0.0061 - acc: 0.9688\n",
      "6030/6030 [==============================] - 0s 30us/sample - loss: 0.0728 - acc: 0.4532\n",
      "--------------[0.0728006200781509, 0.45323384]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 476us/sample - loss: 0.0075 - acc: 0.9750\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 49us/sample - loss: 0.0070 - acc: 0.9750\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 94us/sample - loss: 0.0066 - acc: 0.9812\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 79us/sample - loss: 0.0064 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0777 - acc: 0.4318\n",
      "--------------[0.07765317615090714, 0.4318408]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 448us/sample - loss: 0.0132 - acc: 0.9250\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 50us/sample - loss: 0.0125 - acc: 0.9250\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 93us/sample - loss: 0.0120 - acc: 0.9250\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 74us/sample - loss: 0.0115 - acc: 0.9187\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0803 - acc: 0.4207\n",
      "--------------[0.08030278188968773, 0.4207297]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 458us/sample - loss: 0.0213 - acc: 0.8562\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 54us/sample - loss: 0.0201 - acc: 0.8562\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 62us/sample - loss: 0.0189 - acc: 0.8562\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 80us/sample - loss: 0.0179 - acc: 0.8687\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0825 - acc: 0.4060\n",
      "--------------[0.08250740250297645, 0.40597016]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 451us/sample - loss: 0.0090 - acc: 0.9500\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 101us/sample - loss: 0.0085 - acc: 0.9500\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0082 - acc: 0.9563\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 80us/sample - loss: 0.0080 - acc: 0.9500\n",
      "6030/6030 [==============================] - 0s 36us/sample - loss: 0.0854 - acc: 0.3955\n",
      "--------------[0.08540180267682716, 0.3955224]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 456us/sample - loss: 0.0100 - acc: 0.9563\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 126us/sample - loss: 0.0096 - acc: 0.9563\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 91us/sample - loss: 0.0093 - acc: 0.9563\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 126us/sample - loss: 0.0090 - acc: 0.9563\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0879 - acc: 0.3851\n",
      "--------------[0.08787148459188973, 0.38507462]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 465us/sample - loss: 0.0103 - acc: 0.9250\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 102us/sample - loss: 0.0101 - acc: 0.9438\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 95us/sample - loss: 0.0096 - acc: 0.9438\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0094 - acc: 0.9438\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0894 - acc: 0.3755\n",
      "--------------[0.08944105884773815, 0.37545606]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 422us/sample - loss: 0.0052 - acc: 0.9812\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 110us/sample - loss: 0.0049 - acc: 0.9750\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 51us/sample - loss: 0.0046 - acc: 0.9875\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 103us/sample - loss: 0.0044 - acc: 0.9875\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0915 - acc: 0.3657\n",
      "--------------[0.09148262357632715, 0.36567163]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 390us/sample - loss: 0.0928 - acc: 0.2688\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 128us/sample - loss: 0.0471 - acc: 0.6250\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 75us/sample - loss: 0.0222 - acc: 0.9250\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 143us/sample - loss: 0.0138 - acc: 0.9625\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0677 - acc: 0.4925\n",
      "--------------[0.06771278413719997, 0.49253732]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 513us/sample - loss: 0.0100 - acc: 1.0000\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 56us/sample - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 111us/sample - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 53us/sample - loss: 0.0063 - acc: 1.0000\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0802 - acc: 0.4284\n",
      "--------------[0.08024997440341299, 0.4283582]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 418us/sample - loss: 0.0057 - acc: 0.9937\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 114us/sample - loss: 0.0052 - acc: 0.9937\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 54us/sample - loss: 0.0049 - acc: 0.9937\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 100us/sample - loss: 0.0045 - acc: 0.9937\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0871 - acc: 0.4015\n",
      "--------------[0.08713532043729058, 0.40149254]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 434us/sample - loss: 0.0072 - acc: 0.9875\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 107us/sample - loss: 0.0067 - acc: 0.9875\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 54us/sample - loss: 0.0063 - acc: 0.9875\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 121us/sample - loss: 0.0060 - acc: 0.9875\n",
      "6030/6030 [==============================] - ETA: 0s - loss: 0.0929 - acc: 0.378 - 0s 31us/sample - loss: 0.0925 - acc: 0.3814\n",
      "--------------[0.09250048480025967, 0.38142622]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 280us/sample - loss: 0.0072 - acc: 0.9563\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0067 - acc: 0.9688\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 70us/sample - loss: 0.0064 - acc: 0.9750\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 49us/sample - loss: 0.0061 - acc: 0.9688\n",
      "6030/6030 [==============================] - 0s 20us/sample - loss: 0.0991 - acc: 0.3594\n",
      "--------------[0.09905085696608669, 0.3593698]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 305us/sample - loss: 0.0044 - acc: 0.9937\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 59us/sample - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 61us/sample - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 65us/sample - loss: 0.0036 - acc: 1.0000\n",
      "6030/6030 [==============================] - 0s 21us/sample - loss: 0.1007 - acc: 0.3473\n",
      "--------------[0.10070708249487094, 0.3472637]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 267us/sample - loss: 0.0042 - acc: 0.9812\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 57us/sample - loss: 0.0039 - acc: 0.9875\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 49us/sample - loss: 0.0038 - acc: 0.9812\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 53us/sample - loss: 0.0037 - acc: 0.9875\n",
      "6030/6030 [==============================] - 0s 20us/sample - loss: 0.1046 - acc: 0.3385\n",
      "--------------[0.10464111392326023, 0.3384743]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 279us/sample - loss: 0.0078 - acc: 0.9563\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 54us/sample - loss: 0.0075 - acc: 0.9688\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 54us/sample - loss: 0.0072 - acc: 0.9625\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 56us/sample - loss: 0.0069 - acc: 0.9688\n",
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.1069 - acc: 0.3322\n",
      "--------------[0.1069085110009804, 0.33217248]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 384us/sample - loss: 0.0068 - acc: 0.9563\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 81us/sample - loss: 0.0064 - acc: 0.9625\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0062 - acc: 0.9625\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 150us/sample - loss: 0.0060 - acc: 0.9625\n",
      "6030/6030 [==============================] - 0s 36us/sample - loss: 0.1067 - acc: 0.3299\n",
      "--------------[0.10673715091908156, 0.32985073]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 469us/sample - loss: 0.0054 - acc: 0.9750\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0051 - acc: 0.9750\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 76us/sample - loss: 0.0049 - acc: 0.9750\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 103us/sample - loss: 0.0048 - acc: 0.9750\n",
      "6030/6030 [==============================] - 0s 36us/sample - loss: 0.1090 - acc: 0.3284\n",
      "--------------[0.10899622649893437, 0.3283582]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 416us/sample - loss: 0.1248 - acc: 0.1625\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 90us/sample - loss: 0.0535 - acc: 0.5875\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 101us/sample - loss: 0.0215 - acc: 0.8875\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 90us/sample - loss: 0.0139 - acc: 0.9438\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0650 - acc: 0.5272\n",
      "--------------[0.06504385166030816, 0.52719736]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 455us/sample - loss: 0.0057 - acc: 0.9812\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 137us/sample - loss: 0.0051 - acc: 0.9875\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 58us/sample - loss: 0.0047 - acc: 0.9875\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 69us/sample - loss: 0.0044 - acc: 0.9875\n",
      "6030/6030 [==============================] - 0s 30us/sample - loss: 0.0700 - acc: 0.4990\n",
      "--------------[0.07002635770917531, 0.499005]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 420us/sample - loss: 0.0074 - acc: 0.9563\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 92us/sample - loss: 0.0070 - acc: 0.9625\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 79us/sample - loss: 0.0067 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 50us/sample - loss: 0.0065 - acc: 0.9750\n",
      "6030/6030 [==============================] - 0s 30us/sample - loss: 0.0744 - acc: 0.4760\n",
      "--------------[0.07436297406530498, 0.47595358]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 357us/sample - loss: 0.0073 - acc: 0.9438\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 69us/sample - loss: 0.0071 - acc: 0.9500\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 117us/sample - loss: 0.0068 - acc: 0.9563\n",
      "Epoch 4/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0065 - acc: 0.9625\n",
      "6030/6030 [==============================] - 0s 30us/sample - loss: 0.0770 - acc: 0.4658\n",
      "--------------[0.07702872664304712, 0.46583748]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 352us/sample - loss: 0.0047 - acc: 0.9688\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 127us/sample - loss: 0.0045 - acc: 0.9688\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 57us/sample - loss: 0.0045 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 99us/sample - loss: 0.0043 - acc: 0.9750\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0786 - acc: 0.4584\n",
      "--------------[0.07861147272720266, 0.4583748]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 541us/sample - loss: 0.0068 - acc: 0.9563\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 52us/sample - loss: 0.0067 - acc: 0.9625\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 86us/sample - loss: 0.0063 - acc: 0.9625\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 92us/sample - loss: 0.0063 - acc: 0.9625\n",
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.0812 - acc: 0.4446\n",
      "--------------[0.08115744671072335, 0.44461027]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 423us/sample - loss: 0.0065 - acc: 0.9563\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 142us/sample - loss: 0.0059 - acc: 0.9625\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 71us/sample - loss: 0.0056 - acc: 0.9563\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 60us/sample - loss: 0.0055 - acc: 0.9625\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0829 - acc: 0.4340\n",
      "--------------[0.08285762773669181, 0.43399668]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 432us/sample - loss: 0.0092 - acc: 0.9500\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 80us/sample - loss: 0.0075 - acc: 0.9688\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 60us/sample - loss: 0.0070 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0067 - acc: 0.9688\n",
      "6030/6030 [==============================] - 0s 30us/sample - loss: 0.0850 - acc: 0.4270\n",
      "--------------[0.08499730550629978, 0.42703152]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 474us/sample - loss: 0.0048 - acc: 0.9812\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 100us/sample - loss: 0.0044 - acc: 0.9812\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 75us/sample - loss: 0.0045 - acc: 0.9812\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 57us/sample - loss: 0.0041 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0859 - acc: 0.4235\n",
      "--------------[0.08593682747080947, 0.42354894]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 487us/sample - loss: 0.0071 - acc: 0.9625\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 83us/sample - loss: 0.0067 - acc: 0.9625\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 93us/sample - loss: 0.0065 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 49us/sample - loss: 0.0061 - acc: 0.9750\n",
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.0884 - acc: 0.4129\n",
      "--------------[0.08837107528699176, 0.41293532]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 476us/sample - loss: 0.0806 - acc: 0.3875\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0266 - acc: 0.8125\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 119us/sample - loss: 0.0133 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 69us/sample - loss: 0.0101 - acc: 0.9688\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0673 - acc: 0.5308\n",
      "--------------[0.06734312668220321, 0.53084576]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 414us/sample - loss: 0.0093 - acc: 0.9563\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 75us/sample - loss: 0.0079 - acc: 0.9625\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 133us/sample - loss: 0.0072 - acc: 0.9625\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 56us/sample - loss: 0.0066 - acc: 0.9625\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0793 - acc: 0.4468\n",
      "--------------[0.07931478241239219, 0.44676617]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 452us/sample - loss: 0.0052 - acc: 0.9625\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 64us/sample - loss: 0.0047 - acc: 0.9625\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 102us/sample - loss: 0.0043 - acc: 0.9625\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 94us/sample - loss: 0.0040 - acc: 0.9750\n",
      "6030/6030 [==============================] - 0s 29us/sample - loss: 0.0836 - acc: 0.4212\n",
      "--------------[0.08357172142436255, 0.4212272]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 456us/sample - loss: 0.0035 - acc: 0.9812\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 106us/sample - loss: 0.0033 - acc: 0.9812\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0032 - acc: 0.9812\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 55us/sample - loss: 0.0031 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0878 - acc: 0.4106\n",
      "--------------[0.08781078195888209, 0.4106136]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 457us/sample - loss: 0.0031 - acc: 0.9875\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 51us/sample - loss: 0.0030 - acc: 0.9875\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 65us/sample - loss: 0.0028 - acc: 0.9875\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 71us/sample - loss: 0.0027 - acc: 0.9875\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0916 - acc: 0.4012\n",
      "--------------[0.09158648143014307, 0.40116087]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 405us/sample - loss: 0.0041 - acc: 0.9812\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 103us/sample - loss: 0.0037 - acc: 0.9875\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 50us/sample - loss: 0.0035 - acc: 0.9875\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 113us/sample - loss: 0.0034 - acc: 0.9875\n",
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.0928 - acc: 0.3947\n",
      "--------------[0.09280979064467733, 0.3946932]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 423us/sample - loss: 0.0032 - acc: 0.9875\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0030 - acc: 0.9875\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 94us/sample - loss: 0.0030 - acc: 0.9875\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 95us/sample - loss: 0.0029 - acc: 0.9875\n",
      "6030/6030 [==============================] - 0s 21us/sample - loss: 0.0964 - acc: 0.3876\n",
      "--------------[0.0963829377644493, 0.3875622]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 269us/sample - loss: 0.0054 - acc: 0.9688\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0051 - acc: 0.9750\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 37us/sample - loss: 0.0049 - acc: 0.9875\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0047 - acc: 0.9875\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0979 - acc: 0.3813\n",
      "--------------[0.09794126213783055, 0.38126037]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 282us/sample - loss: 0.0032 - acc: 0.9875\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0031 - acc: 0.9875\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0029 - acc: 0.9875\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 53us/sample - loss: 0.0028 - acc: 0.9937\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0993 - acc: 0.3751\n",
      "--------------[0.09930026724712172, 0.37512437]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 281us/sample - loss: 0.0041 - acc: 0.9750\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 63us/sample - loss: 0.0039 - acc: 0.9812\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 39us/sample - loss: 0.0038 - acc: 0.9812\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0036 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 22us/sample - loss: 0.1026 - acc: 0.3670\n",
      "--------------[0.10260103985197706, 0.36699834]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 421us/sample - loss: 0.0930 - acc: 0.3562\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 124us/sample - loss: 0.0192 - acc: 0.8687\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 78us/sample - loss: 0.0106 - acc: 0.9563\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 85us/sample - loss: 0.0083 - acc: 0.9563\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0644 - acc: 0.5415\n",
      "--------------[0.06438262513645648, 0.5414594]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 420us/sample - loss: 0.0071 - acc: 0.9563\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 82us/sample - loss: 0.0064 - acc: 0.9563\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 77us/sample - loss: 0.0060 - acc: 0.9563\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 98us/sample - loss: 0.0057 - acc: 0.9563\n",
      "6030/6030 [==============================] - 0s 36us/sample - loss: 0.0686 - acc: 0.5201\n",
      "--------------[0.06864073699584253, 0.5200663]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 457us/sample - loss: 0.0067 - acc: 0.9688\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 52us/sample - loss: 0.0065 - acc: 0.9750\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 119us/sample - loss: 0.0062 - acc: 0.9750\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 61us/sample - loss: 0.0061 - acc: 0.9750\n",
      "6030/6030 [==============================] - 0s 29us/sample - loss: 0.0713 - acc: 0.5066\n",
      "--------------[0.07134159020647085, 0.5066335]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 384us/sample - loss: 0.0071 - acc: 0.9625\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 101us/sample - loss: 0.0062 - acc: 0.9563\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 52us/sample - loss: 0.0059 - acc: 0.9625\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 81us/sample - loss: 0.0057 - acc: 0.9625\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0735 - acc: 0.4980\n",
      "--------------[0.0734590341906939, 0.49800995]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 445us/sample - loss: 0.0059 - acc: 0.9750\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 70us/sample - loss: 0.0057 - acc: 0.9750\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 104us/sample - loss: 0.0055 - acc: 0.9750\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 55us/sample - loss: 0.0054 - acc: 0.9750\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0760 - acc: 0.4867\n",
      "--------------[0.07598230520118134, 0.486733]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 420us/sample - loss: 0.0064 - acc: 0.9500\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 128us/sample - loss: 0.0060 - acc: 0.9688\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0058 - acc: 0.9750\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 89us/sample - loss: 0.0058 - acc: 0.9688\n",
      "6030/6030 [==============================] - 0s 30us/sample - loss: 0.0779 - acc: 0.4774\n",
      "--------------[0.07788542026459282, 0.4774461]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 455us/sample - loss: 0.0061 - acc: 0.9625\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 122us/sample - loss: 0.0059 - acc: 0.9625\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 57us/sample - loss: 0.0056 - acc: 0.9625\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 84us/sample - loss: 0.0054 - acc: 0.9625\n",
      "6030/6030 [==============================] - 0s 28us/sample - loss: 0.0800 - acc: 0.4688\n",
      "--------------[0.07999787284416543, 0.46882257]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 456us/sample - loss: 0.0093 - acc: 0.9438\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 51us/sample - loss: 0.0089 - acc: 0.9438\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 77us/sample - loss: 0.0085 - acc: 0.9500\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 78us/sample - loss: 0.0082 - acc: 0.9500\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0810 - acc: 0.4637\n",
      "--------------[0.08102423969291732, 0.46368158]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 476us/sample - loss: 0.0062 - acc: 0.9750\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 56us/sample - loss: 0.0060 - acc: 0.9750\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 93us/sample - loss: 0.0054 - acc: 0.9750\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 106us/sample - loss: 0.0051 - acc: 0.9750\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0831 - acc: 0.4527\n",
      "--------------[0.08308549465281058, 0.45273632]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 468us/sample - loss: 0.0091 - acc: 0.9438\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 58us/sample - loss: 0.0090 - acc: 0.9438\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 90us/sample - loss: 0.0087 - acc: 0.9500\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 85us/sample - loss: 0.0086 - acc: 0.9500\n",
      "6030/6030 [==============================] - 0s 37us/sample - loss: 0.0843 - acc: 0.4439\n",
      "--------------[0.08427535443015359, 0.44394693]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 429us/sample - loss: 0.0710 - acc: 0.4688\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 87us/sample - loss: 0.0162 - acc: 0.9187\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 49us/sample - loss: 0.0077 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 81us/sample - loss: 0.0059 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0671 - acc: 0.5514\n",
      "--------------[0.0671271968070745, 0.5514096]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 407us/sample - loss: 0.0035 - acc: 0.9937\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 75us/sample - loss: 0.0032 - acc: 0.9937\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 57us/sample - loss: 0.0029 - acc: 0.9937\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 87us/sample - loss: 0.0028 - acc: 0.9937\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0713 - acc: 0.5134\n",
      "--------------[0.07133384777192849, 0.51343286]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 415us/sample - loss: 0.0101 - acc: 0.9375\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 102us/sample - loss: 0.0094 - acc: 0.9438\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0088 - acc: 0.9500\n",
      "Epoch 4/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 89us/sample - loss: 0.0084 - acc: 0.9500\n",
      "6030/6030 [==============================] - 0s 36us/sample - loss: 0.0805 - acc: 0.4594\n",
      "--------------[0.08054472531499357, 0.4593698]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 462us/sample - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 140us/sample - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 84us/sample - loss: 0.0018 - acc: 1.0000\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0864 - acc: 0.4332\n",
      "--------------[0.08635966482990812, 0.4331675]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 502us/sample - loss: 0.0038 - acc: 0.9812\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 52us/sample - loss: 0.0037 - acc: 0.9812\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 92us/sample - loss: 0.0036 - acc: 0.9812\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 79us/sample - loss: 0.0035 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0866 - acc: 0.4307\n",
      "--------------[0.0865534330951436, 0.43067995]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 438us/sample - loss: 0.0052 - acc: 0.9688\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 81us/sample - loss: 0.0050 - acc: 0.9688\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 111us/sample - loss: 0.0048 - acc: 0.9688\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0046 - acc: 0.9688\n",
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.0902 - acc: 0.4144\n",
      "--------------[0.09024010038445048, 0.41442785]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 482us/sample - loss: 0.0035 - acc: 0.9937\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 50us/sample - loss: 0.0030 - acc: 0.9937\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 110us/sample - loss: 0.0028 - acc: 0.9937\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 61us/sample - loss: 0.0025 - acc: 0.9937\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0902 - acc: 0.4075\n",
      "--------------[0.09018640729844274, 0.4074627]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 468us/sample - loss: 0.0057 - acc: 0.9625\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 91us/sample - loss: 0.0051 - acc: 0.9750\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 52us/sample - loss: 0.0048 - acc: 0.9750\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 69us/sample - loss: 0.0045 - acc: 0.9750\n",
      "6030/6030 [==============================] - 0s 30us/sample - loss: 0.0943 - acc: 0.3993\n",
      "--------------[0.0942757391489758, 0.39933664]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 473us/sample - loss: 0.0022 - acc: 0.9875\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 52us/sample - loss: 0.0018 - acc: 0.9875\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 83us/sample - loss: 0.0016 - acc: 0.9937\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 109us/sample - loss: 0.0014 - acc: 0.9937\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0926 - acc: 0.3970\n",
      "--------------[0.09257337944968225, 0.39701492]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "Epoch 1/4\n",
      "160/160 [==============================] - 0s 317us/sample - loss: 0.0045 - acc: 0.9812\n",
      "Epoch 2/4\n",
      "160/160 [==============================] - 0s 68us/sample - loss: 0.0043 - acc: 0.9812\n",
      "Epoch 3/4\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0042 - acc: 0.9812\n",
      "Epoch 4/4\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0040 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0958 - acc: 0.3897\n",
      "--------------[0.09582414620650151, 0.3897181]\n"
     ]
    }
   ],
   "source": [
    "# ASSIMILATION - ONLY REMOTE\n",
    "assim_epochs = 4\n",
    "coeff = 0.5\n",
    "first_exc_locs = []\n",
    "cur_weights = init_weights\n",
    "eval_hist2 = [eval_weights(cur_weights)]\n",
    "for i in range(len(y_train_list)):\n",
    "    print(\"fit on others\".format(0, i))\n",
    "    target_model = get_model()\n",
    "    target_model.set_weights(cur_weights)\n",
    "    compile_model(target_model)\n",
    "    target_model.fit(x_train_list[i], y_train_list[i], epochs=assim_epochs, shuffle=True)\n",
    "#     target_model.fit(x_target, y_target, epochs=assim_epochs, shuffle=True)\n",
    "    hist = target_model.evaluate(x_test, y_test)\n",
    "    print(\"--------------{}\".format(hist))\n",
    "    eval_hist2.append(copy.deepcopy(hist))\n",
    "    cur_weights = copy.deepcopy(target_model.get_weights())\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6030/6030 [==============================] - 0s 22us/sample - loss: 0.0809 - acc: 0.5299\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 289us/sample - loss: 0.0820 - acc: 0.5000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0844 - acc: 0.4500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 47us/sample - loss: 0.0782 - acc: 0.5813\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 56us/sample - loss: 0.0830 - acc: 0.4500\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0775 - acc: 0.5736\n",
      "--------------[0.07749465867802871, 0.5736318]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 440us/sample - loss: 0.0745 - acc: 0.6687\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 55us/sample - loss: 0.0818 - acc: 0.4500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 123us/sample - loss: 0.0704 - acc: 0.7375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 49us/sample - loss: 0.0807 - acc: 0.4563\n",
      "6030/6030 [==============================] - 0s 29us/sample - loss: 0.0741 - acc: 0.5839\n",
      "--------------[0.07409982411916774, 0.58391374]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 429us/sample - loss: 0.0650 - acc: 0.7188\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 47us/sample - loss: 0.0798 - acc: 0.4625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 134us/sample - loss: 0.0599 - acc: 0.8000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 58us/sample - loss: 0.0789 - acc: 0.4375\n",
      "6030/6030 [==============================] - 0s 28us/sample - loss: 0.0705 - acc: 0.6002\n",
      "--------------[0.07046826931819394, 0.60016584]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 397us/sample - loss: 0.0538 - acc: 0.8625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 72us/sample - loss: 0.0782 - acc: 0.4688\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 68us/sample - loss: 0.0490 - acc: 0.8813\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 73us/sample - loss: 0.0774 - acc: 0.4500\n",
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.0671 - acc: 0.6129\n",
      "--------------[0.06706373629038212, 0.6129353]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 459us/sample - loss: 0.0439 - acc: 0.9312\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 47us/sample - loss: 0.0763 - acc: 0.4938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 132us/sample - loss: 0.0398 - acc: 0.9375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 58us/sample - loss: 0.0752 - acc: 0.4812\n",
      "6030/6030 [==============================] - 0s 36us/sample - loss: 0.0639 - acc: 0.6234\n",
      "--------------[0.06393040331886775, 0.6233831]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 431us/sample - loss: 0.0388 - acc: 0.9250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 47us/sample - loss: 0.0740 - acc: 0.5188\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 85us/sample - loss: 0.0356 - acc: 0.9375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 82us/sample - loss: 0.0730 - acc: 0.5250\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0615 - acc: 0.6302\n",
      "--------------[0.06146055228921707, 0.63018245]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 444us/sample - loss: 0.0338 - acc: 0.9062\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 50us/sample - loss: 0.0720 - acc: 0.5437\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 81us/sample - loss: 0.0314 - acc: 0.9000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 73us/sample - loss: 0.0710 - acc: 0.5500\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0595 - acc: 0.6347\n",
      "--------------[0.05946855995044186, 0.63466]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 380us/sample - loss: 0.0278 - acc: 0.9375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 108us/sample - loss: 0.0702 - acc: 0.5688\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 55us/sample - loss: 0.0256 - acc: 0.9500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 116us/sample - loss: 0.0695 - acc: 0.5625\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0578 - acc: 0.6396\n",
      "--------------[0.057836157827333826, 0.63963515]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 451us/sample - loss: 0.0294 - acc: 0.9500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0690 - acc: 0.5625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 71us/sample - loss: 0.0272 - acc: 0.9500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 90us/sample - loss: 0.0684 - acc: 0.5688\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0567 - acc: 0.6396\n",
      "--------------[0.05674563129841787, 0.63963515]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 488us/sample - loss: 0.0274 - acc: 0.9062\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 78us/sample - loss: 0.0674 - acc: 0.5625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 77us/sample - loss: 0.0262 - acc: 0.9125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 53us/sample - loss: 0.0667 - acc: 0.5688\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0557 - acc: 0.6428\n",
      "--------------[0.05569974680741628, 0.6427861]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 383us/sample - loss: 0.1143 - acc: 0.0000e+00\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 64us/sample - loss: 0.0620 - acc: 0.5938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 87us/sample - loss: 0.1092 - acc: 0.0000e+00\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0601 - acc: 0.6062\n",
      "6030/6030 [==============================] - 0s 30us/sample - loss: 0.0549 - acc: 0.6272\n",
      "--------------[0.054913744491032306, 0.6271973]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 442us/sample - loss: 0.1071 - acc: 0.0000e+00\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0593 - acc: 0.6187\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 97us/sample - loss: 0.1019 - acc: 0.0000e+00\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 76us/sample - loss: 0.0588 - acc: 0.6125\n",
      "6030/6030 [==============================] - 0s 28us/sample - loss: 0.0550 - acc: 0.6111\n",
      "--------------[0.05504259205675046, 0.6111111]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 435us/sample - loss: 0.0934 - acc: 0.1125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 73us/sample - loss: 0.0587 - acc: 0.6125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 81us/sample - loss: 0.0844 - acc: 0.3000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 143us/sample - loss: 0.0592 - acc: 0.6125\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0545 - acc: 0.6755\n",
      "--------------[0.05454053561485822, 0.67545605]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 463us/sample - loss: 0.0766 - acc: 0.4437\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 89us/sample - loss: 0.0601 - acc: 0.6125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 51us/sample - loss: 0.0695 - acc: 0.4938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 81us/sample - loss: 0.0609 - acc: 0.5938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0540 - acc: 0.6897\n",
      "--------------[0.05404054051014914, 0.68971807]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 415us/sample - loss: 0.0644 - acc: 0.6125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 103us/sample - loss: 0.0612 - acc: 0.5938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 64us/sample - loss: 0.0583 - acc: 0.7188\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 95us/sample - loss: 0.0619 - acc: 0.5813\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0537 - acc: 0.6915\n",
      "--------------[0.05374605541749183, 0.69154227]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 374us/sample - loss: 0.0516 - acc: 0.7312\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 98us/sample - loss: 0.0622 - acc: 0.5938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 62us/sample - loss: 0.0466 - acc: 0.7688\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 78us/sample - loss: 0.0623 - acc: 0.5750\n",
      "6030/6030 [==============================] - 0s 37us/sample - loss: 0.0539 - acc: 0.6566\n",
      "--------------[0.053945522074576834, 0.6565506]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 398us/sample - loss: 0.0475 - acc: 0.7437\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 81us/sample - loss: 0.0621 - acc: 0.5813\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 55us/sample - loss: 0.0437 - acc: 0.7812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 133us/sample - loss: 0.0617 - acc: 0.5813\n",
      "6030/6030 [==============================] - 0s 43us/sample - loss: 0.0543 - acc: 0.6390\n",
      "--------------[0.05430934902645067, 0.6389718]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 372us/sample - loss: 0.0378 - acc: 0.8562\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 117us/sample - loss: 0.0615 - acc: 0.5938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 50us/sample - loss: 0.0347 - acc: 0.9000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 70us/sample - loss: 0.0611 - acc: 0.5938\n",
      "6030/6030 [==============================] - 0s 40us/sample - loss: 0.0550 - acc: 0.6320\n",
      "--------------[0.055002915832039534, 0.63200665]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 389us/sample - loss: 0.0358 - acc: 0.8500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 91us/sample - loss: 0.0602 - acc: 0.5938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 51us/sample - loss: 0.0343 - acc: 0.8562\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 85us/sample - loss: 0.0595 - acc: 0.6000\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0557 - acc: 0.6235\n",
      "--------------[0.05573662508828921, 0.6235489]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 429us/sample - loss: 0.0349 - acc: 0.8125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 75us/sample - loss: 0.0590 - acc: 0.6062\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 113us/sample - loss: 0.0329 - acc: 0.8438\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 52us/sample - loss: 0.0582 - acc: 0.6062\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0561 - acc: 0.6232\n",
      "--------------[0.05609749359623908, 0.6232172]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 479us/sample - loss: 0.1054 - acc: 0.0625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 50us/sample - loss: 0.0534 - acc: 0.6375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 49us/sample - loss: 0.0724 - acc: 0.3750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 59us/sample - loss: 0.0539 - acc: 0.6562\n",
      "6030/6030 [==============================] - 0s 20us/sample - loss: 0.0420 - acc: 0.8045\n",
      "--------------[0.04204173666574864, 0.80447763]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 288us/sample - loss: 0.0431 - acc: 0.7688\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0549 - acc: 0.6375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 39us/sample - loss: 0.0323 - acc: 0.8625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 53us/sample - loss: 0.0555 - acc: 0.6187\n",
      "6030/6030 [==============================] - 0s 20us/sample - loss: 0.0411 - acc: 0.7637\n",
      "--------------[0.04106536232441614, 0.7636816]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 274us/sample - loss: 0.0177 - acc: 0.9500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0551 - acc: 0.6313\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0158 - acc: 0.9563\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 49us/sample - loss: 0.0545 - acc: 0.6250\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0423 - acc: 0.7478\n",
      "--------------[0.042343149517058934, 0.7477612]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 275us/sample - loss: 0.0172 - acc: 0.9375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0537 - acc: 0.6187\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 50us/sample - loss: 0.0163 - acc: 0.9500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0529 - acc: 0.6187\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0436 - acc: 0.7313\n",
      "--------------[0.043616819846294015, 0.73134327]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 376us/sample - loss: 0.0213 - acc: 0.8875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 113us/sample - loss: 0.0525 - acc: 0.6125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0205 - acc: 0.8875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 99us/sample - loss: 0.0516 - acc: 0.6187\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0448 - acc: 0.7174\n",
      "--------------[0.04481096466382344, 0.71741295]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 395us/sample - loss: 0.0340 - acc: 0.7812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 130us/sample - loss: 0.0526 - acc: 0.6250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0318 - acc: 0.8000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 82us/sample - loss: 0.0522 - acc: 0.6187\n",
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.0458 - acc: 0.7073\n",
      "--------------[0.045779206843469075, 0.70729685]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 438us/sample - loss: 0.0186 - acc: 0.9250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 53us/sample - loss: 0.0508 - acc: 0.6375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0181 - acc: 0.9187\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 119us/sample - loss: 0.0502 - acc: 0.6438\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0466 - acc: 0.6982\n",
      "--------------[0.046631693088790865, 0.6981758]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 468us/sample - loss: 0.0215 - acc: 0.9125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0502 - acc: 0.6500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 85us/sample - loss: 0.0205 - acc: 0.9125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 103us/sample - loss: 0.0494 - acc: 0.6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6030/6030 [==============================] - 0s 37us/sample - loss: 0.0479 - acc: 0.6841\n",
      "--------------[0.04785299849870984, 0.6840796]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 441us/sample - loss: 0.0176 - acc: 0.9062\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 89us/sample - loss: 0.0476 - acc: 0.6687\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 59us/sample - loss: 0.0177 - acc: 0.8938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 81us/sample - loss: 0.0467 - acc: 0.6687\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0485 - acc: 0.6728\n",
      "--------------[0.04850165923164654, 0.6728026]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 458us/sample - loss: 0.0149 - acc: 0.9438\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 47us/sample - loss: 0.0478 - acc: 0.6812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 55us/sample - loss: 0.0135 - acc: 0.9500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 121us/sample - loss: 0.0475 - acc: 0.6625\n",
      "6030/6030 [==============================] - 0s 37us/sample - loss: 0.0485 - acc: 0.6760\n",
      "--------------[0.0485361261129577, 0.67595357]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 418us/sample - loss: 0.0862 - acc: 0.3000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 100us/sample - loss: 0.0442 - acc: 0.6687\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0637 - acc: 0.4938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 66us/sample - loss: 0.0440 - acc: 0.7000\n",
      "6030/6030 [==============================] - 0s 28us/sample - loss: 0.0400 - acc: 0.7474\n",
      "--------------[0.03998170417932729, 0.7474295]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 394us/sample - loss: 0.0511 - acc: 0.5750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 99us/sample - loss: 0.0449 - acc: 0.7063\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 52us/sample - loss: 0.0358 - acc: 0.8125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 81us/sample - loss: 0.0468 - acc: 0.6812\n",
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.0386 - acc: 0.8013\n",
      "--------------[0.03857273851609349, 0.8013267]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 402us/sample - loss: 0.0285 - acc: 0.8750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 103us/sample - loss: 0.0477 - acc: 0.6812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 88us/sample - loss: 0.0244 - acc: 0.9000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 98us/sample - loss: 0.0476 - acc: 0.6750\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0418 - acc: 0.7396\n",
      "--------------[0.041762417953949464, 0.73963517]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 444us/sample - loss: 0.0263 - acc: 0.9000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 60us/sample - loss: 0.0467 - acc: 0.6750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 189us/sample - loss: 0.0247 - acc: 0.9187\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 54us/sample - loss: 0.0457 - acc: 0.6875\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0443 - acc: 0.7007\n",
      "--------------[0.04430557125638769, 0.7006633]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 461us/sample - loss: 0.0256 - acc: 0.8625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 65us/sample - loss: 0.0458 - acc: 0.6875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 143us/sample - loss: 0.0242 - acc: 0.8813\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0457 - acc: 0.6812\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0470 - acc: 0.6791\n",
      "--------------[0.047026271922869074, 0.6791045]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 445us/sample - loss: 0.0202 - acc: 0.9000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 57us/sample - loss: 0.0449 - acc: 0.6938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 69us/sample - loss: 0.0190 - acc: 0.9312\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 97us/sample - loss: 0.0446 - acc: 0.6938\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0491 - acc: 0.6582\n",
      "--------------[0.04909400546160306, 0.65820897]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 447us/sample - loss: 0.0162 - acc: 0.9312\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 52us/sample - loss: 0.0432 - acc: 0.7000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 130us/sample - loss: 0.0155 - acc: 0.9500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 60us/sample - loss: 0.0427 - acc: 0.7063\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0508 - acc: 0.6466\n",
      "--------------[0.05083210646092991, 0.6466003]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 469us/sample - loss: 0.0240 - acc: 0.8750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 117us/sample - loss: 0.0427 - acc: 0.6938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 68us/sample - loss: 0.0231 - acc: 0.8875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 120us/sample - loss: 0.0419 - acc: 0.6812\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0521 - acc: 0.6386\n",
      "--------------[0.052078593371568824, 0.6386401]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 202us/sample - loss: 0.0192 - acc: 0.8875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 49us/sample - loss: 0.0412 - acc: 0.7125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0188 - acc: 0.8813\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 47us/sample - loss: 0.0407 - acc: 0.7250\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0532 - acc: 0.6284\n",
      "--------------[0.05315701716500728, 0.6283582]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 193us/sample - loss: 0.0172 - acc: 0.9000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0398 - acc: 0.7250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 57us/sample - loss: 0.0170 - acc: 0.8938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0393 - acc: 0.7500\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0541 - acc: 0.6098\n",
      "--------------[0.054060745239257815, 0.6097844]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 202us/sample - loss: 0.0953 - acc: 0.1688\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0366 - acc: 0.7937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0494 - acc: 0.6438\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0387 - acc: 0.7688\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0332 - acc: 0.8156\n",
      "--------------[0.03324971136082563, 0.8155887]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 186us/sample - loss: 0.0182 - acc: 0.9312\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0398 - acc: 0.7500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0146 - acc: 0.9500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0395 - acc: 0.7750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6030/6030 [==============================] - 0s 20us/sample - loss: 0.0352 - acc: 0.7706\n",
      "--------------[0.03520055004576249, 0.77064675]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 202us/sample - loss: 0.0170 - acc: 0.9000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.7750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0159 - acc: 0.9187\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0390 - acc: 0.7750\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0375 - acc: 0.7493\n",
      "--------------[0.03745737561020092, 0.74925375]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 193us/sample - loss: 0.0149 - acc: 0.9563\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 38us/sample - loss: 0.0390 - acc: 0.7688\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0141 - acc: 0.9500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 47us/sample - loss: 0.0384 - acc: 0.7812\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0393 - acc: 0.7348\n",
      "--------------[0.039288404436896296, 0.73482585]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 198us/sample - loss: 0.0097 - acc: 0.9563\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0368 - acc: 0.7750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0097 - acc: 0.9625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 47us/sample - loss: 0.0366 - acc: 0.7812\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0401 - acc: 0.7244\n",
      "--------------[0.040106494868078435, 0.7243781]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 204us/sample - loss: 0.0139 - acc: 0.9250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0363 - acc: 0.7937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0133 - acc: 0.9250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0362 - acc: 0.7875\n",
      "6030/6030 [==============================] - 0s 17us/sample - loss: 0.0415 - acc: 0.7136\n",
      "--------------[0.041513898044478637, 0.71359867]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 194us/sample - loss: 0.0135 - acc: 0.9125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0361 - acc: 0.8000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0125 - acc: 0.9250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0354 - acc: 0.8000\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0419 - acc: 0.7051\n",
      "--------------[0.04191224058197308, 0.70514095]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 193us/sample - loss: 0.0180 - acc: 0.8750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0350 - acc: 0.8000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0170 - acc: 0.8750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 49us/sample - loss: 0.0352 - acc: 0.7750\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0427 - acc: 0.6947\n",
      "--------------[0.04265597864837196, 0.6946932]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 200us/sample - loss: 0.0109 - acc: 0.9375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 39us/sample - loss: 0.0347 - acc: 0.8062\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0103 - acc: 0.9438\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 39us/sample - loss: 0.0346 - acc: 0.8188\n",
      "6030/6030 [==============================] - 0s 17us/sample - loss: 0.0432 - acc: 0.6949\n",
      "--------------[0.043162716340712254, 0.694859]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 195us/sample - loss: 0.0145 - acc: 0.9187\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0339 - acc: 0.7937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0139 - acc: 0.9375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0335 - acc: 0.8000\n",
      "6030/6030 [==============================] - 0s 17us/sample - loss: 0.0445 - acc: 0.6896\n",
      "--------------[0.04448441544773171, 0.68955225]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 197us/sample - loss: 0.0733 - acc: 0.3875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0327 - acc: 0.8000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 39us/sample - loss: 0.0396 - acc: 0.7250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0333 - acc: 0.8313\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0313 - acc: 0.8101\n",
      "--------------[0.0312521640619087, 0.8101161]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 191us/sample - loss: 0.0234 - acc: 0.8938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0335 - acc: 0.8188\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0191 - acc: 0.9250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0336 - acc: 0.8062\n",
      "6030/6030 [==============================] - 0s 17us/sample - loss: 0.0351 - acc: 0.7614\n",
      "--------------[0.03513377537552397, 0.7613599]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 191us/sample - loss: 0.0205 - acc: 0.8813\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0343 - acc: 0.7937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0185 - acc: 0.9000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0339 - acc: 0.8062\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0388 - acc: 0.7239\n",
      "--------------[0.03875186673394879, 0.7238806]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 193us/sample - loss: 0.0136 - acc: 0.9375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 38us/sample - loss: 0.0329 - acc: 0.8188\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0133 - acc: 0.9438\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0324 - acc: 0.8000\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0412 - acc: 0.6932\n",
      "--------------[0.0412204270067302, 0.69320065]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 197us/sample - loss: 0.0133 - acc: 0.9312\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0326 - acc: 0.8125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0126 - acc: 0.9375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0323 - acc: 0.8000\n",
      "6030/6030 [==============================] - 0s 16us/sample - loss: 0.0434 - acc: 0.6701\n",
      "--------------[0.04336668981569719, 0.67014927]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 200us/sample - loss: 0.0185 - acc: 0.8750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0321 - acc: 0.8000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0172 - acc: 0.9000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0320 - acc: 0.8062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6030/6030 [==============================] - 0s 17us/sample - loss: 0.0449 - acc: 0.6590\n",
      "--------------[0.04490119634724375, 0.6590381]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 192us/sample - loss: 0.0108 - acc: 0.9500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 39us/sample - loss: 0.0308 - acc: 0.8313\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0106 - acc: 0.9563\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0302 - acc: 0.8062\n",
      "6030/6030 [==============================] - 0s 17us/sample - loss: 0.0473 - acc: 0.6418\n",
      "--------------[0.047339508242620953, 0.64179105]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 188us/sample - loss: 0.0157 - acc: 0.9250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 39us/sample - loss: 0.0305 - acc: 0.8313\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0148 - acc: 0.9250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0309 - acc: 0.8188\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0482 - acc: 0.6328\n",
      "--------------[0.04818426143149436, 0.6328358]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 191us/sample - loss: 0.0130 - acc: 0.9062\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0300 - acc: 0.8313\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0127 - acc: 0.9062\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0296 - acc: 0.8250\n",
      "6030/6030 [==============================] - 0s 17us/sample - loss: 0.0491 - acc: 0.6245\n",
      "--------------[0.04907280272042771, 0.62454396]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 190us/sample - loss: 0.0101 - acc: 0.9563\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 39us/sample - loss: 0.0292 - acc: 0.8313\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0098 - acc: 0.9563\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0292 - acc: 0.8375\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0506 - acc: 0.6186\n",
      "--------------[0.05057238120072912, 0.6185738]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 192us/sample - loss: 0.0710 - acc: 0.4500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0284 - acc: 0.8375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 39us/sample - loss: 0.0236 - acc: 0.8438\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0295 - acc: 0.8313\n",
      "6030/6030 [==============================] - 0s 17us/sample - loss: 0.0301 - acc: 0.7929\n",
      "--------------[0.030059719392118565, 0.792869]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 203us/sample - loss: 0.0137 - acc: 0.9187\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0292 - acc: 0.8313\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0121 - acc: 0.9312\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0286 - acc: 0.8375\n",
      "6030/6030 [==============================] - 0s 17us/sample - loss: 0.0331 - acc: 0.7564\n",
      "--------------[0.033057246278125056, 0.75638473]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 192us/sample - loss: 0.0139 - acc: 0.9312\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0297 - acc: 0.8250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0126 - acc: 0.9500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 47us/sample - loss: 0.0292 - acc: 0.8375\n",
      "6030/6030 [==============================] - 0s 17us/sample - loss: 0.0340 - acc: 0.7466\n",
      "--------------[0.03404295198174555, 0.74660033]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 197us/sample - loss: 0.0134 - acc: 0.9250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0289 - acc: 0.8313\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0125 - acc: 0.9187\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0281 - acc: 0.8250\n",
      "6030/6030 [==============================] - 0s 17us/sample - loss: 0.0349 - acc: 0.7363\n",
      "--------------[0.03492630545735656, 0.7363184]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 199us/sample - loss: 0.0117 - acc: 0.9563\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0276 - acc: 0.8562\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0114 - acc: 0.9563\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0272 - acc: 0.8313\n",
      "6030/6030 [==============================] - 0s 17us/sample - loss: 0.0363 - acc: 0.7254\n",
      "--------------[0.0363122887341043, 0.72537315]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 196us/sample - loss: 0.0111 - acc: 0.9500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0273 - acc: 0.8375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0107 - acc: 0.9625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 39us/sample - loss: 0.0274 - acc: 0.8562\n",
      "6030/6030 [==============================] - 0s 17us/sample - loss: 0.0388 - acc: 0.7104\n",
      "--------------[0.03877455182435303, 0.7104478]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 195us/sample - loss: 0.0137 - acc: 0.9250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0273 - acc: 0.8438\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 47us/sample - loss: 0.0133 - acc: 0.9250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0277 - acc: 0.8500\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0385 - acc: 0.7104\n",
      "--------------[0.03851462722220033, 0.7104478]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 192us/sample - loss: 0.0184 - acc: 0.8813\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 47us/sample - loss: 0.0269 - acc: 0.8375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0180 - acc: 0.8938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0263 - acc: 0.8500\n",
      "6030/6030 [==============================] - 0s 17us/sample - loss: 0.0396 - acc: 0.7055\n",
      "--------------[0.039553243408649914, 0.70547265]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 193us/sample - loss: 0.0166 - acc: 0.9062\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0273 - acc: 0.8500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0155 - acc: 0.9062\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0268 - acc: 0.8500\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0402 - acc: 0.6975\n",
      "--------------[0.04016740260580879, 0.69751245]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 203us/sample - loss: 0.0147 - acc: 0.9125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0264 - acc: 0.8687\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0147 - acc: 0.9125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0253 - acc: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0412 - acc: 0.6975\n",
      "--------------[0.04124879635759254, 0.69751245]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 199us/sample - loss: 0.0602 - acc: 0.5437\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0244 - acc: 0.8500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0207 - acc: 0.9000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 51us/sample - loss: 0.0256 - acc: 0.8625\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0293 - acc: 0.8027\n",
      "--------------[0.029284684941370293, 0.8026534]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 187us/sample - loss: 0.0101 - acc: 0.9625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 50us/sample - loss: 0.0258 - acc: 0.8750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0091 - acc: 0.9688\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0248 - acc: 0.8625\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0321 - acc: 0.7680\n",
      "--------------[0.032061025701697984, 0.7679934]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 189us/sample - loss: 0.0193 - acc: 0.8750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0244 - acc: 0.8687\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0184 - acc: 0.8813\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0242 - acc: 0.8625\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0345 - acc: 0.7431\n",
      "--------------[0.03448399249804059, 0.74311775]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 211us/sample - loss: 0.0112 - acc: 0.9625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0248 - acc: 0.8625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0098 - acc: 0.9625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0247 - acc: 0.8500\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0377 - acc: 0.7143\n",
      "--------------[0.03770203564569329, 0.714262]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 192us/sample - loss: 0.0112 - acc: 0.9312\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 47us/sample - loss: 0.0253 - acc: 0.8438\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0108 - acc: 0.9375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0245 - acc: 0.8500\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0395 - acc: 0.6990\n",
      "--------------[0.039454931721313674, 0.69900495]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 210us/sample - loss: 0.0130 - acc: 0.9187\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0235 - acc: 0.8687\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0128 - acc: 0.9187\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0237 - acc: 0.8750\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0412 - acc: 0.6808\n",
      "--------------[0.041245817477084314, 0.6807628]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 189us/sample - loss: 0.0202 - acc: 0.8562\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 50us/sample - loss: 0.0250 - acc: 0.8750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0186 - acc: 0.8562\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0249 - acc: 0.8625\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0426 - acc: 0.6701\n",
      "--------------[0.042627320112428854, 0.67014927]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 196us/sample - loss: 0.0168 - acc: 0.8687\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0239 - acc: 0.8750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0156 - acc: 0.9000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0239 - acc: 0.8750\n",
      "6030/6030 [==============================] - 0s 17us/sample - loss: 0.0436 - acc: 0.6638\n",
      "--------------[0.04361379907943716, 0.66384745]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 201us/sample - loss: 0.0077 - acc: 0.9688\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0226 - acc: 0.8813\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0075 - acc: 0.9625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0228 - acc: 0.8687\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0441 - acc: 0.6594\n",
      "--------------[0.04409191629557467, 0.6593698]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 189us/sample - loss: 0.0157 - acc: 0.8813\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0229 - acc: 0.8813\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0149 - acc: 0.8938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0230 - acc: 0.8875\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0455 - acc: 0.6498\n",
      "--------------[0.04552541378866974, 0.64975125]\n"
     ]
    }
   ],
   "source": [
    "# ASSIMILATION MIXED \n",
    "coeff = 0.5\n",
    "first_exc_locs = []\n",
    "cur_weights = init_weights\n",
    "eval_hist3 = [eval_weights(cur_weights)]\n",
    "for i in range(len(y_train_list)):\n",
    "    print(\"fit on others\".format(0, i))\n",
    "    target_model = get_model()\n",
    "    target_model.set_weights(cur_weights)\n",
    "    compile_model(target_model)\n",
    "    target_model.fit(x_train_list[i], y_train_list[i], epochs=1, shuffle=True)\n",
    "    target_model.fit(x_target, y_target, epochs=1, shuffle=True)\n",
    "    target_model.fit(x_train_list[i], y_train_list[i], epochs=1, shuffle=True)\n",
    "    target_model.fit(x_target, y_target, epochs=1, shuffle=True)\n",
    "    hist = target_model.evaluate(x_test, y_test)\n",
    "    print(\"--------------{}\".format(hist))\n",
    "    eval_hist3.append(copy.deepcopy(hist))\n",
    "    cur_weights = copy.deepcopy(target_model.get_weights())\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0809 - acc: 0.5299\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 191us/sample - loss: 0.0820 - acc: 0.5125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0844 - acc: 0.4563\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 212us/sample - loss: 0.0828 - acc: 0.4563\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0776 - acc: 0.5731\n",
      "--------------[0.07756605300786681, 0.5731343]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 194us/sample - loss: 0.0751 - acc: 0.7063\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0816 - acc: 0.4563\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 204us/sample - loss: 0.0804 - acc: 0.4375\n",
      "6030/6030 [==============================] - 0s 17us/sample - loss: 0.0743 - acc: 0.5801\n",
      "--------------[0.07425495439253833, 0.5800995]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 193us/sample - loss: 0.0660 - acc: 0.7063\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0794 - acc: 0.4500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 203us/sample - loss: 0.0784 - acc: 0.4625\n",
      "6030/6030 [==============================] - 0s 17us/sample - loss: 0.0707 - acc: 0.5993\n",
      "--------------[0.07072106496265673, 0.5993366]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 194us/sample - loss: 0.0554 - acc: 0.8438\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0777 - acc: 0.4750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 207us/sample - loss: 0.0770 - acc: 0.4500\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0673 - acc: 0.6146\n",
      "--------------[0.06734561663411348, 0.6145937]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 202us/sample - loss: 0.0453 - acc: 0.9312\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0761 - acc: 0.5000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 200us/sample - loss: 0.0751 - acc: 0.5125\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0642 - acc: 0.6245\n",
      "--------------[0.06422258403961537, 0.62454396]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 191us/sample - loss: 0.0397 - acc: 0.9187\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 49us/sample - loss: 0.0740 - acc: 0.5375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 202us/sample - loss: 0.0729 - acc: 0.5250\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0617 - acc: 0.6287\n",
      "--------------[0.06174855585616224, 0.6286899]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 194us/sample - loss: 0.0343 - acc: 0.8938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0720 - acc: 0.5375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 200us/sample - loss: 0.0712 - acc: 0.5375\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0597 - acc: 0.6332\n",
      "--------------[0.05971923043725898, 0.6331675]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 193us/sample - loss: 0.0283 - acc: 0.9500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 39us/sample - loss: 0.0702 - acc: 0.5625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.0688 - acc: 0.625 - 0s 205us/sample - loss: 0.0695 - acc: 0.5625\n",
      "6030/6030 [==============================] - 0s 20us/sample - loss: 0.0581 - acc: 0.6362\n",
      "--------------[0.05807068453202793, 0.63615257]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 197us/sample - loss: 0.0300 - acc: 0.9438\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0690 - acc: 0.5625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 207us/sample - loss: 0.0684 - acc: 0.5625\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0568 - acc: 0.6395\n",
      "--------------[0.056828505969660395, 0.6394693]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 199us/sample - loss: 0.0279 - acc: 0.9062\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0674 - acc: 0.5625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 208us/sample - loss: 0.0667 - acc: 0.5625\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0558 - acc: 0.6415\n",
      "--------------[0.055823866770931735, 0.64145935]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 192us/sample - loss: 0.1145 - acc: 0.0000e+00\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0621 - acc: 0.5938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 226us/sample - loss: 0.0596 - acc: 0.6125\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0555 - acc: 0.6232\n",
      "--------------[0.05554124047457678, 0.6232172]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 189us/sample - loss: 0.1079 - acc: 0.0000e+00\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 39us/sample - loss: 0.0589 - acc: 0.6187\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 212us/sample - loss: 0.0582 - acc: 0.6125\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0561 - acc: 0.5960\n",
      "--------------[0.05610830094140165, 0.5960199]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 205us/sample - loss: 0.0964 - acc: 0.0437\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0579 - acc: 0.6125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 202us/sample - loss: 0.0581 - acc: 0.6125\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0561 - acc: 0.6348\n",
      "--------------[0.05608210574285703, 0.6348259]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 192us/sample - loss: 0.0820 - acc: 0.3438\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 39us/sample - loss: 0.0588 - acc: 0.6125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 207us/sample - loss: 0.0600 - acc: 0.6125\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0552 - acc: 0.6788\n",
      "--------------[0.055249980729610765, 0.6787728]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 193us/sample - loss: 0.0690 - acc: 0.5125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0604 - acc: 0.6000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 211us/sample - loss: 0.0610 - acc: 0.5813\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0550 - acc: 0.6841\n",
      "--------------[0.05500715707566212, 0.6840796]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 192us/sample - loss: 0.0566 - acc: 0.6875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0616 - acc: 0.5875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 203us/sample - loss: 0.0615 - acc: 0.5813\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0549 - acc: 0.6569\n",
      "--------------[0.054887992459940874, 0.6568822]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 202us/sample - loss: 0.0518 - acc: 0.7000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0613 - acc: 0.6062\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 202us/sample - loss: 0.0612 - acc: 0.5875\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0550 - acc: 0.6358\n",
      "--------------[0.05501996797214495, 0.6358209]\n",
      "fit on others\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 191us/sample - loss: 0.0408 - acc: 0.8562\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0610 - acc: 0.5938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 210us/sample - loss: 0.0605 - acc: 0.5938\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0554 - acc: 0.6290\n",
      "--------------[0.05540693391170075, 0.6290216]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 189us/sample - loss: 0.0382 - acc: 0.8313\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0600 - acc: 0.5938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 209us/sample - loss: 0.0594 - acc: 0.6125\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0562 - acc: 0.6194\n",
      "--------------[0.05623599103780133, 0.619403]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 224us/sample - loss: 0.0370 - acc: 0.7812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0585 - acc: 0.6125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 207us/sample - loss: 0.0578 - acc: 0.6375\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0567 - acc: 0.6166\n",
      "--------------[0.05667649688659418, 0.61658376]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 208us/sample - loss: 0.1043 - acc: 0.0688\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 47us/sample - loss: 0.0530 - acc: 0.6562\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 207us/sample - loss: 0.0516 - acc: 0.6625\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0468 - acc: 0.7139\n",
      "--------------[0.0467825823125258, 0.71393037]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 207us/sample - loss: 0.0505 - acc: 0.6687\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 47us/sample - loss: 0.0533 - acc: 0.6438\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 202us/sample - loss: 0.0563 - acc: 0.6250\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0423 - acc: 0.7665\n",
      "--------------[0.04228836441440369, 0.76650083]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 198us/sample - loss: 0.0181 - acc: 0.9563\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 39us/sample - loss: 0.0553 - acc: 0.6250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 205us/sample - loss: 0.0547 - acc: 0.6125\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0435 - acc: 0.7456\n",
      "--------------[0.043486597267895395, 0.7456053]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 200us/sample - loss: 0.0175 - acc: 0.9500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0538 - acc: 0.6313\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 199us/sample - loss: 0.0528 - acc: 0.6187\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0448 - acc: 0.7249\n",
      "--------------[0.044844636274115564, 0.7248756]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 204us/sample - loss: 0.0215 - acc: 0.8813\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0526 - acc: 0.6313\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 211us/sample - loss: 0.0516 - acc: 0.6187\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0458 - acc: 0.7109\n",
      "--------------[0.04579791838849955, 0.71094525]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 205us/sample - loss: 0.0345 - acc: 0.7937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0522 - acc: 0.6250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 391us/sample - loss: 0.0525 - acc: 0.6125\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0468 - acc: 0.7027\n",
      "--------------[0.046834149704643745, 0.7026534]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 425us/sample - loss: 0.0186 - acc: 0.9250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 53us/sample - loss: 0.0508 - acc: 0.6375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 406us/sample - loss: 0.0499 - acc: 0.6438\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0474 - acc: 0.6940\n",
      "--------------[0.04737927311688513, 0.69402987]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 480us/sample - loss: 0.0221 - acc: 0.9000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 82us/sample - loss: 0.0496 - acc: 0.6562\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 428us/sample - loss: 0.0493 - acc: 0.6687\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0482 - acc: 0.6808\n",
      "--------------[0.04823349024328229, 0.6807628]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 392us/sample - loss: 0.0179 - acc: 0.9125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 98us/sample - loss: 0.0477 - acc: 0.6750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 405us/sample - loss: 0.0468 - acc: 0.6687\n",
      "6030/6030 [==============================] - 0s 26us/sample - loss: 0.0484 - acc: 0.6786\n",
      "--------------[0.048358993332332637, 0.678607]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 265us/sample - loss: 0.0152 - acc: 0.9438\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 47us/sample - loss: 0.0474 - acc: 0.6687\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 281us/sample - loss: 0.0476 - acc: 0.6812\n",
      "6030/6030 [==============================] - 0s 20us/sample - loss: 0.0496 - acc: 0.6605\n",
      "--------------[0.04958639201610836, 0.6605307]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 272us/sample - loss: 0.0877 - acc: 0.3000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0440 - acc: 0.6938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 287us/sample - loss: 0.0432 - acc: 0.7125\n",
      "6030/6030 [==============================] - 0s 21us/sample - loss: 0.0409 - acc: 0.7469\n",
      "--------------[0.04089234171938738, 0.746932]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 265us/sample - loss: 0.0555 - acc: 0.5125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 33us/sample - loss: 0.0442 - acc: 0.7000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 220us/sample - loss: 0.0450 - acc: 0.6875\n",
      "6030/6030 [==============================] - 0s 17us/sample - loss: 0.0402 - acc: 0.7856\n",
      "--------------[0.040245349304889565, 0.7855721]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 192us/sample - loss: 0.0366 - acc: 0.7750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0461 - acc: 0.6938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 204us/sample - loss: 0.0475 - acc: 0.6875\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0413 - acc: 0.7566\n",
      "--------------[0.041317401113448844, 0.7565506]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 197us/sample - loss: 0.0287 - acc: 0.8750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0465 - acc: 0.6938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 200us/sample - loss: 0.0461 - acc: 0.6687\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0446 - acc: 0.7003\n",
      "--------------[0.04455626285565433, 0.7003317]\n",
      "fit on others\n",
      "Train on 160 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 190us/sample - loss: 0.0272 - acc: 0.8687\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0461 - acc: 0.6875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 208us/sample - loss: 0.0456 - acc: 0.6812\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0470 - acc: 0.6798\n",
      "--------------[0.0469668045788262, 0.67976785]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 194us/sample - loss: 0.0217 - acc: 0.9000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0449 - acc: 0.6875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 213us/sample - loss: 0.0447 - acc: 0.6750\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0487 - acc: 0.6645\n",
      "--------------[0.048695346929293566, 0.6645108]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 189us/sample - loss: 0.0170 - acc: 0.9438\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0432 - acc: 0.7125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 212us/sample - loss: 0.0429 - acc: 0.6875\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0506 - acc: 0.6516\n",
      "--------------[0.0505974070349736, 0.65157545]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 204us/sample - loss: 0.0249 - acc: 0.8625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 49us/sample - loss: 0.0424 - acc: 0.7437\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 202us/sample - loss: 0.0424 - acc: 0.7125\n",
      "6030/6030 [==============================] - 0s 20us/sample - loss: 0.0523 - acc: 0.6423\n",
      "--------------[0.05227017600219048, 0.64228857]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 209us/sample - loss: 0.0198 - acc: 0.8813\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 39us/sample - loss: 0.0415 - acc: 0.7375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 200us/sample - loss: 0.0412 - acc: 0.7250\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0533 - acc: 0.6269\n",
      "--------------[0.05329614397181603, 0.6268657]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 195us/sample - loss: 0.0179 - acc: 0.8813\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0396 - acc: 0.7625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 203us/sample - loss: 0.0392 - acc: 0.7375\n",
      "6030/6030 [==============================] - 0s 20us/sample - loss: 0.0540 - acc: 0.6196\n",
      "--------------[0.054009428410288905, 0.6195688]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 202us/sample - loss: 0.0962 - acc: 0.1625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0369 - acc: 0.7625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 199us/sample - loss: 0.0376 - acc: 0.7437\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0352 - acc: 0.7915\n",
      "--------------[0.03515447483739351, 0.7915423]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 186us/sample - loss: 0.0205 - acc: 0.9000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0391 - acc: 0.7500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 204us/sample - loss: 0.0409 - acc: 0.7750\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0372 - acc: 0.7574\n",
      "--------------[0.03716005345630408, 0.7573798]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 201us/sample - loss: 0.0165 - acc: 0.9062\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0398 - acc: 0.7750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 204us/sample - loss: 0.0391 - acc: 0.7688\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0380 - acc: 0.7439\n",
      "--------------[0.03797564359619645, 0.7439469]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 239us/sample - loss: 0.0154 - acc: 0.9375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0386 - acc: 0.7875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 253us/sample - loss: 0.0387 - acc: 0.7688\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0394 - acc: 0.7318\n",
      "--------------[0.03943238710338994, 0.7318408]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 189us/sample - loss: 0.0098 - acc: 0.9563\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 37us/sample - loss: 0.0373 - acc: 0.7688\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 206us/sample - loss: 0.0360 - acc: 0.8000\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0399 - acc: 0.7186\n",
      "--------------[0.03991147803009842, 0.7185738]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 198us/sample - loss: 0.0142 - acc: 0.9250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0365 - acc: 0.7875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 201us/sample - loss: 0.0364 - acc: 0.7750\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0411 - acc: 0.7076\n",
      "--------------[0.04110603597676181, 0.70762855]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 194us/sample - loss: 0.0132 - acc: 0.9187\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0363 - acc: 0.7750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 221us/sample - loss: 0.0354 - acc: 0.7500\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0414 - acc: 0.6993\n",
      "--------------[0.0414022173059125, 0.69933665]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 199us/sample - loss: 0.0185 - acc: 0.8625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0350 - acc: 0.7937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 216us/sample - loss: 0.0349 - acc: 0.7875\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0429 - acc: 0.6995\n",
      "--------------[0.0428980023311343, 0.69950247]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 201us/sample - loss: 0.0109 - acc: 0.9438\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0347 - acc: 0.8062\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 246us/sample - loss: 0.0346 - acc: 0.8000\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0431 - acc: 0.6959\n",
      "--------------[0.04312045011626152, 0.69585407]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 196us/sample - loss: 0.0149 - acc: 0.9187\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0344 - acc: 0.7875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 203us/sample - loss: 0.0341 - acc: 0.7937\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0448 - acc: 0.6874\n",
      "--------------[0.044830157941401896, 0.68739635]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 193us/sample - loss: 0.0757 - acc: 0.4000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0314 - acc: 0.8313\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 206us/sample - loss: 0.0330 - acc: 0.8000\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0333 - acc: 0.7849\n",
      "--------------[0.03333334823758349, 0.7849088]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 218us/sample - loss: 0.0266 - acc: 0.8438\n",
      "Train on 160 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0333 - acc: 0.8188\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 206us/sample - loss: 0.0339 - acc: 0.7937\n",
      "6030/6030 [==============================] - 0s 20us/sample - loss: 0.0372 - acc: 0.7441\n",
      "--------------[0.03717179504743658, 0.7441128]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 197us/sample - loss: 0.0208 - acc: 0.8813\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0342 - acc: 0.8000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 199us/sample - loss: 0.0342 - acc: 0.8000\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0405 - acc: 0.7093\n",
      "--------------[0.04046244671688744, 0.7092869]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 194us/sample - loss: 0.0143 - acc: 0.9187\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0331 - acc: 0.8125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 211us/sample - loss: 0.0325 - acc: 0.8125\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0422 - acc: 0.6847\n",
      "--------------[0.04218861002159949, 0.6847429]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 210us/sample - loss: 0.0137 - acc: 0.9438\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0325 - acc: 0.8125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 203us/sample - loss: 0.0326 - acc: 0.8188\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0444 - acc: 0.6572\n",
      "--------------[0.04438322463488302, 0.6572139]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 189us/sample - loss: 0.0193 - acc: 0.8813\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0326 - acc: 0.8062\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 205us/sample - loss: 0.0324 - acc: 0.8062\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0455 - acc: 0.6549\n",
      "--------------[0.04554022402930418, 0.6548922]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 190us/sample - loss: 0.0110 - acc: 0.9500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0310 - acc: 0.8188\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 202us/sample - loss: 0.0302 - acc: 0.8250\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0468 - acc: 0.6439\n",
      "--------------[0.04678708027374883, 0.64394695]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 189us/sample - loss: 0.0161 - acc: 0.9187\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0305 - acc: 0.8250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 205us/sample - loss: 0.0307 - acc: 0.8313\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0485 - acc: 0.6302\n",
      "--------------[0.04845693598734601, 0.63018245]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 193us/sample - loss: 0.0133 - acc: 0.9062\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0308 - acc: 0.8188\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 219us/sample - loss: 0.0306 - acc: 0.8125\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0493 - acc: 0.6244\n",
      "--------------[0.04930820243053175, 0.6243781]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 192us/sample - loss: 0.0103 - acc: 0.9563\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0293 - acc: 0.8313\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 206us/sample - loss: 0.0289 - acc: 0.8250\n",
      "6030/6030 [==============================] - 0s 20us/sample - loss: 0.0506 - acc: 0.6186\n",
      "--------------[0.0506137843093963, 0.6185738]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 201us/sample - loss: 0.0739 - acc: 0.4062\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0276 - acc: 0.8500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 210us/sample - loss: 0.0322 - acc: 0.8062\n",
      "6030/6030 [==============================] - 0s 20us/sample - loss: 0.0340 - acc: 0.7499\n",
      "--------------[0.03403575503225647, 0.7499171]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 211us/sample - loss: 0.0112 - acc: 0.9312\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0297 - acc: 0.8375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 205us/sample - loss: 0.0289 - acc: 0.8313\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0365 - acc: 0.7318\n",
      "--------------[0.036518968771494444, 0.7318408]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 192us/sample - loss: 0.0134 - acc: 0.9438\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0292 - acc: 0.8188\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 209us/sample - loss: 0.0294 - acc: 0.8250\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0362 - acc: 0.7257\n",
      "--------------[0.03624767666963696, 0.7257048]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 190us/sample - loss: 0.0130 - acc: 0.9375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 39us/sample - loss: 0.0287 - acc: 0.8438\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 205us/sample - loss: 0.0283 - acc: 0.8375\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0366 - acc: 0.7231\n",
      "--------------[0.03664035493782899, 0.7230514]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 191us/sample - loss: 0.0117 - acc: 0.9500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0273 - acc: 0.8500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 200us/sample - loss: 0.0269 - acc: 0.8438\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0386 - acc: 0.7177\n",
      "--------------[0.0385524275488719, 0.7177446]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 231us/sample - loss: 0.0113 - acc: 0.9500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 51us/sample - loss: 0.0271 - acc: 0.8500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 203us/sample - loss: 0.0273 - acc: 0.8375\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0394 - acc: 0.7101\n",
      "--------------[0.03939159719727526, 0.7101161]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 188us/sample - loss: 0.0136 - acc: 0.9187\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 38us/sample - loss: 0.0268 - acc: 0.8625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 208us/sample - loss: 0.0275 - acc: 0.8438\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0396 - acc: 0.7055\n",
      "--------------[0.03958826540516779, 0.70547265]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 188us/sample - loss: 0.0186 - acc: 0.8875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0267 - acc: 0.8500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 199us/sample - loss: 0.0264 - acc: 0.8438\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0405 - acc: 0.7008\n",
      "--------------[0.04045232819828821, 0.7008292]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 189us/sample - loss: 0.0167 - acc: 0.9000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0266 - acc: 0.8438\n",
      "Train on 160 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 213us/sample - loss: 0.0264 - acc: 0.8438\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0411 - acc: 0.6980\n",
      "--------------[0.04114357178434606, 0.69800997]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 196us/sample - loss: 0.0147 - acc: 0.9187\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0261 - acc: 0.8562\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 202us/sample - loss: 0.0259 - acc: 0.8562\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0420 - acc: 0.6886\n",
      "--------------[0.04199617422412877, 0.6885572]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 200us/sample - loss: 0.0667 - acc: 0.4875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0240 - acc: 0.8500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 212us/sample - loss: 0.0251 - acc: 0.8438\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0322 - acc: 0.7677\n",
      "--------------[0.032160344289903026, 0.7676617]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 203us/sample - loss: 0.0103 - acc: 0.9563\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 47us/sample - loss: 0.0253 - acc: 0.8625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 213us/sample - loss: 0.0248 - acc: 0.8687\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0341 - acc: 0.7496\n",
      "--------------[0.034083251766922264, 0.7495854]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 209us/sample - loss: 0.0192 - acc: 0.8750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0246 - acc: 0.8562\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 210us/sample - loss: 0.0251 - acc: 0.8625\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0360 - acc: 0.7327\n",
      "--------------[0.035986664439018684, 0.73267]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 204us/sample - loss: 0.0117 - acc: 0.9563\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0247 - acc: 0.8625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 207us/sample - loss: 0.0253 - acc: 0.8687\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0390 - acc: 0.7027\n",
      "--------------[0.03903857800572073, 0.7026534]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 222us/sample - loss: 0.0114 - acc: 0.9375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 33us/sample - loss: 0.0245 - acc: 0.8687\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 247us/sample - loss: 0.0256 - acc: 0.8438\n",
      "6030/6030 [==============================] - 0s 20us/sample - loss: 0.0400 - acc: 0.6968\n",
      "--------------[0.04004259561597807, 0.6968491]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 186us/sample - loss: 0.0130 - acc: 0.9250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 38us/sample - loss: 0.0239 - acc: 0.8687\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 208us/sample - loss: 0.0241 - acc: 0.8687\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0417 - acc: 0.6798\n",
      "--------------[0.04169237167631611, 0.67976785]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 189us/sample - loss: 0.0210 - acc: 0.8500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 49us/sample - loss: 0.0250 - acc: 0.8250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 221us/sample - loss: 0.0249 - acc: 0.8750\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0436 - acc: 0.6655\n",
      "--------------[0.04360451136976728, 0.6655058]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 189us/sample - loss: 0.0172 - acc: 0.8875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0240 - acc: 0.8687\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 201us/sample - loss: 0.0239 - acc: 0.8562\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0439 - acc: 0.6643\n",
      "--------------[0.04391325578884304, 0.66434497]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 195us/sample - loss: 0.0082 - acc: 0.9625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0237 - acc: 0.8500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 213us/sample - loss: 0.0230 - acc: 0.8625\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0441 - acc: 0.6597\n",
      "--------------[0.044088741562408, 0.65970147]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 194us/sample - loss: 0.0162 - acc: 0.8750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0231 - acc: 0.8813\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 210us/sample - loss: 0.0231 - acc: 0.8687\n",
      "6030/6030 [==============================] - 0s 18us/sample - loss: 0.0457 - acc: 0.6493\n",
      "--------------[0.0457424515651332, 0.6492537]\n"
     ]
    }
   ],
   "source": [
    "# ASSIMILATION - Momentum\n",
    "assim_epochs = 2\n",
    "coeff = 0.5\n",
    "first_exc_locs = []\n",
    "cur_weights = init_weights\n",
    "eval_hist4 = [eval_weights(cur_weights)]\n",
    "for i in range(len(y_train_list)):\n",
    "    print(\"fit on others\".format(0, i))\n",
    "    target_model = get_model()\n",
    "    target_model.set_weights(cur_weights)\n",
    "    compile_model(target_model)\n",
    "    prev_weights = copy.deepcopy(target_model.get_weights())\n",
    "    # fit to theirs\n",
    "    target_model.fit(x_train_list[i], y_train_list[i], epochs=1, shuffle=True)\n",
    "    new_weights = copy.deepcopy(updates(prev_weights, target_model.get_weights()))\n",
    "    # fit to mine\n",
    "    target_model.fit(x_target, y_target, epochs=1, shuffle=True)\n",
    "    # momentum to theirs\n",
    "    new_weights = add_weights(target_model.get_weights(), new_weights)\n",
    "    target_model = get_model()\n",
    "    target_model.set_weights(new_weights)\n",
    "    compile_model(target_model)          \n",
    "    # fit to mine\n",
    "    target_model.fit(x_target, y_target, epochs=1, shuffle=True)\n",
    "    hist = target_model.evaluate(x_test, y_test)\n",
    "    print(\"--------------{}\".format(hist))\n",
    "    eval_hist4.append(copy.deepcopy(hist))\n",
    "    cur_weights = copy.deepcopy(target_model.get_weights())\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0809 - acc: 0.5299\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 405us/sample - loss: 0.0820 - acc: 0.4750\n",
      "6030/6030 [==============================] - 0s 38us/sample - loss: 0.0809 - acc: 0.5299\n",
      "--------------[0.08087842092782901, 0.5298507]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 457us/sample - loss: 0.0819 - acc: 0.5000\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0809 - acc: 0.5299\n",
      "--------------[0.08087842092782901, 0.5298507]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 442us/sample - loss: 0.0812 - acc: 0.5000\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0809 - acc: 0.5299\n",
      "--------------[0.08087842092782901, 0.5298507]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 410us/sample - loss: 0.0805 - acc: 0.5813\n",
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.0809 - acc: 0.5299\n",
      "--------------[0.08087842092782901, 0.5298507]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 415us/sample - loss: 0.0798 - acc: 0.6062\n",
      "6030/6030 [==============================] - 0s 38us/sample - loss: 0.0809 - acc: 0.5299\n",
      "--------------[0.08087842092782901, 0.5298507]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 420us/sample - loss: 0.0809 - acc: 0.5437\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0809 - acc: 0.5299\n",
      "--------------[0.08087842092782901, 0.5298507]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 355us/sample - loss: 0.0806 - acc: 0.5375\n",
      "6030/6030 [==============================] - 0s 37us/sample - loss: 0.0809 - acc: 0.5299\n",
      "--------------[0.08087842092782901, 0.5298507]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 377us/sample - loss: 0.0804 - acc: 0.5312\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0809 - acc: 0.5299\n",
      "--------------[0.08087842092782901, 0.5298507]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 394us/sample - loss: 0.0822 - acc: 0.5375\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0809 - acc: 0.5299\n",
      "--------------[0.08087842092782901, 0.5298507]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 418us/sample - loss: 0.0818 - acc: 0.4688\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0809 - acc: 0.5299\n",
      "--------------[0.08087842092782901, 0.5298507]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 397us/sample - loss: 0.0844 - acc: 0.4437\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 70us/sample - loss: 0.0868 - acc: 0.2812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 467us/sample - loss: 0.0833 - acc: 0.4375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 124us/sample - loss: 0.0849 - acc: 0.3625\n",
      "6030/6030 [==============================] - 0s 36us/sample - loss: 0.0768 - acc: 0.6612\n",
      "--------------[0.0767946069463964, 0.661194]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 410us/sample - loss: 0.0824 - acc: 0.4313\n",
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.0768 - acc: 0.6612\n",
      "--------------[0.0767946069463964, 0.661194]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 414us/sample - loss: 0.0801 - acc: 0.5500\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0768 - acc: 0.6612\n",
      "--------------[0.0767946069463964, 0.661194]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 284us/sample - loss: 0.0816 - acc: 0.5250\n",
      "6030/6030 [==============================] - 0s 20us/sample - loss: 0.0768 - acc: 0.6612\n",
      "--------------[0.0767946069463964, 0.661194]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 269us/sample - loss: 0.0811 - acc: 0.5625\n",
      "6030/6030 [==============================] - 0s 21us/sample - loss: 0.0768 - acc: 0.6612\n",
      "--------------[0.0767946069463964, 0.661194]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 275us/sample - loss: 0.0806 - acc: 0.5875\n",
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.0768 - acc: 0.6612\n",
      "--------------[0.0767946069463964, 0.661194]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 400us/sample - loss: 0.0828 - acc: 0.4688\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0768 - acc: 0.6612\n",
      "--------------[0.0767946069463964, 0.661194]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 473us/sample - loss: 0.0799 - acc: 0.5375\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0768 - acc: 0.6612\n",
      "--------------[0.0767946069463964, 0.661194]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 365us/sample - loss: 0.0814 - acc: 0.5750\n",
      "6030/6030 [==============================] - 0s 38us/sample - loss: 0.0768 - acc: 0.6612\n",
      "--------------[0.0767946069463964, 0.661194]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 387us/sample - loss: 0.0830 - acc: 0.5375\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0768 - acc: 0.6612\n",
      "--------------[0.0767946069463964, 0.661194]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 427us/sample - loss: 0.0819 - acc: 0.5312\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 76us/sample - loss: 0.0784 - acc: 0.5625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 388us/sample - loss: 0.0813 - acc: 0.5125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 85us/sample - loss: 0.0740 - acc: 0.6500\n",
      "6030/6030 [==============================] - 0s 30us/sample - loss: 0.0725 - acc: 0.6982\n",
      "--------------[0.07248468270299842, 0.6981758]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 421us/sample - loss: 0.0671 - acc: 0.7688\n",
      "6030/6030 [==============================] - 0s 38us/sample - loss: 0.0725 - acc: 0.6982\n",
      "--------------[0.07248468270299842, 0.6981758]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 376us/sample - loss: 0.0620 - acc: 0.8562\n",
      "6030/6030 [==============================] - 0s 29us/sample - loss: 0.0725 - acc: 0.6982\n",
      "--------------[0.07248468270299842, 0.6981758]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 373us/sample - loss: 0.0626 - acc: 0.8125\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0725 - acc: 0.6982\n",
      "--------------[0.07248468270299842, 0.6981758]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 425us/sample - loss: 0.0653 - acc: 0.7937\n",
      "6030/6030 [==============================] - 0s 30us/sample - loss: 0.0725 - acc: 0.6982\n",
      "--------------[0.07248468270299842, 0.6981758]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 404us/sample - loss: 0.0714 - acc: 0.6875\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0725 - acc: 0.6982\n",
      "--------------[0.07248468270299842, 0.6981758]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 403us/sample - loss: 0.0663 - acc: 0.7500\n",
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.0725 - acc: 0.6982\n",
      "--------------[0.07248468270299842, 0.6981758]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 349us/sample - loss: 0.0697 - acc: 0.7188\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0725 - acc: 0.6982\n",
      "--------------[0.07248468270299842, 0.6981758]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 418us/sample - loss: 0.0661 - acc: 0.7688\n",
      "6030/6030 [==============================] - 0s 36us/sample - loss: 0.0725 - acc: 0.6982\n",
      "--------------[0.07248468270299842, 0.6981758]\n",
      "fit on others\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 394us/sample - loss: 0.0668 - acc: 0.8313\n",
      "6030/6030 [==============================] - 0s 41us/sample - loss: 0.0725 - acc: 0.6982\n",
      "--------------[0.07248468270299842, 0.6981758]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 400us/sample - loss: 0.0822 - acc: 0.4187\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 72us/sample - loss: 0.0799 - acc: 0.4250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 405us/sample - loss: 0.0812 - acc: 0.4437\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 66us/sample - loss: 0.0757 - acc: 0.5000\n",
      "6030/6030 [==============================] - 0s 36us/sample - loss: 0.0675 - acc: 0.7481\n",
      "--------------[0.06753636799740356, 0.7480929]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 412us/sample - loss: 0.0701 - acc: 0.6438\n",
      "6030/6030 [==============================] - 0s 24us/sample - loss: 0.0675 - acc: 0.7481\n",
      "--------------[0.06753636799740356, 0.7480929]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 262us/sample - loss: 0.0671 - acc: 0.6062\n",
      "6030/6030 [==============================] - 0s 22us/sample - loss: 0.0675 - acc: 0.7481\n",
      "--------------[0.06753636799740356, 0.7480929]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 275us/sample - loss: 0.0700 - acc: 0.6313\n",
      "6030/6030 [==============================] - 0s 22us/sample - loss: 0.0675 - acc: 0.7481\n",
      "--------------[0.06753636799740356, 0.7480929]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 257us/sample - loss: 0.0697 - acc: 0.5750\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0675 - acc: 0.7481\n",
      "--------------[0.06753636799740356, 0.7480929]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 427us/sample - loss: 0.0709 - acc: 0.5938\n",
      "6030/6030 [==============================] - 0s 30us/sample - loss: 0.0675 - acc: 0.7481\n",
      "--------------[0.06753636799740356, 0.7480929]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 387us/sample - loss: 0.0672 - acc: 0.5938\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0675 - acc: 0.7481\n",
      "--------------[0.06753636799740356, 0.7480929]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 382us/sample - loss: 0.0739 - acc: 0.5688\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0675 - acc: 0.7481\n",
      "--------------[0.06753636799740356, 0.7480929]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 423us/sample - loss: 0.0707 - acc: 0.6313\n",
      "6030/6030 [==============================] - 0s 37us/sample - loss: 0.0675 - acc: 0.7481\n",
      "--------------[0.06753636799740356, 0.7480929]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 452us/sample - loss: 0.0697 - acc: 0.6562\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0675 - acc: 0.7481\n",
      "--------------[0.06753636799740356, 0.7480929]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 382us/sample - loss: 0.0798 - acc: 0.5312\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 105us/sample - loss: 0.0731 - acc: 0.6000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 421us/sample - loss: 0.0792 - acc: 0.5125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 73us/sample - loss: 0.0695 - acc: 0.6313\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0629 - acc: 0.7491\n",
      "--------------[0.0629414225148522, 0.74908787]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 388us/sample - loss: 0.0504 - acc: 0.9312\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0629 - acc: 0.7491\n",
      "--------------[0.0629414225148522, 0.74908787]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 420us/sample - loss: 0.0532 - acc: 0.8562\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0629 - acc: 0.7491\n",
      "--------------[0.0629414225148522, 0.74908787]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 421us/sample - loss: 0.0542 - acc: 0.8687\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0629 - acc: 0.7491\n",
      "--------------[0.0629414225148522, 0.74908787]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 379us/sample - loss: 0.0506 - acc: 0.8625\n",
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.0629 - acc: 0.7491\n",
      "--------------[0.0629414225148522, 0.74908787]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 360us/sample - loss: 0.0504 - acc: 0.8750\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0629 - acc: 0.7491\n",
      "--------------[0.0629414225148522, 0.74908787]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 371us/sample - loss: 0.0524 - acc: 0.8188\n",
      "6030/6030 [==============================] - 0s 37us/sample - loss: 0.0629 - acc: 0.7491\n",
      "--------------[0.0629414225148522, 0.74908787]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 419us/sample - loss: 0.0544 - acc: 0.8125\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0629 - acc: 0.7491\n",
      "--------------[0.0629414225148522, 0.74908787]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 420us/sample - loss: 0.0505 - acc: 0.9187\n",
      "6030/6030 [==============================] - 0s 29us/sample - loss: 0.0629 - acc: 0.7491\n",
      "--------------[0.0629414225148522, 0.74908787]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 394us/sample - loss: 0.0556 - acc: 0.7750\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0629 - acc: 0.7491\n",
      "--------------[0.0629414225148522, 0.74908787]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 400us/sample - loss: 0.0800 - acc: 0.4250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0736 - acc: 0.4313\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 418us/sample - loss: 0.0784 - acc: 0.4750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 51us/sample - loss: 0.0693 - acc: 0.4938\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0579 - acc: 0.7950\n",
      "--------------[0.057901378575199676, 0.7950249]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 301us/sample - loss: 0.0583 - acc: 0.7437\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0579 - acc: 0.7950\n",
      "--------------[0.057901378575199676, 0.7950249]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 261us/sample - loss: 0.0592 - acc: 0.7000\n",
      "6030/6030 [==============================] - 0s 21us/sample - loss: 0.0579 - acc: 0.7950\n",
      "--------------[0.057901378575199676, 0.7950249]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 253us/sample - loss: 0.0531 - acc: 0.7875\n",
      "6030/6030 [==============================] - 0s 20us/sample - loss: 0.0579 - acc: 0.7950\n",
      "--------------[0.057901378575199676, 0.7950249]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 263us/sample - loss: 0.0560 - acc: 0.7375\n",
      "6030/6030 [==============================] - 0s 36us/sample - loss: 0.0579 - acc: 0.7950\n",
      "--------------[0.057901378575199676, 0.7950249]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 435us/sample - loss: 0.0627 - acc: 0.6062\n",
      "6030/6030 [==============================] - 0s 30us/sample - loss: 0.0579 - acc: 0.7950\n",
      "--------------[0.057901378575199676, 0.7950249]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 398us/sample - loss: 0.0552 - acc: 0.7688\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0579 - acc: 0.7950\n",
      "--------------[0.057901378575199676, 0.7950249]\n",
      "fit on others\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 359us/sample - loss: 0.0576 - acc: 0.6750\n",
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.0579 - acc: 0.7950\n",
      "--------------[0.057901378575199676, 0.7950249]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 422us/sample - loss: 0.0527 - acc: 0.7500\n",
      "6030/6030 [==============================] - 0s 37us/sample - loss: 0.0579 - acc: 0.7950\n",
      "--------------[0.057901378575199676, 0.7950249]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 424us/sample - loss: 0.0564 - acc: 0.7500\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0579 - acc: 0.7950\n",
      "--------------[0.057901378575199676, 0.7950249]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 422us/sample - loss: 0.0774 - acc: 0.5250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 47us/sample - loss: 0.0594 - acc: 0.7625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 392us/sample - loss: 0.0769 - acc: 0.5188\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 71us/sample - loss: 0.0520 - acc: 0.8375\n",
      "6030/6030 [==============================] - 0s 37us/sample - loss: 0.0534 - acc: 0.7698\n",
      "--------------[0.053393882876308404, 0.7698176]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 473us/sample - loss: 0.0350 - acc: 0.9187\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0534 - acc: 0.7698\n",
      "--------------[0.053393882876308404, 0.7698176]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 396us/sample - loss: 0.0401 - acc: 0.8687\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0534 - acc: 0.7698\n",
      "--------------[0.053393882876308404, 0.7698176]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 401us/sample - loss: 0.0402 - acc: 0.8750\n",
      "6030/6030 [==============================] - 0s 30us/sample - loss: 0.0534 - acc: 0.7698\n",
      "--------------[0.053393882876308404, 0.7698176]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 433us/sample - loss: 0.0389 - acc: 0.9000\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0534 - acc: 0.7698\n",
      "--------------[0.053393882876308404, 0.7698176]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 437us/sample - loss: 0.0367 - acc: 0.9062\n",
      "6030/6030 [==============================] - 0s 38us/sample - loss: 0.0534 - acc: 0.7698\n",
      "--------------[0.053393882876308404, 0.7698176]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 391us/sample - loss: 0.0379 - acc: 0.9125\n",
      "6030/6030 [==============================] - 0s 38us/sample - loss: 0.0534 - acc: 0.7698\n",
      "--------------[0.053393882876308404, 0.7698176]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 415us/sample - loss: 0.0418 - acc: 0.8687\n",
      "6030/6030 [==============================] - 0s 30us/sample - loss: 0.0534 - acc: 0.7698\n",
      "--------------[0.053393882876308404, 0.7698176]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 417us/sample - loss: 0.0449 - acc: 0.7812\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0534 - acc: 0.7698\n",
      "--------------[0.053393882876308404, 0.7698176]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 416us/sample - loss: 0.0404 - acc: 0.9062\n",
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.0534 - acc: 0.7698\n",
      "--------------[0.053393882876308404, 0.7698176]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 256us/sample - loss: 0.0783 - acc: 0.4250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0611 - acc: 0.5750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 279us/sample - loss: 0.0759 - acc: 0.5063\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0498 - acc: 0.7750\n",
      "6030/6030 [==============================] - 0s 19us/sample - loss: 0.0502 - acc: 0.8091\n",
      "--------------[0.05019191861473901, 0.8091211]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 269us/sample - loss: 0.0342 - acc: 0.9250\n",
      "6030/6030 [==============================] - 0s 21us/sample - loss: 0.0502 - acc: 0.8091\n",
      "--------------[0.05019191861473901, 0.8091211]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 252us/sample - loss: 0.0420 - acc: 0.8438\n",
      "6030/6030 [==============================] - 0s 21us/sample - loss: 0.0502 - acc: 0.8091\n",
      "--------------[0.05019191861473901, 0.8091211]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 544us/sample - loss: 0.0434 - acc: 0.8500\n",
      "6030/6030 [==============================] - 0s 36us/sample - loss: 0.0502 - acc: 0.8091\n",
      "--------------[0.05019191861473901, 0.8091211]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 384us/sample - loss: 0.0359 - acc: 0.8938\n",
      "6030/6030 [==============================] - 0s 29us/sample - loss: 0.0502 - acc: 0.8091\n",
      "--------------[0.05019191861473901, 0.8091211]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 410us/sample - loss: 0.0398 - acc: 0.8750\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0502 - acc: 0.8091\n",
      "--------------[0.05019191861473901, 0.8091211]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 413us/sample - loss: 0.0442 - acc: 0.8250\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0502 - acc: 0.8091\n",
      "--------------[0.05019191861473901, 0.8091211]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 385us/sample - loss: 0.0458 - acc: 0.7875\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0502 - acc: 0.8091\n",
      "--------------[0.05019191861473901, 0.8091211]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 401us/sample - loss: 0.0396 - acc: 0.8562\n",
      "6030/6030 [==============================] - 0s 36us/sample - loss: 0.0502 - acc: 0.8091\n",
      "--------------[0.05019191861473901, 0.8091211]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 375us/sample - loss: 0.0456 - acc: 0.8125\n",
      "6030/6030 [==============================] - 0s 37us/sample - loss: 0.0502 - acc: 0.8091\n",
      "--------------[0.05019191861473901, 0.8091211]\n"
     ]
    }
   ],
   "source": [
    "# ASSIMILATION - Cache\n",
    "updates_cache = None\n",
    "assim_epochs = 2\n",
    "coeff = 0.5\n",
    "first_exc_locs = []\n",
    "cur_weights = init_weights\n",
    "eval_hist5 = [eval_weights(cur_weights)]\n",
    "for i in range(len(y_train_list)):\n",
    "    print(\"fit on others\".format(0, i))\n",
    "    # distribution changing points\n",
    "    if i != 0 and i % 10 == 0:\n",
    "        # fit to previous remote\n",
    "        new_model_weights = add_weights(cur_weights, updates_cache) \n",
    "        target_model = get_model()\n",
    "        target_model.set_weights(new_model_weights)\n",
    "        compile_model(target_model) \n",
    "        # fit to mine\n",
    "        target_model.fit(x_target, y_target, epochs=1, shuffle=True)\n",
    "        # fit to current remote\n",
    "        target_model.fit(x_train_list[i], y_train_list[i], epochs=1, shuffle=True)\n",
    "        \n",
    "        # fit to previous remote\n",
    "        new_model_weights = add_weights(target_model.get_weights(), updates_cache) \n",
    "        target_model.set_weights(new_model_weights)\n",
    "        compile_model(target_model) \n",
    "        # fit to mine\n",
    "        target_model.fit(x_target, y_target, epochs=1, shuffle=True)\n",
    "        # fit to current remote\n",
    "        target_model.fit(x_train_list[i], y_train_list[i], epochs=1, shuffle=True)\n",
    "        \n",
    "        hist = target_model.evaluate(x_test, y_test)\n",
    "        # actually update our model here\n",
    "        cur_weights = copy.deepcopy(target_model.get_weights())\n",
    "        updates_cache = None\n",
    "    # just cache\n",
    "    else:\n",
    "        target_model = get_model()\n",
    "        target_model.set_weights(cur_weights)\n",
    "        compile_model(target_model) \n",
    "        target_model.fit(x_train_list[i], y_train_list[i], epochs=1, shuffle=True)\n",
    "        new_updates = copy.deepcopy(updates(cur_weights, target_model.get_weights()))\n",
    "        updates_cache = avg_weights(updates_cache, new_updates)\n",
    "        # don't do any updates to our model..\n",
    "        target_model = get_model()\n",
    "        target_model.set_weights(cur_weights)\n",
    "        compile_model(target_model)\n",
    "        hist = target_model.evaluate(x_test, y_test)\n",
    "    print(\"--------------{}\".format(hist))\n",
    "    eval_hist5.append(copy.deepcopy(hist))\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0175 - acc: 0.8811\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 413us/sample - loss: 0.0169 - acc: 0.8938\n",
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.0175 - acc: 0.8811\n",
      "--------------[0.01753742097325586, 0.8810945]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 427us/sample - loss: 0.0169 - acc: 0.8938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 70us/sample - loss: 0.0032 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0161 - acc: 0.8907\n",
      "--------------[0.0160658264640799, 0.8907131]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 445us/sample - loss: 0.0240 - acc: 0.8375\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0161 - acc: 0.8907\n",
      "--------------[0.0160658264640799, 0.8907131]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 423us/sample - loss: 0.0230 - acc: 0.8562\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 85us/sample - loss: 0.0034 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 30us/sample - loss: 0.0151 - acc: 0.8985\n",
      "--------------[0.015050269862880952, 0.8985075]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 382us/sample - loss: 0.0250 - acc: 0.8375\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0151 - acc: 0.8985\n",
      "--------------[0.015050269862880952, 0.8985075]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 443us/sample - loss: 0.0118 - acc: 0.9125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 61us/sample - loss: 0.0037 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 38us/sample - loss: 0.0144 - acc: 0.9036\n",
      "--------------[0.014367508403895111, 0.90364844]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 423us/sample - loss: 0.0255 - acc: 0.8375\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0144 - acc: 0.9036\n",
      "--------------[0.014367508403895111, 0.90364844]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 340us/sample - loss: 0.0104 - acc: 0.9312\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 96us/sample - loss: 0.0037 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0138 - acc: 0.9060\n",
      "--------------[0.013785284951909957, 0.90597016]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 439us/sample - loss: 0.0189 - acc: 0.8625\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0138 - acc: 0.9060\n",
      "--------------[0.013785284951909957, 0.90597016]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 339us/sample - loss: 0.0069 - acc: 0.9563\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 101us/sample - loss: 0.0036 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0131 - acc: 0.9116\n",
      "--------------[0.013105833595294264, 0.91160864]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 417us/sample - loss: 0.0236 - acc: 0.8438\n",
      "6030/6030 [==============================] - 0s 30us/sample - loss: 0.0131 - acc: 0.9116\n",
      "--------------[0.013105833595294264, 0.91160864]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 394us/sample - loss: 0.0126 - acc: 0.9187\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 110us/sample - loss: 0.0036 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0139 - acc: 0.9053\n",
      "--------------[0.013930628072180064, 0.9053068]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 472us/sample - loss: 0.0234 - acc: 0.8562\n",
      "6030/6030 [==============================] - 0s 36us/sample - loss: 0.0139 - acc: 0.9053\n",
      "--------------[0.013930628072180064, 0.9053068]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 427us/sample - loss: 0.0141 - acc: 0.9187\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 98us/sample - loss: 0.0038 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0132 - acc: 0.9106\n",
      "--------------[0.013230793461957283, 0.9106136]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 440us/sample - loss: 0.0158 - acc: 0.8875\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0132 - acc: 0.9106\n",
      "--------------[0.013230793461957283, 0.9106136]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 263us/sample - loss: 0.0062 - acc: 0.9563\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 52us/sample - loss: 0.0038 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 22us/sample - loss: 0.0136 - acc: 0.9098\n",
      "--------------[0.013559411325882719, 0.90978444]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 304us/sample - loss: 0.0208 - acc: 0.8687\n",
      "6030/6030 [==============================] - 0s 40us/sample - loss: 0.0136 - acc: 0.9098\n",
      "--------------[0.013559411325882719, 0.90978444]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 415us/sample - loss: 0.0096 - acc: 0.9500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 113us/sample - loss: 0.0039 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0141 - acc: 0.9071\n",
      "--------------[0.014103028632910493, 0.907131]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 428us/sample - loss: 0.0286 - acc: 0.8125\n",
      "6030/6030 [==============================] - 0s 37us/sample - loss: 0.0141 - acc: 0.9071\n",
      "--------------[0.014103028632910493, 0.907131]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 380us/sample - loss: 0.0078 - acc: 0.9438\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 49us/sample - loss: 0.0041 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 45us/sample - loss: 0.0145 - acc: 0.9058\n",
      "--------------[0.014453403714420289, 0.90580434]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 427us/sample - loss: 0.0222 - acc: 0.8438\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0145 - acc: 0.9058\n",
      "--------------[0.014453403714420289, 0.90580434]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 379us/sample - loss: 0.0134 - acc: 0.9125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 47us/sample - loss: 0.0039 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0134 - acc: 0.9114\n",
      "--------------[0.013446298293509887, 0.91144276]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 409us/sample - loss: 0.0232 - acc: 0.8562\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0134 - acc: 0.9114\n",
      "--------------[0.013446298293509887, 0.91144276]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 387us/sample - loss: 0.0140 - acc: 0.9125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 73us/sample - loss: 0.0037 - acc: 0.9750\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0132 - acc: 0.9116\n",
      "--------------[0.01322230931748304, 0.91160864]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 407us/sample - loss: 0.0190 - acc: 0.8625\n",
      "6030/6030 [==============================] - 0s 29us/sample - loss: 0.0132 - acc: 0.9116\n",
      "--------------[0.01322230931748304, 0.91160864]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 481us/sample - loss: 0.0048 - acc: 0.9625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 148us/sample - loss: 0.0035 - acc: 0.9812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0118 - acc: 0.9207\n",
      "--------------[0.011799103488981921, 0.9207297]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 430us/sample - loss: 0.0202 - acc: 0.8625\n",
      "6030/6030 [==============================] - 0s 29us/sample - loss: 0.0118 - acc: 0.9207\n",
      "--------------[0.011799103488981921, 0.9207297]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 422us/sample - loss: 0.0074 - acc: 0.9500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 103us/sample - loss: 0.0033 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 37us/sample - loss: 0.0116 - acc: 0.9229\n",
      "--------------[0.011564039957291055, 0.9228856]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 443us/sample - loss: 0.0153 - acc: 0.8875\n",
      "6030/6030 [==============================] - 0s 38us/sample - loss: 0.0116 - acc: 0.9229\n",
      "--------------[0.011564039957291055, 0.9228856]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 373us/sample - loss: 0.0176 - acc: 0.8750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 60us/sample - loss: 0.0034 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 39us/sample - loss: 0.0119 - acc: 0.9204\n",
      "--------------[0.011859679301493302, 0.920398]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 424us/sample - loss: 0.0193 - acc: 0.8938\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0119 - acc: 0.9204\n",
      "--------------[0.011859679301493302, 0.920398]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 410us/sample - loss: 0.0279 - acc: 0.8062\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 52us/sample - loss: 0.0039 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0124 - acc: 0.9158\n",
      "--------------[0.012448009761485888, 0.91575456]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 270us/sample - loss: 0.0255 - acc: 0.8375\n",
      "6030/6030 [==============================] - 0s 20us/sample - loss: 0.0124 - acc: 0.9158\n",
      "--------------[0.012448009761485888, 0.91575456]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 416us/sample - loss: 0.0097 - acc: 0.9375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 53us/sample - loss: 0.0038 - acc: 0.9750\n",
      "6030/6030 [==============================] - 0s 35us/sample - loss: 0.0124 - acc: 0.9161\n",
      "--------------[0.0124239530148692, 0.91608626]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 425us/sample - loss: 0.0194 - acc: 0.8438\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0124 - acc: 0.9161\n",
      "--------------[0.0124239530148692, 0.91608626]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 439us/sample - loss: 0.0094 - acc: 0.9438\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0034 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0121 - acc: 0.9192\n",
      "--------------[0.012099747566095434, 0.91923714]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 420us/sample - loss: 0.0252 - acc: 0.8188\n",
      "6030/6030 [==============================] - 0s 33us/sample - loss: 0.0121 - acc: 0.9192\n",
      "--------------[0.012099747566095434, 0.91923714]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 434us/sample - loss: 0.0119 - acc: 0.9062\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 49us/sample - loss: 0.0031 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 31us/sample - loss: 0.0118 - acc: 0.9206\n",
      "--------------[0.011838361821067867, 0.9205639]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 419us/sample - loss: 0.0258 - acc: 0.8188\n",
      "6030/6030 [==============================] - 0s 32us/sample - loss: 0.0118 - acc: 0.9206\n",
      "--------------[0.011838361821067867, 0.9205639]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 457us/sample - loss: 0.0076 - acc: 0.9625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 77us/sample - loss: 0.0029 - acc: 0.9812\n",
      "6030/6030 [==============================] - 0s 28us/sample - loss: 0.0119 - acc: 0.9204\n",
      "--------------[0.011936044530822566, 0.920398]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 460us/sample - loss: 0.0134 - acc: 0.9125\n",
      "6030/6030 [==============================] - 0s 34us/sample - loss: 0.0119 - acc: 0.9204\n",
      "--------------[0.011936044530822566, 0.920398]\n"
     ]
    }
   ],
   "source": [
    "pass# ASSIMILATION - Cache-Momentum\n",
    "updates_cache = None\n",
    "assim_epochs = 2\n",
    "coeff = 0.5\n",
    "first_exc_locs = []\n",
    "cur_weights = init_weights\n",
    "eval_hist6 = [eval_weights(cur_weights)]\n",
    "for i in range(len(y_train_list)):\n",
    "    print(\"fit on others\".format(0, i))\n",
    "    target_model = get_model()\n",
    "    target_model.set_weights(cur_weights)\n",
    "    compile_model(target_model)\n",
    "    prev_weights = copy.deepcopy(target_model.get_weights())\n",
    "    target_model.fit(x_train_list[i], y_train_list[i], epochs=1, shuffle=True)\n",
    "    new_updates = copy.deepcopy(updates(prev_weights, target_model.get_weights()))\n",
    "\n",
    "    if i != 0 and i % 2 == 1:\n",
    "        target_model.fit(x_target, y_target, epochs=1, shuffle=True)\n",
    "        agg_updates = add_weights_by_ratio(new_updates, updates_cache, 0.5 + 0.02 * (i%20))\n",
    "        new_model_weights = add_weights(target_model.get_weights(), agg_updates) \n",
    "        target_model = get_model()\n",
    "        target_model.set_weights(new_model_weights)\n",
    "        compile_model(target_model)          \n",
    "        hist = target_model.evaluate(x_test, y_test)\n",
    "        # update model\n",
    "        cur_weights = copy.deepcopy(target_model.get_weights())\n",
    "        updates_cache = None\n",
    "        \n",
    "    else:\n",
    "        updates_cache = avg_weights(updates_cache, new_updates)\n",
    "        # don't do any updates to our model..\n",
    "        target_model = get_model()\n",
    "        target_model.set_weights(cur_weights)\n",
    "        compile_model(target_model)\n",
    "        hist = target_model.evaluate(x_test, y_test)\n",
    "    # distribution changing points\n",
    "    print(\"--------------{}\".format(hist))\n",
    "    eval_hist6.append(copy.deepcopy(hist))\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400/2400 [==============================] - 0s 37us/sample - loss: 0.0136 - acc: 0.9075\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 375us/sample - loss: 0.0174 - acc: 0.8813\n",
      "2400/2400 [==============================] - 0s 43us/sample - loss: 0.0136 - acc: 0.9075\n",
      "------num0--------[0.013570347133403023, 0.9075]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 392us/sample - loss: 0.0161 - acc: 0.8813\n",
      "2400/2400 [==============================] - 0s 32us/sample - loss: 0.0136 - acc: 0.9075\n",
      "------num1--------[0.013570347133403023, 0.9075]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 435us/sample - loss: 0.0200 - acc: 0.8750\n",
      "2400/2400 [==============================] - 0s 36us/sample - loss: 0.0136 - acc: 0.9075\n",
      "------num2--------[0.013570347133403023, 0.9075]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 423us/sample - loss: 0.0158 - acc: 0.8938\n",
      "2400/2400 [==============================] - 0s 40us/sample - loss: 0.0136 - acc: 0.9075\n",
      "------num3--------[0.013570347133403023, 0.9075]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 379us/sample - loss: 0.0189 - acc: 0.8625\n",
      "2400/2400 [==============================] - 0s 26us/sample - loss: 0.0136 - acc: 0.9075\n",
      "------num4--------[0.013570347133403023, 0.9075]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 448us/sample - loss: 0.0220 - acc: 0.8500\n",
      "2400/2400 [==============================] - 0s 35us/sample - loss: 0.0136 - acc: 0.9075\n",
      "------num5--------[0.013570347133403023, 0.9075]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 407us/sample - loss: 0.0165 - acc: 0.8875\n",
      "2400/2400 [==============================] - 0s 36us/sample - loss: 0.0136 - acc: 0.9075\n",
      "------num6--------[0.013570347133403023, 0.9075]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 452us/sample - loss: 0.0122 - acc: 0.9187\n",
      "2400/2400 [==============================] - 0s 44us/sample - loss: 0.0136 - acc: 0.9075\n",
      "------num7--------[0.013570347133403023, 0.9075]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 449us/sample - loss: 0.0201 - acc: 0.8625\n",
      "2400/2400 [==============================] - 0s 41us/sample - loss: 0.0136 - acc: 0.9075\n",
      "------num8--------[0.013570347133403023, 0.9075]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 422us/sample - loss: 0.0206 - acc: 0.8750\n",
      "2400/2400 [==============================] - 0s 37us/sample - loss: 0.0136 - acc: 0.9075\n",
      "------num9--------[0.013570347133403023, 0.9075]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 278us/sample - loss: 0.0161 - acc: 0.8938\n",
      "------num10--------[0.013570347133403023, 0.9075]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 464us/sample - loss: 0.0184 - acc: 0.8938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 73us/sample - loss: 0.0153 - acc: 0.8938\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 72us/sample - loss: 0.1044 - acc: 0.4437\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 64us/sample - loss: 0.0134 - acc: 0.9125\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 70us/sample - loss: 0.1032 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 35us/sample - loss: 0.0155 - acc: 0.9000\n",
      "------num11--------[0.015490095329781373, 0.9]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 422us/sample - loss: 0.0171 - acc: 0.8625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 70us/sample - loss: 0.1046 - acc: 0.4437\n",
      "2400/2400 [==============================] - 0s 39us/sample - loss: 0.0158 - acc: 0.8971\n",
      "------num12--------[0.01580908801096181, 0.89708334]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 425us/sample - loss: 0.0079 - acc: 0.9438\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 86us/sample - loss: 0.1019 - acc: 0.4313\n",
      "2400/2400 [==============================] - 0s 39us/sample - loss: 0.0222 - acc: 0.8554\n",
      "------num13--------[0.02218165680145224, 0.85541666]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 393us/sample - loss: 0.0111 - acc: 0.9187\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 52us/sample - loss: 0.1004 - acc: 0.4125\n",
      "2400/2400 [==============================] - 0s 36us/sample - loss: 0.0267 - acc: 0.8304\n",
      "------num14--------[0.02671309797714154, 0.8304167]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 427us/sample - loss: 0.0116 - acc: 0.9250\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 81us/sample - loss: 0.1008 - acc: 0.3938\n",
      "2400/2400 [==============================] - 0s 42us/sample - loss: 0.0300 - acc: 0.8092\n",
      "------num15--------[0.0300212736800313, 0.80916667]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 382us/sample - loss: 0.0075 - acc: 0.9500\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.1003 - acc: 0.3938\n",
      "2400/2400 [==============================] - 0s 37us/sample - loss: 0.0358 - acc: 0.7725\n",
      "------num16--------[0.03577263168990612, 0.7725]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 436us/sample - loss: 0.0057 - acc: 0.9563\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 70us/sample - loss: 0.1005 - acc: 0.3750\n",
      "2400/2400 [==============================] - 0s 36us/sample - loss: 0.0330 - acc: 0.7933\n",
      "------num17--------[0.03296315272649129, 0.79333335]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 393us/sample - loss: 0.0058 - acc: 0.9750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 52us/sample - loss: 0.0994 - acc: 0.3938\n",
      "2400/2400 [==============================] - 0s 37us/sample - loss: 0.0369 - acc: 0.7729\n",
      "------num18--------[0.03685397756596406, 0.7729167]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 411us/sample - loss: 0.0062 - acc: 0.9625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 76us/sample - loss: 0.0992 - acc: 0.3812\n",
      "2400/2400 [==============================] - 0s 36us/sample - loss: 0.0369 - acc: 0.7729\n",
      "------num19--------[0.03689718532065551, 0.7729167]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 396us/sample - loss: 0.0579 - acc: 0.6500\n",
      "2400/2400 [==============================] - 0s 38us/sample - loss: 0.0369 - acc: 0.7729\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 409us/sample - loss: 0.0990 - acc: 0.4000\n",
      "2400/2400 [==============================] - 0s 41us/sample - loss: 0.0169 - acc: 0.8950\n",
      "------num20--------[0.016922848982115588, 0.895]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 399us/sample - loss: 0.0315 - acc: 0.7875\n",
      "2400/2400 [==============================] - 0s 23us/sample - loss: 0.0169 - acc: 0.8950\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 467us/sample - loss: 0.0994 - acc: 0.4313\n",
      "2400/2400 [==============================] - 0s 42us/sample - loss: 0.0143 - acc: 0.9050\n",
      "------num21--------[0.014307429076482853, 0.905]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 413us/sample - loss: 0.0070 - acc: 0.9688\n",
      "2400/2400 [==============================] - 0s 36us/sample - loss: 0.0143 - acc: 0.9050\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 404us/sample - loss: 0.1015 - acc: 0.4000\n",
      "2400/2400 [==============================] - 0s 34us/sample - loss: 0.0153 - acc: 0.9038\n",
      "------num22--------[0.01526322568456332, 0.90375]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 430us/sample - loss: 0.0065 - acc: 0.9625\n",
      "2400/2400 [==============================] - 0s 33us/sample - loss: 0.0153 - acc: 0.9038\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 443us/sample - loss: 0.1010 - acc: 0.4062\n",
      "2400/2400 [==============================] - 0s 43us/sample - loss: 0.0167 - acc: 0.8933\n",
      "------num23--------[0.016742996200919152, 0.8933333]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 400us/sample - loss: 0.0060 - acc: 0.9688\n",
      "2400/2400 [==============================] - 0s 33us/sample - loss: 0.0167 - acc: 0.8933\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 283us/sample - loss: 0.1004 - acc: 0.4000\n",
      "2400/2400 [==============================] - 0s 44us/sample - loss: 0.0175 - acc: 0.8883\n",
      "------num24--------[0.017481978852301835, 0.8883333]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 387us/sample - loss: 0.0093 - acc: 0.9312\n",
      "2400/2400 [==============================] - 0s 43us/sample - loss: 0.0175 - acc: 0.8883\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 410us/sample - loss: 0.0992 - acc: 0.4000\n",
      "2400/2400 [==============================] - 0s 40us/sample - loss: 0.0219 - acc: 0.8633\n",
      "------num25--------[0.021926632380733887, 0.86333334]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 386us/sample - loss: 0.0040 - acc: 0.9812\n",
      "2400/2400 [==============================] - 0s 39us/sample - loss: 0.0219 - acc: 0.8633\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 401us/sample - loss: 0.0985 - acc: 0.4062\n",
      "2400/2400 [==============================] - 0s 40us/sample - loss: 0.0199 - acc: 0.8767\n",
      "------num26--------[0.019883167737474044, 0.87666667]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 398us/sample - loss: 0.0051 - acc: 0.9688\n",
      "2400/2400 [==============================] - 0s 37us/sample - loss: 0.0199 - acc: 0.8767\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 503us/sample - loss: 0.0970 - acc: 0.4125\n",
      "2400/2400 [==============================] - 0s 27us/sample - loss: 0.0196 - acc: 0.8800\n",
      "------num27--------[0.01961960212637981, 0.88]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 379us/sample - loss: 0.0042 - acc: 0.9625\n",
      "2400/2400 [==============================] - 0s 35us/sample - loss: 0.0196 - acc: 0.8800\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 413us/sample - loss: 0.0964 - acc: 0.4125\n",
      "2400/2400 [==============================] - 0s 42us/sample - loss: 0.0216 - acc: 0.8646\n",
      "------num28--------[0.02157843020434181, 0.8645833]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 389us/sample - loss: 0.0042 - acc: 0.9875\n",
      "2400/2400 [==============================] - 0s 36us/sample - loss: 0.0216 - acc: 0.8646\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 439us/sample - loss: 0.0961 - acc: 0.4187\n",
      "2400/2400 [==============================] - 0s 40us/sample - loss: 0.0221 - acc: 0.8583\n",
      "------num29--------[0.022127523372570675, 0.85833335]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 417us/sample - loss: 0.0046 - acc: 0.9625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 51us/sample - loss: 0.0960 - acc: 0.4125\n",
      "2400/2400 [==============================] - 0s 35us/sample - loss: 0.0232 - acc: 0.8533\n",
      "------num30--------[0.0232147639306883, 0.85333335]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 447us/sample - loss: 0.0030 - acc: 0.9875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 75us/sample - loss: 0.0958 - acc: 0.4187\n",
      "2400/2400 [==============================] - 0s 32us/sample - loss: 0.0250 - acc: 0.8371\n",
      "------num31--------[0.025020942774911722, 0.83708334]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 390us/sample - loss: 0.0048 - acc: 0.9812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 54us/sample - loss: 0.0962 - acc: 0.4125\n",
      "2400/2400 [==============================] - 0s 39us/sample - loss: 0.0271 - acc: 0.8233\n",
      "------num32--------[0.027116995590428513, 0.8233333]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 401us/sample - loss: 0.0040 - acc: 0.9812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 62us/sample - loss: 0.0955 - acc: 0.4062\n",
      "2400/2400 [==============================] - 0s 37us/sample - loss: 0.0267 - acc: 0.8258\n",
      "------num33--------[0.026663610724111397, 0.8258333]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 405us/sample - loss: 0.0024 - acc: 0.9875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0951 - acc: 0.4187\n",
      "2400/2400 [==============================] - 0s 34us/sample - loss: 0.0275 - acc: 0.8200\n",
      "------num34--------[0.02748656099041303, 0.82]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 397us/sample - loss: 0.0019 - acc: 0.9937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 76us/sample - loss: 0.0949 - acc: 0.4125\n",
      "2400/2400 [==============================] - 0s 38us/sample - loss: 0.0277 - acc: 0.8200\n",
      "------num35--------[0.027715633666763703, 0.82]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 411us/sample - loss: 0.0020 - acc: 0.9875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0946 - acc: 0.4125\n",
      "2400/2400 [==============================] - 0s 37us/sample - loss: 0.0294 - acc: 0.8092\n",
      "------num36--------[0.02938995070755482, 0.80916667]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 390us/sample - loss: 0.0041 - acc: 0.9750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 73us/sample - loss: 0.0944 - acc: 0.4187\n",
      "2400/2400 [==============================] - 0s 38us/sample - loss: 0.0306 - acc: 0.8017\n",
      "------num37--------[0.03060844528178374, 0.8016667]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 257us/sample - loss: 0.0027 - acc: 0.9750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0941 - acc: 0.4062\n",
      "2400/2400 [==============================] - 0s 33us/sample - loss: 0.0298 - acc: 0.8087\n",
      "------num38--------[0.02982079508403937, 0.80875]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 386us/sample - loss: 0.0024 - acc: 0.9812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 83us/sample - loss: 0.0939 - acc: 0.4250\n",
      "2400/2400 [==============================] - 0s 36us/sample - loss: 0.0342 - acc: 0.7800\n",
      "------num39--------[0.03418780455365777, 0.78]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 405us/sample - loss: 0.0038 - acc: 0.9750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 84us/sample - loss: 0.0940 - acc: 0.4187\n",
      "2400/2400 [==============================] - 0s 35us/sample - loss: 0.0316 - acc: 0.7967\n",
      "------num40--------[0.03163739530369639, 0.7966667]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 372us/sample - loss: 0.0033 - acc: 0.9750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 50us/sample - loss: 0.0937 - acc: 0.4187\n",
      "2400/2400 [==============================] - 0s 35us/sample - loss: 0.0357 - acc: 0.7742\n",
      "------num41--------[0.035651979061464466, 0.77416664]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 422us/sample - loss: 0.0041 - acc: 0.9688\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 91us/sample - loss: 0.0939 - acc: 0.4250\n",
      "2400/2400 [==============================] - 0s 40us/sample - loss: 0.0363 - acc: 0.7696\n",
      "------num42--------[0.036311909686774016, 0.76958334]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 432us/sample - loss: 0.0052 - acc: 0.9688\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 81us/sample - loss: 0.0938 - acc: 0.4125\n",
      "2400/2400 [==============================] - 0s 37us/sample - loss: 0.0367 - acc: 0.7704\n",
      "------num43--------[0.03665942954520385, 0.7704167]\n",
      "fit on others\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 291us/sample - loss: 0.0026 - acc: 0.9937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 76us/sample - loss: 0.0932 - acc: 0.4187\n",
      "2400/2400 [==============================] - 0s 35us/sample - loss: 0.0365 - acc: 0.7733\n",
      "------num44--------[0.03649586442237099, 0.7733333]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 363us/sample - loss: 0.0020 - acc: 0.9875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 70us/sample - loss: 0.0929 - acc: 0.4250\n",
      "2400/2400 [==============================] - 0s 36us/sample - loss: 0.0359 - acc: 0.7750\n",
      "------num45--------[0.0359066033984224, 0.775]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 358us/sample - loss: 0.0032 - acc: 0.9812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 49us/sample - loss: 0.0926 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 34us/sample - loss: 0.0375 - acc: 0.7663\n",
      "------num46--------[0.03751175856217742, 0.76625]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 417us/sample - loss: 0.0012 - acc: 0.9937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 75us/sample - loss: 0.0922 - acc: 0.4313\n",
      "2400/2400 [==============================] - 0s 39us/sample - loss: 0.0375 - acc: 0.7663\n",
      "------num47--------[0.037494826794912416, 0.76625]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 378us/sample - loss: 0.0018 - acc: 0.9875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 79us/sample - loss: 0.0923 - acc: 0.4313\n",
      "2400/2400 [==============================] - 0s 38us/sample - loss: 0.0392 - acc: 0.7583\n",
      "------num48--------[0.03921476407597462, 0.7583333]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 426us/sample - loss: 9.8893e-04 - acc: 1.0000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 50us/sample - loss: 0.0923 - acc: 0.4313\n",
      "2400/2400 [==============================] - 0s 37us/sample - loss: 0.0403 - acc: 0.7546\n",
      "------num49--------[0.040329165924340486, 0.75458336]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 388us/sample - loss: 0.0025 - acc: 0.9750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0920 - acc: 0.4313\n",
      "2400/2400 [==============================] - 0s 21us/sample - loss: 0.0388 - acc: 0.7629\n",
      "------num50--------[0.038776886432121196, 0.7629167]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 233us/sample - loss: 0.0084 - acc: 0.9375\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0915 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 20us/sample - loss: 0.0379 - acc: 0.7679\n",
      "------num51--------[0.037905443217605354, 0.7679167]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 191us/sample - loss: 0.0026 - acc: 0.9875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0913 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 23us/sample - loss: 0.0414 - acc: 0.7508\n",
      "------num52--------[0.04135252395644784, 0.75083333]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 200us/sample - loss: 0.0027 - acc: 0.9812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0917 - acc: 0.4313\n",
      "2400/2400 [==============================] - 0s 23us/sample - loss: 0.0425 - acc: 0.7442\n",
      "------num53--------[0.042475339584052564, 0.7441667]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 203us/sample - loss: 0.0030 - acc: 0.9812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 51us/sample - loss: 0.0913 - acc: 0.4313\n",
      "2400/2400 [==============================] - 0s 21us/sample - loss: 0.0414 - acc: 0.7492\n",
      "------num54--------[0.0413625545365115, 0.74916667]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 193us/sample - loss: 5.7196e-04 - acc: 1.0000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0910 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0415 - acc: 0.7479\n",
      "------num55--------[0.041529858292390906, 0.74791664]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 192us/sample - loss: 0.0052 - acc: 0.9625\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0911 - acc: 0.4313\n",
      "2400/2400 [==============================] - 0s 21us/sample - loss: 0.0444 - acc: 0.7367\n",
      "------num56--------[0.044430027231574055, 0.7366667]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 194us/sample - loss: 0.0017 - acc: 0.9875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0912 - acc: 0.4313\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0435 - acc: 0.7421\n",
      "------num57--------[0.0435374191403389, 0.7420833]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 191us/sample - loss: 0.0026 - acc: 0.9812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0907 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 21us/sample - loss: 0.0430 - acc: 0.7429\n",
      "------num58--------[0.0429558513003091, 0.74291664]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 196us/sample - loss: 0.0032 - acc: 0.9688\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 49us/sample - loss: 0.0907 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 23us/sample - loss: 0.0447 - acc: 0.7375\n",
      "------num59--------[0.04467338085795442, 0.7375]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 192us/sample - loss: 0.0030 - acc: 0.9875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0906 - acc: 0.4313\n",
      "2400/2400 [==============================] - 0s 21us/sample - loss: 0.0440 - acc: 0.7396\n",
      "------num60--------[0.043979550587634246, 0.7395833]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 190us/sample - loss: 0.0012 - acc: 0.9937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0904 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 21us/sample - loss: 0.0461 - acc: 0.7333\n",
      "------num61--------[0.046122252829372885, 0.73333335]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 191us/sample - loss: 0.0024 - acc: 0.9875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0904 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0453 - acc: 0.7350\n",
      "------num62--------[0.045349047370255, 0.735]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 189us/sample - loss: 4.6941e-04 - acc: 1.0000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 38us/sample - loss: 0.0900 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 21us/sample - loss: 0.0453 - acc: 0.7346\n",
      "------num63--------[0.045313203868766624, 0.7345833]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 191us/sample - loss: 0.0013 - acc: 0.9937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0899 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0456 - acc: 0.7354\n",
      "------num64--------[0.045550048239529135, 0.73541665]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 190us/sample - loss: 0.0022 - acc: 0.9875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0898 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 21us/sample - loss: 0.0473 - acc: 0.7292\n",
      "------num65--------[0.04727221641689539, 0.7291667]\n",
      "fit on others\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 197us/sample - loss: 2.6964e-04 - acc: 1.0000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0900 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0472 - acc: 0.7300\n",
      "------num66--------[0.047181856110692026, 0.73]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 193us/sample - loss: 5.0019e-04 - acc: 1.0000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0895 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 20us/sample - loss: 0.0473 - acc: 0.7275\n",
      "------num67--------[0.04732973987236619, 0.7275]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 191us/sample - loss: 0.0020 - acc: 0.9937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0894 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 20us/sample - loss: 0.0472 - acc: 0.7283\n",
      "------num68--------[0.04715506726875901, 0.72833335]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 195us/sample - loss: 0.0026 - acc: 0.9750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0894 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 23us/sample - loss: 0.0488 - acc: 0.7221\n",
      "------num69--------[0.04883513312786818, 0.72208333]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 200us/sample - loss: 7.2315e-04 - acc: 1.0000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0894 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 24us/sample - loss: 0.0495 - acc: 0.7183\n",
      "------num70--------[0.0494634659960866, 0.7183333]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 195us/sample - loss: 9.9155e-04 - acc: 0.9937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0891 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0480 - acc: 0.7246\n",
      "------num71--------[0.048035430243859686, 0.7245833]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 191us/sample - loss: 5.3098e-04 - acc: 1.0000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 38us/sample - loss: 0.0888 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 20us/sample - loss: 0.0491 - acc: 0.7179\n",
      "------num72--------[0.049072078466415404, 0.71791667]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 192us/sample - loss: 0.0022 - acc: 0.9812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0888 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0493 - acc: 0.7183\n",
      "------num73--------[0.04926584046334028, 0.7183333]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 190us/sample - loss: 8.3748e-04 - acc: 1.0000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0887 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0497 - acc: 0.7150\n",
      "------num74--------[0.04970002637555202, 0.715]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 188us/sample - loss: 0.0047 - acc: 0.9688\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0888 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 21us/sample - loss: 0.0497 - acc: 0.7154\n",
      "------num75--------[0.04966171979904175, 0.71541667]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 236us/sample - loss: 0.0029 - acc: 0.9812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 50us/sample - loss: 0.0885 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0500 - acc: 0.7133\n",
      "------num76--------[0.05000582453484337, 0.7133333]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 195us/sample - loss: 0.0044 - acc: 0.9688\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0884 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 21us/sample - loss: 0.0518 - acc: 0.7075\n",
      "------num77--------[0.05176883372167746, 0.7075]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 190us/sample - loss: 0.0017 - acc: 0.9875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0882 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0496 - acc: 0.7171\n",
      "------num78--------[0.04958349597329895, 0.71708333]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 191us/sample - loss: 0.0013 - acc: 0.9937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0881 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 23us/sample - loss: 0.0503 - acc: 0.7125\n",
      "------num79--------[0.05028350050871571, 0.7125]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 199us/sample - loss: 0.0036 - acc: 0.9812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 47us/sample - loss: 0.0879 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 23us/sample - loss: 0.0503 - acc: 0.7133\n",
      "------num80--------[0.050270668665568036, 0.7133333]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 196us/sample - loss: 0.0017 - acc: 0.9875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0877 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0508 - acc: 0.7121\n",
      "------num81--------[0.05079343595852454, 0.71208334]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 196us/sample - loss: 0.0016 - acc: 0.9937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0876 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 23us/sample - loss: 0.0508 - acc: 0.7121\n",
      "------num82--------[0.050840870539347334, 0.71208334]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 221us/sample - loss: 0.0020 - acc: 0.9875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0876 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 23us/sample - loss: 0.0501 - acc: 0.7196\n",
      "------num83--------[0.05005055178577701, 0.71958333]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 187us/sample - loss: 0.0028 - acc: 0.9875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0874 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0522 - acc: 0.7058\n",
      "------num84--------[0.05218531814093391, 0.7058333]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 189us/sample - loss: 0.0025 - acc: 0.9812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 49us/sample - loss: 0.0874 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 23us/sample - loss: 0.0518 - acc: 0.7088\n",
      "------num85--------[0.05182154448702932, 0.70875]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 190us/sample - loss: 0.0012 - acc: 0.9937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0873 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 21us/sample - loss: 0.0522 - acc: 0.7067\n",
      "------num86--------[0.052204698137938974, 0.70666665]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 196us/sample - loss: 0.0019 - acc: 0.9812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0870 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0517 - acc: 0.7088\n",
      "------num87--------[0.05173557352895538, 0.70875]\n",
      "fit on others\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 192us/sample - loss: 7.6443e-04 - acc: 1.0000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0870 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 21us/sample - loss: 0.0523 - acc: 0.7050\n",
      "------num88--------[0.0522917465865612, 0.705]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 198us/sample - loss: 0.0026 - acc: 0.9812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0869 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 21us/sample - loss: 0.0532 - acc: 0.7017\n",
      "------num89--------[0.05321451480189959, 0.70166665]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 195us/sample - loss: 0.0021 - acc: 0.9812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 46us/sample - loss: 0.0870 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 23us/sample - loss: 0.0546 - acc: 0.6938\n",
      "------num90--------[0.05458850727106134, 0.69375]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 196us/sample - loss: 9.5691e-04 - acc: 0.9937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0869 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 21us/sample - loss: 0.0544 - acc: 0.6963\n",
      "------num91--------[0.05437991147860885, 0.69625]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 190us/sample - loss: 0.0014 - acc: 0.9937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0870 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 23us/sample - loss: 0.0536 - acc: 0.7008\n",
      "------num92--------[0.05363043088465929, 0.7008333]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 196us/sample - loss: 0.0036 - acc: 0.9750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0861 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 21us/sample - loss: 0.0522 - acc: 0.7104\n",
      "------num93--------[0.05218695389727752, 0.7104167]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 202us/sample - loss: 0.0036 - acc: 0.9812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0861 - acc: 0.4437\n",
      "2400/2400 [==============================] - 0s 23us/sample - loss: 0.0543 - acc: 0.6992\n",
      "------num94--------[0.054254120606929065, 0.69916666]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 190us/sample - loss: 0.0020 - acc: 0.9812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0866 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0551 - acc: 0.6950\n",
      "------num95--------[0.05508709645519654, 0.695]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 185us/sample - loss: 0.0012 - acc: 0.9937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0860 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 21us/sample - loss: 0.0551 - acc: 0.6946\n",
      "------num96--------[0.05513649464895328, 0.69458336]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 192us/sample - loss: 0.0033 - acc: 0.9750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0857 - acc: 0.4437\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0538 - acc: 0.7042\n",
      "------num97--------[0.05376413853218158, 0.70416665]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 187us/sample - loss: 0.0030 - acc: 0.9750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 35us/sample - loss: 0.0857 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0564 - acc: 0.6862\n",
      "------num98--------[0.05643928237259388, 0.68625]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 199us/sample - loss: 0.0030 - acc: 0.9812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 48us/sample - loss: 0.0856 - acc: 0.4437\n",
      "2400/2400 [==============================] - 0s 23us/sample - loss: 0.0548 - acc: 0.6979\n",
      "------num99--------[0.05482823399826884, 0.6979167]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 203us/sample - loss: 8.8250e-04 - acc: 0.9937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0849 - acc: 0.4437\n",
      "2400/2400 [==============================] - 0s 23us/sample - loss: 0.0546 - acc: 0.6979\n",
      "------num100--------[0.05456934190665682, 0.6979167]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 211us/sample - loss: 0.0014 - acc: 0.9875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 38us/sample - loss: 0.0846 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 23us/sample - loss: 0.0556 - acc: 0.6913\n",
      "------num101--------[0.055629831987122694, 0.69125]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 245us/sample - loss: 0.0025 - acc: 0.9875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 47us/sample - loss: 0.0844 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 21us/sample - loss: 0.0561 - acc: 0.6879\n",
      "------num102--------[0.05607325641438365, 0.6879167]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 198us/sample - loss: 0.0016 - acc: 0.9812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0840 - acc: 0.4375\n",
      "2400/2400 [==============================] - 0s 21us/sample - loss: 0.0562 - acc: 0.6858\n",
      "------num103--------[0.05618803907806675, 0.68583333]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 194us/sample - loss: 0.0012 - acc: 0.9937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 53us/sample - loss: 0.0833 - acc: 0.4437\n",
      "2400/2400 [==============================] - 0s 21us/sample - loss: 0.0566 - acc: 0.6842\n",
      "------num104--------[0.05664899628609419, 0.68416667]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 197us/sample - loss: 0.0017 - acc: 0.9937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0826 - acc: 0.4500\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0561 - acc: 0.6900\n",
      "------num105--------[0.056087306942790745, 0.69]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 192us/sample - loss: 0.0018 - acc: 0.9875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 41us/sample - loss: 0.0811 - acc: 0.4625\n",
      "2400/2400 [==============================] - 0s 23us/sample - loss: 0.0580 - acc: 0.6712\n",
      "------num106--------[0.05802967419847846, 0.67125]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 195us/sample - loss: 0.0015 - acc: 0.9937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0799 - acc: 0.4625\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0599 - acc: 0.6533\n",
      "------num107--------[0.05992375652616223, 0.6533333]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 194us/sample - loss: 0.0027 - acc: 0.9875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0780 - acc: 0.4688\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0594 - acc: 0.6538\n",
      "------num108--------[0.05940697737038136, 0.65375]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 188us/sample - loss: 6.1236e-04 - acc: 1.0000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0758 - acc: 0.4875\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0620 - acc: 0.6288\n",
      "------num109--------[0.062044446213791765, 0.62875]\n",
      "fit on others\n",
      "Train on 160 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 190us/sample - loss: 0.0014 - acc: 0.9937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 40us/sample - loss: 0.0741 - acc: 0.5125\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0635 - acc: 0.6075\n",
      "------num110--------[0.06345232750599583, 0.6075]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 201us/sample - loss: 0.0016 - acc: 0.9875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 51us/sample - loss: 0.0724 - acc: 0.5125\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0629 - acc: 0.6075\n",
      "------num111--------[0.06288091106340289, 0.6075]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 197us/sample - loss: 0.0021 - acc: 0.9812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 44us/sample - loss: 0.0714 - acc: 0.5250\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0630 - acc: 0.6050\n",
      "------num112--------[0.06301678366338213, 0.605]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 192us/sample - loss: 0.0028 - acc: 0.9812\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 45us/sample - loss: 0.0712 - acc: 0.5250\n",
      "2400/2400 [==============================] - 0s 20us/sample - loss: 0.0660 - acc: 0.5833\n",
      "------num113--------[0.06603163332988818, 0.5833333]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 188us/sample - loss: 0.0012 - acc: 1.0000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0709 - acc: 0.5437\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0649 - acc: 0.5913\n",
      "------num114--------[0.06486402243375779, 0.59125]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 196us/sample - loss: 0.0017 - acc: 0.9875\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0702 - acc: 0.5250\n",
      "2400/2400 [==============================] - 0s 21us/sample - loss: 0.0644 - acc: 0.5954\n",
      "------num115--------[0.06444222047924995, 0.59541667]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 200us/sample - loss: 0.0031 - acc: 0.9750\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0698 - acc: 0.5312\n",
      "2400/2400 [==============================] - 0s 23us/sample - loss: 0.0657 - acc: 0.5850\n",
      "------num116--------[0.06572119979187846, 0.585]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 213us/sample - loss: 3.2070e-04 - acc: 1.0000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 42us/sample - loss: 0.0698 - acc: 0.5375\n",
      "2400/2400 [==============================] - 0s 21us/sample - loss: 0.0652 - acc: 0.5917\n",
      "------num117--------[0.06523490893964966, 0.59166664]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 215us/sample - loss: 0.0026 - acc: 0.9937\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 43us/sample - loss: 0.0692 - acc: 0.5250\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0669 - acc: 0.5788\n",
      "------num118--------[0.06689932913829882, 0.57875]\n",
      "fit on others\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 196us/sample - loss: 4.7267e-04 - acc: 1.0000\n",
      "Train on 160 samples\n",
      "160/160 [==============================] - 0s 37us/sample - loss: 0.0691 - acc: 0.5375\n",
      "2400/2400 [==============================] - 0s 22us/sample - loss: 0.0667 - acc: 0.5796\n",
      "------num119--------[0.06666036132723092, 0.57958335]\n"
     ]
    }
   ],
   "source": [
    "# ASSIMILATION - Test\n",
    "updates_cache_2to3 = None\n",
    "assim_epochs = 2\n",
    "coeff = 0.5\n",
    "first_exc_locs = []\n",
    "cur_weights = init_weights\n",
    "eval_hist7 = [eval_weights(cur_weights)]\n",
    "for i in range(len(y_train_list)):\n",
    "    print(\"fit on others\".format(0, i))\n",
    "    target_model = get_model()\n",
    "    target_model.set_weights(cur_weights)\n",
    "    compile_model(target_model)\n",
    "    prev_weights = copy.deepcopy(target_model.get_weights())\n",
    "    target_model.fit(x_train_list[i], y_train_list[i], epochs=1, shuffle=True)\n",
    "    new_updates = copy.deepcopy(updates(prev_weights, target_model.get_weights()))\n",
    "    if i < 10 or (20 <= i and i < 30):\n",
    "        updates_cache_2to3 = avg_weights(updates_cache_2to3, new_updates)\n",
    "        # don't do any updates to our model..\n",
    "        target_model = get_model()\n",
    "        target_model.set_weights(cur_weights)\n",
    "        compile_model(target_model)\n",
    "        hist = target_model.evaluate(x_test, y_test)\n",
    "    if i == 11:\n",
    "        target_model.fit(x_train_list[i], y_train_list[i], epochs=1, shuffle=True)\n",
    "        target_model.fit(x_target, y_target, epochs=1, shuffle=True)\n",
    "        target_model.fit(x_train_list[i], y_train_list[i], epochs=1, shuffle=True)\n",
    "        target_model.fit(x_target, y_target, epochs=1, shuffle=True)\n",
    "        hist = target_model.evaluate(x_test, y_test)\n",
    "    if i > 11:\n",
    "        target_model.fit(x_target, y_target, epochs=1, shuffle=True)\n",
    "        agg_updates = add_weights(new_updates, updates_cache_2to3)\n",
    "        new_model_weights = add_weights(target_model.get_weights(), agg_updates) \n",
    "        target_model = get_model()\n",
    "        target_model.set_weights(new_model_weights)\n",
    "        compile_model(target_model)          \n",
    "        hist = target_model.evaluate(x_test, y_test)\n",
    "        cur_weights = copy.deepcopy(target_model.get_weights())\n",
    "    print(\"------num{}--------{}\".format(i, hist))\n",
    "    eval_hist7.append(copy.deepcopy(hist))\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updates(prev_weights, new_weights):\n",
    "    updates = []\n",
    "    for i in range(len(prev_weights)):\n",
    "        updates.append(new_weights[i] - prev_weights[i])\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weights(w1, w2):\n",
    "    res = []\n",
    "    for i in range(len(w1)):\n",
    "        res.append(w1[i] + w2[i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weights_by_ratio(w1, w2, w1_ratio):\n",
    "    res = []\n",
    "    for i in range(len(w1)):\n",
    "        res.append(w1_ratio*w1[i] + (1-w1_ratio)*w2[i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0125 - acc: 0.9120\n",
      "avg between 0 and 1\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0075 - acc: 0.9508\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 92us/sample - loss: 0.0063 - acc: 0.9580\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0058 - acc: 0.9640\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0054 - acc: 0.9680\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0050 - acc: 0.9700\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0046 - acc: 0.9740\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0041 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 56us/sample - loss: 0.0032 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 51us/sample - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 68us/sample - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 69us/sample - loss: 0.0016 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0070 - acc: 0.9536\n",
      "[0.007037430424289778, 0.9536]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 95us/sample - loss: 0.0052 - acc: 0.9700\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0048 - acc: 0.9700\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 44us/sample - loss: 0.0044 - acc: 0.9800\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 43us/sample - loss: 0.0042 - acc: 0.9800\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0040 - acc: 0.9800\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0031 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 55us/sample - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 61us/sample - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 55us/sample - loss: 0.0011 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0068 - acc: 0.9564\n",
      "[0.006771102832991164, 0.9564]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 92us/sample - loss: 0.0045 - acc: 0.9760\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0041 - acc: 0.9800\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0039 - acc: 0.9800\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0037 - acc: 0.9800\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0036 - acc: 0.9820\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 54us/sample - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 51us/sample - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 66us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 65us/sample - loss: 9.2166e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0066 - acc: 0.9580\n",
      "[0.00659137652964564, 0.958]\n",
      "avg between 0 and 2\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0070 - acc: 0.9552\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 103us/sample - loss: 0.0076 - acc: 0.9520\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0072 - acc: 0.9600\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 43us/sample - loss: 0.0068 - acc: 0.9600\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0065 - acc: 0.9620\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0062 - acc: 0.9620\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0050 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 57us/sample - loss: 0.0040 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 58us/sample - loss: 0.0032 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 68us/sample - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 0.0019 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0067 - acc: 0.9568\n",
      "[0.006749342624703422, 0.9568]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 93us/sample - loss: 0.0068 - acc: 0.9600\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0064 - acc: 0.9600\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0062 - acc: 0.9640\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0059 - acc: 0.9640\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0057 - acc: 0.9660\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0036 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 64us/sample - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 68us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 63us/sample - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 62us/sample - loss: 0.0014 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0066 - acc: 0.9584\n",
      "[0.006557803131802939, 0.9584]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 92us/sample - loss: 0.0061 - acc: 0.9640\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0059 - acc: 0.9660\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 43us/sample - loss: 0.0057 - acc: 0.9660\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0054 - acc: 0.9700\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0053 - acc: 0.9680\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 64us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 67us/sample - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 64us/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 65us/sample - loss: 0.0011 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0064 - acc: 0.9592\n",
      "[0.006418859629437793, 0.9592]\n",
      "avg between 0 and 3\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0068 - acc: 0.9560\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 104us/sample - loss: 0.0049 - acc: 0.9640\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0044 - acc: 0.9680\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0040 - acc: 0.9760\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0037 - acc: 0.9780\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0035 - acc: 0.9800\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0050 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 54us/sample - loss: 0.0042 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 74us/sample - loss: 0.0033 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 62us/sample - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 68us/sample - loss: 0.0021 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0066 - acc: 0.9580\n",
      "[0.006632311210029002, 0.958]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 93us/sample - loss: 0.0040 - acc: 0.9780\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0037 - acc: 0.9780\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 43us/sample - loss: 0.0034 - acc: 0.9820\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 44us/sample - loss: 0.0032 - acc: 0.9840\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0031 - acc: 0.9860\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0037 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 0.0029 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 64us/sample - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 82us/sample - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 70us/sample - loss: 0.0015 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0065 - acc: 0.9588\n",
      "[0.0064984069274898505, 0.9588]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 91us/sample - loss: 0.0035 - acc: 0.9800\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0032 - acc: 0.9840\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0030 - acc: 0.9860\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0029 - acc: 0.9880\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0028 - acc: 0.9880\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 54us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 70us/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 75us/sample - loss: 0.0011 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0064 - acc: 0.9592\n",
      "[0.006382002238916175, 0.9592]\n",
      "avg between 0 and 4\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0067 - acc: 0.9564\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 94us/sample - loss: 0.0067 - acc: 0.9560\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 45us/sample - loss: 0.0065 - acc: 0.9560\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0063 - acc: 0.9600\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0060 - acc: 0.9640\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0059 - acc: 0.9640\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 51us/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 8.8149e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 54us/sample - loss: 7.6263e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0066 - acc: 0.9560\n",
      "[0.0066219530902744735, 0.956]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 95us/sample - loss: 0.0062 - acc: 0.9600\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 43us/sample - loss: 0.0059 - acc: 0.9640\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0058 - acc: 0.9640\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 43us/sample - loss: 0.0056 - acc: 0.9680\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 43us/sample - loss: 0.0054 - acc: 0.9680\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 8.6451e-04 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 65us/sample - loss: 7.3443e-04 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 61us/sample - loss: 6.3789e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 5.6394e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 70us/sample - loss: 5.0573e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0065 - acc: 0.9580\n",
      "[0.006525888448924525, 0.958]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 88us/sample - loss: 0.0057 - acc: 0.9640\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0055 - acc: 0.9680\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0053 - acc: 0.9700\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0051 - acc: 0.9700\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0050 - acc: 0.9720\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 5.9988e-04 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 5.2768e-04 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 61us/sample - loss: 4.7316e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 58us/sample - loss: 4.2917e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 69us/sample - loss: 3.9301e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0064 - acc: 0.9576\n",
      "[0.006423539851812529, 0.9576]\n",
      "avg between 0 and 5\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0068 - acc: 0.9560\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 96us/sample - loss: 0.0066 - acc: 0.9600\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0063 - acc: 0.9660\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0062 - acc: 0.9660\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0060 - acc: 0.9680\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0059 - acc: 0.9680\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0050 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 76us/sample - loss: 0.0040 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 58us/sample - loss: 0.0032 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 69us/sample - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 56us/sample - loss: 0.0019 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0067 - acc: 0.9556\n",
      "[0.006668601034427411, 0.9556]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 94us/sample - loss: 0.0062 - acc: 0.9640\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0060 - acc: 0.9680\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0058 - acc: 0.9680\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 43us/sample - loss: 0.0057 - acc: 0.9680\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0056 - acc: 0.9720\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0035 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 56us/sample - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 55us/sample - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 67us/sample - loss: 0.0013 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0065 - acc: 0.9576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.006541065305451048, 0.9576]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 93us/sample - loss: 0.0058 - acc: 0.9680\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0057 - acc: 0.9680\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0055 - acc: 0.9700\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0054 - acc: 0.9700\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0053 - acc: 0.9740\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 65us/sample - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 72us/sample - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 69us/sample - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 58us/sample - loss: 0.0010 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0064 - acc: 0.9584\n",
      "[0.006435600538749714, 0.9584]\n",
      "avg between 0 and 6\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0067 - acc: 0.9576\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 94us/sample - loss: 0.0057 - acc: 0.9720\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 43us/sample - loss: 0.0055 - acc: 0.9720\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0053 - acc: 0.9720\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 47us/sample - loss: 0.0052 - acc: 0.9720\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 45us/sample - loss: 0.0050 - acc: 0.9740\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 5.4959e-04 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 73us/sample - loss: 4.9984e-04 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 4.5855e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 44us/sample - loss: 4.2378e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 3.9412e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0066 - acc: 0.9588\n",
      "[0.0065867999394977235, 0.9588]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 94us/sample - loss: 0.0053 - acc: 0.9720\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0051 - acc: 0.9740\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0050 - acc: 0.9740\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0049 - acc: 0.9740\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0048 - acc: 0.9740\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 3.0718e-04 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 53us/sample - loss: 2.9230e-04 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 60us/sample - loss: 2.7888e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 65us/sample - loss: 2.6672e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 62us/sample - loss: 2.5565e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0064 - acc: 0.9608\n",
      "[0.006441818540473468, 0.9608]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 110us/sample - loss: 0.0050 - acc: 0.9740\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0048 - acc: 0.9740\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0047 - acc: 0.9760\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0046 - acc: 0.9760\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 43us/sample - loss: 0.0046 - acc: 0.9760\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 2.2927e-04 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 48us/sample - loss: 2.2141e-04 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 47us/sample - loss: 2.1411e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 2.0733e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 63us/sample - loss: 2.0101e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0064 - acc: 0.9612\n",
      "[0.006355581199770677, 0.9612]\n",
      "avg between 0 and 7\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0071 - acc: 0.9528\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 94us/sample - loss: 0.0048 - acc: 0.9700\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0046 - acc: 0.9740\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0044 - acc: 0.9720\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0042 - acc: 0.9720\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0040 - acc: 0.9740\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0040 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 66us/sample - loss: 0.0032 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 58us/sample - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 78us/sample - loss: 0.0016 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0069 - acc: 0.9564\n",
      "[0.006896850753831677, 0.9564]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 94us/sample - loss: 0.0044 - acc: 0.9720\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 43us/sample - loss: 0.0042 - acc: 0.9740\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0040 - acc: 0.9740\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0038 - acc: 0.9760\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0037 - acc: 0.9780\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 55us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 67us/sample - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 60us/sample - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 62us/sample - loss: 0.0011 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0067 - acc: 0.9564\n",
      "[0.006718113236199133, 0.9564]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 91us/sample - loss: 0.0040 - acc: 0.9760\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0038 - acc: 0.9780\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0036 - acc: 0.9780\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 43us/sample - loss: 0.0035 - acc: 0.9800\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0034 - acc: 0.9820\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 58us/sample - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 62us/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 65us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 71us/sample - loss: 9.3725e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0066 - acc: 0.9572\n",
      "[0.006591406562555494, 0.9572]\n",
      "avg between 0 and 8\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0069 - acc: 0.9548\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 107us/sample - loss: 0.0063 - acc: 0.9620\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0060 - acc: 0.9600\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0058 - acc: 0.9640\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0056 - acc: 0.9700\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0054 - acc: 0.9700\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0049 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 67us/sample - loss: 0.0038 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 74us/sample - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 77us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 72us/sample - loss: 0.0017 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0065 - acc: 0.9568\n",
      "[0.006541117933462374, 0.9568]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 89us/sample - loss: 0.0058 - acc: 0.9660\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0055 - acc: 0.9700\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0053 - acc: 0.9720\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0051 - acc: 0.9700\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0050 - acc: 0.9720\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0030 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 64us/sample - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 69us/sample - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 85us/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 78us/sample - loss: 0.0011 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0063 - acc: 0.9580\n",
      "[0.0063251089054974724, 0.958]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 93us/sample - loss: 0.0053 - acc: 0.9700\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0051 - acc: 0.9700\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0049 - acc: 0.9720\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0047 - acc: 0.9720\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0046 - acc: 0.9720\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 63us/sample - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 66us/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 69us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 74us/sample - loss: 8.9637e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0062 - acc: 0.9600\n",
      "[0.006153968240990071, 0.96]\n",
      "avg between 0 and 9\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0067 - acc: 0.9580\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 92us/sample - loss: 0.0054 - acc: 0.9660\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0052 - acc: 0.9700\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0049 - acc: 0.9720\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0048 - acc: 0.9720\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0046 - acc: 0.9720\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 63us/sample - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 63us/sample - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 58us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 68us/sample - loss: 9.6265e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 24us/sample - loss: 0.0065 - acc: 0.9568\n",
      "[0.006515544825897087, 0.9568]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 92us/sample - loss: 0.0049 - acc: 0.9720\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0047 - acc: 0.9720\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0045 - acc: 0.9720\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0044 - acc: 0.9720\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0042 - acc: 0.9740\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 45us/sample - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 55us/sample - loss: 8.7988e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 47us/sample - loss: 7.7414e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 47us/sample - loss: 6.9066e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0064 - acc: 0.9576\n",
      "[0.006380255919546471, 0.9576]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 91us/sample - loss: 0.0044 - acc: 0.9740\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 43us/sample - loss: 0.0043 - acc: 0.9760\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0041 - acc: 0.9780\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0040 - acc: 0.9800\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0039 - acc: 0.9800\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 9.2935e-04 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 64us/sample - loss: 8.0680e-04 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 70us/sample - loss: 7.1221e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 72us/sample - loss: 6.3722e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 65us/sample - loss: 5.7634e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0063 - acc: 0.9588\n",
      "[0.006290081111756445, 0.9588]\n",
      "avg between 0 and 10\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0070 - acc: 0.9568\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 91us/sample - loss: 0.0067 - acc: 0.9560\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0064 - acc: 0.9560\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 44us/sample - loss: 0.0061 - acc: 0.9600\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0059 - acc: 0.9620\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0056 - acc: 0.9660\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 63us/sample - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 57us/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 56us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 51us/sample - loss: 9.2076e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0068 - acc: 0.9572\n",
      "[0.006783994392864406, 0.9572]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 94us/sample - loss: 0.0060 - acc: 0.9600\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0057 - acc: 0.9620\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0055 - acc: 0.9660\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0052 - acc: 0.9700\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0050 - acc: 0.9700\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 83us/sample - loss: 8.8240e-04 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 80us/sample - loss: 7.7155e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 79us/sample - loss: 6.8503e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 70us/sample - loss: 6.1577e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0066 - acc: 0.9572\n",
      "[0.006626598456851207, 0.9572]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 92us/sample - loss: 0.0054 - acc: 0.9660\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0051 - acc: 0.9700\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0049 - acc: 0.9700\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0047 - acc: 0.9700\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0046 - acc: 0.9740\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 6.7629e-04 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 63us/sample - loss: 6.0764e-04 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 81us/sample - loss: 5.5175e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 69us/sample - loss: 5.0543e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 78us/sample - loss: 4.6646e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0065 - acc: 0.9568\n",
      "[0.006476036992669106, 0.9568]\n",
      "avg between 0 and 11\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0071 - acc: 0.9540\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 94us/sample - loss: 0.0063 - acc: 0.9600\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0061 - acc: 0.9600\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0058 - acc: 0.9640\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 35us/sample - loss: 0.0057 - acc: 0.9660\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0055 - acc: 0.9720\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0036 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 76us/sample - loss: 0.0029 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 78us/sample - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 66us/sample - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 55us/sample - loss: 0.0015 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0069 - acc: 0.9564\n",
      "[0.006866620459733531, 0.9564]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 91us/sample - loss: 0.0058 - acc: 0.9680\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0056 - acc: 0.9700\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0054 - acc: 0.9720\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0052 - acc: 0.9720\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 48us/sample - loss: 0.0051 - acc: 0.9720\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 74us/sample - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 65us/sample - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 63us/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 68us/sample - loss: 0.0011 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0067 - acc: 0.9564\n",
      "[0.006712788759850082, 0.9564]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 91us/sample - loss: 0.0053 - acc: 0.9700\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0051 - acc: 0.9720\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0050 - acc: 0.9720\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0048 - acc: 0.9740\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0047 - acc: 0.9740\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 58us/sample - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 63us/sample - loss: 9.9636e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 62us/sample - loss: 8.6222e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 25us/sample - loss: 0.0066 - acc: 0.9572\n",
      "[0.006579056647667312, 0.9572]\n",
      "avg between 0 and 12\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0070 - acc: 0.9564\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 92us/sample - loss: 0.0070 - acc: 0.9660\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0068 - acc: 0.9660\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0066 - acc: 0.9660\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0065 - acc: 0.9660\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0063 - acc: 0.9660\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0034 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 47us/sample - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 46us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 72us/sample - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 63us/sample - loss: 0.0014 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0068 - acc: 0.9580\n",
      "[0.00676798428260663, 0.958]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 85us/sample - loss: 0.0065 - acc: 0.9660\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0064 - acc: 0.9660\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0062 - acc: 0.9660\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0061 - acc: 0.9660\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 44us/sample - loss: 0.0059 - acc: 0.9660\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 66us/sample - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 71us/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 71us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 69us/sample - loss: 9.0996e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 24us/sample - loss: 0.0066 - acc: 0.9584\n",
      "[0.006582788776417147, 0.9584]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 92us/sample - loss: 0.0062 - acc: 0.9660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0060 - acc: 0.9660\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0059 - acc: 0.9680\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0058 - acc: 0.9680\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 43us/sample - loss: 0.0056 - acc: 0.9680\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 51us/sample - loss: 9.0842e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 61us/sample - loss: 7.8808e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 78us/sample - loss: 6.9495e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0064 - acc: 0.9592\n",
      "[0.006436397360567935, 0.9592]\n",
      "avg between 0 and 13\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0070 - acc: 0.9552\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 95us/sample - loss: 0.0059 - acc: 0.9640\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0056 - acc: 0.9660\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0054 - acc: 0.9660\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0052 - acc: 0.9700\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0050 - acc: 0.9700\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0044 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 66us/sample - loss: 0.0034 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 63us/sample - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 67us/sample - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 64us/sample - loss: 0.0015 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0067 - acc: 0.9568\n",
      "[0.006684073755974532, 0.9568]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 89us/sample - loss: 0.0053 - acc: 0.9660\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0051 - acc: 0.9680\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0050 - acc: 0.9680\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0048 - acc: 0.9700\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0047 - acc: 0.9720\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 51us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 61us/sample - loss: 8.9604e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0065 - acc: 0.9592\n",
      "[0.0065038802236900665, 0.9592]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 95us/sample - loss: 0.0049 - acc: 0.9700\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 43us/sample - loss: 0.0047 - acc: 0.9720\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0046 - acc: 0.9740\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0044 - acc: 0.9760\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0043 - acc: 0.9760\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 54us/sample - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 58us/sample - loss: 9.4950e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 80us/sample - loss: 7.7381e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 57us/sample - loss: 6.5189e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0064 - acc: 0.9596\n",
      "[0.006361453903978691, 0.9596]\n",
      "avg between 0 and 14\n",
      "2500/2500 [==============================] - 0s 25us/sample - loss: 0.0070 - acc: 0.9560\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 95us/sample - loss: 0.0058 - acc: 0.9680\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0056 - acc: 0.9680\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 43us/sample - loss: 0.0054 - acc: 0.9700\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0052 - acc: 0.9720\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0051 - acc: 0.9740\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 57us/sample - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 73us/sample - loss: 8.5667e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 7.4424e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 85us/sample - loss: 6.5796e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0068 - acc: 0.9568\n",
      "[0.006832697641816049, 0.9568]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 96us/sample - loss: 0.0053 - acc: 0.9720\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 43us/sample - loss: 0.0052 - acc: 0.9740\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0050 - acc: 0.9740\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0049 - acc: 0.9760\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0048 - acc: 0.9760\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 7.8394e-04 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 6.8656e-04 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 53us/sample - loss: 6.1079e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 71us/sample - loss: 5.5024e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 82us/sample - loss: 5.0030e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0067 - acc: 0.9568\n",
      "[0.00672509433010564, 0.9568]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 91us/sample - loss: 0.0050 - acc: 0.9740\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0048 - acc: 0.9780\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0047 - acc: 0.9780\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0046 - acc: 0.9780\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 45us/sample - loss: 0.0045 - acc: 0.9780\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 6.6771e-04 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 44us/sample - loss: 5.9544e-04 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 58us/sample - loss: 5.3727e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 4.8944e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 67us/sample - loss: 4.4943e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0066 - acc: 0.9576\n",
      "[0.0066338917489920275, 0.9576]\n",
      "avg between 0 and 15\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0067 - acc: 0.9568\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 103us/sample - loss: 0.0061 - acc: 0.9640\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0059 - acc: 0.9640\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0056 - acc: 0.9660\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0055 - acc: 0.9680\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0053 - acc: 0.9700\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0045 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 68us/sample - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 56us/sample - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 55us/sample - loss: 0.0016 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0065 - acc: 0.9580\n",
      "[0.00652618865603581, 0.958]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 91us/sample - loss: 0.0057 - acc: 0.9680\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0054 - acc: 0.9720\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0053 - acc: 0.9720\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0051 - acc: 0.9740\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0050 - acc: 0.9740\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 64us/sample - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 85us/sample - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 62us/sample - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 68us/sample - loss: 0.0012 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0064 - acc: 0.9592\n",
      "[0.006373906400043052, 0.9592]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 90us/sample - loss: 0.0053 - acc: 0.9720\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0051 - acc: 0.9740\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 45us/sample - loss: 0.0050 - acc: 0.9760\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0048 - acc: 0.9760\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0047 - acc: 0.9780\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 56us/sample - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 54us/sample - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 66us/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 78us/sample - loss: 0.0011 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0062 - acc: 0.9592\n",
      "[0.00624948797734105, 0.9592]\n",
      "avg between 0 and 16\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0068 - acc: 0.9560\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 88us/sample - loss: 0.0059 - acc: 0.9640\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0057 - acc: 0.9660\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0055 - acc: 0.9660\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0054 - acc: 0.9680\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0053 - acc: 0.9680\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0042 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 48us/sample - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 61us/sample - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 65us/sample - loss: 0.0015 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0066 - acc: 0.9592\n",
      "[0.006602592621542862, 0.9592]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 89us/sample - loss: 0.0055 - acc: 0.9640\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0053 - acc: 0.9680\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0052 - acc: 0.9680\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0051 - acc: 0.9720\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0049 - acc: 0.9720\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 45us/sample - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 43us/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 57us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 48us/sample - loss: 9.4927e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0065 - acc: 0.9604\n",
      "[0.00646725901493337, 0.9604]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 91us/sample - loss: 0.0051 - acc: 0.9680\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0050 - acc: 0.9720\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0049 - acc: 0.9720\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0048 - acc: 0.9740\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0047 - acc: 0.9740\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 51us/sample - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 9.9034e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 57us/sample - loss: 8.5698e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 46us/sample - loss: 7.5547e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0064 - acc: 0.9596\n",
      "[0.006365655606050859, 0.9596]\n",
      "avg between 0 and 17\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0066 - acc: 0.9572\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 96us/sample - loss: 0.0079 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0074 - acc: 0.9560\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0070 - acc: 0.9600\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0066 - acc: 0.9620\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0064 - acc: 0.9640\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0033 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 55us/sample - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 63us/sample - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 64us/sample - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 57us/sample - loss: 0.0013 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0064 - acc: 0.9576\n",
      "[0.006353634034021525, 0.9576]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 96us/sample - loss: 0.0069 - acc: 0.9580\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0066 - acc: 0.9620\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0063 - acc: 0.9640\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0060 - acc: 0.9640\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0058 - acc: 0.9660\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 48us/sample - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 60us/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 61us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 46us/sample - loss: 9.0771e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0062 - acc: 0.9576\n",
      "[0.006211570351436967, 0.9576]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 89us/sample - loss: 0.0062 - acc: 0.9640\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0060 - acc: 0.9640\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0058 - acc: 0.9660\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0056 - acc: 0.9660\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0055 - acc: 0.9660\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 73us/sample - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 58us/sample - loss: 8.7766e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 66us/sample - loss: 7.6110e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0061 - acc: 0.9592\n",
      "[0.006101974468657863, 0.9592]\n",
      "avg between 0 and 18\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0066 - acc: 0.9576\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 93us/sample - loss: 0.0050 - acc: 0.9620\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0047 - acc: 0.9640\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0045 - acc: 0.9680\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0042 - acc: 0.9760\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 43us/sample - loss: 0.0040 - acc: 0.9760\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0034 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 69us/sample - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 71us/sample - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 70us/sample - loss: 0.0014 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0065 - acc: 0.9580\n",
      "[0.00645070542061585, 0.958]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 101us/sample - loss: 0.0043 - acc: 0.9680\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0041 - acc: 0.9740\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0039 - acc: 0.9780\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0037 - acc: 0.9800\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0035 - acc: 0.9820\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 67us/sample - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 55us/sample - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 67us/sample - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 71us/sample - loss: 0.0011 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0063 - acc: 0.9592\n",
      "[0.0063146498562651684, 0.9592]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 92us/sample - loss: 0.0039 - acc: 0.9780\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0037 - acc: 0.9800\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0035 - acc: 0.9820\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0033 - acc: 0.9840\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0032 - acc: 0.9840\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 56us/sample - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 65us/sample - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 61us/sample - loss: 8.8826e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0062 - acc: 0.9612\n",
      "[0.00620429210899747, 0.9612]\n",
      "avg between 0 and 19\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0066 - acc: 0.9568\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 95us/sample - loss: 0.0067 - acc: 0.9600\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0065 - acc: 0.9640\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 45us/sample - loss: 0.0063 - acc: 0.9660\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0062 - acc: 0.9660\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0061 - acc: 0.9660\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 57us/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 58us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 74us/sample - loss: 9.1531e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 56us/sample - loss: 7.9517e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0064 - acc: 0.9580\n",
      "[0.006411169899790548, 0.958]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 94us/sample - loss: 0.0063 - acc: 0.9660\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0062 - acc: 0.9660\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0060 - acc: 0.9660\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0059 - acc: 0.9680\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0058 - acc: 0.9700\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 9.1080e-04 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 62us/sample - loss: 7.8582e-04 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 70us/sample - loss: 6.9054e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 71us/sample - loss: 6.1568e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 61us/sample - loss: 5.5547e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0063 - acc: 0.9588\n",
      "[0.006276612473354907, 0.9588]\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 91us/sample - loss: 0.0060 - acc: 0.9660\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0059 - acc: 0.9660\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0058 - acc: 0.9700\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0057 - acc: 0.9720\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0056 - acc: 0.9720\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 6.8461e-04 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 70us/sample - loss: 6.1016e-04 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 64us/sample - loss: 5.5028e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 44us/sample - loss: 5.0113e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 56us/sample - loss: 4.6019e-04 - acc: 1.0000\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0062 - acc: 0.9600\n",
      "[0.0061732404185197085, 0.96]\n"
     ]
    }
   ],
   "source": [
    "# run FR\n",
    "FR_NUM = 3\n",
    "first_exc_locs = []\n",
    "cur_weights = model_weights_list[0]\n",
    "eval_hist = [eval_weights(cur_weights)]\n",
    "for i in range(1, len(model_weights_list)):\n",
    "    print(\"avg between {} and {}\".format(0, i))\n",
    "    agg_weights = avg_weights(cur_weights, model_weights_list[i])\n",
    "    first_exc_locs.append(len(eval_hist) + 1)\n",
    "    eval_hist.append(eval_weights(agg_weights))\n",
    "    for j in range(FR_NUM):\n",
    "        agg_weights = run_fr(agg_weights, 0, i)\n",
    "        hist = eval_weights(agg_weights)\n",
    "        print(hist)\n",
    "        eval_hist.append(copy.deepcopy(hist))\n",
    "\n",
    "    cur_weights = copy.deepcopy(agg_weights)\n",
    "#     weights_hist.append(copy.deepcopy(agg_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 24us/sample - loss: 0.0205 - acc: 0.8615\n",
      "avg between 0 and 1\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 57us/sample - loss: 0.0050 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 70us/sample - loss: 0.0039 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 71us/sample - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 84us/sample - loss: 0.0023 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 100us/sample - loss: 0.0121 - acc: 0.9200\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0103 - acc: 0.9320\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 44us/sample - loss: 0.0095 - acc: 0.9380\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 44us/sample - loss: 0.0086 - acc: 0.9440\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0080 - acc: 0.9480\n",
      "2000/2000 [==============================] - 0s 24us/sample - loss: 0.0263 - acc: 0.8320\n",
      "[0.02632456935942173, 0.832]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0062 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 63us/sample - loss: 0.0050 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 77us/sample - loss: 0.0039 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 68us/sample - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 74us/sample - loss: 0.0023 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 94us/sample - loss: 0.0121 - acc: 0.9200\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0103 - acc: 0.9340\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0093 - acc: 0.9380\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0086 - acc: 0.9440\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0079 - acc: 0.9480\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0264 - acc: 0.8320\n",
      "[0.026386716581881048, 0.832]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0062 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 44us/sample - loss: 0.0050 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 53us/sample - loss: 0.0039 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 56us/sample - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 54us/sample - loss: 0.0023 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 109us/sample - loss: 0.0121 - acc: 0.9200\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0103 - acc: 0.9360\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0094 - acc: 0.9380\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0086 - acc: 0.9440\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0079 - acc: 0.9480\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0265 - acc: 0.8320\n",
      "[0.026466679230332375, 0.832]\n",
      "avg between 0 and 2\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0059 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 0.0050 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 0.0041 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 61us/sample - loss: 0.0033 - acc: 0.9500\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 65us/sample - loss: 0.0027 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 96us/sample - loss: 0.0102 - acc: 0.9340\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0096 - acc: 0.9360\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0090 - acc: 0.9380\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0084 - acc: 0.9460\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0079 - acc: 0.9480\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0304 - acc: 0.7985\n",
      "[0.03037838103622198, 0.7985]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0059 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 62us/sample - loss: 0.0050 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 69us/sample - loss: 0.0041 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 61us/sample - loss: 0.0033 - acc: 0.9500\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 71us/sample - loss: 0.0027 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 94us/sample - loss: 0.0102 - acc: 0.9300\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0096 - acc: 0.9360\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0090 - acc: 0.9420\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0084 - acc: 0.9440\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0079 - acc: 0.9520\n",
      "2000/2000 [==============================] - 0s 21us/sample - loss: 0.0304 - acc: 0.7995\n",
      "[0.030358977995812893, 0.7995]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 65us/sample - loss: 0.0050 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 58us/sample - loss: 0.0041 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 60us/sample - loss: 0.0033 - acc: 0.9500\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 0.0027 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 97us/sample - loss: 0.0102 - acc: 0.9360\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0096 - acc: 0.9360\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0089 - acc: 0.9440\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0084 - acc: 0.9460\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0079 - acc: 0.9500\n",
      "2000/2000 [==============================] - 0s 23us/sample - loss: 0.0303 - acc: 0.8000\n",
      "[0.03027739191800356, 0.8]\n",
      "avg between 0 and 3\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0057 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 60us/sample - loss: 0.0050 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 63us/sample - loss: 0.0042 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 71us/sample - loss: 0.0035 - acc: 0.9500\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 74us/sample - loss: 0.0029 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 94us/sample - loss: 0.0074 - acc: 0.9440\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0066 - acc: 0.9480\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0059 - acc: 0.9560\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0053 - acc: 0.9600\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0049 - acc: 0.9660\n",
      "2000/2000 [==============================] - 0s 21us/sample - loss: 0.0322 - acc: 0.7820\n",
      "[0.032227830611169336, 0.782]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0057 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 76us/sample - loss: 0.0050 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 65us/sample - loss: 0.0042 - acc: 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 69us/sample - loss: 0.0035 - acc: 0.9500\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 54us/sample - loss: 0.0029 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 96us/sample - loss: 0.0074 - acc: 0.9460\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0066 - acc: 0.9480\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0059 - acc: 0.9560\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0053 - acc: 0.9600\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0048 - acc: 0.9600\n",
      "2000/2000 [==============================] - 0s 23us/sample - loss: 0.0322 - acc: 0.7815\n",
      "[0.032237358555197715, 0.7815]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0057 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 51us/sample - loss: 0.0050 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 60us/sample - loss: 0.0042 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 55us/sample - loss: 0.0035 - acc: 0.9500\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 60us/sample - loss: 0.0029 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 90us/sample - loss: 0.0074 - acc: 0.9460\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0066 - acc: 0.9480\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0060 - acc: 0.9540\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0054 - acc: 0.9580\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0049 - acc: 0.9640\n",
      "2000/2000 [==============================] - 0s 21us/sample - loss: 0.0322 - acc: 0.7825\n",
      "[0.03218913687765598, 0.7825]\n",
      "avg between 0 and 4\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 74us/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 73us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 61us/sample - loss: 9.1647e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 61us/sample - loss: 8.0004e-04 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 99us/sample - loss: 0.0088 - acc: 0.9380\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0081 - acc: 0.9440\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 34us/sample - loss: 0.0076 - acc: 0.9420\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 45us/sample - loss: 0.0070 - acc: 0.9520\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 43us/sample - loss: 0.0065 - acc: 0.9560\n",
      "2000/2000 [==============================] - 0s 23us/sample - loss: 0.0308 - acc: 0.8020\n",
      "[0.03082183538377285, 0.802]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 57us/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 57us/sample - loss: 9.1647e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 66us/sample - loss: 8.0004e-04 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 110us/sample - loss: 0.0088 - acc: 0.9360\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0081 - acc: 0.9440\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0075 - acc: 0.9460\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0069 - acc: 0.9540\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0064 - acc: 0.9600\n",
      "2000/2000 [==============================] - 0s 23us/sample - loss: 0.0309 - acc: 0.8010\n",
      "[0.030916996613144874, 0.801]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 58us/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 46us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 60us/sample - loss: 9.1647e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 8.0004e-04 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 94us/sample - loss: 0.0089 - acc: 0.9360\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0081 - acc: 0.9440\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0075 - acc: 0.9440\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0069 - acc: 0.9540\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0065 - acc: 0.9560\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0309 - acc: 0.8020\n",
      "[0.03092030657082796, 0.802]\n",
      "avg between 0 and 5\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0064 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 0.0056 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 70us/sample - loss: 0.0048 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 65us/sample - loss: 0.0040 - acc: 0.9500\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 55us/sample - loss: 0.0032 - acc: 0.9500\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 93us/sample - loss: 0.0082 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0078 - acc: 0.9540\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0074 - acc: 0.9580\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0071 - acc: 0.9620\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0069 - acc: 0.9620\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0310 - acc: 0.7970\n",
      "[0.03103071840852499, 0.797]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0064 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 66us/sample - loss: 0.0056 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 67us/sample - loss: 0.0048 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 75us/sample - loss: 0.0040 - acc: 0.9500\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 71us/sample - loss: 0.0032 - acc: 0.9500\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 93us/sample - loss: 0.0083 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0078 - acc: 0.9540\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0074 - acc: 0.9580\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0071 - acc: 0.9600\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0069 - acc: 0.9600\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0310 - acc: 0.7970\n",
      "[0.031039475955069066, 0.797]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0064 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 53us/sample - loss: 0.0056 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 65us/sample - loss: 0.0048 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 71us/sample - loss: 0.0040 - acc: 0.9500\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 0.0032 - acc: 0.9500\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 102us/sample - loss: 0.0082 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0078 - acc: 0.9540\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0074 - acc: 0.9580\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 35us/sample - loss: 0.0071 - acc: 0.9600\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0068 - acc: 0.9620\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0309 - acc: 0.7970\n",
      "[0.03091345577687025, 0.797]\n",
      "avg between 0 and 6\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 4.0665e-04 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 60us/sample - loss: 3.8103e-04 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 3.5859e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 80us/sample - loss: 3.3879e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 56us/sample - loss: 3.2135e-04 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 92us/sample - loss: 0.0068 - acc: 0.9620\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0063 - acc: 0.9640\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0060 - acc: 0.9640\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0058 - acc: 0.9660\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0056 - acc: 0.9680\n",
      "2000/2000 [==============================] - 0s 21us/sample - loss: 0.0322 - acc: 0.7880\n",
      "[0.032156713768839836, 0.788]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 4.0665e-04 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 3.8103e-04 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 3.5859e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 47us/sample - loss: 3.3879e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 48us/sample - loss: 3.2135e-04 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 95us/sample - loss: 0.0067 - acc: 0.9580\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0064 - acc: 0.9640\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0060 - acc: 0.9640\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0058 - acc: 0.9660\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0056 - acc: 0.9720\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0322 - acc: 0.7885\n",
      "[0.03216028749942779, 0.7885]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 4.0665e-04 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 68us/sample - loss: 3.8103e-04 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 68us/sample - loss: 3.5859e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 70us/sample - loss: 3.3879e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 3.2135e-04 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 95us/sample - loss: 0.0068 - acc: 0.9600\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0063 - acc: 0.9640\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0061 - acc: 0.9640\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0058 - acc: 0.9680\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0056 - acc: 0.9720\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0322 - acc: 0.7885\n",
      "[0.032183184131979944, 0.7885]\n",
      "avg between 0 and 7\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0060 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 54us/sample - loss: 0.0051 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 47us/sample - loss: 0.0043 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 67us/sample - loss: 0.0035 - acc: 0.9500\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 64us/sample - loss: 0.0028 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 95us/sample - loss: 0.0058 - acc: 0.9580\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0053 - acc: 0.9680\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0050 - acc: 0.9720\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0048 - acc: 0.9720\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0046 - acc: 0.9740\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0304 - acc: 0.7955\n",
      "[0.03035676520317793, 0.7955]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0060 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 55us/sample - loss: 0.0051 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 48us/sample - loss: 0.0043 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 65us/sample - loss: 0.0035 - acc: 0.9500\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 68us/sample - loss: 0.0028 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 95us/sample - loss: 0.0059 - acc: 0.9580\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 43us/sample - loss: 0.0054 - acc: 0.9660\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 43us/sample - loss: 0.0050 - acc: 0.9720\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0048 - acc: 0.9720\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0046 - acc: 0.9740\n",
      "2000/2000 [==============================] - 0s 23us/sample - loss: 0.0304 - acc: 0.7960\n",
      "[0.030383170299232005, 0.796]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0060 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 62us/sample - loss: 0.0051 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 63us/sample - loss: 0.0043 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 62us/sample - loss: 0.0035 - acc: 0.9500\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 70us/sample - loss: 0.0028 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 101us/sample - loss: 0.0059 - acc: 0.9600\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0054 - acc: 0.9680\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0050 - acc: 0.9720\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0048 - acc: 0.9740\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0046 - acc: 0.9740\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0304 - acc: 0.7960\n",
      "[0.03037447366118431, 0.796]\n",
      "avg between 0 and 8\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0060 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 68us/sample - loss: 0.0049 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 68us/sample - loss: 0.0038 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 82us/sample - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 124us/sample - loss: 0.0022 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 100us/sample - loss: 0.0073 - acc: 0.9480\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0069 - acc: 0.9540\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0065 - acc: 0.9560\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0061 - acc: 0.9600\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0058 - acc: 0.9640\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0304 - acc: 0.7975\n",
      "[0.030408539280295372, 0.7975]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0060 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 0.0049 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 60us/sample - loss: 0.0038 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 70us/sample - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 55us/sample - loss: 0.0022 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 96us/sample - loss: 0.0074 - acc: 0.9460\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0069 - acc: 0.9520\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0065 - acc: 0.9540\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0061 - acc: 0.9620\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0058 - acc: 0.9620\n",
      "2000/2000 [==============================] - 0s 24us/sample - loss: 0.0303 - acc: 0.7970\n",
      "[0.03034329704940319, 0.797]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0060 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 61us/sample - loss: 0.0049 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 60us/sample - loss: 0.0038 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 69us/sample - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 0.0022 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 96us/sample - loss: 0.0073 - acc: 0.9480\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0069 - acc: 0.9540\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0065 - acc: 0.9540\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0061 - acc: 0.9620\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0058 - acc: 0.9640\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0303 - acc: 0.7970\n",
      "[0.03033983089029789, 0.797]\n",
      "avg between 0 and 9\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 58us/sample - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 62us/sample - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 61us/sample - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 65us/sample - loss: 0.0010 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 95us/sample - loss: 0.0071 - acc: 0.9460\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0064 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0060 - acc: 0.9560\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0056 - acc: 0.9600\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0054 - acc: 0.9640\n",
      "2000/2000 [==============================] - 0s 21us/sample - loss: 0.0310 - acc: 0.7950\n",
      "[0.03102793451398611, 0.795]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 54us/sample - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 61us/sample - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 58us/sample - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 54us/sample - loss: 0.0010 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 103us/sample - loss: 0.0071 - acc: 0.9420\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0064 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0060 - acc: 0.9580\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0056 - acc: 0.9620\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0054 - acc: 0.9640\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0310 - acc: 0.7955\n",
      "[0.030991284295916556, 0.7955]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 58us/sample - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 63us/sample - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 66us/sample - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 55us/sample - loss: 0.0010 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 91us/sample - loss: 0.0071 - acc: 0.9440\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0064 - acc: 0.9540\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0060 - acc: 0.9580\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0057 - acc: 0.9580\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0053 - acc: 0.9680\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0310 - acc: 0.7960\n",
      "[0.031004569709300996, 0.796]\n",
      "avg between 0 and 10\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 57us/sample - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 43us/sample - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 57us/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 69us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 94us/sample - loss: 0.0083 - acc: 0.9460\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0080 - acc: 0.9460\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0077 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0074 - acc: 0.9500\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0071 - acc: 0.9520\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0279 - acc: 0.8155\n",
      "[0.027916589021682738, 0.8155]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 67us/sample - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 53us/sample - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 62us/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 54us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 98us/sample - loss: 0.0083 - acc: 0.9460\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0080 - acc: 0.9460\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 44us/sample - loss: 0.0078 - acc: 0.9480\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0074 - acc: 0.9500\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0071 - acc: 0.9520\n",
      "2000/2000 [==============================] - 0s 23us/sample - loss: 0.0279 - acc: 0.8150\n",
      "[0.027938700951635836, 0.815]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 55us/sample - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 66us/sample - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 69us/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 69us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 94us/sample - loss: 0.0083 - acc: 0.9460\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0080 - acc: 0.9460\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0077 - acc: 0.9520\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 33us/sample - loss: 0.0074 - acc: 0.9520\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0071 - acc: 0.9520\n",
      "2000/2000 [==============================] - 0s 21us/sample - loss: 0.0280 - acc: 0.8155\n",
      "[0.0279998374953866, 0.8155]\n",
      "avg between 0 and 11\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0048 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 0.0041 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 47us/sample - loss: 0.0034 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 53us/sample - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 72us/sample - loss: 0.0023 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 95us/sample - loss: 0.0078 - acc: 0.9480\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0071 - acc: 0.9560\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0067 - acc: 0.9560\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 44us/sample - loss: 0.0064 - acc: 0.9580\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0061 - acc: 0.9580\n",
      "2000/2000 [==============================] - 0s 23us/sample - loss: 0.0298 - acc: 0.8005\n",
      "[0.02977269198000431, 0.8005]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0048 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 72us/sample - loss: 0.0041 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 82us/sample - loss: 0.0034 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 69us/sample - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 75us/sample - loss: 0.0023 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 94us/sample - loss: 0.0078 - acc: 0.9480\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0072 - acc: 0.9540\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0067 - acc: 0.9560\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0064 - acc: 0.9560\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0061 - acc: 0.9600\n",
      "2000/2000 [==============================] - 0s 23us/sample - loss: 0.0297 - acc: 0.8015\n",
      "[0.02974615781009197, 0.8015]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0048 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 56us/sample - loss: 0.0041 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 0.0034 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 71us/sample - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 0.0023 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 92us/sample - loss: 0.0078 - acc: 0.9460\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0072 - acc: 0.9520\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0067 - acc: 0.9560\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0064 - acc: 0.9560\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0061 - acc: 0.9580\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0297 - acc: 0.8005\n",
      "[0.02974960821866989, 0.8005]\n",
      "avg between 0 and 12\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0042 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 53us/sample - loss: 0.0033 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 51us/sample - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 61us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 62us/sample - loss: 0.0017 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 93us/sample - loss: 0.0079 - acc: 0.9560\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0075 - acc: 0.9620\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0073 - acc: 0.9620\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0071 - acc: 0.9600\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0069 - acc: 0.9620\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0303 - acc: 0.8010\n",
      "[0.03032937726378441, 0.801]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0042 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 67us/sample - loss: 0.0033 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 76us/sample - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 63us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 56us/sample - loss: 0.0017 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 101us/sample - loss: 0.0079 - acc: 0.9540\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0075 - acc: 0.9580\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0073 - acc: 0.9580\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0071 - acc: 0.9620\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0069 - acc: 0.9640\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0303 - acc: 0.8015\n",
      "[0.030339247554540635, 0.8015]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0042 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 58us/sample - loss: 0.0033 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 69us/sample - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 68us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 70us/sample - loss: 0.0017 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 97us/sample - loss: 0.0079 - acc: 0.9580\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0075 - acc: 0.9580\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0073 - acc: 0.9620\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0071 - acc: 0.9620\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0069 - acc: 0.9640\n",
      "2000/2000 [==============================] - 0s 23us/sample - loss: 0.0303 - acc: 0.8010\n",
      "[0.030344144605100154, 0.801]\n",
      "avg between 0 and 13\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0057 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 66us/sample - loss: 0.0047 - acc: 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 56us/sample - loss: 0.0037 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 71us/sample - loss: 0.0028 - acc: 0.9500\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 63us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 95us/sample - loss: 0.0075 - acc: 0.9480\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0070 - acc: 0.9540\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0067 - acc: 0.9540\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0064 - acc: 0.9560\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0061 - acc: 0.9600\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0315 - acc: 0.7935\n",
      "[0.03151591530442238, 0.7935]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0057 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 55us/sample - loss: 0.0047 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 57us/sample - loss: 0.0037 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 88us/sample - loss: 0.0028 - acc: 0.9500\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 61us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 91us/sample - loss: 0.0075 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0070 - acc: 0.9540\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0066 - acc: 0.9560\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0064 - acc: 0.9580\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0061 - acc: 0.9600\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0315 - acc: 0.7930\n",
      "[0.03152862799167633, 0.793]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 56us/sample - loss: 0.0047 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 75us/sample - loss: 0.0037 - acc: 0.9500\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 69us/sample - loss: 0.0028 - acc: 0.9500\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 57us/sample - loss: 0.0021 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 106us/sample - loss: 0.0075 - acc: 0.9480\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0070 - acc: 0.9540\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0067 - acc: 0.9560\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0063 - acc: 0.9580\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0061 - acc: 0.9580\n",
      "2000/2000 [==============================] - 0s 20us/sample - loss: 0.0315 - acc: 0.7925\n",
      "[0.03152738655358553, 0.7925]\n",
      "avg between 0 and 14\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 53us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 54us/sample - loss: 9.5665e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 65us/sample - loss: 8.3315e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 58us/sample - loss: 7.3751e-04 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 99us/sample - loss: 0.0066 - acc: 0.9580\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0063 - acc: 0.9640\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0060 - acc: 0.9640\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0058 - acc: 0.9660\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0056 - acc: 0.9680\n",
      "2000/2000 [==============================] - 0s 23us/sample - loss: 0.0298 - acc: 0.8080\n",
      "[0.02983746878057718, 0.808]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 55us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 54us/sample - loss: 9.5665e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 65us/sample - loss: 8.3315e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 7.3751e-04 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 95us/sample - loss: 0.0066 - acc: 0.9600\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0063 - acc: 0.9640\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0060 - acc: 0.9640\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0058 - acc: 0.9640\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0056 - acc: 0.9680\n",
      "2000/2000 [==============================] - 0s 23us/sample - loss: 0.0298 - acc: 0.8065\n",
      "[0.029837264075875284, 0.8065]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 9.5665e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 76us/sample - loss: 8.3315e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 62us/sample - loss: 7.3751e-04 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 94us/sample - loss: 0.0066 - acc: 0.9600\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0063 - acc: 0.9640\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0060 - acc: 0.9640\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0058 - acc: 0.9660\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 43us/sample - loss: 0.0055 - acc: 0.9700\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0299 - acc: 0.8065\n",
      "[0.02985175843536854, 0.8065]\n",
      "avg between 0 and 15\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0063 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 74us/sample - loss: 0.0047 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 62us/sample - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 64us/sample - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 57us/sample - loss: 0.0022 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 93us/sample - loss: 0.0080 - acc: 0.9440\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0073 - acc: 0.9540\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0068 - acc: 0.9600\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0065 - acc: 0.9580\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0062 - acc: 0.9620\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0311 - acc: 0.7950\n",
      "[0.03112352268397808, 0.795]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0063 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 55us/sample - loss: 0.0047 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 57us/sample - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 55us/sample - loss: 0.0022 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 96us/sample - loss: 0.0080 - acc: 0.9480\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 43us/sample - loss: 0.0073 - acc: 0.9540\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0068 - acc: 0.9580\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0065 - acc: 0.9600\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0062 - acc: 0.9620\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0310 - acc: 0.7975\n",
      "[0.031010425582528114, 0.7975]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0063 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 57us/sample - loss: 0.0047 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 47us/sample - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 54us/sample - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 63us/sample - loss: 0.0022 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 96us/sample - loss: 0.0080 - acc: 0.9480\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 35us/sample - loss: 0.0073 - acc: 0.9540\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0068 - acc: 0.9580\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0065 - acc: 0.9620\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0062 - acc: 0.9660\n",
      "2000/2000 [==============================] - 0s 21us/sample - loss: 0.0311 - acc: 0.7975\n",
      "[0.031078182451426982, 0.7975]\n",
      "avg between 0 and 16\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0050 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 79us/sample - loss: 0.0038 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 62us/sample - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 72us/sample - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 57us/sample - loss: 0.0017 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 90us/sample - loss: 0.0070 - acc: 0.9520\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0066 - acc: 0.9600\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0064 - acc: 0.9640\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 36us/sample - loss: 0.0062 - acc: 0.9640\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0060 - acc: 0.9640\n",
      "2000/2000 [==============================] - 0s 21us/sample - loss: 0.0305 - acc: 0.8005\n",
      "[0.030464138120412827, 0.8005]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0050 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 61us/sample - loss: 0.0038 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 44us/sample - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 66us/sample - loss: 0.0017 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 96us/sample - loss: 0.0069 - acc: 0.9540\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0066 - acc: 0.9580\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0064 - acc: 0.9600\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0062 - acc: 0.9640\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0060 - acc: 0.9660\n",
      "2000/2000 [==============================] - 0s 21us/sample - loss: 0.0305 - acc: 0.8000\n",
      "[0.03046402249485254, 0.8]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0050 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 90us/sample - loss: 0.0038 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 65us/sample - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 69us/sample - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 57us/sample - loss: 0.0017 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 96us/sample - loss: 0.0070 - acc: 0.9540\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0067 - acc: 0.9580\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0064 - acc: 0.9620\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0062 - acc: 0.9640\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 43us/sample - loss: 0.0060 - acc: 0.9640\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0304 - acc: 0.8010\n",
      "[0.030447037890553474, 0.801]\n",
      "avg between 0 and 17\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0043 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 44us/sample - loss: 0.0033 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 56us/sample - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 70us/sample - loss: 0.0016 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 95us/sample - loss: 0.0101 - acc: 0.9300\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0095 - acc: 0.9320\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0090 - acc: 0.9360\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0085 - acc: 0.9400\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0081 - acc: 0.9460\n",
      "2000/2000 [==============================] - 0s 23us/sample - loss: 0.0336 - acc: 0.7770\n",
      "[0.033562774926424024, 0.777]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0043 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 60us/sample - loss: 0.0033 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 57us/sample - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 57us/sample - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 63us/sample - loss: 0.0016 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 92us/sample - loss: 0.0101 - acc: 0.9280\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0095 - acc: 0.9320\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0090 - acc: 0.9340\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0085 - acc: 0.9400\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0080 - acc: 0.9480\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0336 - acc: 0.7765\n",
      "[0.0335961861461401, 0.7765]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0043 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 55us/sample - loss: 0.0033 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 56us/sample - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 55us/sample - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 70us/sample - loss: 0.0016 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 98us/sample - loss: 0.0101 - acc: 0.9280\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0095 - acc: 0.9320\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0090 - acc: 0.9360\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0084 - acc: 0.9400\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0080 - acc: 0.9440\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0337 - acc: 0.7755\n",
      "[0.033674749180674556, 0.7755]\n",
      "avg between 0 and 18\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0042 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 69us/sample - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 67us/sample - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 60us/sample - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 64us/sample - loss: 0.0018 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 95us/sample - loss: 0.0067 - acc: 0.9540\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 44us/sample - loss: 0.0061 - acc: 0.9560\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0056 - acc: 0.9560\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0053 - acc: 0.9620\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0049 - acc: 0.9620\n",
      "2000/2000 [==============================] - 0s 20us/sample - loss: 0.0325 - acc: 0.7845\n",
      "[0.032500337779521944, 0.7845]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0042 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 60us/sample - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 57us/sample - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 62us/sample - loss: 0.0018 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 100us/sample - loss: 0.0067 - acc: 0.9540\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0061 - acc: 0.9560\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0056 - acc: 0.9560\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0052 - acc: 0.9620\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0049 - acc: 0.9640\n",
      "2000/2000 [==============================] - 0s 23us/sample - loss: 0.0326 - acc: 0.7835\n",
      "[0.03258960650861263, 0.7835]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0042 - acc: 0.9500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 54us/sample - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 56us/sample - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 60us/sample - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 77us/sample - loss: 0.0018 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 98us/sample - loss: 0.0066 - acc: 0.9560\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0060 - acc: 0.9560\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0057 - acc: 0.9560\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0053 - acc: 0.9620\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0049 - acc: 0.9640\n",
      "2000/2000 [==============================] - 0s 22us/sample - loss: 0.0324 - acc: 0.7840\n",
      "[0.03239942370355129, 0.784]\n",
      "avg between 0 and 19\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 56us/sample - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 62us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 70us/sample - loss: 9.5400e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 66us/sample - loss: 8.2304e-04 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 92us/sample - loss: 0.0077 - acc: 0.9520\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0072 - acc: 0.9580\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 39us/sample - loss: 0.0070 - acc: 0.9580\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0067 - acc: 0.9600\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 42us/sample - loss: 0.0065 - acc: 0.9640\n",
      "2000/2000 [==============================] - 0s 21us/sample - loss: 0.0324 - acc: 0.7820\n",
      "[0.032439536169171335, 0.782]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 46us/sample - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 61us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 62us/sample - loss: 9.5400e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 8.2304e-04 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 95us/sample - loss: 0.0077 - acc: 0.9540\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0072 - acc: 0.9580\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 40us/sample - loss: 0.0069 - acc: 0.9600\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0067 - acc: 0.9580\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0066 - acc: 0.9640\n",
      "2000/2000 [==============================] - 0s 21us/sample - loss: 0.0324 - acc: 0.7825\n",
      "[0.03236026480793953, 0.7825]\n",
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 75us/sample - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 68us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 62us/sample - loss: 9.5400e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 55us/sample - loss: 8.2304e-04 - acc: 1.0000\n",
      "Train on 500 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 0s 92us/sample - loss: 0.0077 - acc: 0.9520\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0072 - acc: 0.9580\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 0s 37us/sample - loss: 0.0069 - acc: 0.9580\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 0s 38us/sample - loss: 0.0067 - acc: 0.9600\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 0s 41us/sample - loss: 0.0065 - acc: 0.9640\n",
      "2000/2000 [==============================] - 0s 21us/sample - loss: 0.0324 - acc: 0.7825\n",
      "[0.03239141806960106, 0.7825]\n"
     ]
    }
   ],
   "source": [
    "# run alt_FR\n",
    "FR_NUM = 3\n",
    "first_exc_locs = []\n",
    "cur_weights = model_weights_list[0]\n",
    "eval_hist = [eval_weights(cur_weights)]\n",
    "for i in range(1, len(model_weights_list)):\n",
    "    print(\"avg between {} and {}\".format(0, i))\n",
    "    first_exc_locs.append(len(eval_hist) + 1)\n",
    "    for j in range(FR_NUM):\n",
    "        agg_weights = run_alt_fr(cur_weights,model_weights_list[i], 0, i)\n",
    "        hist = eval_weights(agg_weights)\n",
    "        print(hist)\n",
    "        eval_hist.append(copy.deepcopy(hist))\n",
    "\n",
    "    cur_weights = copy.deepcopy(agg_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_weights(my_weights, other_weights):\n",
    "    if my_weights == None:\n",
    "        return other_weights\n",
    "    weights = [my_weights, other_weights]\n",
    "    agg_weights = list()\n",
    "    coeff = 0.5\n",
    "    for weights_list_tuple in zip(*weights):\n",
    "        agg_weights.append(np.array([np.average(np.array(w), axis=0, weights=[coeff, 1.-coeff]) for w in zip(*weights_list_tuple)]))\n",
    "    \n",
    "    return agg_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_weights(_weights):\n",
    "    target_model = get_model()\n",
    "    target_model.set_weights(_weights)\n",
    "    compile_model(target_model)\n",
    "    return target_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_alt_fr(my_weights, other_weights, my_idx, other_idx):\n",
    "    other_model = get_model()\n",
    "    other_model.set_weights(other_weights)\n",
    "    compile_model(other_model)\n",
    "    other_model.fit(x_train_list[my_idx], y_train_list[my_idx], epochs=5, shuffle=True)\n",
    "    \n",
    "    target_model = get_model()\n",
    "    target_model.set_weights(my_weights)\n",
    "    compile_model(target_model)\n",
    "    target_model.fit(x_train_list[other_idx], y_train_list[other_idx], epochs=5, shuffle=True)\n",
    "    \n",
    "    weights = [target_model.get_weights(), other_model.get_weights()]\n",
    "    agg_weights = list()\n",
    "    for weights_list_tuple in zip(*weights):\n",
    "        agg_weights.append(np.array([np.average(np.array(w), axis=0, weights=[coeff, 1.-coeff]) for w in zip(*weights_list_tuple)]))\n",
    "    \n",
    "    K.clear_session()\n",
    "    return agg_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fr(agg_weights, my_idx, other_idx):\n",
    "    target_model = get_model()\n",
    "    target_model.set_weights(agg_weights)\n",
    "    compile_model(target_model)\n",
    "    target_model.fit(x_train_list[other_idx], y_train_list[other_idx], epochs=5, shuffle=True)\n",
    "    \n",
    "    other_model = get_model()\n",
    "    other_model.set_weights(agg_weights)\n",
    "    compile_model(other_model)\n",
    "    other_model.fit(x_train_list[my_idx], y_train_list[my_idx], epochs=5, shuffle=True)\n",
    "    \n",
    "    weights = [target_model.get_weights(), other_model.get_weights()]\n",
    "    agg_weights = list()\n",
    "    for weights_list_tuple in zip(*weights):\n",
    "        agg_weights.append(np.array([np.average(np.array(w), axis=0, weights=[coeff, 1.-coeff]) for w in zip(*weights_list_tuple)]))\n",
    "    \n",
    "    K.clear_session()\n",
    "    return agg_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0060 - acc: 0.9612\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0080 - acc: 0.9476\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0076 - acc: 0.9508\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0071 - acc: 0.9540\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0075 - acc: 0.9516\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0068 - acc: 0.9552\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0080 - acc: 0.9484\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0073 - acc: 0.9520\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0077 - acc: 0.9504\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0085 - acc: 0.9448\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0071 - acc: 0.9540\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0077 - acc: 0.9492\n",
      "2500/2500 [==============================] - 0s 25us/sample - loss: 0.0078 - acc: 0.9504\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0075 - acc: 0.9520\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0076 - acc: 0.9504\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0071 - acc: 0.9528\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0081 - acc: 0.9496\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0075 - acc: 0.9500\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0075 - acc: 0.9520\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0070 - acc: 0.9536\n"
     ]
    }
   ],
   "source": [
    "for w in model_weights_list:\n",
    "    new_model = tm.custom_model()\n",
    "    new_model.set_weights(w)\n",
    "    compile_model(new_model)\n",
    "    hist_list.append(new_model.evaluate(x_test, y_test))\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0068 - acc: 0.9548\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0065 - acc: 0.9556\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0062 - acc: 0.9572\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0059 - acc: 0.9600\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0058 - acc: 0.9616\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0056 - acc: 0.9616\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0055 - acc: 0.9624\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0059 - acc: 0.9608\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0057 - acc: 0.9628\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0056 - acc: 0.9648\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0055 - acc: 0.9660\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0054 - acc: 0.9668\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0054 - acc: 0.9672\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0058 - acc: 0.9624\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0056 - acc: 0.9644\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0055 - acc: 0.9664\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0054 - acc: 0.9676\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0053 - acc: 0.9680\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0052 - acc: 0.9680\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0054 - acc: 0.9648\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0053 - acc: 0.9668\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0052 - acc: 0.9676\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0051 - acc: 0.9688\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0050 - acc: 0.9692\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0049 - acc: 0.9700\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0054 - acc: 0.9640\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0053 - acc: 0.9668\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0052 - acc: 0.9672\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0051 - acc: 0.9680\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0050 - acc: 0.9700\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0050 - acc: 0.9696\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0057 - acc: 0.9636\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0055 - acc: 0.9648\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0053 - acc: 0.9664\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0053 - acc: 0.9668\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0052 - acc: 0.9676\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0052 - acc: 0.9672\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0057 - acc: 0.9636\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0054 - acc: 0.9660\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0053 - acc: 0.9656\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0053 - acc: 0.9664\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0052 - acc: 0.9672\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0052 - acc: 0.9676\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0055 - acc: 0.9648\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0054 - acc: 0.9660\n",
      "2500/2500 [==============================] - 0s 24us/sample - loss: 0.0053 - acc: 0.9668\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0052 - acc: 0.9664\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0051 - acc: 0.9664\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0051 - acc: 0.9676\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0059 - acc: 0.9632\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0056 - acc: 0.9640\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0055 - acc: 0.9636\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0054 - acc: 0.9648\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0053 - acc: 0.9652\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0052 - acc: 0.9660\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0058 - acc: 0.9608\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0056 - acc: 0.9640\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0055 - acc: 0.9652\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0055 - acc: 0.9644\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0054 - acc: 0.9648\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0054 - acc: 0.9652\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0062 - acc: 0.9576\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0059 - acc: 0.9620\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0057 - acc: 0.9644\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0055 - acc: 0.9644\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0055 - acc: 0.9664\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0054 - acc: 0.9660\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0059 - acc: 0.9612\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0058 - acc: 0.9600\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0057 - acc: 0.9608\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0057 - acc: 0.9620\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0056 - acc: 0.9624\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0056 - acc: 0.9640\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0059 - acc: 0.9628\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0057 - acc: 0.9640\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0055 - acc: 0.9636\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0054 - acc: 0.9640\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0054 - acc: 0.9648\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0053 - acc: 0.9648\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0056 - acc: 0.9628\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0054 - acc: 0.9652\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0052 - acc: 0.9664\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0051 - acc: 0.9688\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0050 - acc: 0.9688\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0050 - acc: 0.9696\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0055 - acc: 0.9636\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0053 - acc: 0.9660\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0051 - acc: 0.9676\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0050 - acc: 0.9684\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0050 - acc: 0.9684\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0049 - acc: 0.9672\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0054 - acc: 0.9644\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0053 - acc: 0.9676\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0052 - acc: 0.9696\n",
      "2500/2500 [==============================] - 0s 18us/sample - loss: 0.0051 - acc: 0.9692\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0050 - acc: 0.9684\n",
      "2500/2500 [==============================] - 0s 23us/sample - loss: 0.0050 - acc: 0.9688\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0055 - acc: 0.9636\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0054 - acc: 0.9644\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0052 - acc: 0.9656\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0051 - acc: 0.9664\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0050 - acc: 0.9676\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0050 - acc: 0.9680\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0057 - acc: 0.9620\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0056 - acc: 0.9644\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0055 - acc: 0.9656\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0054 - acc: 0.9664\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0054 - acc: 0.9664\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0054 - acc: 0.9660\n",
      "2500/2500 [==============================] - 0s 20us/sample - loss: 0.0058 - acc: 0.9604\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0055 - acc: 0.9632\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0053 - acc: 0.9664\n",
      "2500/2500 [==============================] - 0s 22us/sample - loss: 0.0052 - acc: 0.9684\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0051 - acc: 0.9688\n",
      "2500/2500 [==============================] - 0s 21us/sample - loss: 0.0050 - acc: 0.9692\n"
     ]
    }
   ],
   "source": [
    "hist_list = []\n",
    "\n",
    "for w in weights_hist:\n",
    "    new_model = tm.custom_model()\n",
    "    new_model.set_weights(w)\n",
    "    compile_model(new_model)\n",
    "    hist_list.append(new_model.evaluate(x_test, y_test))\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as plot\n",
    "x = np.arange(len(eval_hist))\n",
    "temp = np.ones(np.array(eval_hist)[:,1].shape) * 0.82\n",
    "plt.plot(x, np.array(eval_hist)[:,1])\n",
    "plt.plot(x, np.array(eval_hist2)[:,1])\n",
    "plt.plot(x, np.array(eval_hist3)[:,1])\n",
    "plt.plot(x, np.array(eval_hist4)[:,1])\n",
    "plt.plot(x, np.array(eval_hist5)[:,1])\n",
    "# plt.plot(x, np.array(eval_hist6)[:,1])\n",
    "plt.legend(('only local','only remote', 'mixed', 'momentum', 'cache', 'cache-momentum'),loc='lower left')\n",
    "plt.title(\"[MNIST] From one model's perspective\")\n",
    "plt.ylabel(\"val\")\n",
    "plt.xlabel(\"encounters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as plot\n",
    "x = np.arange(len(eval_hist))\n",
    "temp = np.ones(np.array(eval_hist)[:,1].shape) * 0.88\n",
    "plt.plot(x, temp)\n",
    "plt.plot(x, temp)\n",
    "plt.plot(x, np.array(eval_hist3)[:,1])\n",
    "plt.plot(x, np.array(eval_hist4)[:,1])\n",
    "plt.plot(x, np.array(eval_hist5)[:,1])\n",
    "# plt.plot(x, np.array(eval_hist6)[:,1])\n",
    "plt.legend(('.','.', 'mixed', 'momentum', 'cache', 'cache-momentum'),loc='lower right')\n",
    "plt.title(\"[MNIST] From one model's perspective\")\n",
    "plt.ylabel(\"val\")\n",
    "plt.xlabel(\"encounters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_exc_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "del weights_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "x=%{x}<br>y=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57
         ],
         "xaxis": "x",
         "y": [
          0.9120000004768372,
          0.9524000287055969,
          0.9524000287055969,
          0.9524000287055969,
          0.9575999975204468,
          0.9575999975204468,
          0.9575999975204468,
          0.9584000110626221,
          0.9588000178337097,
          0.9575999975204468,
          0.9584000110626221,
          0.9567999839782715,
          0.9580000042915344,
          0.9599999785423279,
          0.9592000246047974,
          0.9599999785423279,
          0.9599999785423279,
          0.9599999785423279,
          0.9595999717712402,
          0.9575999975204468,
          0.9571999907493591,
          0.9575999975204468,
          0.9584000110626221,
          0.9580000042915344,
          0.9580000042915344,
          0.9575999975204468,
          0.9580000042915344,
          0.9575999975204468,
          0.9592000246047974,
          0.9592000246047974,
          0.9592000246047974,
          0.9556000232696533,
          0.9556000232696533,
          0.9559999704360962,
          0.9584000110626221,
          0.9584000110626221,
          0.9584000110626221,
          0.9580000042915344,
          0.9580000042915344,
          0.9588000178337097,
          0.9588000178337097,
          0.9588000178337097,
          0.9584000110626221,
          0.9592000246047974,
          0.9595999717712402,
          0.9592000246047974,
          0.9588000178337097,
          0.9588000178337097,
          0.9588000178337097,
          0.9588000178337097,
          0.9588000178337097,
          0.9595999717712402,
          0.9571999907493591,
          0.9588000178337097,
          0.9571999907493591,
          0.9584000110626221,
          0.9595999717712402,
          0.9584000110626221
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"f2874821-6437-4e78-8349-a173b2fffa26\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"f2874821-6437-4e78-8349-a173b2fffa26\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'f2874821-6437-4e78-8349-a173b2fffa26',\n",
       "                        [{\"hovertemplate\": \"x=%{x}<br>y=%{y}<extra></extra>\", \"legendgroup\": \"\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], \"xaxis\": \"x\", \"y\": [0.9120000004768372, 0.9524000287055969, 0.9524000287055969, 0.9524000287055969, 0.9575999975204468, 0.9575999975204468, 0.9575999975204468, 0.9584000110626221, 0.9588000178337097, 0.9575999975204468, 0.9584000110626221, 0.9567999839782715, 0.9580000042915344, 0.9599999785423279, 0.9592000246047974, 0.9599999785423279, 0.9599999785423279, 0.9599999785423279, 0.9595999717712402, 0.9575999975204468, 0.9571999907493591, 0.9575999975204468, 0.9584000110626221, 0.9580000042915344, 0.9580000042915344, 0.9575999975204468, 0.9580000042915344, 0.9575999975204468, 0.9592000246047974, 0.9592000246047974, 0.9592000246047974, 0.9556000232696533, 0.9556000232696533, 0.9559999704360962, 0.9584000110626221, 0.9584000110626221, 0.9584000110626221, 0.9580000042915344, 0.9580000042915344, 0.9588000178337097, 0.9588000178337097, 0.9588000178337097, 0.9584000110626221, 0.9592000246047974, 0.9595999717712402, 0.9592000246047974, 0.9588000178337097, 0.9588000178337097, 0.9588000178337097, 0.9588000178337097, 0.9588000178337097, 0.9595999717712402, 0.9571999907493591, 0.9588000178337097, 0.9571999907493591, 0.9584000110626221, 0.9595999717712402, 0.9584000110626221], \"yaxis\": \"y\"}],\n",
       "                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"x\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"y\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('f2874821-6437-4e78-8349-a173b2fffa26');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "fig = px.line(x=np.arange(len(eval_hist)), y=np.array(eval_hist)[:,1])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "x=%{x}<br>y=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "xaxis": "x",
         "y": [
          0.9120000004768372,
          0.9128000140190125,
          0.9132000207901001,
          0.9136000275611877,
          0.9136000275611877,
          0.9136000275611877,
          0.9136000275611877,
          0.9136000275611877,
          0.9143999814987183,
          0.9139999747276306,
          0.9136000275611877,
          0.9136000275611877,
          0.9139999747276306,
          0.9143999814987183,
          0.9139999747276306,
          0.9143999814987183,
          0.9143999814987183,
          0.9139999747276306,
          0.9139999747276306,
          0.9136000275611877
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"7e8ae834-b959-4356-b363-ec99b1c92d5f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"7e8ae834-b959-4356-b363-ec99b1c92d5f\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '7e8ae834-b959-4356-b363-ec99b1c92d5f',\n",
       "                        [{\"hovertemplate\": \"x=%{x}<br>y=%{y}<extra></extra>\", \"legendgroup\": \"\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"xaxis\": \"x\", \"y\": [0.9120000004768372, 0.9128000140190125, 0.9132000207901001, 0.9136000275611877, 0.9136000275611877, 0.9136000275611877, 0.9136000275611877, 0.9136000275611877, 0.9143999814987183, 0.9139999747276306, 0.9136000275611877, 0.9136000275611877, 0.9139999747276306, 0.9143999814987183, 0.9139999747276306, 0.9143999814987183, 0.9143999814987183, 0.9139999747276306, 0.9139999747276306, 0.9136000275611877], \"yaxis\": \"y\"}],\n",
       "                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"x\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"y\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('7e8ae834-b959-4356-b363-ec99b1c92d5f');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "fig = px.line(x=np.arange(len(eval_hist3)), y=np.array(eval_hist3)[:,1])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
