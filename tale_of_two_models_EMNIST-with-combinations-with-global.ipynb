{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d6n47ueeqbXb"
   },
   "source": [
    "## Personalized Learning (Localized Learning?)\n",
    "\n",
    "#### This notebook includes the following online models;\n",
    "1. A single global model with all data\n",
    "2. Multiple local models (starting from a single global model)\n",
    "   1. that are updated with new data\n",
    "   2. that exchanges data in clusters\n",
    "   3. that exchanges parameters in clusters\n",
    "\n",
    "  \n",
    "#### The dataset that is used for this project is [CIFAR-100 dataset][1]\n",
    "* Has 100 classes containing 600 images each\n",
    "\n",
    "#### New data are fed by the following rules;\n",
    "1. Distributed, according to superclasses\n",
    "  * Clusters will only be updated with data that belongs to a specific superclass\n",
    "  * We update the NN by\n",
    "    1. Changing all parameters of the NN\n",
    "    2. Only changing the last few layers, as in many MTL models\n",
    "2. Randomly (why?)\n",
    "\n",
    "#### We expect to find an answer to the following research questions with this project;\n",
    "1. If models are updated with data (or parameters) that are shared within a cluster, can the model perform good enough with the labels that count?\n",
    "  * For example, the performance of the cluster that are updated with \"Vehicles\" superclass is only assessed with the labels that corresponds to the superclass.\n",
    "  \n",
    "[1]: https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oji0BTfoqbXc"
   },
   "source": [
    "#### Questions\n",
    "\n",
    "Retraining: how does it work <br>\n",
    "How do we compare these models?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mr4-uY0LqbXd"
   },
   "source": [
    "### Implementation with Custom Neural Network and EMNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tGoXLnOyqbXe",
    "outputId": "9ccd7215-80bf-4a0a-b852-8896b17c38f1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.lines as mlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E2faBs1yqbXj"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 50\n",
    "epochs = 20\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QXfylSWLqbXl"
   },
   "source": [
    "#### Load EMNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/ubuntu/fed-learn-experiment/utils.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEMNIST_PATH = \"./leaf/data/femnist/data/train/\"\n",
    "FEMNIST_TEST_PATH = \"./leaf/data/femnist/data/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what's the number after all_data_(num)? Thought it was a label but there are every class in one json file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for i in range(0, 63):\n",
    "    files.append(FEMNIST_PATH + utils.get_train_data_from_filename(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/63) processing: ./leaf/data/femnist/data/train/all_data_0_niid_0_keep_10_train_9.json\n",
      "(2/63) processing: ./leaf/data/femnist/data/train/all_data_1_niid_0_keep_10_train_9.json\n",
      "(3/63) processing: ./leaf/data/femnist/data/train/all_data_2_niid_0_keep_10_train_9.json\n",
      "(4/63) processing: ./leaf/data/femnist/data/train/all_data_3_niid_0_keep_10_train_9.json\n",
      "(5/63) processing: ./leaf/data/femnist/data/train/all_data_4_niid_0_keep_10_train_9.json\n",
      "(6/63) processing: ./leaf/data/femnist/data/train/all_data_5_niid_0_keep_10_train_9.json\n",
      "(7/63) processing: ./leaf/data/femnist/data/train/all_data_6_niid_0_keep_10_train_9.json\n",
      "(8/63) processing: ./leaf/data/femnist/data/train/all_data_7_niid_0_keep_10_train_9.json\n",
      "(9/63) processing: ./leaf/data/femnist/data/train/all_data_8_niid_0_keep_10_train_9.json\n",
      "(10/63) processing: ./leaf/data/femnist/data/train/all_data_9_niid_0_keep_10_train_9.json\n",
      "(11/63) processing: ./leaf/data/femnist/data/train/all_data_10_niid_0_keep_10_train_9.json\n",
      "(12/63) processing: ./leaf/data/femnist/data/train/all_data_11_niid_0_keep_10_train_9.json\n",
      "(13/63) processing: ./leaf/data/femnist/data/train/all_data_12_niid_0_keep_10_train_9.json\n",
      "(14/63) processing: ./leaf/data/femnist/data/train/all_data_13_niid_0_keep_10_train_9.json\n",
      "(15/63) processing: ./leaf/data/femnist/data/train/all_data_14_niid_0_keep_10_train_9.json\n",
      "(16/63) processing: ./leaf/data/femnist/data/train/all_data_15_niid_0_keep_10_train_9.json\n",
      "(17/63) processing: ./leaf/data/femnist/data/train/all_data_16_niid_0_keep_10_train_9.json\n",
      "(18/63) processing: ./leaf/data/femnist/data/train/all_data_17_niid_0_keep_10_train_9.json\n",
      "(19/63) processing: ./leaf/data/femnist/data/train/all_data_18_niid_0_keep_10_train_9.json\n",
      "(20/63) processing: ./leaf/data/femnist/data/train/all_data_19_niid_0_keep_10_train_9.json\n",
      "(21/63) processing: ./leaf/data/femnist/data/train/all_data_20_niid_0_keep_10_train_9.json\n",
      "(22/63) processing: ./leaf/data/femnist/data/train/all_data_21_niid_0_keep_10_train_9.json\n",
      "(23/63) processing: ./leaf/data/femnist/data/train/all_data_22_niid_0_keep_10_train_9.json\n",
      "(24/63) processing: ./leaf/data/femnist/data/train/all_data_23_niid_0_keep_10_train_9.json\n",
      "(25/63) processing: ./leaf/data/femnist/data/train/all_data_24_niid_0_keep_10_train_9.json\n",
      "(26/63) processing: ./leaf/data/femnist/data/train/all_data_25_niid_0_keep_10_train_9.json\n",
      "(27/63) processing: ./leaf/data/femnist/data/train/all_data_26_niid_0_keep_10_train_9.json\n",
      "(28/63) processing: ./leaf/data/femnist/data/train/all_data_27_niid_0_keep_10_train_9.json\n",
      "(29/63) processing: ./leaf/data/femnist/data/train/all_data_28_niid_0_keep_10_train_9.json\n",
      "(30/63) processing: ./leaf/data/femnist/data/train/all_data_29_niid_0_keep_10_train_9.json\n",
      "(31/63) processing: ./leaf/data/femnist/data/train/all_data_30_niid_0_keep_10_train_9.json\n",
      "(32/63) processing: ./leaf/data/femnist/data/train/all_data_31_niid_0_keep_10_train_9.json\n",
      "(33/63) processing: ./leaf/data/femnist/data/train/all_data_32_niid_0_keep_10_train_9.json\n",
      "(34/63) processing: ./leaf/data/femnist/data/train/all_data_33_niid_0_keep_10_train_9.json\n",
      "(35/63) processing: ./leaf/data/femnist/data/train/all_data_34_niid_0_keep_10_train_9.json\n",
      "(36/63) processing: ./leaf/data/femnist/data/train/all_data_35_niid_0_keep_10_train_9.json\n",
      "(37/63) processing: ./leaf/data/femnist/data/train/all_data_36_niid_0_keep_10_train_9.json\n",
      "(38/63) processing: ./leaf/data/femnist/data/train/all_data_37_niid_0_keep_10_train_9.json\n",
      "(39/63) processing: ./leaf/data/femnist/data/train/all_data_38_niid_0_keep_10_train_9.json\n",
      "(40/63) processing: ./leaf/data/femnist/data/train/all_data_39_niid_0_keep_10_train_9.json\n",
      "(41/63) processing: ./leaf/data/femnist/data/train/all_data_40_niid_0_keep_10_train_9.json\n",
      "(42/63) processing: ./leaf/data/femnist/data/train/all_data_41_niid_0_keep_10_train_9.json\n",
      "(43/63) processing: ./leaf/data/femnist/data/train/all_data_42_niid_0_keep_10_train_9.json\n",
      "(44/63) processing: ./leaf/data/femnist/data/train/all_data_43_niid_0_keep_10_train_9.json\n",
      "(45/63) processing: ./leaf/data/femnist/data/train/all_data_44_niid_0_keep_10_train_9.json\n",
      "(46/63) processing: ./leaf/data/femnist/data/train/all_data_45_niid_0_keep_10_train_9.json\n",
      "(47/63) processing: ./leaf/data/femnist/data/train/all_data_46_niid_0_keep_10_train_9.json\n",
      "(48/63) processing: ./leaf/data/femnist/data/train/all_data_47_niid_0_keep_10_train_9.json\n",
      "(49/63) processing: ./leaf/data/femnist/data/train/all_data_48_niid_0_keep_10_train_9.json\n",
      "(50/63) processing: ./leaf/data/femnist/data/train/all_data_49_niid_0_keep_10_train_9.json\n",
      "(51/63) processing: ./leaf/data/femnist/data/train/all_data_50_niid_0_keep_10_train_9.json\n",
      "(52/63) processing: ./leaf/data/femnist/data/train/all_data_51_niid_0_keep_10_train_9.json\n",
      "(53/63) processing: ./leaf/data/femnist/data/train/all_data_52_niid_0_keep_10_train_9.json\n",
      "(54/63) processing: ./leaf/data/femnist/data/train/all_data_53_niid_0_keep_10_train_9.json\n",
      "(55/63) processing: ./leaf/data/femnist/data/train/all_data_54_niid_0_keep_10_train_9.json\n",
      "(56/63) processing: ./leaf/data/femnist/data/train/all_data_55_niid_0_keep_10_train_9.json\n",
      "(57/63) processing: ./leaf/data/femnist/data/train/all_data_56_niid_0_keep_10_train_9.json\n",
      "(58/63) processing: ./leaf/data/femnist/data/train/all_data_57_niid_0_keep_10_train_9.json\n",
      "(59/63) processing: ./leaf/data/femnist/data/train/all_data_58_niid_0_keep_10_train_9.json\n",
      "(60/63) processing: ./leaf/data/femnist/data/train/all_data_59_niid_0_keep_10_train_9.json\n",
      "(61/63) processing: ./leaf/data/femnist/data/train/all_data_60_niid_0_keep_10_train_9.json\n",
      "(62/63) processing: ./leaf/data/femnist/data/train/all_data_61_niid_0_keep_10_train_9.json\n",
      "(63/63) processing: ./leaf/data/femnist/data/train/all_data_62_niid_0_keep_10_train_9.json\n"
     ]
    }
   ],
   "source": [
    "X, Y, users = utils.get_data(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = []\n",
    "for i in range(0, 6):\n",
    "    test_files.append(FEMNIST_TEST_PATH + utils.get_test_data_from_filename(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/6) processing: ./leaf/data/femnist/data/test/all_data_0_niid_0_keep_10_test_9.json\n",
      "(2/6) processing: ./leaf/data/femnist/data/test/all_data_1_niid_0_keep_10_test_9.json\n",
      "(3/6) processing: ./leaf/data/femnist/data/test/all_data_2_niid_0_keep_10_test_9.json\n",
      "(4/6) processing: ./leaf/data/femnist/data/test/all_data_3_niid_0_keep_10_test_9.json\n",
      "(5/6) processing: ./leaf/data/femnist/data/test/all_data_4_niid_0_keep_10_test_9.json\n",
      "(6/6) processing: ./leaf/data/femnist/data/test/all_data_5_niid_0_keep_10_test_9.json\n"
     ]
    }
   ],
   "source": [
    "X_test, Y_test, users_test = utils.get_data(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "722701 training data, 69393 test data\n"
     ]
    }
   ],
   "source": [
    "print(\"{} training data, {} test data\".format(sum([n.shape[0] for n in X]), sum([n.shape[0] for n in X_test])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_global, Y_global, local_data = \\\n",
    "utils.fl_parse(X=X, Y=Y, num_clients=20, min_num_global=200000, min_num_local=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = utils.serialize_data(X_test)\n",
    "Y_test = utils.serialize_data(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_global[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_global = keras.utils.to_categorical(Y_global, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200086, 62)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_global.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(local_data)):\n",
    "    local_data[i] = (local_data[i][0], keras.utils.to_categorical(local_data[i][1], num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models and compile & fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_model():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=input_shape))\n",
    "    model.add(Dense(600, activation='relu'))\n",
    "    model.add(Dense(600, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):  \n",
    "    # initiate SGD optimizer\n",
    "    opt = keras.optimizers.SGD(lr=0.1)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model_lr(model):  \n",
    "    # initiate SGD optimizer\n",
    "    opt = keras.optimizers.SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_global(model, epochs):\n",
    "    now = datetime.datetime.now()\n",
    "    print (\"Training date and time : \")\n",
    "    print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    return model.fit(X_global, Y_global,\n",
    "                      batch_size=100,\n",
    "                      epochs=40,\n",
    "                      shuffle=True, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_with_datasets(model, epochs, x_train, y_train):\n",
    "    now = datetime.datetime.now()\n",
    "    print (\"Training date and time : \")\n",
    "    print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    return model.fit(x_train, y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      validation_split=0.2,\n",
    "                      shuffle=True, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200086, 62)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_global.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training date and time : \n",
      "2020-04-08 05:09:27\n",
      "Train on 160068 samples, validate on 40018 samples\n",
      "Epoch 1/60\n",
      "160068/160068 [==============================] - 14s 85us/sample - loss: 0.0156 - accuracy: 0.0855 - val_loss: 0.0157 - val_accuracy: 0.0839\n",
      "Epoch 2/60\n",
      "160068/160068 [==============================] - 13s 79us/sample - loss: 0.0155 - accuracy: 0.1430 - val_loss: 0.0157 - val_accuracy: 0.1094\n",
      "Epoch 3/60\n",
      "160068/160068 [==============================] - 12s 78us/sample - loss: 0.0153 - accuracy: 0.1788 - val_loss: 0.0157 - val_accuracy: 0.1153\n",
      "Epoch 4/60\n",
      "160068/160068 [==============================] - 13s 80us/sample - loss: 0.0152 - accuracy: 0.2048 - val_loss: 0.0156 - val_accuracy: 0.1330\n",
      "Epoch 5/60\n",
      "160068/160068 [==============================] - 13s 80us/sample - loss: 0.0149 - accuracy: 0.2343 - val_loss: 0.0154 - val_accuracy: 0.1612\n",
      "Epoch 6/60\n",
      "160068/160068 [==============================] - 14s 87us/sample - loss: 0.0146 - accuracy: 0.2716 - val_loss: 0.0153 - val_accuracy: 0.1842\n",
      "Epoch 7/60\n",
      "160068/160068 [==============================] - 14s 85us/sample - loss: 0.0142 - accuracy: 0.3178 - val_loss: 0.0150 - val_accuracy: 0.2162\n",
      "Epoch 8/60\n",
      "160068/160068 [==============================] - 13s 79us/sample - loss: 0.0137 - accuracy: 0.3539 - val_loss: 0.0148 - val_accuracy: 0.2379\n",
      "Epoch 9/60\n",
      "160068/160068 [==============================] - 13s 84us/sample - loss: 0.0133 - accuracy: 0.3864 - val_loss: 0.0145 - val_accuracy: 0.2708\n",
      "Epoch 10/60\n",
      "160068/160068 [==============================] - 13s 81us/sample - loss: 0.0128 - accuracy: 0.4143 - val_loss: 0.0142 - val_accuracy: 0.2968\n",
      "Epoch 11/60\n",
      "160068/160068 [==============================] - 13s 84us/sample - loss: 0.0124 - accuracy: 0.4320 - val_loss: 0.0140 - val_accuracy: 0.3068\n",
      "Epoch 12/60\n",
      "160068/160068 [==============================] - 12s 77us/sample - loss: 0.0121 - accuracy: 0.4427 - val_loss: 0.0137 - val_accuracy: 0.3242\n",
      "Epoch 13/60\n",
      "160068/160068 [==============================] - 14s 90us/sample - loss: 0.0118 - accuracy: 0.4507 - val_loss: 0.0135 - val_accuracy: 0.3350\n",
      "Epoch 14/60\n",
      "160068/160068 [==============================] - 13s 82us/sample - loss: 0.0116 - accuracy: 0.4576 - val_loss: 0.0133 - val_accuracy: 0.3414\n",
      "Epoch 15/60\n",
      "160068/160068 [==============================] - 13s 81us/sample - loss: 0.0114 - accuracy: 0.4652 - val_loss: 0.0132 - val_accuracy: 0.3479\n",
      "Epoch 16/60\n",
      "160068/160068 [==============================] - 13s 81us/sample - loss: 0.0113 - accuracy: 0.4723 - val_loss: 0.0130 - val_accuracy: 0.3590\n",
      "Epoch 17/60\n",
      "160068/160068 [==============================] - 13s 84us/sample - loss: 0.0111 - accuracy: 0.4800 - val_loss: 0.0128 - val_accuracy: 0.3761\n",
      "Epoch 18/60\n",
      "160068/160068 [==============================] - 14s 85us/sample - loss: 0.0110 - accuracy: 0.4864 - val_loss: 0.0127 - val_accuracy: 0.3797\n",
      "Epoch 19/60\n",
      "160068/160068 [==============================] - 13s 82us/sample - loss: 0.0109 - accuracy: 0.4919 - val_loss: 0.0126 - val_accuracy: 0.3884\n",
      "Epoch 20/60\n",
      "160068/160068 [==============================] - 13s 83us/sample - loss: 0.0108 - accuracy: 0.4967 - val_loss: 0.0124 - val_accuracy: 0.3984\n",
      "Epoch 21/60\n",
      "160068/160068 [==============================] - 13s 81us/sample - loss: 0.0107 - accuracy: 0.5013 - val_loss: 0.0124 - val_accuracy: 0.4001\n",
      "Epoch 22/60\n",
      "160068/160068 [==============================] - 12s 78us/sample - loss: 0.0106 - accuracy: 0.5062 - val_loss: 0.0122 - val_accuracy: 0.4081\n",
      "Epoch 23/60\n",
      "160068/160068 [==============================] - 13s 81us/sample - loss: 0.0105 - accuracy: 0.5114 - val_loss: 0.0121 - val_accuracy: 0.4205\n",
      "Epoch 24/60\n",
      "160068/160068 [==============================] - 14s 86us/sample - loss: 0.0104 - accuracy: 0.5163 - val_loss: 0.0119 - val_accuracy: 0.4274\n",
      "Epoch 25/60\n",
      "160068/160068 [==============================] - 13s 81us/sample - loss: 0.0103 - accuracy: 0.5216 - val_loss: 0.0119 - val_accuracy: 0.4314\n",
      "Epoch 26/60\n",
      "160068/160068 [==============================] - 13s 82us/sample - loss: 0.0102 - accuracy: 0.5258 - val_loss: 0.0119 - val_accuracy: 0.4338\n",
      "Epoch 27/60\n",
      "160068/160068 [==============================] - 15s 92us/sample - loss: 0.0102 - accuracy: 0.5294 - val_loss: 0.0117 - val_accuracy: 0.4444\n",
      "Epoch 28/60\n",
      "160068/160068 [==============================] - 13s 83us/sample - loss: 0.0101 - accuracy: 0.5334 - val_loss: 0.0117 - val_accuracy: 0.4418\n",
      "Epoch 29/60\n",
      "160068/160068 [==============================] - 13s 79us/sample - loss: 0.0100 - accuracy: 0.5360 - val_loss: 0.0114 - val_accuracy: 0.4545\n",
      "Epoch 30/60\n",
      "160068/160068 [==============================] - 13s 81us/sample - loss: 0.0100 - accuracy: 0.5382 - val_loss: 0.0115 - val_accuracy: 0.4499\n",
      "Epoch 31/60\n",
      "160068/160068 [==============================] - 13s 81us/sample - loss: 0.0099 - accuracy: 0.5409 - val_loss: 0.0112 - val_accuracy: 0.4637\n",
      "Epoch 32/60\n",
      "160068/160068 [==============================] - 13s 78us/sample - loss: 0.0098 - accuracy: 0.5439 - val_loss: 0.0112 - val_accuracy: 0.4687\n",
      "Epoch 33/60\n",
      "160068/160068 [==============================] - 13s 79us/sample - loss: 0.0098 - accuracy: 0.5454 - val_loss: 0.0112 - val_accuracy: 0.4606\n",
      "Epoch 34/60\n",
      "160068/160068 [==============================] - 13s 80us/sample - loss: 0.0097 - accuracy: 0.5483 - val_loss: 0.0110 - val_accuracy: 0.4738\n",
      "Epoch 35/60\n",
      "160068/160068 [==============================] - 13s 80us/sample - loss: 0.0097 - accuracy: 0.5506 - val_loss: 0.0110 - val_accuracy: 0.4754\n",
      "Epoch 36/60\n",
      "160068/160068 [==============================] - 13s 83us/sample - loss: 0.0096 - accuracy: 0.5533 - val_loss: 0.0108 - val_accuracy: 0.4868\n",
      "Epoch 37/60\n",
      "160068/160068 [==============================] - 13s 80us/sample - loss: 0.0096 - accuracy: 0.5572 - val_loss: 0.0109 - val_accuracy: 0.4770\n",
      "Epoch 38/60\n",
      "160068/160068 [==============================] - 13s 82us/sample - loss: 0.0095 - accuracy: 0.5599 - val_loss: 0.0108 - val_accuracy: 0.4871\n",
      "Epoch 39/60\n",
      "160068/160068 [==============================] - 13s 80us/sample - loss: 0.0095 - accuracy: 0.5628 - val_loss: 0.0107 - val_accuracy: 0.4960\n",
      "Epoch 40/60\n",
      "160068/160068 [==============================] - 13s 80us/sample - loss: 0.0094 - accuracy: 0.5674 - val_loss: 0.0107 - val_accuracy: 0.4932\n",
      "Epoch 41/60\n",
      "160068/160068 [==============================] - 15s 93us/sample - loss: 0.0093 - accuracy: 0.5725 - val_loss: 0.0107 - val_accuracy: 0.4932\n",
      "Epoch 42/60\n",
      "160068/160068 [==============================] - 13s 79us/sample - loss: 0.0093 - accuracy: 0.5775 - val_loss: 0.0104 - val_accuracy: 0.5166\n",
      "Epoch 43/60\n",
      "160068/160068 [==============================] - 13s 82us/sample - loss: 0.0092 - accuracy: 0.5826 - val_loss: 0.0103 - val_accuracy: 0.5213\n",
      "Epoch 44/60\n",
      "160068/160068 [==============================] - 13s 80us/sample - loss: 0.0091 - accuracy: 0.5868 - val_loss: 0.0103 - val_accuracy: 0.5278\n",
      "Epoch 45/60\n",
      "160068/160068 [==============================] - 13s 79us/sample - loss: 0.0091 - accuracy: 0.5905 - val_loss: 0.0102 - val_accuracy: 0.5339\n",
      "Epoch 46/60\n",
      "160068/160068 [==============================] - 13s 80us/sample - loss: 0.0090 - accuracy: 0.5936 - val_loss: 0.0101 - val_accuracy: 0.5389\n",
      "Epoch 47/60\n",
      "160068/160068 [==============================] - 13s 80us/sample - loss: 0.0090 - accuracy: 0.5965 - val_loss: 0.0100 - val_accuracy: 0.5459\n",
      "Epoch 48/60\n",
      "160068/160068 [==============================] - 13s 83us/sample - loss: 0.0089 - accuracy: 0.5983 - val_loss: 0.0100 - val_accuracy: 0.5413\n",
      "Epoch 49/60\n",
      "160068/160068 [==============================] - 13s 79us/sample - loss: 0.0089 - accuracy: 0.6011 - val_loss: 0.0099 - val_accuracy: 0.5490\n",
      "Epoch 50/60\n",
      "160068/160068 [==============================] - 13s 81us/sample - loss: 0.0088 - accuracy: 0.6038 - val_loss: 0.0098 - val_accuracy: 0.5538\n",
      "Epoch 51/60\n",
      "160068/160068 [==============================] - 13s 81us/sample - loss: 0.0088 - accuracy: 0.6056 - val_loss: 0.0097 - val_accuracy: 0.5627\n",
      "Epoch 52/60\n",
      "160068/160068 [==============================] - 12s 78us/sample - loss: 0.0088 - accuracy: 0.6081 - val_loss: 0.0098 - val_accuracy: 0.5537\n",
      "Epoch 53/60\n",
      "160068/160068 [==============================] - 12s 77us/sample - loss: 0.0087 - accuracy: 0.6102 - val_loss: 0.0098 - val_accuracy: 0.5579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/60\n",
      "160068/160068 [==============================] - 13s 80us/sample - loss: 0.0087 - accuracy: 0.6119 - val_loss: 0.0097 - val_accuracy: 0.5583\n",
      "Epoch 55/60\n",
      "160068/160068 [==============================] - 15s 92us/sample - loss: 0.0086 - accuracy: 0.6136 - val_loss: 0.0096 - val_accuracy: 0.5653\n",
      "Epoch 56/60\n",
      "160068/160068 [==============================] - 13s 80us/sample - loss: 0.0086 - accuracy: 0.6159 - val_loss: 0.0096 - val_accuracy: 0.5666\n",
      "Epoch 57/60\n",
      "160068/160068 [==============================] - 13s 80us/sample - loss: 0.0086 - accuracy: 0.6171 - val_loss: 0.0094 - val_accuracy: 0.5746\n",
      "Epoch 58/60\n",
      "160068/160068 [==============================] - 13s 82us/sample - loss: 0.0085 - accuracy: 0.6189 - val_loss: 0.0096 - val_accuracy: 0.5658\n",
      "Epoch 59/60\n",
      "160068/160068 [==============================] - 13s 80us/sample - loss: 0.0085 - accuracy: 0.6204 - val_loss: 0.0096 - val_accuracy: 0.5662\n",
      "Epoch 60/60\n",
      "160068/160068 [==============================] - 12s 78us/sample - loss: 0.0085 - accuracy: 0.6222 - val_loss: 0.0094 - val_accuracy: 0.5744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f453fe52e10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = custom_model()\n",
    "compile_model(model1)\n",
    "fit_model_with_datasets(model1, 60, X_global, Y_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = list()\n",
    "for _ in range(10):\n",
    "    model_list.append(tf.keras.models.clone_model(model1)) \n",
    "    model_list[_].set_weights(model1.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort models according to similarity. We arbitrarily take the model1 as a \"standard\"\n",
    "standard_model = tf.keras.models.clone_model(model1)\n",
    "standard_model.set_weights(model_list[0].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'semantic_drift' from '/home/ubuntu/fed-learn-experiment/semantic_drift.py'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(semantic_drift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_list = [semantic_drift.l1_distance(standard_model, m) for m in model_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct transfer learning in local models using different datasets & epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20025, 62)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_data[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training date and time : \n",
      "2020-04-08 05:22:33\n",
      "Train on 16020 samples, validate on 4005 samples\n",
      "Epoch 1/5\n",
      "16020/16020 [==============================] - 2s 107us/sample - loss: 0.0090 - accuracy: 0.5973 - val_loss: 0.0115 - val_accuracy: 0.4602\n",
      "Epoch 2/5\n",
      "16020/16020 [==============================] - 1s 82us/sample - loss: 0.0089 - accuracy: 0.5979 - val_loss: 0.0118 - val_accuracy: 0.4469\n",
      "Epoch 3/5\n",
      "16020/16020 [==============================] - 1s 80us/sample - loss: 0.0089 - accuracy: 0.6001 - val_loss: 0.0121 - val_accuracy: 0.4277\n",
      "Epoch 4/5\n",
      "16020/16020 [==============================] - 1s 82us/sample - loss: 0.0089 - accuracy: 0.6021 - val_loss: 0.0122 - val_accuracy: 0.4207\n",
      "Epoch 5/5\n",
      "16020/16020 [==============================] - 1s 80us/sample - loss: 0.0089 - accuracy: 0.6031 - val_loss: 0.0120 - val_accuracy: 0.4280\n",
      "Training date and time : \n",
      "2020-04-08 05:22:40\n",
      "Train on 16087 samples, validate on 4022 samples\n",
      "Epoch 1/10\n",
      "16087/16087 [==============================] - 2s 111us/sample - loss: 0.0084 - accuracy: 0.6288 - val_loss: 0.0079 - val_accuracy: 0.6459\n",
      "Epoch 2/10\n",
      "16087/16087 [==============================] - 1s 81us/sample - loss: 0.0083 - accuracy: 0.6352 - val_loss: 0.0079 - val_accuracy: 0.6467\n",
      "Epoch 3/10\n",
      "16087/16087 [==============================] - 1s 82us/sample - loss: 0.0082 - accuracy: 0.6375 - val_loss: 0.0080 - val_accuracy: 0.6425\n",
      "Epoch 4/10\n",
      "16087/16087 [==============================] - 1s 83us/sample - loss: 0.0082 - accuracy: 0.6390 - val_loss: 0.0079 - val_accuracy: 0.6484\n",
      "Epoch 5/10\n",
      "16087/16087 [==============================] - 1s 86us/sample - loss: 0.0082 - accuracy: 0.6405 - val_loss: 0.0079 - val_accuracy: 0.6459\n",
      "Epoch 6/10\n",
      "16087/16087 [==============================] - 1s 84us/sample - loss: 0.0081 - accuracy: 0.6406 - val_loss: 0.0079 - val_accuracy: 0.6452\n",
      "Epoch 7/10\n",
      "16087/16087 [==============================] - 1s 82us/sample - loss: 0.0081 - accuracy: 0.6427 - val_loss: 0.0078 - val_accuracy: 0.6459\n",
      "Epoch 8/10\n",
      "16087/16087 [==============================] - 1s 82us/sample - loss: 0.0081 - accuracy: 0.6427 - val_loss: 0.0078 - val_accuracy: 0.6454\n",
      "Epoch 9/10\n",
      "16087/16087 [==============================] - 1s 80us/sample - loss: 0.0081 - accuracy: 0.6442 - val_loss: 0.0078 - val_accuracy: 0.6494\n",
      "Epoch 10/10\n",
      "16087/16087 [==============================] - 1s 82us/sample - loss: 0.0081 - accuracy: 0.6452 - val_loss: 0.0079 - val_accuracy: 0.6472\n",
      "Training date and time : \n",
      "2020-04-08 05:22:54\n",
      "Train on 16184 samples, validate on 4046 samples\n",
      "Epoch 1/15\n",
      "16184/16184 [==============================] - 2s 107us/sample - loss: 0.0083 - accuracy: 0.6311 - val_loss: 0.0085 - val_accuracy: 0.6228\n",
      "Epoch 2/15\n",
      "16184/16184 [==============================] - 1s 80us/sample - loss: 0.0083 - accuracy: 0.6340 - val_loss: 0.0085 - val_accuracy: 0.6298\n",
      "Epoch 3/15\n",
      "16184/16184 [==============================] - 1s 81us/sample - loss: 0.0083 - accuracy: 0.6335 - val_loss: 0.0085 - val_accuracy: 0.6295\n",
      "Epoch 4/15\n",
      "16184/16184 [==============================] - 1s 81us/sample - loss: 0.0083 - accuracy: 0.6349 - val_loss: 0.0086 - val_accuracy: 0.6204\n",
      "Epoch 5/15\n",
      "16184/16184 [==============================] - 1s 91us/sample - loss: 0.0083 - accuracy: 0.6346 - val_loss: 0.0085 - val_accuracy: 0.6241\n",
      "Epoch 6/15\n",
      "16184/16184 [==============================] - 1s 79us/sample - loss: 0.0082 - accuracy: 0.6362 - val_loss: 0.0085 - val_accuracy: 0.6335\n",
      "Epoch 7/15\n",
      "16184/16184 [==============================] - 1s 81us/sample - loss: 0.0082 - accuracy: 0.6377 - val_loss: 0.0085 - val_accuracy: 0.6298\n",
      "Epoch 8/15\n",
      "16184/16184 [==============================] - 1s 86us/sample - loss: 0.0082 - accuracy: 0.6388 - val_loss: 0.0085 - val_accuracy: 0.6275\n",
      "Epoch 9/15\n",
      "16184/16184 [==============================] - 1s 82us/sample - loss: 0.0082 - accuracy: 0.6372 - val_loss: 0.0085 - val_accuracy: 0.6290\n",
      "Epoch 10/15\n",
      "16184/16184 [==============================] - 1s 80us/sample - loss: 0.0082 - accuracy: 0.6376 - val_loss: 0.0085 - val_accuracy: 0.6290\n",
      "Epoch 11/15\n",
      "16184/16184 [==============================] - 1s 83us/sample - loss: 0.0082 - accuracy: 0.6383 - val_loss: 0.0085 - val_accuracy: 0.6288\n",
      "Epoch 12/15\n",
      "16184/16184 [==============================] - 1s 88us/sample - loss: 0.0082 - accuracy: 0.6393 - val_loss: 0.0085 - val_accuracy: 0.6253\n",
      "Epoch 13/15\n",
      "16184/16184 [==============================] - 1s 87us/sample - loss: 0.0082 - accuracy: 0.6398 - val_loss: 0.0085 - val_accuracy: 0.6253\n",
      "Epoch 14/15\n",
      "16184/16184 [==============================] - 1s 85us/sample - loss: 0.0082 - accuracy: 0.6414 - val_loss: 0.0085 - val_accuracy: 0.6283\n",
      "Epoch 15/15\n",
      "16184/16184 [==============================] - 1s 85us/sample - loss: 0.0082 - accuracy: 0.6408 - val_loss: 0.0085 - val_accuracy: 0.6280\n",
      "Training date and time : \n",
      "2020-04-08 05:23:14\n",
      "Train on 16069 samples, validate on 4018 samples\n",
      "Epoch 1/20\n",
      "16069/16069 [==============================] - 2s 109us/sample - loss: 0.0084 - accuracy: 0.6281 - val_loss: 0.0095 - val_accuracy: 0.5662\n",
      "Epoch 2/20\n",
      "16069/16069 [==============================] - 1s 83us/sample - loss: 0.0084 - accuracy: 0.6300 - val_loss: 0.0095 - val_accuracy: 0.5707\n",
      "Epoch 3/20\n",
      "16069/16069 [==============================] - 1s 83us/sample - loss: 0.0083 - accuracy: 0.6287 - val_loss: 0.0095 - val_accuracy: 0.5727\n",
      "Epoch 4/20\n",
      "16069/16069 [==============================] - 1s 80us/sample - loss: 0.0083 - accuracy: 0.6318 - val_loss: 0.0095 - val_accuracy: 0.5669\n",
      "Epoch 5/20\n",
      "16069/16069 [==============================] - 1s 83us/sample - loss: 0.0083 - accuracy: 0.6314 - val_loss: 0.0095 - val_accuracy: 0.5679\n",
      "Epoch 6/20\n",
      "16069/16069 [==============================] - 1s 82us/sample - loss: 0.0083 - accuracy: 0.6317 - val_loss: 0.0095 - val_accuracy: 0.5679\n",
      "Epoch 7/20\n",
      "16069/16069 [==============================] - 1s 82us/sample - loss: 0.0083 - accuracy: 0.6317 - val_loss: 0.0094 - val_accuracy: 0.5699\n",
      "Epoch 8/20\n",
      "16069/16069 [==============================] - 1s 83us/sample - loss: 0.0082 - accuracy: 0.6336 - val_loss: 0.0094 - val_accuracy: 0.5777\n",
      "Epoch 9/20\n",
      "16069/16069 [==============================] - 1s 82us/sample - loss: 0.0082 - accuracy: 0.6332 - val_loss: 0.0094 - val_accuracy: 0.5727\n",
      "Epoch 10/20\n",
      "16069/16069 [==============================] - 1s 82us/sample - loss: 0.0082 - accuracy: 0.6353 - val_loss: 0.0094 - val_accuracy: 0.5717\n",
      "Epoch 11/20\n",
      "16069/16069 [==============================] - 1s 82us/sample - loss: 0.0082 - accuracy: 0.6359 - val_loss: 0.0094 - val_accuracy: 0.5754\n",
      "Epoch 12/20\n",
      "16069/16069 [==============================] - 1s 84us/sample - loss: 0.0082 - accuracy: 0.6362 - val_loss: 0.0094 - val_accuracy: 0.5714\n",
      "Epoch 13/20\n",
      "16069/16069 [==============================] - 1s 79us/sample - loss: 0.0082 - accuracy: 0.6349 - val_loss: 0.0094 - val_accuracy: 0.5739\n",
      "Epoch 14/20\n",
      "16069/16069 [==============================] - 1s 82us/sample - loss: 0.0082 - accuracy: 0.6360 - val_loss: 0.0094 - val_accuracy: 0.5679\n",
      "Epoch 15/20\n",
      "16069/16069 [==============================] - 1s 83us/sample - loss: 0.0082 - accuracy: 0.6354 - val_loss: 0.0093 - val_accuracy: 0.5789\n",
      "Epoch 16/20\n",
      "16069/16069 [==============================] - 1s 81us/sample - loss: 0.0082 - accuracy: 0.6374 - val_loss: 0.0093 - val_accuracy: 0.5737\n",
      "Epoch 17/20\n",
      "16069/16069 [==============================] - 1s 83us/sample - loss: 0.0081 - accuracy: 0.6372 - val_loss: 0.0094 - val_accuracy: 0.5699\n",
      "Epoch 18/20\n",
      "16069/16069 [==============================] - 1s 82us/sample - loss: 0.0081 - accuracy: 0.6379 - val_loss: 0.0093 - val_accuracy: 0.5772\n",
      "Epoch 19/20\n",
      "16069/16069 [==============================] - 1s 80us/sample - loss: 0.0081 - accuracy: 0.6394 - val_loss: 0.0093 - val_accuracy: 0.5784\n",
      "Epoch 20/20\n",
      "16069/16069 [==============================] - 1s 82us/sample - loss: 0.0081 - accuracy: 0.6395 - val_loss: 0.0093 - val_accuracy: 0.5744\n",
      "Training date and time : \n",
      "2020-04-08 05:23:41\n",
      "Train on 16109 samples, validate on 4028 samples\n",
      "Epoch 1/25\n",
      "16109/16109 [==============================] - 2s 108us/sample - loss: 0.0095 - accuracy: 0.5656 - val_loss: 0.0093 - val_accuracy: 0.5794\n",
      "Epoch 2/25\n",
      "16109/16109 [==============================] - 1s 80us/sample - loss: 0.0095 - accuracy: 0.5662 - val_loss: 0.0092 - val_accuracy: 0.5849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25\n",
      "16109/16109 [==============================] - 1s 86us/sample - loss: 0.0094 - accuracy: 0.5676 - val_loss: 0.0091 - val_accuracy: 0.5861\n",
      "Epoch 4/25\n",
      "16109/16109 [==============================] - 1s 82us/sample - loss: 0.0094 - accuracy: 0.5692 - val_loss: 0.0091 - val_accuracy: 0.5852\n",
      "Epoch 5/25\n",
      "16109/16109 [==============================] - 1s 81us/sample - loss: 0.0094 - accuracy: 0.5699 - val_loss: 0.0091 - val_accuracy: 0.5909\n",
      "Epoch 6/25\n",
      "16109/16109 [==============================] - 1s 86us/sample - loss: 0.0094 - accuracy: 0.5715 - val_loss: 0.0091 - val_accuracy: 0.5884\n",
      "Epoch 7/25\n",
      "16109/16109 [==============================] - 1s 85us/sample - loss: 0.0093 - accuracy: 0.5719 - val_loss: 0.0091 - val_accuracy: 0.5886\n",
      "Epoch 8/25\n",
      "16109/16109 [==============================] - 1s 82us/sample - loss: 0.0093 - accuracy: 0.5712 - val_loss: 0.0091 - val_accuracy: 0.5847\n",
      "Epoch 9/25\n",
      "16109/16109 [==============================] - 2s 97us/sample - loss: 0.0093 - accuracy: 0.5710 - val_loss: 0.0091 - val_accuracy: 0.5847\n",
      "Epoch 10/25\n",
      "16109/16109 [==============================] - 1s 84us/sample - loss: 0.0093 - accuracy: 0.5734 - val_loss: 0.0091 - val_accuracy: 0.5906\n",
      "Epoch 11/25\n",
      "16109/16109 [==============================] - 1s 82us/sample - loss: 0.0093 - accuracy: 0.5742 - val_loss: 0.0090 - val_accuracy: 0.5916\n",
      "Epoch 12/25\n",
      "16109/16109 [==============================] - 1s 79us/sample - loss: 0.0093 - accuracy: 0.5755 - val_loss: 0.0090 - val_accuracy: 0.5931\n",
      "Epoch 13/25\n",
      "16109/16109 [==============================] - 1s 85us/sample - loss: 0.0093 - accuracy: 0.5753 - val_loss: 0.0090 - val_accuracy: 0.5814\n",
      "Epoch 14/25\n",
      "16109/16109 [==============================] - 2s 97us/sample - loss: 0.0092 - accuracy: 0.5768 - val_loss: 0.0090 - val_accuracy: 0.5871\n",
      "Epoch 15/25\n",
      "16109/16109 [==============================] - 1s 85us/sample - loss: 0.0092 - accuracy: 0.5764 - val_loss: 0.0090 - val_accuracy: 0.5881\n",
      "Epoch 16/25\n",
      "16109/16109 [==============================] - 1s 80us/sample - loss: 0.0092 - accuracy: 0.5771 - val_loss: 0.0090 - val_accuracy: 0.5916\n",
      "Epoch 17/25\n",
      "16109/16109 [==============================] - 1s 81us/sample - loss: 0.0092 - accuracy: 0.5779 - val_loss: 0.0090 - val_accuracy: 0.5911\n",
      "Epoch 18/25\n",
      "16109/16109 [==============================] - 1s 81us/sample - loss: 0.0092 - accuracy: 0.5776 - val_loss: 0.0089 - val_accuracy: 0.5919\n",
      "Epoch 19/25\n",
      "16109/16109 [==============================] - 1s 81us/sample - loss: 0.0092 - accuracy: 0.5789 - val_loss: 0.0090 - val_accuracy: 0.5983\n",
      "Epoch 20/25\n",
      "16109/16109 [==============================] - 1s 78us/sample - loss: 0.0092 - accuracy: 0.5787 - val_loss: 0.0089 - val_accuracy: 0.5904\n",
      "Epoch 21/25\n",
      "16109/16109 [==============================] - 1s 80us/sample - loss: 0.0092 - accuracy: 0.5800 - val_loss: 0.0090 - val_accuracy: 0.5926\n",
      "Epoch 22/25\n",
      "16109/16109 [==============================] - 1s 78us/sample - loss: 0.0092 - accuracy: 0.5809 - val_loss: 0.0089 - val_accuracy: 0.5963\n",
      "Epoch 23/25\n",
      "16109/16109 [==============================] - 1s 82us/sample - loss: 0.0091 - accuracy: 0.5797 - val_loss: 0.0089 - val_accuracy: 0.5943\n",
      "Epoch 24/25\n",
      "16109/16109 [==============================] - 1s 83us/sample - loss: 0.0091 - accuracy: 0.5810 - val_loss: 0.0090 - val_accuracy: 0.5961\n",
      "Epoch 25/25\n",
      "16109/16109 [==============================] - 3s 188us/sample - loss: 0.0091 - accuracy: 0.5808 - val_loss: 0.0089 - val_accuracy: 0.5953\n",
      "Training date and time : \n",
      "2020-04-08 05:24:17\n",
      "Train on 16090 samples, validate on 4023 samples\n",
      "Epoch 1/30\n",
      "16090/16090 [==============================] - 2s 107us/sample - loss: 0.0097 - accuracy: 0.5590 - val_loss: 0.0103 - val_accuracy: 0.5217\n",
      "Epoch 2/30\n",
      "16090/16090 [==============================] - 1s 81us/sample - loss: 0.0096 - accuracy: 0.5610 - val_loss: 0.0103 - val_accuracy: 0.5198\n",
      "Epoch 3/30\n",
      "16090/16090 [==============================] - 1s 81us/sample - loss: 0.0096 - accuracy: 0.5616 - val_loss: 0.0103 - val_accuracy: 0.5265\n",
      "Epoch 4/30\n",
      "16090/16090 [==============================] - 1s 87us/sample - loss: 0.0096 - accuracy: 0.5623 - val_loss: 0.0102 - val_accuracy: 0.5232\n",
      "Epoch 5/30\n",
      "16090/16090 [==============================] - 1s 80us/sample - loss: 0.0096 - accuracy: 0.5635 - val_loss: 0.0102 - val_accuracy: 0.5265\n",
      "Epoch 6/30\n",
      "16090/16090 [==============================] - 1s 87us/sample - loss: 0.0096 - accuracy: 0.5641 - val_loss: 0.0102 - val_accuracy: 0.5237\n",
      "Epoch 7/30\n",
      "16090/16090 [==============================] - 1s 80us/sample - loss: 0.0095 - accuracy: 0.5664 - val_loss: 0.0103 - val_accuracy: 0.5232\n",
      "Epoch 8/30\n",
      "16090/16090 [==============================] - 1s 87us/sample - loss: 0.0095 - accuracy: 0.5647 - val_loss: 0.0101 - val_accuracy: 0.5240\n",
      "Epoch 9/30\n",
      "16090/16090 [==============================] - 1s 82us/sample - loss: 0.0095 - accuracy: 0.5649 - val_loss: 0.0101 - val_accuracy: 0.5260\n",
      "Epoch 10/30\n",
      "16090/16090 [==============================] - 1s 81us/sample - loss: 0.0095 - accuracy: 0.5655 - val_loss: 0.0102 - val_accuracy: 0.5240\n",
      "Epoch 11/30\n",
      "16090/16090 [==============================] - 1s 84us/sample - loss: 0.0095 - accuracy: 0.5666 - val_loss: 0.0101 - val_accuracy: 0.5267\n",
      "Epoch 12/30\n",
      "16090/16090 [==============================] - 1s 83us/sample - loss: 0.0095 - accuracy: 0.5682 - val_loss: 0.0101 - val_accuracy: 0.5297\n",
      "Epoch 13/30\n",
      "16090/16090 [==============================] - 1s 86us/sample - loss: 0.0095 - accuracy: 0.5682 - val_loss: 0.0102 - val_accuracy: 0.5227\n",
      "Epoch 14/30\n",
      "16090/16090 [==============================] - 1s 81us/sample - loss: 0.0095 - accuracy: 0.5694 - val_loss: 0.0101 - val_accuracy: 0.5297\n",
      "Epoch 15/30\n",
      "16090/16090 [==============================] - 1s 93us/sample - loss: 0.0095 - accuracy: 0.5695 - val_loss: 0.0101 - val_accuracy: 0.5309\n",
      "Epoch 16/30\n",
      "16090/16090 [==============================] - 1s 80us/sample - loss: 0.0094 - accuracy: 0.5693 - val_loss: 0.0101 - val_accuracy: 0.5312\n",
      "Epoch 17/30\n",
      "16090/16090 [==============================] - 1s 85us/sample - loss: 0.0094 - accuracy: 0.5694 - val_loss: 0.0101 - val_accuracy: 0.5270\n",
      "Epoch 18/30\n",
      "16090/16090 [==============================] - 1s 85us/sample - loss: 0.0094 - accuracy: 0.5716 - val_loss: 0.0101 - val_accuracy: 0.5307\n",
      "Epoch 19/30\n",
      "16090/16090 [==============================] - 1s 80us/sample - loss: 0.0094 - accuracy: 0.5709 - val_loss: 0.0101 - val_accuracy: 0.5297\n",
      "Epoch 20/30\n",
      "16090/16090 [==============================] - 1s 79us/sample - loss: 0.0094 - accuracy: 0.5709 - val_loss: 0.0101 - val_accuracy: 0.5302\n",
      "Epoch 21/30\n",
      "16090/16090 [==============================] - 1s 86us/sample - loss: 0.0094 - accuracy: 0.5720 - val_loss: 0.0100 - val_accuracy: 0.5339\n",
      "Epoch 22/30\n",
      "16090/16090 [==============================] - 1s 79us/sample - loss: 0.0094 - accuracy: 0.5716 - val_loss: 0.0101 - val_accuracy: 0.5314\n",
      "Epoch 23/30\n",
      "16090/16090 [==============================] - 1s 84us/sample - loss: 0.0094 - accuracy: 0.5727 - val_loss: 0.0101 - val_accuracy: 0.5265\n",
      "Epoch 24/30\n",
      "16090/16090 [==============================] - 1s 81us/sample - loss: 0.0094 - accuracy: 0.5733 - val_loss: 0.0101 - val_accuracy: 0.5302\n",
      "Epoch 25/30\n",
      "16090/16090 [==============================] - 1s 81us/sample - loss: 0.0094 - accuracy: 0.5725 - val_loss: 0.0101 - val_accuracy: 0.5314\n",
      "Epoch 26/30\n",
      "16090/16090 [==============================] - 1s 83us/sample - loss: 0.0093 - accuracy: 0.5734 - val_loss: 0.0100 - val_accuracy: 0.5344\n",
      "Epoch 27/30\n",
      "16090/16090 [==============================] - 1s 80us/sample - loss: 0.0093 - accuracy: 0.5743 - val_loss: 0.0101 - val_accuracy: 0.5309\n",
      "Epoch 28/30\n",
      "16090/16090 [==============================] - 1s 78us/sample - loss: 0.0093 - accuracy: 0.5749 - val_loss: 0.0100 - val_accuracy: 0.5327\n",
      "Epoch 29/30\n",
      "16090/16090 [==============================] - 1s 85us/sample - loss: 0.0093 - accuracy: 0.5739 - val_loss: 0.0100 - val_accuracy: 0.5339\n",
      "Epoch 30/30\n",
      "16090/16090 [==============================] - 1s 82us/sample - loss: 0.0093 - accuracy: 0.5740 - val_loss: 0.0100 - val_accuracy: 0.5347\n",
      "Training date and time : \n",
      "2020-04-08 05:24:57\n",
      "Train on 16220 samples, validate on 4056 samples\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16220/16220 [==============================] - 2s 107us/sample - loss: 0.0093 - accuracy: 0.5745 - val_loss: 0.0089 - val_accuracy: 0.6023\n",
      "Epoch 2/35\n",
      "16220/16220 [==============================] - 1s 80us/sample - loss: 0.0092 - accuracy: 0.5774 - val_loss: 0.0089 - val_accuracy: 0.5996\n",
      "Epoch 3/35\n",
      "16220/16220 [==============================] - 1s 84us/sample - loss: 0.0092 - accuracy: 0.5775 - val_loss: 0.0088 - val_accuracy: 0.6050\n",
      "Epoch 4/35\n",
      "16220/16220 [==============================] - 1s 82us/sample - loss: 0.0092 - accuracy: 0.5806 - val_loss: 0.0089 - val_accuracy: 0.6058\n",
      "Epoch 5/35\n",
      "16220/16220 [==============================] - 1s 83us/sample - loss: 0.0092 - accuracy: 0.5801 - val_loss: 0.0089 - val_accuracy: 0.6021\n",
      "Epoch 6/35\n",
      "16220/16220 [==============================] - 1s 81us/sample - loss: 0.0091 - accuracy: 0.5816 - val_loss: 0.0088 - val_accuracy: 0.6097\n",
      "Epoch 7/35\n",
      "16220/16220 [==============================] - 1s 83us/sample - loss: 0.0091 - accuracy: 0.5828 - val_loss: 0.0089 - val_accuracy: 0.6065\n",
      "Epoch 8/35\n",
      "16220/16220 [==============================] - 1s 84us/sample - loss: 0.0091 - accuracy: 0.5823 - val_loss: 0.0088 - val_accuracy: 0.6050\n",
      "Epoch 9/35\n",
      "16220/16220 [==============================] - 1s 81us/sample - loss: 0.0091 - accuracy: 0.5855 - val_loss: 0.0088 - val_accuracy: 0.6016\n",
      "Epoch 10/35\n",
      "16220/16220 [==============================] - 1s 84us/sample - loss: 0.0091 - accuracy: 0.5848 - val_loss: 0.0087 - val_accuracy: 0.6065\n",
      "Epoch 11/35\n",
      "16220/16220 [==============================] - 1s 81us/sample - loss: 0.0090 - accuracy: 0.5867 - val_loss: 0.0088 - val_accuracy: 0.6058\n",
      "Epoch 12/35\n",
      "16220/16220 [==============================] - 1s 80us/sample - loss: 0.0090 - accuracy: 0.5872 - val_loss: 0.0088 - val_accuracy: 0.6045\n",
      "Epoch 13/35\n",
      "16220/16220 [==============================] - 1s 85us/sample - loss: 0.0090 - accuracy: 0.5866 - val_loss: 0.0087 - val_accuracy: 0.6095\n",
      "Epoch 14/35\n",
      "16220/16220 [==============================] - 1s 82us/sample - loss: 0.0090 - accuracy: 0.5882 - val_loss: 0.0087 - val_accuracy: 0.6095\n",
      "Epoch 15/35\n",
      "16220/16220 [==============================] - 1s 82us/sample - loss: 0.0090 - accuracy: 0.5893 - val_loss: 0.0087 - val_accuracy: 0.6090\n",
      "Epoch 16/35\n",
      "16220/16220 [==============================] - 1s 82us/sample - loss: 0.0090 - accuracy: 0.5900 - val_loss: 0.0087 - val_accuracy: 0.6031\n",
      "Epoch 17/35\n",
      "16220/16220 [==============================] - 1s 82us/sample - loss: 0.0089 - accuracy: 0.5902 - val_loss: 0.0087 - val_accuracy: 0.6090\n",
      "Epoch 18/35\n",
      "16220/16220 [==============================] - 1s 81us/sample - loss: 0.0089 - accuracy: 0.5914 - val_loss: 0.0087 - val_accuracy: 0.6109\n",
      "Epoch 19/35\n",
      "16220/16220 [==============================] - 1s 81us/sample - loss: 0.0089 - accuracy: 0.5928 - val_loss: 0.0087 - val_accuracy: 0.6092\n",
      "Epoch 20/35\n",
      "16220/16220 [==============================] - 1s 83us/sample - loss: 0.0089 - accuracy: 0.5940 - val_loss: 0.0087 - val_accuracy: 0.6124\n",
      "Epoch 21/35\n",
      "16220/16220 [==============================] - 1s 81us/sample - loss: 0.0089 - accuracy: 0.5928 - val_loss: 0.0087 - val_accuracy: 0.6132\n",
      "Epoch 22/35\n",
      "16220/16220 [==============================] - 1s 84us/sample - loss: 0.0089 - accuracy: 0.5940 - val_loss: 0.0087 - val_accuracy: 0.6075\n",
      "Epoch 23/35\n",
      "16220/16220 [==============================] - 1s 82us/sample - loss: 0.0089 - accuracy: 0.5948 - val_loss: 0.0086 - val_accuracy: 0.6100\n",
      "Epoch 24/35\n",
      "16220/16220 [==============================] - 1s 82us/sample - loss: 0.0089 - accuracy: 0.5940 - val_loss: 0.0086 - val_accuracy: 0.6112\n",
      "Epoch 25/35\n",
      "16220/16220 [==============================] - 1s 81us/sample - loss: 0.0088 - accuracy: 0.5964 - val_loss: 0.0087 - val_accuracy: 0.6097\n",
      "Epoch 26/35\n",
      "16220/16220 [==============================] - 1s 81us/sample - loss: 0.0088 - accuracy: 0.5962 - val_loss: 0.0087 - val_accuracy: 0.6087\n",
      "Epoch 27/35\n",
      "16220/16220 [==============================] - 1s 84us/sample - loss: 0.0088 - accuracy: 0.5969 - val_loss: 0.0087 - val_accuracy: 0.6092\n",
      "Epoch 28/35\n",
      "16220/16220 [==============================] - 1s 82us/sample - loss: 0.0088 - accuracy: 0.5973 - val_loss: 0.0086 - val_accuracy: 0.6082\n",
      "Epoch 29/35\n",
      "16220/16220 [==============================] - 1s 81us/sample - loss: 0.0088 - accuracy: 0.5989 - val_loss: 0.0086 - val_accuracy: 0.6100\n",
      "Epoch 30/35\n",
      "16220/16220 [==============================] - 1s 81us/sample - loss: 0.0088 - accuracy: 0.5975 - val_loss: 0.0087 - val_accuracy: 0.6087\n",
      "Epoch 31/35\n",
      "16220/16220 [==============================] - 1s 83us/sample - loss: 0.0088 - accuracy: 0.5998 - val_loss: 0.0086 - val_accuracy: 0.6127\n",
      "Epoch 32/35\n",
      "16220/16220 [==============================] - 1s 81us/sample - loss: 0.0088 - accuracy: 0.5994 - val_loss: 0.0086 - val_accuracy: 0.6112\n",
      "Epoch 33/35\n",
      "16220/16220 [==============================] - 1s 82us/sample - loss: 0.0088 - accuracy: 0.6001 - val_loss: 0.0086 - val_accuracy: 0.6085\n",
      "Epoch 34/35\n",
      "16220/16220 [==============================] - 1s 80us/sample - loss: 0.0087 - accuracy: 0.6015 - val_loss: 0.0086 - val_accuracy: 0.6077\n",
      "Epoch 35/35\n",
      "16220/16220 [==============================] - 1s 81us/sample - loss: 0.0087 - accuracy: 0.6014 - val_loss: 0.0086 - val_accuracy: 0.6107\n",
      "Training date and time : \n",
      "2020-04-08 05:25:45\n",
      "Train on 16275 samples, validate on 4069 samples\n",
      "Epoch 1/40\n",
      "16275/16275 [==============================] - 2s 112us/sample - loss: 0.0099 - accuracy: 0.5476 - val_loss: 0.0101 - val_accuracy: 0.5345\n",
      "Epoch 2/40\n",
      "16275/16275 [==============================] - 1s 85us/sample - loss: 0.0098 - accuracy: 0.5492 - val_loss: 0.0101 - val_accuracy: 0.5358\n",
      "Epoch 3/40\n",
      "16275/16275 [==============================] - 1s 81us/sample - loss: 0.0098 - accuracy: 0.5511 - val_loss: 0.0101 - val_accuracy: 0.5358\n",
      "Epoch 4/40\n",
      "16275/16275 [==============================] - 1s 81us/sample - loss: 0.0098 - accuracy: 0.5534 - val_loss: 0.0100 - val_accuracy: 0.5385\n",
      "Epoch 5/40\n",
      "16275/16275 [==============================] - 1s 84us/sample - loss: 0.0098 - accuracy: 0.5524 - val_loss: 0.0100 - val_accuracy: 0.5434\n",
      "Epoch 6/40\n",
      "16275/16275 [==============================] - 2s 93us/sample - loss: 0.0097 - accuracy: 0.5547 - val_loss: 0.0100 - val_accuracy: 0.5458\n",
      "Epoch 7/40\n",
      "16275/16275 [==============================] - 1s 82us/sample - loss: 0.0097 - accuracy: 0.5553 - val_loss: 0.0100 - val_accuracy: 0.5417\n",
      "Epoch 8/40\n",
      "16275/16275 [==============================] - 1s 83us/sample - loss: 0.0097 - accuracy: 0.5558 - val_loss: 0.0100 - val_accuracy: 0.5441\n",
      "Epoch 9/40\n",
      "16275/16275 [==============================] - 2s 94us/sample - loss: 0.0097 - accuracy: 0.5566 - val_loss: 0.0100 - val_accuracy: 0.5409\n",
      "Epoch 10/40\n",
      "16275/16275 [==============================] - 1s 85us/sample - loss: 0.0097 - accuracy: 0.5574 - val_loss: 0.0100 - val_accuracy: 0.5412\n",
      "Epoch 11/40\n",
      "16275/16275 [==============================] - 1s 86us/sample - loss: 0.0097 - accuracy: 0.5588 - val_loss: 0.0099 - val_accuracy: 0.5431\n",
      "Epoch 12/40\n",
      "16275/16275 [==============================] - 1s 86us/sample - loss: 0.0096 - accuracy: 0.5583 - val_loss: 0.0099 - val_accuracy: 0.5463\n",
      "Epoch 13/40\n",
      "16275/16275 [==============================] - 1s 84us/sample - loss: 0.0096 - accuracy: 0.5602 - val_loss: 0.0099 - val_accuracy: 0.5424\n",
      "Epoch 14/40\n",
      "16275/16275 [==============================] - 1s 90us/sample - loss: 0.0096 - accuracy: 0.5602 - val_loss: 0.0099 - val_accuracy: 0.5453\n",
      "Epoch 15/40\n",
      "16275/16275 [==============================] - 1s 85us/sample - loss: 0.0096 - accuracy: 0.5618 - val_loss: 0.0099 - val_accuracy: 0.5466\n",
      "Epoch 16/40\n",
      "16275/16275 [==============================] - 1s 81us/sample - loss: 0.0096 - accuracy: 0.5629 - val_loss: 0.0099 - val_accuracy: 0.5476\n",
      "Epoch 17/40\n",
      "16275/16275 [==============================] - 1s 84us/sample - loss: 0.0096 - accuracy: 0.5630 - val_loss: 0.0099 - val_accuracy: 0.5485\n",
      "Epoch 18/40\n",
      "16275/16275 [==============================] - 1s 85us/sample - loss: 0.0096 - accuracy: 0.5637 - val_loss: 0.0099 - val_accuracy: 0.5471\n",
      "Epoch 19/40\n",
      "16275/16275 [==============================] - 1s 85us/sample - loss: 0.0095 - accuracy: 0.5641 - val_loss: 0.0099 - val_accuracy: 0.5483\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16275/16275 [==============================] - 1s 92us/sample - loss: 0.0095 - accuracy: 0.5642 - val_loss: 0.0098 - val_accuracy: 0.5498\n",
      "Epoch 21/40\n",
      "16275/16275 [==============================] - 1s 79us/sample - loss: 0.0095 - accuracy: 0.5653 - val_loss: 0.0099 - val_accuracy: 0.5453\n",
      "Epoch 22/40\n",
      "16275/16275 [==============================] - 1s 83us/sample - loss: 0.0095 - accuracy: 0.5668 - val_loss: 0.0098 - val_accuracy: 0.5478\n",
      "Epoch 23/40\n",
      "16275/16275 [==============================] - 1s 82us/sample - loss: 0.0095 - accuracy: 0.5665 - val_loss: 0.0098 - val_accuracy: 0.5495\n",
      "Epoch 24/40\n",
      "16275/16275 [==============================] - 1s 82us/sample - loss: 0.0095 - accuracy: 0.5667 - val_loss: 0.0098 - val_accuracy: 0.5525\n",
      "Epoch 25/40\n",
      "16275/16275 [==============================] - 2s 93us/sample - loss: 0.0095 - accuracy: 0.5661 - val_loss: 0.0098 - val_accuracy: 0.5500\n",
      "Epoch 26/40\n",
      "16275/16275 [==============================] - 2s 100us/sample - loss: 0.0095 - accuracy: 0.5681 - val_loss: 0.0098 - val_accuracy: 0.5500\n",
      "Epoch 27/40\n",
      "16275/16275 [==============================] - 1s 82us/sample - loss: 0.0095 - accuracy: 0.5670 - val_loss: 0.0098 - val_accuracy: 0.5515\n",
      "Epoch 28/40\n",
      "16275/16275 [==============================] - 1s 90us/sample - loss: 0.0095 - accuracy: 0.5689 - val_loss: 0.0098 - val_accuracy: 0.5498\n",
      "Epoch 29/40\n",
      "16275/16275 [==============================] - 1s 87us/sample - loss: 0.0094 - accuracy: 0.5687 - val_loss: 0.0098 - val_accuracy: 0.5525\n",
      "Epoch 30/40\n",
      "16275/16275 [==============================] - 2s 94us/sample - loss: 0.0094 - accuracy: 0.5683 - val_loss: 0.0098 - val_accuracy: 0.5505\n",
      "Epoch 31/40\n",
      "16275/16275 [==============================] - 2s 96us/sample - loss: 0.0094 - accuracy: 0.5685 - val_loss: 0.0098 - val_accuracy: 0.5500\n",
      "Epoch 32/40\n",
      "16275/16275 [==============================] - 1s 89us/sample - loss: 0.0094 - accuracy: 0.5690 - val_loss: 0.0098 - val_accuracy: 0.5525\n",
      "Epoch 33/40\n",
      "16275/16275 [==============================] - 1s 82us/sample - loss: 0.0094 - accuracy: 0.5714 - val_loss: 0.0098 - val_accuracy: 0.5520\n",
      "Epoch 34/40\n",
      "16275/16275 [==============================] - 1s 81us/sample - loss: 0.0094 - accuracy: 0.5703 - val_loss: 0.0098 - val_accuracy: 0.5532\n",
      "Epoch 35/40\n",
      "16275/16275 [==============================] - 1s 84us/sample - loss: 0.0094 - accuracy: 0.5712 - val_loss: 0.0098 - val_accuracy: 0.5507\n",
      "Epoch 36/40\n",
      "16275/16275 [==============================] - 1s 89us/sample - loss: 0.0094 - accuracy: 0.5728 - val_loss: 0.0098 - val_accuracy: 0.5557\n",
      "Epoch 37/40\n",
      "16275/16275 [==============================] - 1s 86us/sample - loss: 0.0094 - accuracy: 0.5720 - val_loss: 0.0098 - val_accuracy: 0.5537\n",
      "Epoch 38/40\n",
      "16275/16275 [==============================] - 1s 82us/sample - loss: 0.0094 - accuracy: 0.5726 - val_loss: 0.0097 - val_accuracy: 0.5569\n",
      "Epoch 39/40\n",
      "16275/16275 [==============================] - 2s 97us/sample - loss: 0.0094 - accuracy: 0.5736 - val_loss: 0.0098 - val_accuracy: 0.5512\n",
      "Epoch 40/40\n",
      "16275/16275 [==============================] - 1s 84us/sample - loss: 0.0094 - accuracy: 0.5739 - val_loss: 0.0097 - val_accuracy: 0.5571\n",
      "Training date and time : \n",
      "2020-04-08 05:26:41\n",
      "Train on 16106 samples, validate on 4027 samples\n",
      "Epoch 1/45\n",
      "16106/16106 [==============================] - 2s 106us/sample - loss: 0.0092 - accuracy: 0.5887 - val_loss: 0.0084 - val_accuracy: 0.6377\n",
      "Epoch 2/45\n",
      "16106/16106 [==============================] - 1s 86us/sample - loss: 0.0092 - accuracy: 0.5907 - val_loss: 0.0084 - val_accuracy: 0.6315\n",
      "Epoch 3/45\n",
      "16106/16106 [==============================] - 1s 81us/sample - loss: 0.0091 - accuracy: 0.5894 - val_loss: 0.0084 - val_accuracy: 0.6370\n",
      "Epoch 4/45\n",
      "16106/16106 [==============================] - 1s 90us/sample - loss: 0.0091 - accuracy: 0.5933 - val_loss: 0.0084 - val_accuracy: 0.6362\n",
      "Epoch 5/45\n",
      "16106/16106 [==============================] - 1s 79us/sample - loss: 0.0091 - accuracy: 0.5933 - val_loss: 0.0083 - val_accuracy: 0.6399\n",
      "Epoch 6/45\n",
      "16106/16106 [==============================] - 1s 79us/sample - loss: 0.0091 - accuracy: 0.5944 - val_loss: 0.0083 - val_accuracy: 0.6377\n",
      "Epoch 7/45\n",
      "16106/16106 [==============================] - 1s 83us/sample - loss: 0.0091 - accuracy: 0.5981 - val_loss: 0.0082 - val_accuracy: 0.6419\n",
      "Epoch 8/45\n",
      "16106/16106 [==============================] - 1s 83us/sample - loss: 0.0090 - accuracy: 0.5974 - val_loss: 0.0083 - val_accuracy: 0.6347\n",
      "Epoch 9/45\n",
      "16106/16106 [==============================] - 1s 82us/sample - loss: 0.0090 - accuracy: 0.5977 - val_loss: 0.0083 - val_accuracy: 0.6427\n",
      "Epoch 10/45\n",
      "16106/16106 [==============================] - 1s 83us/sample - loss: 0.0090 - accuracy: 0.5997 - val_loss: 0.0082 - val_accuracy: 0.6412\n",
      "Epoch 11/45\n",
      "16106/16106 [==============================] - 1s 84us/sample - loss: 0.0090 - accuracy: 0.5987 - val_loss: 0.0082 - val_accuracy: 0.6444\n",
      "Epoch 12/45\n",
      "16106/16106 [==============================] - 1s 82us/sample - loss: 0.0090 - accuracy: 0.6005 - val_loss: 0.0082 - val_accuracy: 0.6456\n",
      "Epoch 13/45\n",
      "16106/16106 [==============================] - 1s 80us/sample - loss: 0.0090 - accuracy: 0.6022 - val_loss: 0.0082 - val_accuracy: 0.6407\n",
      "Epoch 14/45\n",
      "16106/16106 [==============================] - 1s 83us/sample - loss: 0.0089 - accuracy: 0.6041 - val_loss: 0.0082 - val_accuracy: 0.6429\n",
      "Epoch 15/45\n",
      "16106/16106 [==============================] - 1s 83us/sample - loss: 0.0089 - accuracy: 0.6038 - val_loss: 0.0082 - val_accuracy: 0.6449\n",
      "Epoch 16/45\n",
      "16106/16106 [==============================] - 1s 85us/sample - loss: 0.0089 - accuracy: 0.6031 - val_loss: 0.0082 - val_accuracy: 0.6432\n",
      "Epoch 17/45\n",
      "16106/16106 [==============================] - 1s 80us/sample - loss: 0.0089 - accuracy: 0.6044 - val_loss: 0.0081 - val_accuracy: 0.6456\n",
      "Epoch 18/45\n",
      "16106/16106 [==============================] - 1s 84us/sample - loss: 0.0089 - accuracy: 0.6051 - val_loss: 0.0081 - val_accuracy: 0.6474\n",
      "Epoch 19/45\n",
      "16106/16106 [==============================] - 1s 89us/sample - loss: 0.0089 - accuracy: 0.6054 - val_loss: 0.0082 - val_accuracy: 0.6442\n",
      "Epoch 20/45\n",
      "16106/16106 [==============================] - 1s 82us/sample - loss: 0.0089 - accuracy: 0.6075 - val_loss: 0.0081 - val_accuracy: 0.6466\n",
      "Epoch 21/45\n",
      "16106/16106 [==============================] - 1s 86us/sample - loss: 0.0089 - accuracy: 0.6072 - val_loss: 0.0082 - val_accuracy: 0.6444\n",
      "Epoch 22/45\n",
      "16106/16106 [==============================] - 1s 85us/sample - loss: 0.0088 - accuracy: 0.6077 - val_loss: 0.0081 - val_accuracy: 0.6476\n",
      "Epoch 23/45\n",
      "16106/16106 [==============================] - 1s 85us/sample - loss: 0.0088 - accuracy: 0.6075 - val_loss: 0.0080 - val_accuracy: 0.6494\n",
      "Epoch 24/45\n",
      "16106/16106 [==============================] - 1s 80us/sample - loss: 0.0088 - accuracy: 0.6082 - val_loss: 0.0080 - val_accuracy: 0.6514\n",
      "Epoch 25/45\n",
      "16106/16106 [==============================] - 3s 183us/sample - loss: 0.0088 - accuracy: 0.6096 - val_loss: 0.0082 - val_accuracy: 0.6442\n",
      "Epoch 26/45\n",
      "16106/16106 [==============================] - 1s 85us/sample - loss: 0.0088 - accuracy: 0.6110 - val_loss: 0.0080 - val_accuracy: 0.6504\n",
      "Epoch 27/45\n",
      "16106/16106 [==============================] - 1s 84us/sample - loss: 0.0088 - accuracy: 0.6096 - val_loss: 0.0081 - val_accuracy: 0.6481\n",
      "Epoch 28/45\n",
      "16106/16106 [==============================] - 1s 84us/sample - loss: 0.0088 - accuracy: 0.6094 - val_loss: 0.0080 - val_accuracy: 0.6516\n",
      "Epoch 29/45\n",
      "16106/16106 [==============================] - 1s 85us/sample - loss: 0.0088 - accuracy: 0.6119 - val_loss: 0.0081 - val_accuracy: 0.6456\n",
      "Epoch 30/45\n",
      "16106/16106 [==============================] - 1s 85us/sample - loss: 0.0088 - accuracy: 0.6108 - val_loss: 0.0081 - val_accuracy: 0.6461\n",
      "Epoch 31/45\n",
      "16106/16106 [==============================] - 1s 91us/sample - loss: 0.0087 - accuracy: 0.6120 - val_loss: 0.0081 - val_accuracy: 0.6417\n",
      "Epoch 32/45\n",
      "16106/16106 [==============================] - 1s 88us/sample - loss: 0.0087 - accuracy: 0.6126 - val_loss: 0.0080 - val_accuracy: 0.6486\n",
      "Epoch 33/45\n",
      "16106/16106 [==============================] - 1s 82us/sample - loss: 0.0087 - accuracy: 0.6129 - val_loss: 0.0080 - val_accuracy: 0.6526\n",
      "Epoch 34/45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16106/16106 [==============================] - 1s 80us/sample - loss: 0.0087 - accuracy: 0.6136 - val_loss: 0.0080 - val_accuracy: 0.6496\n",
      "Epoch 35/45\n",
      "16106/16106 [==============================] - 1s 81us/sample - loss: 0.0087 - accuracy: 0.6136 - val_loss: 0.0080 - val_accuracy: 0.6518\n",
      "Epoch 36/45\n",
      "16106/16106 [==============================] - 1s 80us/sample - loss: 0.0087 - accuracy: 0.6138 - val_loss: 0.0080 - val_accuracy: 0.6499\n",
      "Epoch 37/45\n",
      "16106/16106 [==============================] - 1s 88us/sample - loss: 0.0087 - accuracy: 0.6160 - val_loss: 0.0079 - val_accuracy: 0.6511\n",
      "Epoch 38/45\n",
      "16106/16106 [==============================] - 1s 81us/sample - loss: 0.0087 - accuracy: 0.6147 - val_loss: 0.0079 - val_accuracy: 0.6566\n",
      "Epoch 39/45\n",
      "16106/16106 [==============================] - 1s 82us/sample - loss: 0.0087 - accuracy: 0.6165 - val_loss: 0.0079 - val_accuracy: 0.6566\n",
      "Epoch 40/45\n",
      "16106/16106 [==============================] - 1s 79us/sample - loss: 0.0087 - accuracy: 0.6160 - val_loss: 0.0080 - val_accuracy: 0.6469\n",
      "Epoch 41/45\n",
      "16106/16106 [==============================] - 1s 81us/sample - loss: 0.0087 - accuracy: 0.6162 - val_loss: 0.0079 - val_accuracy: 0.6528\n",
      "Epoch 42/45\n",
      "16106/16106 [==============================] - 1s 80us/sample - loss: 0.0086 - accuracy: 0.6177 - val_loss: 0.0079 - val_accuracy: 0.6556\n",
      "Epoch 43/45\n",
      "16106/16106 [==============================] - 1s 85us/sample - loss: 0.0086 - accuracy: 0.6174 - val_loss: 0.0080 - val_accuracy: 0.6538\n",
      "Epoch 44/45\n",
      "16106/16106 [==============================] - 1s 80us/sample - loss: 0.0086 - accuracy: 0.6167 - val_loss: 0.0080 - val_accuracy: 0.6469\n",
      "Epoch 45/45\n",
      "16106/16106 [==============================] - 1s 83us/sample - loss: 0.0086 - accuracy: 0.6180 - val_loss: 0.0079 - val_accuracy: 0.6573\n",
      "Training date and time : \n",
      "2020-04-08 05:27:44\n",
      "Train on 16076 samples, validate on 4020 samples\n",
      "Epoch 1/50\n",
      "16076/16076 [==============================] - 2s 106us/sample - loss: 0.0090 - accuracy: 0.5965 - val_loss: 0.0106 - val_accuracy: 0.5112\n",
      "Epoch 2/50\n",
      "16076/16076 [==============================] - 1s 83us/sample - loss: 0.0089 - accuracy: 0.5990 - val_loss: 0.0108 - val_accuracy: 0.4983\n",
      "Epoch 3/50\n",
      "16076/16076 [==============================] - 1s 84us/sample - loss: 0.0089 - accuracy: 0.5988 - val_loss: 0.0108 - val_accuracy: 0.5017\n",
      "Epoch 4/50\n",
      "16076/16076 [==============================] - 1s 83us/sample - loss: 0.0089 - accuracy: 0.5988 - val_loss: 0.0108 - val_accuracy: 0.5005\n",
      "Epoch 5/50\n",
      "16076/16076 [==============================] - 1s 82us/sample - loss: 0.0089 - accuracy: 0.6002 - val_loss: 0.0105 - val_accuracy: 0.5137\n",
      "Epoch 6/50\n",
      "16076/16076 [==============================] - 1s 82us/sample - loss: 0.0089 - accuracy: 0.6021 - val_loss: 0.0106 - val_accuracy: 0.5095\n",
      "Epoch 7/50\n",
      "16076/16076 [==============================] - 1s 80us/sample - loss: 0.0089 - accuracy: 0.6020 - val_loss: 0.0105 - val_accuracy: 0.5182\n",
      "Epoch 8/50\n",
      "16076/16076 [==============================] - 1s 86us/sample - loss: 0.0088 - accuracy: 0.6022 - val_loss: 0.0108 - val_accuracy: 0.5007\n",
      "Epoch 9/50\n",
      "16076/16076 [==============================] - 1s 81us/sample - loss: 0.0088 - accuracy: 0.6041 - val_loss: 0.0106 - val_accuracy: 0.5114\n",
      "Epoch 10/50\n",
      "16076/16076 [==============================] - 1s 82us/sample - loss: 0.0088 - accuracy: 0.6050 - val_loss: 0.0108 - val_accuracy: 0.5002\n",
      "Epoch 11/50\n",
      "16076/16076 [==============================] - 1s 83us/sample - loss: 0.0088 - accuracy: 0.6048 - val_loss: 0.0106 - val_accuracy: 0.5075\n",
      "Epoch 12/50\n",
      "16076/16076 [==============================] - 1s 81us/sample - loss: 0.0088 - accuracy: 0.6042 - val_loss: 0.0106 - val_accuracy: 0.5102\n",
      "Epoch 13/50\n",
      "16076/16076 [==============================] - 1s 83us/sample - loss: 0.0088 - accuracy: 0.6057 - val_loss: 0.0109 - val_accuracy: 0.4910\n",
      "Epoch 14/50\n",
      "16076/16076 [==============================] - 1s 85us/sample - loss: 0.0088 - accuracy: 0.6071 - val_loss: 0.0110 - val_accuracy: 0.4918\n",
      "Epoch 15/50\n",
      "16076/16076 [==============================] - 1s 77us/sample - loss: 0.0088 - accuracy: 0.6077 - val_loss: 0.0107 - val_accuracy: 0.5080\n",
      "Epoch 16/50\n",
      "16076/16076 [==============================] - 1s 85us/sample - loss: 0.0087 - accuracy: 0.6074 - val_loss: 0.0107 - val_accuracy: 0.5022\n",
      "Epoch 17/50\n",
      "16076/16076 [==============================] - 1s 83us/sample - loss: 0.0087 - accuracy: 0.6087 - val_loss: 0.0109 - val_accuracy: 0.4923\n",
      "Epoch 18/50\n",
      "16076/16076 [==============================] - 1s 80us/sample - loss: 0.0087 - accuracy: 0.6069 - val_loss: 0.0109 - val_accuracy: 0.4933\n",
      "Epoch 19/50\n",
      "16076/16076 [==============================] - 1s 80us/sample - loss: 0.0087 - accuracy: 0.6092 - val_loss: 0.0110 - val_accuracy: 0.4878\n",
      "Epoch 20/50\n",
      "16076/16076 [==============================] - 1s 85us/sample - loss: 0.0087 - accuracy: 0.6103 - val_loss: 0.0105 - val_accuracy: 0.5152\n",
      "Epoch 21/50\n",
      "16076/16076 [==============================] - 1s 81us/sample - loss: 0.0087 - accuracy: 0.6087 - val_loss: 0.0107 - val_accuracy: 0.5020\n",
      "Epoch 22/50\n",
      "16076/16076 [==============================] - 1s 79us/sample - loss: 0.0087 - accuracy: 0.6108 - val_loss: 0.0108 - val_accuracy: 0.4988\n",
      "Epoch 23/50\n",
      "16076/16076 [==============================] - 1s 83us/sample - loss: 0.0087 - accuracy: 0.6118 - val_loss: 0.0109 - val_accuracy: 0.4940\n",
      "Epoch 24/50\n",
      "16076/16076 [==============================] - 1s 86us/sample - loss: 0.0087 - accuracy: 0.6099 - val_loss: 0.0110 - val_accuracy: 0.4970\n",
      "Epoch 25/50\n",
      "16076/16076 [==============================] - 1s 81us/sample - loss: 0.0087 - accuracy: 0.6109 - val_loss: 0.0109 - val_accuracy: 0.4938\n",
      "Epoch 26/50\n",
      "16076/16076 [==============================] - 1s 85us/sample - loss: 0.0087 - accuracy: 0.6122 - val_loss: 0.0111 - val_accuracy: 0.4871\n",
      "Epoch 27/50\n",
      "16076/16076 [==============================] - 1s 81us/sample - loss: 0.0086 - accuracy: 0.6113 - val_loss: 0.0110 - val_accuracy: 0.4913\n",
      "Epoch 28/50\n",
      "16076/16076 [==============================] - 1s 82us/sample - loss: 0.0086 - accuracy: 0.6131 - val_loss: 0.0109 - val_accuracy: 0.4943\n",
      "Epoch 29/50\n",
      "16076/16076 [==============================] - 1s 83us/sample - loss: 0.0086 - accuracy: 0.6122 - val_loss: 0.0109 - val_accuracy: 0.4910\n",
      "Epoch 30/50\n",
      "16076/16076 [==============================] - 1s 82us/sample - loss: 0.0086 - accuracy: 0.6127 - val_loss: 0.0108 - val_accuracy: 0.4933\n",
      "Epoch 31/50\n",
      "16076/16076 [==============================] - 1s 90us/sample - loss: 0.0086 - accuracy: 0.6146 - val_loss: 0.0108 - val_accuracy: 0.5017\n",
      "Epoch 32/50\n",
      "16076/16076 [==============================] - 1s 83us/sample - loss: 0.0086 - accuracy: 0.6131 - val_loss: 0.0112 - val_accuracy: 0.4771\n",
      "Epoch 33/50\n",
      "16076/16076 [==============================] - 1s 82us/sample - loss: 0.0086 - accuracy: 0.6138 - val_loss: 0.0110 - val_accuracy: 0.4861\n",
      "Epoch 34/50\n",
      "16076/16076 [==============================] - 1s 81us/sample - loss: 0.0086 - accuracy: 0.6140 - val_loss: 0.0109 - val_accuracy: 0.4905\n",
      "Epoch 35/50\n",
      "16076/16076 [==============================] - 1s 82us/sample - loss: 0.0086 - accuracy: 0.6140 - val_loss: 0.0109 - val_accuracy: 0.4918\n",
      "Epoch 36/50\n",
      "16076/16076 [==============================] - 1s 82us/sample - loss: 0.0086 - accuracy: 0.6156 - val_loss: 0.0107 - val_accuracy: 0.5077\n",
      "Epoch 37/50\n",
      "16076/16076 [==============================] - 1s 84us/sample - loss: 0.0086 - accuracy: 0.6148 - val_loss: 0.0111 - val_accuracy: 0.4856\n",
      "Epoch 38/50\n",
      "16076/16076 [==============================] - 1s 83us/sample - loss: 0.0086 - accuracy: 0.6169 - val_loss: 0.0109 - val_accuracy: 0.4925\n",
      "Epoch 39/50\n",
      "16076/16076 [==============================] - 1s 86us/sample - loss: 0.0085 - accuracy: 0.6161 - val_loss: 0.0111 - val_accuracy: 0.4833\n",
      "Epoch 40/50\n",
      "16076/16076 [==============================] - 1s 82us/sample - loss: 0.0085 - accuracy: 0.6164 - val_loss: 0.0108 - val_accuracy: 0.4998\n",
      "Epoch 41/50\n",
      "16076/16076 [==============================] - 1s 79us/sample - loss: 0.0085 - accuracy: 0.6177 - val_loss: 0.0109 - val_accuracy: 0.4935\n",
      "Epoch 42/50\n",
      "16076/16076 [==============================] - 1s 86us/sample - loss: 0.0085 - accuracy: 0.6176 - val_loss: 0.0110 - val_accuracy: 0.4893\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16076/16076 [==============================] - 1s 83us/sample - loss: 0.0085 - accuracy: 0.6167 - val_loss: 0.0108 - val_accuracy: 0.4978\n",
      "Epoch 44/50\n",
      "16076/16076 [==============================] - 1s 84us/sample - loss: 0.0085 - accuracy: 0.6176 - val_loss: 0.0111 - val_accuracy: 0.4833\n",
      "Epoch 45/50\n",
      "16076/16076 [==============================] - 1s 82us/sample - loss: 0.0085 - accuracy: 0.6172 - val_loss: 0.0108 - val_accuracy: 0.4988\n",
      "Epoch 46/50\n",
      "16076/16076 [==============================] - 1s 82us/sample - loss: 0.0085 - accuracy: 0.6192 - val_loss: 0.0111 - val_accuracy: 0.4851\n",
      "Epoch 47/50\n",
      "16076/16076 [==============================] - 1s 79us/sample - loss: 0.0085 - accuracy: 0.6179 - val_loss: 0.0110 - val_accuracy: 0.4883\n",
      "Epoch 48/50\n",
      "16076/16076 [==============================] - 1s 78us/sample - loss: 0.0085 - accuracy: 0.6192 - val_loss: 0.0111 - val_accuracy: 0.4813\n",
      "Epoch 49/50\n",
      "16076/16076 [==============================] - 1s 82us/sample - loss: 0.0085 - accuracy: 0.6186 - val_loss: 0.0106 - val_accuracy: 0.5104\n",
      "Epoch 50/50\n",
      "16076/16076 [==============================] - 1s 81us/sample - loss: 0.0085 - accuracy: 0.6190 - val_loss: 0.0110 - val_accuracy: 0.4891\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(model_list)):\n",
    "    compile_model(model_list[i])\n",
    "    fit_model_with_datasets(model_list[i], (i+1)*5, local_data[i][0], local_data[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see how these models are different from each other, compared to the base model(before training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list.sort(key=lambda m : semantic_drift.l2_distance(model1, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_list = list(np.arange(0, 1.05, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_weights_list_per_pi = list()\n",
    "for model_comp in model_list:\n",
    "    weights = [model1.get_weights(), model_comp.get_weights()]\n",
    "    agg_weights_list = list()\n",
    "    for theta in theta_list:\n",
    "        agg_weights = list()\n",
    "        for weights_list_tuple in zip(*weights):\n",
    "            agg_weights.append(np.array([np.average(np.array(w), axis=0, weights=[1. - theta, theta]) for w in zip(*weights_list_tuple)]))\n",
    "        agg_weights_list.append(agg_weights)\n",
    "    agg_weights_list_per_pi.append(agg_weights_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_list = [semantic_drift.l2_distance(standard_model, m) for m in model_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.4901943232478577e-08,\n",
       " 8.552184075957508e-08,\n",
       " 1.1138670458294076e-07,\n",
       " 1.9842548400837185e-07,\n",
       " 3.122630650372902e-07,\n",
       " 3.8301490482357875e-07,\n",
       " 6.656196983349213e-07,\n",
       " 7.014420164946945e-07,\n",
       " 8.524899299672931e-07,\n",
       " 9.079676970388701e-07]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.meshgrid(np.array(theta_list), np.array(sorted(dist_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.zeros(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0089 - accuracy: 0.6010\n",
      "69393/69393 [==============================] - 4s 62us/sample - loss: 0.0089 - accuracy: 0.6015\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0089 - accuracy: 0.6016\n",
      "69393/69393 [==============================] - 5s 66us/sample - loss: 0.0089 - accuracy: 0.6015\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6016\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0089 - accuracy: 0.6016\n",
      "69393/69393 [==============================] - 4s 62us/sample - loss: 0.0089 - accuracy: 0.6014\n",
      "69393/69393 [==============================] - 5s 66us/sample - loss: 0.0089 - accuracy: 0.6006\n",
      "69393/69393 [==============================] - 5s 66us/sample - loss: 0.0089 - accuracy: 0.6004\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0089 - accuracy: 0.5997\n",
      "69393/69393 [==============================] - 4s 62us/sample - loss: 0.0089 - accuracy: 0.5990\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.5984\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0089 - accuracy: 0.5976\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0089 - accuracy: 0.5967\n",
      "69393/69393 [==============================] - 5s 76us/sample - loss: 0.0090 - accuracy: 0.5954\n",
      "69393/69393 [==============================] - 5s 67us/sample - loss: 0.0090 - accuracy: 0.5943\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0090 - accuracy: 0.5928\n",
      "69393/69393 [==============================] - 4s 64us/sample - loss: 0.0090 - accuracy: 0.5914\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0091 - accuracy: 0.5894\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0091 - accuracy: 0.5876\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0091 - accuracy: 0.5859\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6010\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0089 - accuracy: 0.6017\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6023\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6028\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6031\n",
      "69393/69393 [==============================] - 5s 68us/sample - loss: 0.0089 - accuracy: 0.6036\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0089 - accuracy: 0.6038\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0089 - accuracy: 0.6042\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0088 - accuracy: 0.6044\n",
      "69393/69393 [==============================] - 4s 64us/sample - loss: 0.0088 - accuracy: 0.6047\n",
      "69393/69393 [==============================] - 5s 68us/sample - loss: 0.0088 - accuracy: 0.6048\n",
      "69393/69393 [==============================] - 5s 65us/sample - loss: 0.0088 - accuracy: 0.6048\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0088 - accuracy: 0.6048\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0088 - accuracy: 0.6046\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0088 - accuracy: 0.6046\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0088 - accuracy: 0.6041\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6037\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6033\n",
      "69393/69393 [==============================] - 5s 66us/sample - loss: 0.0089 - accuracy: 0.6029\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0089 - accuracy: 0.6025\n",
      "69393/69393 [==============================] - 4s 58us/sample - loss: 0.0089 - accuracy: 0.6021\n",
      "69393/69393 [==============================] - 4s 63us/sample - loss: 0.0089 - accuracy: 0.6010\n",
      "69393/69393 [==============================] - 5s 65us/sample - loss: 0.0089 - accuracy: 0.6014\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6004\n",
      "69393/69393 [==============================] - 4s 58us/sample - loss: 0.0090 - accuracy: 0.5994\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0090 - accuracy: 0.5975\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0090 - accuracy: 0.5956\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0091 - accuracy: 0.5928\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0091 - accuracy: 0.5898\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0092 - accuracy: 0.5860\n",
      "69393/69393 [==============================] - 4s 62us/sample - loss: 0.0092 - accuracy: 0.5818\n",
      "69393/69393 [==============================] - 5s 67us/sample - loss: 0.0093 - accuracy: 0.5766\n",
      "69393/69393 [==============================] - 4s 63us/sample - loss: 0.0094 - accuracy: 0.5711\n",
      "69393/69393 [==============================] - 6s 80us/sample - loss: 0.0095 - accuracy: 0.5661\n",
      "69393/69393 [==============================] - 5s 68us/sample - loss: 0.0095 - accuracy: 0.5617\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0096 - accuracy: 0.5569\n",
      "69393/69393 [==============================] - 5s 66us/sample - loss: 0.0097 - accuracy: 0.5528\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0098 - accuracy: 0.5488\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0098 - accuracy: 0.5451\n",
      "69393/69393 [==============================] - 4s 64us/sample - loss: 0.0099 - accuracy: 0.5411\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0100 - accuracy: 0.5378\n",
      "69393/69393 [==============================] - 4s 62us/sample - loss: 0.0101 - accuracy: 0.5345\n",
      "69393/69393 [==============================] - 4s 62us/sample - loss: 0.0089 - accuracy: 0.6010\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0089 - accuracy: 0.6015\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6020\n",
      "69393/69393 [==============================] - 4s 63us/sample - loss: 0.0089 - accuracy: 0.6019\n",
      "69393/69393 [==============================] - 4s 62us/sample - loss: 0.0089 - accuracy: 0.6024\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6025\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6024\n",
      "69393/69393 [==============================] - 4s 63us/sample - loss: 0.0089 - accuracy: 0.6023\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6020\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6020\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0089 - accuracy: 0.6018\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0089 - accuracy: 0.6015\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0089 - accuracy: 0.6010\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6002\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0089 - accuracy: 0.5993\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0089 - accuracy: 0.5988\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.5978\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0089 - accuracy: 0.5969\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0090 - accuracy: 0.5957\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0090 - accuracy: 0.5944\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0090 - accuracy: 0.5934\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0089 - accuracy: 0.6010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6020\n",
      "69393/69393 [==============================] - 5s 67us/sample - loss: 0.0089 - accuracy: 0.6024\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0089 - accuracy: 0.6028\n",
      "69393/69393 [==============================] - 5s 68us/sample - loss: 0.0089 - accuracy: 0.6030\n",
      "69393/69393 [==============================] - 4s 62us/sample - loss: 0.0089 - accuracy: 0.6029\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0089 - accuracy: 0.6032\n",
      "69393/69393 [==============================] - 5s 69us/sample - loss: 0.0089 - accuracy: 0.6031\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6028\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6023\n",
      "69393/69393 [==============================] - 5s 66us/sample - loss: 0.0089 - accuracy: 0.6015\n",
      "69393/69393 [==============================] - 5s 70us/sample - loss: 0.0089 - accuracy: 0.6009\n",
      "69393/69393 [==============================] - 5s 65us/sample - loss: 0.0089 - accuracy: 0.5997\n",
      "69393/69393 [==============================] - 4s 64us/sample - loss: 0.0090 - accuracy: 0.5987\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0090 - accuracy: 0.5974\n",
      "69393/69393 [==============================] - 4s 62us/sample - loss: 0.0090 - accuracy: 0.5958\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0090 - accuracy: 0.5940\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0091 - accuracy: 0.5922\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0091 - accuracy: 0.5905\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0091 - accuracy: 0.5883\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0092 - accuracy: 0.5859\n",
      "69393/69393 [==============================] - 4s 62us/sample - loss: 0.0089 - accuracy: 0.6010\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6019\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0089 - accuracy: 0.6025\n",
      "69393/69393 [==============================] - 4s 62us/sample - loss: 0.0089 - accuracy: 0.6031\n",
      "69393/69393 [==============================] - 5s 70us/sample - loss: 0.0089 - accuracy: 0.6027\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0089 - accuracy: 0.6027\n",
      "69393/69393 [==============================] - 4s 62us/sample - loss: 0.0089 - accuracy: 0.6030\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6030\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6027\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6024\n",
      "69393/69393 [==============================] - 5s 66us/sample - loss: 0.0089 - accuracy: 0.6019\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6015\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0089 - accuracy: 0.6008\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.5998\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0089 - accuracy: 0.5989\n",
      "69393/69393 [==============================] - 4s 64us/sample - loss: 0.0089 - accuracy: 0.5974\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0090 - accuracy: 0.5960\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0090 - accuracy: 0.5949\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0090 - accuracy: 0.5934\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0090 - accuracy: 0.5918\n",
      "69393/69393 [==============================] - 5s 67us/sample - loss: 0.0091 - accuracy: 0.5901\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6010\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0089 - accuracy: 0.6017\n",
      "69393/69393 [==============================] - 5s 68us/sample - loss: 0.0089 - accuracy: 0.6023\n",
      "69393/69393 [==============================] - 4s 62us/sample - loss: 0.0089 - accuracy: 0.6024\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6023\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0089 - accuracy: 0.6021\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0089 - accuracy: 0.6020\n",
      "69393/69393 [==============================] - 4s 64us/sample - loss: 0.0089 - accuracy: 0.6019\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6013\n",
      "69393/69393 [==============================] - 5s 77us/sample - loss: 0.0089 - accuracy: 0.6003\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0089 - accuracy: 0.5990\n",
      "69393/69393 [==============================] - 4s 62us/sample - loss: 0.0089 - accuracy: 0.5980\n",
      "69393/69393 [==============================] - 4s 62us/sample - loss: 0.0089 - accuracy: 0.5965\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0090 - accuracy: 0.5946\n",
      "69393/69393 [==============================] - 5s 66us/sample - loss: 0.0090 - accuracy: 0.5926\n",
      "69393/69393 [==============================] - 5s 66us/sample - loss: 0.0090 - accuracy: 0.5907\n",
      "69393/69393 [==============================] - 5s 67us/sample - loss: 0.0091 - accuracy: 0.5885\n",
      "69393/69393 [==============================] - 5s 67us/sample - loss: 0.0091 - accuracy: 0.5854\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0092 - accuracy: 0.5831\n",
      "69393/69393 [==============================] - 4s 63us/sample - loss: 0.0092 - accuracy: 0.5805\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0093 - accuracy: 0.5773\n",
      "69393/69393 [==============================] - 5s 69us/sample - loss: 0.0089 - accuracy: 0.6010\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6018\n",
      "69393/69393 [==============================] - 5s 66us/sample - loss: 0.0089 - accuracy: 0.6024\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0089 - accuracy: 0.6031\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6035\n",
      "69393/69393 [==============================] - 4s 62us/sample - loss: 0.0088 - accuracy: 0.6037\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0088 - accuracy: 0.6041\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0088 - accuracy: 0.6039\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0088 - accuracy: 0.6035\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0088 - accuracy: 0.6035\n",
      "69393/69393 [==============================] - 5s 65us/sample - loss: 0.0088 - accuracy: 0.6034\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0089 - accuracy: 0.6027\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6021\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0089 - accuracy: 0.6015\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0089 - accuracy: 0.6001\n",
      "69393/69393 [==============================] - 5s 65us/sample - loss: 0.0089 - accuracy: 0.5989\n",
      "69393/69393 [==============================] - 4s 62us/sample - loss: 0.0089 - accuracy: 0.5979\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0090 - accuracy: 0.5962\n",
      "69393/69393 [==============================] - 4s 62us/sample - loss: 0.0090 - accuracy: 0.5940\n",
      "69393/69393 [==============================] - 5s 66us/sample - loss: 0.0090 - accuracy: 0.5922\n",
      "69393/69393 [==============================] - 4s 64us/sample - loss: 0.0091 - accuracy: 0.5902\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6010\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0089 - accuracy: 0.6020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6027\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6032\n",
      "69393/69393 [==============================] - 4s 62us/sample - loss: 0.0088 - accuracy: 0.6038\n",
      "69393/69393 [==============================] - 4s 62us/sample - loss: 0.0088 - accuracy: 0.6041\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0088 - accuracy: 0.6044\n",
      "69393/69393 [==============================] - 5s 67us/sample - loss: 0.0088 - accuracy: 0.6043\n",
      "69393/69393 [==============================] - 5s 67us/sample - loss: 0.0088 - accuracy: 0.6045\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0088 - accuracy: 0.6047\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0088 - accuracy: 0.6044\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0088 - accuracy: 0.6039\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0088 - accuracy: 0.6035\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0088 - accuracy: 0.6030\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0088 - accuracy: 0.6024\n",
      "69393/69393 [==============================] - 5s 67us/sample - loss: 0.0088 - accuracy: 0.6018\n",
      "69393/69393 [==============================] - 4s 63us/sample - loss: 0.0088 - accuracy: 0.6012\n",
      "69393/69393 [==============================] - 4s 63us/sample - loss: 0.0088 - accuracy: 0.6002\n",
      "69393/69393 [==============================] - 4s 58us/sample - loss: 0.0089 - accuracy: 0.5994\n",
      "69393/69393 [==============================] - 4s 63us/sample - loss: 0.0089 - accuracy: 0.5982\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0089 - accuracy: 0.5966\n",
      "69393/69393 [==============================] - 5s 67us/sample - loss: 0.0089 - accuracy: 0.6010\n",
      "69393/69393 [==============================] - 4s 62us/sample - loss: 0.0089 - accuracy: 0.6022\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6028\n",
      "69393/69393 [==============================] - 4s 63us/sample - loss: 0.0089 - accuracy: 0.6033\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0088 - accuracy: 0.6033\n",
      "69393/69393 [==============================] - 4s 63us/sample - loss: 0.0088 - accuracy: 0.6037\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0088 - accuracy: 0.6036\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0088 - accuracy: 0.6034\n",
      "69393/69393 [==============================] - 5s 67us/sample - loss: 0.0088 - accuracy: 0.6027\n",
      "69393/69393 [==============================] - 5s 67us/sample - loss: 0.0089 - accuracy: 0.6023\n",
      "69393/69393 [==============================] - 4s 62us/sample - loss: 0.0089 - accuracy: 0.6014\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.6005\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0089 - accuracy: 0.5989\n",
      "69393/69393 [==============================] - 4s 64us/sample - loss: 0.0089 - accuracy: 0.5972\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0090 - accuracy: 0.5953\n",
      "69393/69393 [==============================] - 4s 61us/sample - loss: 0.0090 - accuracy: 0.5929\n",
      "69393/69393 [==============================] - 5s 66us/sample - loss: 0.0090 - accuracy: 0.5913\n",
      "69393/69393 [==============================] - 4s 65us/sample - loss: 0.0091 - accuracy: 0.5892\n",
      "69393/69393 [==============================] - 4s 59us/sample - loss: 0.0091 - accuracy: 0.5864\n",
      "69393/69393 [==============================] - 4s 60us/sample - loss: 0.0092 - accuracy: 0.5837\n",
      "69393/69393 [==============================] - 4s 62us/sample - loss: 0.0092 - accuracy: 0.5810\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for agg_weights_list in agg_weights_list_per_pi:\n",
    "    j = 0\n",
    "    for agg_weights in agg_weights_list:\n",
    "        aggr_model = keras.models.clone_model(model1)\n",
    "        aggr_model.set_weights(agg_weights)\n",
    "        compile_model(aggr_model)\n",
    "        score = aggr_model.evaluate(X_test, Y_test);\n",
    "        Z[i][j] = score[0]\n",
    "        j += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=cm.rainbow,\n",
    "                       linewidth=0, antialiased=False)\n",
    "ax.set_xlabel('$theta$')\n",
    "ax.set_ylabel('$distance$')\n",
    "ax.set_zlabel('$loss$')\n",
    "# Customize the z axis.\n",
    "# ax.set_xlim(0.051, 0.054)\n",
    "# ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "# ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "# ax.view_init(0, 180)\n",
    "# ax.view_init(0, 0)\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "plt.savefig('fig1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "personalized.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
