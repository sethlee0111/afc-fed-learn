{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d6n47ueeqbXb"
   },
   "source": [
    "## Personalized Learning (Localized Learning?)\n",
    "\n",
    "#### This notebook includes the following online models;\n",
    "1. A single global model with all data\n",
    "2. Multiple local models (starting from a single global model)\n",
    "   1. that are updated with new data\n",
    "   2. that exchanges data in clusters\n",
    "   3. that exchanges parameters in clusters\n",
    "\n",
    "  \n",
    "#### The dataset that is used for this project is [CIFAR-100 dataset][1]\n",
    "* Has 100 classes containing 600 images each\n",
    "\n",
    "#### New data are fed by the following rules;\n",
    "1. Distributed, according to superclasses\n",
    "  * Clusters will only be updated with data that belongs to a specific superclass\n",
    "  * We update the NN by\n",
    "    1. Changing all parameters of the NN\n",
    "    2. Only changing the last few layers, as in many MTL models\n",
    "2. Randomly (why?)\n",
    "\n",
    "#### We expect to find an answer to the following research questions with this project;\n",
    "1. If models are updated with data (or parameters) that are shared within a cluster, can the model perform good enough with the labels that count?\n",
    "  * For example, the performance of the cluster that are updated with \"Vehicles\" superclass is only assessed with the labels that corresponds to the superclass.\n",
    "  \n",
    "[1]: https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oji0BTfoqbXc"
   },
   "source": [
    "#### Questions\n",
    "\n",
    "Retraining: how does it work <br>\n",
    "How do we compare these models?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mr4-uY0LqbXd"
   },
   "source": [
    "### Implementation with Custom Neural Network and MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tGoXLnOyqbXe",
    "outputId": "9ccd7215-80bf-4a0a-b852-8896b17c38f1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.lines as mlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E2faBs1yqbXj"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 50\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QXfylSWLqbXl"
   },
   "source": [
    "#### Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "V7iMvdGXqbXm",
    "outputId": "875da8c3-28b0-48cc-da41-b2d91add5cb3"
   },
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_global = x_train[-5000:]\n",
    "y_train_global = y_train[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_global = keras.utils.to_categorical(y_train_global, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_training_set(size, number, x_train, y_train):\n",
    "    x_train_list = np.split(x_train, x_train.shape[0] / size)[:number]  # +1 cuz the last array will contain everything till the end\n",
    "    y_train_list = np.split(y_train, y_train.shape[0] / size)[:number]\n",
    "    y_train_list = [keras.utils.to_categorical(y, num_classes) for y in y_train_list]\n",
    "    return x_train_list, y_train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_global.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array_split(x_train, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 28, 28, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[3].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models and compile & fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_model():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=input_shape))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):  \n",
    "    # initiate SGD optimizer\n",
    "    opt = keras.optimizers.SGD(lr=0.1)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model_lr(model):  \n",
    "    # initiate SGD optimizer\n",
    "    opt = keras.optimizers.SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model1(model, epochs):\n",
    "    now = datetime.datetime.now()\n",
    "    print (\"Training date and time : \")\n",
    "    print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    return model.fit(x_train1, y_train1,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      validation_data=(x_val1, y_val1),\n",
    "                      shuffle=True, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_with_datasets(model, epochs, x_train, y_train):\n",
    "    now = datetime.datetime.now()\n",
    "    print (\"Training date and time : \")\n",
    "    print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    return model.fit(x_train, y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      shuffle=True, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort by the order of similarity to model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_distance(model1, model2):\n",
    "    w = zip(model1.get_weights(), model2.get_weights())\n",
    "    lw = list(w)\n",
    "    sums = 0\n",
    "    i = 0\n",
    "    for ww in lw:\n",
    "        i += 1\n",
    "        sums += np.average(np.absolute(ww[0] - ww[1]))\n",
    "    return sums / i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not normalized, unlike l1_distance()!\n",
    "# @TODO normalize\n",
    "def l2_distance(model1, model2):\n",
    "    lw = list(zip(model1.get_weights(), model2.get_weights()))\n",
    "    sums = 0\n",
    "    i = 0\n",
    "    for ww in lw:\n",
    "        sq = np.sum(np.square(ww[0] - ww[1]))\n",
    "        sums += sq\n",
    "    return sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We first train them to make a base model to start training from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training date and time : \n",
      "2020-03-18 13:21:32\n",
      "Train on 5000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 0s 94us/sample - loss: 0.0899 - accuracy: 0.1586\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 0s 44us/sample - loss: 0.0856 - accuracy: 0.2234\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 0s 49us/sample - loss: 0.0805 - accuracy: 0.2918\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 0s 48us/sample - loss: 0.0748 - accuracy: 0.4260\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 0s 43us/sample - loss: 0.0681 - accuracy: 0.5560\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 0s 47us/sample - loss: 0.0604 - accuracy: 0.6544\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 0s 41us/sample - loss: 0.0517 - accuracy: 0.7330\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 0s 42us/sample - loss: 0.0430 - accuracy: 0.7940\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 0s 39us/sample - loss: 0.0359 - accuracy: 0.8292\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 0s 34us/sample - loss: 0.0305 - accuracy: 0.8592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x157677320>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = custom_model()\n",
    "compile_model(model1)\n",
    "fit_model_with_datasets(model1, 10, x_train_global, y_train_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = list()\n",
    "for _ in range(10):\n",
    "    model_list.append(tf.keras.models.clone_model(model1)) \n",
    "    model_list[_].set_weights(model1.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort models according to similarity. We arbitrarily take the model1 as a \"standard\"\n",
    "standard_model = tf.keras.models.clone_model(model1)\n",
    "standard_model.set_weights(model_list[0].get_weights())\n",
    "model_list.sort(key=lambda m : l1_distance(standard_model, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_list = [l1_distance(standard_model, m) for m in model_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct transfer learning in local models using different datasets & epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list, y_train_list = split_training_set(size=1000, number=len(model_list), x_train=x_train[:-10000], y_train=y_train[:-10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training date and time : \n",
      "2020-03-18 13:24:18\n",
      "Train on 1000 samples\n",
      "Epoch 1/30\n",
      "1000/1000 [==============================] - 0s 213us/sample - loss: 0.0328 - accuracy: 0.8190\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0319 - accuracy: 0.8270\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0310 - accuracy: 0.8310\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0302 - accuracy: 0.8370\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0295 - accuracy: 0.8360\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0287 - accuracy: 0.8500\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0280 - accuracy: 0.8480\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0274 - accuracy: 0.8590\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0268 - accuracy: 0.8580\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0262 - accuracy: 0.8670\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0256 - accuracy: 0.8660\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0251 - accuracy: 0.8720\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0246 - accuracy: 0.8730\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0240 - accuracy: 0.8780\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0236 - accuracy: 0.8790\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0231 - accuracy: 0.8810\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0227 - accuracy: 0.8830\n",
      "Epoch 18/30\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0223 - accuracy: 0.8830\n",
      "Epoch 19/30\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0219 - accuracy: 0.8860\n",
      "Epoch 20/30\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0215 - accuracy: 0.8860\n",
      "Epoch 21/30\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0211 - accuracy: 0.8930\n",
      "Epoch 22/30\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0208 - accuracy: 0.8960\n",
      "Epoch 23/30\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0204 - accuracy: 0.8970\n",
      "Epoch 24/30\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0201 - accuracy: 0.8970\n",
      "Epoch 25/30\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0198 - accuracy: 0.8950\n",
      "Epoch 26/30\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0195 - accuracy: 0.8970\n",
      "Epoch 27/30\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0192 - accuracy: 0.8990\n",
      "Epoch 28/30\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0189 - accuracy: 0.8990\n",
      "Epoch 29/30\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0187 - accuracy: 0.9020\n",
      "Epoch 30/30\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 0.0184 - accuracy: 0.9020\n",
      "Training date and time : \n",
      "2020-03-18 13:24:20\n",
      "Train on 1000 samples\n",
      "Epoch 1/60\n",
      "1000/1000 [==============================] - 0s 241us/sample - loss: 0.0330 - accuracy: 0.8200\n",
      "Epoch 2/60\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0320 - accuracy: 0.8260\n",
      "Epoch 3/60\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0311 - accuracy: 0.8320\n",
      "Epoch 4/60\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0303 - accuracy: 0.8450\n",
      "Epoch 5/60\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0295 - accuracy: 0.8460\n",
      "Epoch 6/60\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0287 - accuracy: 0.8530\n",
      "Epoch 7/60\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0280 - accuracy: 0.8550\n",
      "Epoch 8/60\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0273 - accuracy: 0.8640\n",
      "Epoch 9/60\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0266 - accuracy: 0.8610\n",
      "Epoch 10/60\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0260 - accuracy: 0.8720\n",
      "Epoch 11/60\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0254 - accuracy: 0.8730\n",
      "Epoch 12/60\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0248 - accuracy: 0.8800\n",
      "Epoch 13/60\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0243 - accuracy: 0.8820\n",
      "Epoch 14/60\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0237 - accuracy: 0.8820\n",
      "Epoch 15/60\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0232 - accuracy: 0.8880\n",
      "Epoch 16/60\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0228 - accuracy: 0.8880\n",
      "Epoch 17/60\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0223 - accuracy: 0.8940\n",
      "Epoch 18/60\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0219 - accuracy: 0.8950\n",
      "Epoch 19/60\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0214 - accuracy: 0.8980\n",
      "Epoch 20/60\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0210 - accuracy: 0.8980\n",
      "Epoch 21/60\n",
      "1000/1000 [==============================] - 0s 80us/sample - loss: 0.0206 - accuracy: 0.9030\n",
      "Epoch 22/60\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.0203 - accuracy: 0.9010\n",
      "Epoch 23/60\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.0199 - accuracy: 0.9060\n",
      "Epoch 24/60\n",
      "1000/1000 [==============================] - 0s 71us/sample - loss: 0.0196 - accuracy: 0.9020\n",
      "Epoch 25/60\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0192 - accuracy: 0.9050\n",
      "Epoch 26/60\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0190 - accuracy: 0.9060\n",
      "Epoch 27/60\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0187 - accuracy: 0.9050\n",
      "Epoch 28/60\n",
      "1000/1000 [==============================] - 0s 79us/sample - loss: 0.0183 - accuracy: 0.9090\n",
      "Epoch 29/60\n",
      "1000/1000 [==============================] - 0s 75us/sample - loss: 0.0180 - accuracy: 0.9080\n",
      "Epoch 30/60\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0178 - accuracy: 0.9120\n",
      "Epoch 31/60\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0175 - accuracy: 0.9100\n",
      "Epoch 32/60\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0172 - accuracy: 0.9120\n",
      "Epoch 33/60\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0170 - accuracy: 0.9150\n",
      "Epoch 34/60\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 0.0167 - accuracy: 0.9150\n",
      "Epoch 35/60\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.0165 - accuracy: 0.9160\n",
      "Epoch 36/60\n",
      "1000/1000 [==============================] - 0s 72us/sample - loss: 0.0163 - accuracy: 0.9160\n",
      "Epoch 37/60\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0160 - accuracy: 0.9180\n",
      "Epoch 38/60\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0158 - accuracy: 0.9170\n",
      "Epoch 39/60\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 0.0156 - accuracy: 0.9220\n",
      "Epoch 40/60\n",
      "1000/1000 [==============================] - 0s 69us/sample - loss: 0.0154 - accuracy: 0.9220\n",
      "Epoch 41/60\n",
      "1000/1000 [==============================] - 0s 73us/sample - loss: 0.0152 - accuracy: 0.9220\n",
      "Epoch 42/60\n",
      "1000/1000 [==============================] - 0s 74us/sample - loss: 0.0150 - accuracy: 0.9250\n",
      "Epoch 43/60\n",
      "1000/1000 [==============================] - 0s 84us/sample - loss: 0.0148 - accuracy: 0.9240\n",
      "Epoch 44/60\n",
      "1000/1000 [==============================] - 0s 71us/sample - loss: 0.0147 - accuracy: 0.9260\n",
      "Epoch 45/60\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 0.0145 - accuracy: 0.9270\n",
      "Epoch 46/60\n",
      "1000/1000 [==============================] - 0s 72us/sample - loss: 0.0143 - accuracy: 0.9280\n",
      "Epoch 47/60\n",
      "1000/1000 [==============================] - 0s 69us/sample - loss: 0.0141 - accuracy: 0.9260\n",
      "Epoch 48/60\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.0139 - accuracy: 0.9270\n",
      "Epoch 49/60\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 0.0137 - accuracy: 0.9320\n",
      "Epoch 50/60\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0136 - accuracy: 0.9310\n",
      "Epoch 51/60\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0134 - accuracy: 0.9320\n",
      "Epoch 52/60\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0133 - accuracy: 0.9330\n",
      "Epoch 53/60\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0131 - accuracy: 0.9310\n",
      "Epoch 54/60\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 0.0130 - accuracy: 0.9320\n",
      "Epoch 55/60\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0128 - accuracy: 0.9350\n",
      "Epoch 56/60\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0127 - accuracy: 0.9390\n",
      "Epoch 57/60\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0126 - accuracy: 0.9400\n",
      "Epoch 58/60\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0124 - accuracy: 0.9390\n",
      "Epoch 59/60\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 0.0123 - accuracy: 0.9420\n",
      "Epoch 60/60\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0122 - accuracy: 0.9430\n",
      "Training date and time : \n",
      "2020-03-18 13:24:24\n",
      "Train on 1000 samples\n",
      "Epoch 1/90\n",
      "1000/1000 [==============================] - 0s 206us/sample - loss: 0.0303 - accuracy: 0.8400\n",
      "Epoch 2/90\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0292 - accuracy: 0.8430\n",
      "Epoch 3/90\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0284 - accuracy: 0.8510\n",
      "Epoch 4/90\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0276 - accuracy: 0.8550\n",
      "Epoch 5/90\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0268 - accuracy: 0.8640\n",
      "Epoch 6/90\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0261 - accuracy: 0.8630\n",
      "Epoch 7/90\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0254 - accuracy: 0.8760\n",
      "Epoch 8/90\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0247 - accuracy: 0.8730\n",
      "Epoch 9/90\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0241 - accuracy: 0.8820\n",
      "Epoch 10/90\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0235 - accuracy: 0.8890\n",
      "Epoch 11/90\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0230 - accuracy: 0.8900\n",
      "Epoch 12/90\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0224 - accuracy: 0.8940\n",
      "Epoch 13/90\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0219 - accuracy: 0.8960\n",
      "Epoch 14/90\n",
      "1000/1000 [==============================] - 0s 73us/sample - loss: 0.0215 - accuracy: 0.8960\n",
      "Epoch 15/90\n",
      "1000/1000 [==============================] - 0s 77us/sample - loss: 0.0210 - accuracy: 0.8980\n",
      "Epoch 16/90\n",
      "1000/1000 [==============================] - 0s 71us/sample - loss: 0.0205 - accuracy: 0.9030\n",
      "Epoch 17/90\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 0.0201 - accuracy: 0.9020\n",
      "Epoch 18/90\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.0197 - accuracy: 0.9040\n",
      "Epoch 19/90\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0193 - accuracy: 0.9020\n",
      "Epoch 20/90\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0190 - accuracy: 0.9050\n",
      "Epoch 21/90\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.0186 - accuracy: 0.9080\n",
      "Epoch 22/90\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0183 - accuracy: 0.9080\n",
      "Epoch 23/90\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.0179 - accuracy: 0.9110\n",
      "Epoch 24/90\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 0.0176 - accuracy: 0.9130\n",
      "Epoch 25/90\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.0173 - accuracy: 0.9190\n",
      "Epoch 26/90\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.0170 - accuracy: 0.9200\n",
      "Epoch 27/90\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0168 - accuracy: 0.9210\n",
      "Epoch 28/90\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0164 - accuracy: 0.9240\n",
      "Epoch 29/90\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0162 - accuracy: 0.9270\n",
      "Epoch 30/90\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0159 - accuracy: 0.9260\n",
      "Epoch 31/90\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0157 - accuracy: 0.9290\n",
      "Epoch 32/90\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0154 - accuracy: 0.9300\n",
      "Epoch 33/90\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 0.0152 - accuracy: 0.9290\n",
      "Epoch 34/90\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0150 - accuracy: 0.9300\n",
      "Epoch 35/90\n",
      "1000/1000 [==============================] - 0s 75us/sample - loss: 0.0147 - accuracy: 0.9310\n",
      "Epoch 36/90\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0145 - accuracy: 0.9370\n",
      "Epoch 37/90\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0143 - accuracy: 0.9350\n",
      "Epoch 38/90\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0141 - accuracy: 0.9360\n",
      "Epoch 39/90\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0139 - accuracy: 0.9370\n",
      "Epoch 40/90\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0137 - accuracy: 0.9390\n",
      "Epoch 41/90\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0135 - accuracy: 0.9380\n",
      "Epoch 42/90\n",
      "1000/1000 [==============================] - 0s 70us/sample - loss: 0.0133 - accuracy: 0.9410\n",
      "Epoch 43/90\n",
      "1000/1000 [==============================] - 0s 72us/sample - loss: 0.0132 - accuracy: 0.9380\n",
      "Epoch 44/90\n",
      "1000/1000 [==============================] - 0s 74us/sample - loss: 0.0130 - accuracy: 0.9390\n",
      "Epoch 45/90\n",
      "1000/1000 [==============================] - 0s 86us/sample - loss: 0.0128 - accuracy: 0.9420\n",
      "Epoch 46/90\n",
      "1000/1000 [==============================] - 0s 81us/sample - loss: 0.0127 - accuracy: 0.9410\n",
      "Epoch 47/90\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.0125 - accuracy: 0.9420\n",
      "Epoch 48/90\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 0.0123 - accuracy: 0.9430\n",
      "Epoch 49/90\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 0.0122 - accuracy: 0.9440\n",
      "Epoch 50/90\n",
      "1000/1000 [==============================] - 0s 73us/sample - loss: 0.0120 - accuracy: 0.9460\n",
      "Epoch 51/90\n",
      "1000/1000 [==============================] - 0s 79us/sample - loss: 0.0119 - accuracy: 0.9490\n",
      "Epoch 52/90\n",
      "1000/1000 [==============================] - 0s 85us/sample - loss: 0.0117 - accuracy: 0.9460\n",
      "Epoch 53/90\n",
      "1000/1000 [==============================] - 0s 73us/sample - loss: 0.0116 - accuracy: 0.9450\n",
      "Epoch 54/90\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 0.0114 - accuracy: 0.9460\n",
      "Epoch 55/90\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.0113 - accuracy: 0.9520\n",
      "Epoch 56/90\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0112 - accuracy: 0.9510\n",
      "Epoch 57/90\n",
      "1000/1000 [==============================] - 0s 84us/sample - loss: 0.0111 - accuracy: 0.9500\n",
      "Epoch 58/90\n",
      "1000/1000 [==============================] - 0s 84us/sample - loss: 0.0109 - accuracy: 0.9510\n",
      "Epoch 59/90\n",
      "1000/1000 [==============================] - 0s 79us/sample - loss: 0.0108 - accuracy: 0.9520\n",
      "Epoch 60/90\n",
      "1000/1000 [==============================] - 0s 85us/sample - loss: 0.0107 - accuracy: 0.9520\n",
      "Epoch 61/90\n",
      "1000/1000 [==============================] - 0s 88us/sample - loss: 0.0106 - accuracy: 0.9530\n",
      "Epoch 62/90\n",
      "1000/1000 [==============================] - 0s 71us/sample - loss: 0.0105 - accuracy: 0.9540\n",
      "Epoch 63/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.0103 - accuracy: 0.9560\n",
      "Epoch 64/90\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0102 - accuracy: 0.9580\n",
      "Epoch 65/90\n",
      "1000/1000 [==============================] - 0s 70us/sample - loss: 0.0101 - accuracy: 0.9590\n",
      "Epoch 66/90\n",
      "1000/1000 [==============================] - 0s 69us/sample - loss: 0.0100 - accuracy: 0.9580\n",
      "Epoch 67/90\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0099 - accuracy: 0.9590\n",
      "Epoch 68/90\n",
      "1000/1000 [==============================] - 0s 84us/sample - loss: 0.0098 - accuracy: 0.9600\n",
      "Epoch 69/90\n",
      "1000/1000 [==============================] - 0s 82us/sample - loss: 0.0097 - accuracy: 0.9600\n",
      "Epoch 70/90\n",
      "1000/1000 [==============================] - 0s 83us/sample - loss: 0.0096 - accuracy: 0.9600\n",
      "Epoch 71/90\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 0.0095 - accuracy: 0.9600\n",
      "Epoch 72/90\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0094 - accuracy: 0.9610\n",
      "Epoch 73/90\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0093 - accuracy: 0.9620\n",
      "Epoch 74/90\n",
      "1000/1000 [==============================] - 0s 76us/sample - loss: 0.0092 - accuracy: 0.9610\n",
      "Epoch 75/90\n",
      "1000/1000 [==============================] - 0s 69us/sample - loss: 0.0091 - accuracy: 0.9600\n",
      "Epoch 76/90\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0090 - accuracy: 0.9620\n",
      "Epoch 77/90\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.0089 - accuracy: 0.9620\n",
      "Epoch 78/90\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0088 - accuracy: 0.9630\n",
      "Epoch 79/90\n",
      "1000/1000 [==============================] - 0s 149us/sample - loss: 0.0088 - accuracy: 0.9630\n",
      "Epoch 80/90\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 0.0086 - accuracy: 0.9640\n",
      "Epoch 81/90\n",
      "1000/1000 [==============================] - 0s 77us/sample - loss: 0.0086 - accuracy: 0.9630\n",
      "Epoch 82/90\n",
      "1000/1000 [==============================] - 0s 76us/sample - loss: 0.0085 - accuracy: 0.9630\n",
      "Epoch 83/90\n",
      "1000/1000 [==============================] - 0s 82us/sample - loss: 0.0084 - accuracy: 0.9630\n",
      "Epoch 84/90\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.0083 - accuracy: 0.9630\n",
      "Epoch 85/90\n",
      "1000/1000 [==============================] - 0s 79us/sample - loss: 0.0082 - accuracy: 0.9640\n",
      "Epoch 86/90\n",
      "1000/1000 [==============================] - 0s 74us/sample - loss: 0.0082 - accuracy: 0.9650\n",
      "Epoch 87/90\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0081 - accuracy: 0.9630\n",
      "Epoch 88/90\n",
      "1000/1000 [==============================] - 0s 69us/sample - loss: 0.0080 - accuracy: 0.9660\n",
      "Epoch 89/90\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0079 - accuracy: 0.9640\n",
      "Epoch 90/90\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0079 - accuracy: 0.9650\n",
      "Training date and time : \n",
      "2020-03-18 13:24:30\n",
      "Train on 1000 samples\n",
      "Epoch 1/120\n",
      "1000/1000 [==============================] - 0s 335us/sample - loss: 0.0329 - accuracy: 0.8380\n",
      "Epoch 2/120\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 0.0316 - accuracy: 0.8480\n",
      "Epoch 3/120\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0306 - accuracy: 0.8510\n",
      "Epoch 4/120\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0296 - accuracy: 0.8550\n",
      "Epoch 5/120\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0287 - accuracy: 0.8590\n",
      "Epoch 6/120\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0278 - accuracy: 0.8650\n",
      "Epoch 7/120\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0270 - accuracy: 0.8690\n",
      "Epoch 8/120\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0263 - accuracy: 0.8760\n",
      "Epoch 9/120\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.0256 - accuracy: 0.8790\n",
      "Epoch 10/120\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0249 - accuracy: 0.8830\n",
      "Epoch 11/120\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0242 - accuracy: 0.8840\n",
      "Epoch 12/120\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0236 - accuracy: 0.8920\n",
      "Epoch 13/120\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0231 - accuracy: 0.8950\n",
      "Epoch 14/120\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0225 - accuracy: 0.8970\n",
      "Epoch 15/120\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0219 - accuracy: 0.8980\n",
      "Epoch 16/120\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0215 - accuracy: 0.8990\n",
      "Epoch 17/120\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0210 - accuracy: 0.9010\n",
      "Epoch 18/120\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0205 - accuracy: 0.9010\n",
      "Epoch 19/120\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0201 - accuracy: 0.9030\n",
      "Epoch 20/120\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0196 - accuracy: 0.9070\n",
      "Epoch 21/120\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0193 - accuracy: 0.9080\n",
      "Epoch 22/120\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0189 - accuracy: 0.9070\n",
      "Epoch 23/120\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0185 - accuracy: 0.9090\n",
      "Epoch 24/120\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0182 - accuracy: 0.9090\n",
      "Epoch 25/120\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0179 - accuracy: 0.9150\n",
      "Epoch 26/120\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0175 - accuracy: 0.9130\n",
      "Epoch 27/120\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0172 - accuracy: 0.9130\n",
      "Epoch 28/120\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0169 - accuracy: 0.9140\n",
      "Epoch 29/120\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0166 - accuracy: 0.9120\n",
      "Epoch 30/120\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0164 - accuracy: 0.9170\n",
      "Epoch 31/120\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0161 - accuracy: 0.9180\n",
      "Epoch 32/120\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0158 - accuracy: 0.9170\n",
      "Epoch 33/120\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0156 - accuracy: 0.9210\n",
      "Epoch 34/120\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0153 - accuracy: 0.9240\n",
      "Epoch 35/120\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0151 - accuracy: 0.9210\n",
      "Epoch 36/120\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0149 - accuracy: 0.9250\n",
      "Epoch 37/120\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0146 - accuracy: 0.9220\n",
      "Epoch 38/120\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0144 - accuracy: 0.9260\n",
      "Epoch 39/120\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0142 - accuracy: 0.9260\n",
      "Epoch 40/120\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0140 - accuracy: 0.9290\n",
      "Epoch 41/120\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0138 - accuracy: 0.9320\n",
      "Epoch 42/120\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0136 - accuracy: 0.9310\n",
      "Epoch 43/120\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0134 - accuracy: 0.9320\n",
      "Epoch 44/120\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0132 - accuracy: 0.9300\n",
      "Epoch 45/120\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0130 - accuracy: 0.9370\n",
      "Epoch 46/120\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0128 - accuracy: 0.9370\n",
      "Epoch 47/120\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0127 - accuracy: 0.9380\n",
      "Epoch 48/120\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0125 - accuracy: 0.9420\n",
      "Epoch 49/120\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0124 - accuracy: 0.9390\n",
      "Epoch 50/120\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0122 - accuracy: 0.9420\n",
      "Epoch 51/120\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0120 - accuracy: 0.9410\n",
      "Epoch 52/120\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0119 - accuracy: 0.9420\n",
      "Epoch 53/120\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0117 - accuracy: 0.9430\n",
      "Epoch 54/120\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0115 - accuracy: 0.9450\n",
      "Epoch 55/120\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0114 - accuracy: 0.9470\n",
      "Epoch 56/120\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0113 - accuracy: 0.9480\n",
      "Epoch 57/120\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0111 - accuracy: 0.9460\n",
      "Epoch 58/120\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0110 - accuracy: 0.9490\n",
      "Epoch 59/120\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0108 - accuracy: 0.9490\n",
      "Epoch 60/120\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0107 - accuracy: 0.9510\n",
      "Epoch 61/120\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0106 - accuracy: 0.9490\n",
      "Epoch 62/120\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0105 - accuracy: 0.9510\n",
      "Epoch 63/120\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0103 - accuracy: 0.9490\n",
      "Epoch 64/120\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0102 - accuracy: 0.9530\n",
      "Epoch 65/120\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0101 - accuracy: 0.9520\n",
      "Epoch 66/120\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0100 - accuracy: 0.9540\n",
      "Epoch 67/120\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0099 - accuracy: 0.9520\n",
      "Epoch 68/120\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0097 - accuracy: 0.9550\n",
      "Epoch 69/120\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0097 - accuracy: 0.9550\n",
      "Epoch 70/120\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0095 - accuracy: 0.9560\n",
      "Epoch 71/120\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0094 - accuracy: 0.9570\n",
      "Epoch 72/120\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0093 - accuracy: 0.9590\n",
      "Epoch 73/120\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0092 - accuracy: 0.9620\n",
      "Epoch 74/120\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0091 - accuracy: 0.9600\n",
      "Epoch 75/120\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0090 - accuracy: 0.9600\n",
      "Epoch 76/120\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0089 - accuracy: 0.9620\n",
      "Epoch 77/120\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0088 - accuracy: 0.9630\n",
      "Epoch 78/120\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0087 - accuracy: 0.9640\n",
      "Epoch 79/120\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0086 - accuracy: 0.9630\n",
      "Epoch 80/120\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0085 - accuracy: 0.9630\n",
      "Epoch 81/120\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0085 - accuracy: 0.9630\n",
      "Epoch 82/120\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0083 - accuracy: 0.9670\n",
      "Epoch 83/120\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0082 - accuracy: 0.9650\n",
      "Epoch 84/120\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0081 - accuracy: 0.9670\n",
      "Epoch 85/120\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0081 - accuracy: 0.9670\n",
      "Epoch 86/120\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0080 - accuracy: 0.9690\n",
      "Epoch 87/120\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0079 - accuracy: 0.9710\n",
      "Epoch 88/120\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0078 - accuracy: 0.9690\n",
      "Epoch 89/120\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0077 - accuracy: 0.9700\n",
      "Epoch 90/120\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0077 - accuracy: 0.9700\n",
      "Epoch 91/120\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0076 - accuracy: 0.9720\n",
      "Epoch 92/120\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0075 - accuracy: 0.9730\n",
      "Epoch 93/120\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0074 - accuracy: 0.9740\n",
      "Epoch 94/120\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0074 - accuracy: 0.9740\n",
      "Epoch 95/120\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0073 - accuracy: 0.9740\n",
      "Epoch 96/120\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0072 - accuracy: 0.9740\n",
      "Epoch 97/120\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0072 - accuracy: 0.9740\n",
      "Epoch 98/120\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0071 - accuracy: 0.9750\n",
      "Epoch 99/120\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0070 - accuracy: 0.9750\n",
      "Epoch 100/120\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0069 - accuracy: 0.9750\n",
      "Epoch 101/120\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.0069 - accuracy: 0.9750\n",
      "Epoch 102/120\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 0.0068 - accuracy: 0.9740\n",
      "Epoch 103/120\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0068 - accuracy: 0.9750\n",
      "Epoch 104/120\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0067 - accuracy: 0.9750\n",
      "Epoch 105/120\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0066 - accuracy: 0.9750\n",
      "Epoch 106/120\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0066 - accuracy: 0.9750\n",
      "Epoch 107/120\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0065 - accuracy: 0.9750\n",
      "Epoch 108/120\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0065 - accuracy: 0.9760\n",
      "Epoch 109/120\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0064 - accuracy: 0.9760\n",
      "Epoch 110/120\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0063 - accuracy: 0.9750\n",
      "Epoch 111/120\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0063 - accuracy: 0.9760\n",
      "Epoch 112/120\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0062 - accuracy: 0.9760\n",
      "Epoch 113/120\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0062 - accuracy: 0.9750\n",
      "Epoch 114/120\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0061 - accuracy: 0.9750\n",
      "Epoch 115/120\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0061 - accuracy: 0.9750\n",
      "Epoch 116/120\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0060 - accuracy: 0.9760\n",
      "Epoch 117/120\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0060 - accuracy: 0.9760\n",
      "Epoch 118/120\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0059 - accuracy: 0.9760\n",
      "Epoch 119/120\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0059 - accuracy: 0.9760\n",
      "Epoch 120/120\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0058 - accuracy: 0.9760\n",
      "Training date and time : \n",
      "2020-03-18 13:24:37\n",
      "Train on 1000 samples\n",
      "Epoch 1/150\n",
      "1000/1000 [==============================] - 0s 204us/sample - loss: 0.0320 - accuracy: 0.8280\n",
      "Epoch 2/150\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0311 - accuracy: 0.8370\n",
      "Epoch 3/150\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0302 - accuracy: 0.8410\n",
      "Epoch 4/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0293 - accuracy: 0.8460\n",
      "Epoch 5/150\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0285 - accuracy: 0.8510\n",
      "Epoch 6/150\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0278 - accuracy: 0.8540\n",
      "Epoch 7/150\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0270 - accuracy: 0.8520\n",
      "Epoch 8/150\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0264 - accuracy: 0.8620\n",
      "Epoch 9/150\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0258 - accuracy: 0.8620\n",
      "Epoch 10/150\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0252 - accuracy: 0.8680\n",
      "Epoch 11/150\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0246 - accuracy: 0.8680\n",
      "Epoch 12/150\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0240 - accuracy: 0.8750\n",
      "Epoch 13/150\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0235 - accuracy: 0.8770\n",
      "Epoch 14/150\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0230 - accuracy: 0.8800\n",
      "Epoch 15/150\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0225 - accuracy: 0.8890\n",
      "Epoch 16/150\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0220 - accuracy: 0.8880\n",
      "Epoch 17/150\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0216 - accuracy: 0.8870\n",
      "Epoch 18/150\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0211 - accuracy: 0.8970\n",
      "Epoch 19/150\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0207 - accuracy: 0.8980\n",
      "Epoch 20/150\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0203 - accuracy: 0.8960\n",
      "Epoch 21/150\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0199 - accuracy: 0.9010\n",
      "Epoch 22/150\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0196 - accuracy: 0.9040\n",
      "Epoch 23/150\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0192 - accuracy: 0.9050\n",
      "Epoch 24/150\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0189 - accuracy: 0.9060\n",
      "Epoch 25/150\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0186 - accuracy: 0.9080\n",
      "Epoch 26/150\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0182 - accuracy: 0.9100\n",
      "Epoch 27/150\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0179 - accuracy: 0.9110\n",
      "Epoch 28/150\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0176 - accuracy: 0.9100\n",
      "Epoch 29/150\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 0.0173 - accuracy: 0.9130\n",
      "Epoch 30/150\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0171 - accuracy: 0.9160\n",
      "Epoch 31/150\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0168 - accuracy: 0.9200\n",
      "Epoch 32/150\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0165 - accuracy: 0.9180\n",
      "Epoch 33/150\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0163 - accuracy: 0.9180\n",
      "Epoch 34/150\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0160 - accuracy: 0.9170\n",
      "Epoch 35/150\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0158 - accuracy: 0.9190\n",
      "Epoch 36/150\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0156 - accuracy: 0.9200\n",
      "Epoch 37/150\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0153 - accuracy: 0.9200\n",
      "Epoch 38/150\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0151 - accuracy: 0.9210\n",
      "Epoch 39/150\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0149 - accuracy: 0.9210\n",
      "Epoch 40/150\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0147 - accuracy: 0.9210\n",
      "Epoch 41/150\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0145 - accuracy: 0.9210\n",
      "Epoch 42/150\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0143 - accuracy: 0.9250\n",
      "Epoch 43/150\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0141 - accuracy: 0.9280\n",
      "Epoch 44/150\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0139 - accuracy: 0.9270\n",
      "Epoch 45/150\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0137 - accuracy: 0.9280\n",
      "Epoch 46/150\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0136 - accuracy: 0.9300\n",
      "Epoch 47/150\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0134 - accuracy: 0.9340\n",
      "Epoch 48/150\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0132 - accuracy: 0.9310\n",
      "Epoch 49/150\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0131 - accuracy: 0.9330\n",
      "Epoch 50/150\n",
      "1000/1000 [==============================] - 0s 82us/sample - loss: 0.0129 - accuracy: 0.9360\n",
      "Epoch 51/150\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0127 - accuracy: 0.9370\n",
      "Epoch 52/150\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0126 - accuracy: 0.9360\n",
      "Epoch 53/150\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0125 - accuracy: 0.9360\n",
      "Epoch 54/150\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0123 - accuracy: 0.9370\n",
      "Epoch 55/150\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0121 - accuracy: 0.9370\n",
      "Epoch 56/150\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0120 - accuracy: 0.9400\n",
      "Epoch 57/150\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0119 - accuracy: 0.9380\n",
      "Epoch 58/150\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0117 - accuracy: 0.9420\n",
      "Epoch 59/150\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0116 - accuracy: 0.9420\n",
      "Epoch 60/150\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0115 - accuracy: 0.9420\n",
      "Epoch 61/150\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0114 - accuracy: 0.9470\n",
      "Epoch 62/150\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0112 - accuracy: 0.9440\n",
      "Epoch 63/150\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0111 - accuracy: 0.9460\n",
      "Epoch 64/150\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0110 - accuracy: 0.9460\n",
      "Epoch 65/150\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0109 - accuracy: 0.9460\n",
      "Epoch 66/150\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0108 - accuracy: 0.9480\n",
      "Epoch 67/150\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0106 - accuracy: 0.9470\n",
      "Epoch 68/150\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0105 - accuracy: 0.9480\n",
      "Epoch 69/150\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0104 - accuracy: 0.9510\n",
      "Epoch 70/150\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0103 - accuracy: 0.9490\n",
      "Epoch 71/150\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0102 - accuracy: 0.9510\n",
      "Epoch 72/150\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0101 - accuracy: 0.9520\n",
      "Epoch 73/150\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0100 - accuracy: 0.9510\n",
      "Epoch 74/150\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0099 - accuracy: 0.9520\n",
      "Epoch 75/150\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0098 - accuracy: 0.9550\n",
      "Epoch 76/150\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0097 - accuracy: 0.9540\n",
      "Epoch 77/150\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0096 - accuracy: 0.9550\n",
      "Epoch 78/150\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0095 - accuracy: 0.9560\n",
      "Epoch 79/150\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0094 - accuracy: 0.9550\n",
      "Epoch 80/150\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0093 - accuracy: 0.9570\n",
      "Epoch 81/150\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0092 - accuracy: 0.9560\n",
      "Epoch 82/150\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0091 - accuracy: 0.9600\n",
      "Epoch 83/150\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0090 - accuracy: 0.9600\n",
      "Epoch 84/150\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0089 - accuracy: 0.9580\n",
      "Epoch 85/150\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0089 - accuracy: 0.9590\n",
      "Epoch 86/150\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0088 - accuracy: 0.9600\n",
      "Epoch 87/150\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0087 - accuracy: 0.9610\n",
      "Epoch 88/150\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0086 - accuracy: 0.9600\n",
      "Epoch 89/150\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0085 - accuracy: 0.9620\n",
      "Epoch 90/150\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0085 - accuracy: 0.9610\n",
      "Epoch 91/150\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0084 - accuracy: 0.9620\n",
      "Epoch 92/150\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0084 - accuracy: 0.9640\n",
      "Epoch 93/150\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0082 - accuracy: 0.9640\n",
      "Epoch 94/150\n",
      "1000/1000 [==============================] - 0s 71us/sample - loss: 0.0082 - accuracy: 0.9630\n",
      "Epoch 95/150\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.0081 - accuracy: 0.9670\n",
      "Epoch 96/150\n",
      "1000/1000 [==============================] - 0s 69us/sample - loss: 0.0080 - accuracy: 0.9660\n",
      "Epoch 97/150\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 0.0079 - accuracy: 0.9670\n",
      "Epoch 98/150\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0079 - accuracy: 0.9680\n",
      "Epoch 99/150\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0078 - accuracy: 0.9680\n",
      "Epoch 100/150\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0078 - accuracy: 0.9650\n",
      "Epoch 101/150\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 0.0077 - accuracy: 0.9690\n",
      "Epoch 102/150\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0076 - accuracy: 0.9690\n",
      "Epoch 103/150\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0076 - accuracy: 0.9670\n",
      "Epoch 104/150\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0075 - accuracy: 0.9700\n",
      "Epoch 105/150\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0074 - accuracy: 0.9690\n",
      "Epoch 106/150\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0074 - accuracy: 0.9700\n",
      "Epoch 107/150\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0073 - accuracy: 0.9700\n",
      "Epoch 108/150\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0072 - accuracy: 0.9700\n",
      "Epoch 109/150\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0072 - accuracy: 0.9700\n",
      "Epoch 110/150\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0071 - accuracy: 0.9710\n",
      "Epoch 111/150\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0071 - accuracy: 0.9720\n",
      "Epoch 112/150\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0070 - accuracy: 0.9710\n",
      "Epoch 113/150\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0070 - accuracy: 0.9710\n",
      "Epoch 114/150\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0069 - accuracy: 0.9710\n",
      "Epoch 115/150\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0069 - accuracy: 0.9740\n",
      "Epoch 116/150\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0068 - accuracy: 0.9730\n",
      "Epoch 117/150\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0068 - accuracy: 0.9750\n",
      "Epoch 118/150\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0067 - accuracy: 0.9730\n",
      "Epoch 119/150\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0067 - accuracy: 0.9740\n",
      "Epoch 120/150\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0066 - accuracy: 0.9750\n",
      "Epoch 121/150\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0066 - accuracy: 0.9740\n",
      "Epoch 122/150\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0065 - accuracy: 0.9750\n",
      "Epoch 123/150\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0064 - accuracy: 0.9750\n",
      "Epoch 124/150\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0064 - accuracy: 0.9760\n",
      "Epoch 125/150\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0064 - accuracy: 0.9750\n",
      "Epoch 126/150\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0063 - accuracy: 0.9770\n",
      "Epoch 127/150\n",
      "1000/1000 [==============================] - 0s 69us/sample - loss: 0.0063 - accuracy: 0.9770\n",
      "Epoch 128/150\n",
      "1000/1000 [==============================] - 0s 70us/sample - loss: 0.0062 - accuracy: 0.9770\n",
      "Epoch 129/150\n",
      "1000/1000 [==============================] - 0s 75us/sample - loss: 0.0062 - accuracy: 0.9770\n",
      "Epoch 130/150\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0061 - accuracy: 0.9770\n",
      "Epoch 131/150\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 0.0061 - accuracy: 0.9770\n",
      "Epoch 132/150\n",
      "1000/1000 [==============================] - 0s 71us/sample - loss: 0.0060 - accuracy: 0.9770\n",
      "Epoch 133/150\n",
      "1000/1000 [==============================] - 0s 76us/sample - loss: 0.0060 - accuracy: 0.9770\n",
      "Epoch 134/150\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 0.0059 - accuracy: 0.9770\n",
      "Epoch 135/150\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0059 - accuracy: 0.9780\n",
      "Epoch 136/150\n",
      "1000/1000 [==============================] - 0s 71us/sample - loss: 0.0059 - accuracy: 0.9770\n",
      "Epoch 137/150\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.0058 - accuracy: 0.9790\n",
      "Epoch 138/150\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 0.0058 - accuracy: 0.9790\n",
      "Epoch 139/150\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.0057 - accuracy: 0.9790\n",
      "Epoch 140/150\n",
      "1000/1000 [==============================] - 0s 72us/sample - loss: 0.0057 - accuracy: 0.9800\n",
      "Epoch 141/150\n",
      "1000/1000 [==============================] - 0s 80us/sample - loss: 0.0057 - accuracy: 0.9790\n",
      "Epoch 142/150\n",
      "1000/1000 [==============================] - 0s 83us/sample - loss: 0.0056 - accuracy: 0.9790\n",
      "Epoch 143/150\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0056 - accuracy: 0.9800\n",
      "Epoch 144/150\n",
      "1000/1000 [==============================] - 0s 76us/sample - loss: 0.0055 - accuracy: 0.9790\n",
      "Epoch 145/150\n",
      "1000/1000 [==============================] - 0s 76us/sample - loss: 0.0055 - accuracy: 0.9800\n",
      "Epoch 146/150\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0055 - accuracy: 0.9800\n",
      "Epoch 147/150\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0054 - accuracy: 0.9790\n",
      "Epoch 148/150\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0054 - accuracy: 0.9800\n",
      "Epoch 149/150\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0054 - accuracy: 0.9800\n",
      "Epoch 150/150\n",
      "1000/1000 [==============================] - 0s 71us/sample - loss: 0.0053 - accuracy: 0.9800\n",
      "Training date and time : \n",
      "2020-03-18 13:24:46\n",
      "Train on 1000 samples\n",
      "Epoch 1/180\n",
      "1000/1000 [==============================] - 0s 291us/sample - loss: 0.0308 - accuracy: 0.8380\n",
      "Epoch 2/180\n",
      "1000/1000 [==============================] - 0s 72us/sample - loss: 0.0298 - accuracy: 0.8370\n",
      "Epoch 3/180\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 0.0290 - accuracy: 0.8390\n",
      "Epoch 4/180\n",
      "1000/1000 [==============================] - 0s 69us/sample - loss: 0.0282 - accuracy: 0.8520\n",
      "Epoch 5/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0275 - accuracy: 0.8520\n",
      "Epoch 6/180\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0268 - accuracy: 0.8580\n",
      "Epoch 7/180\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.0262 - accuracy: 0.8600\n",
      "Epoch 8/180\n",
      "1000/1000 [==============================] - 0s 71us/sample - loss: 0.0256 - accuracy: 0.8640\n",
      "Epoch 9/180\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 0.0250 - accuracy: 0.8720\n",
      "Epoch 10/180\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 0.0244 - accuracy: 0.8710\n",
      "Epoch 11/180\n",
      "1000/1000 [==============================] - 0s 71us/sample - loss: 0.0239 - accuracy: 0.8730\n",
      "Epoch 12/180\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 0.0235 - accuracy: 0.8780\n",
      "Epoch 13/180\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 0.0230 - accuracy: 0.8810\n",
      "Epoch 14/180\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0225 - accuracy: 0.8830\n",
      "Epoch 15/180\n",
      "1000/1000 [==============================] - 0s 69us/sample - loss: 0.0221 - accuracy: 0.8870\n",
      "Epoch 16/180\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 0.0217 - accuracy: 0.8860\n",
      "Epoch 17/180\n",
      "1000/1000 [==============================] - 0s 72us/sample - loss: 0.0213 - accuracy: 0.8910\n",
      "Epoch 18/180\n",
      "1000/1000 [==============================] - 0s 76us/sample - loss: 0.0209 - accuracy: 0.8890\n",
      "Epoch 19/180\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 0.0206 - accuracy: 0.8940\n",
      "Epoch 20/180\n",
      "1000/1000 [==============================] - 0s 78us/sample - loss: 0.0202 - accuracy: 0.8960\n",
      "Epoch 21/180\n",
      "1000/1000 [==============================] - 0s 72us/sample - loss: 0.0199 - accuracy: 0.8960\n",
      "Epoch 22/180\n",
      "1000/1000 [==============================] - 0s 80us/sample - loss: 0.0196 - accuracy: 0.8950\n",
      "Epoch 23/180\n",
      "1000/1000 [==============================] - 0s 83us/sample - loss: 0.0193 - accuracy: 0.8990\n",
      "Epoch 24/180\n",
      "1000/1000 [==============================] - 0s 72us/sample - loss: 0.0190 - accuracy: 0.8990\n",
      "Epoch 25/180\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.0187 - accuracy: 0.8990\n",
      "Epoch 26/180\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.0184 - accuracy: 0.9010\n",
      "Epoch 27/180\n",
      "1000/1000 [==============================] - 0s 71us/sample - loss: 0.0181 - accuracy: 0.9010\n",
      "Epoch 28/180\n",
      "1000/1000 [==============================] - 0s 70us/sample - loss: 0.0179 - accuracy: 0.9010\n",
      "Epoch 29/180\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 0.0176 - accuracy: 0.9000\n",
      "Epoch 30/180\n",
      "1000/1000 [==============================] - 0s 72us/sample - loss: 0.0174 - accuracy: 0.9030\n",
      "Epoch 31/180\n",
      "1000/1000 [==============================] - 0s 78us/sample - loss: 0.0172 - accuracy: 0.9070\n",
      "Epoch 32/180\n",
      "1000/1000 [==============================] - 0s 70us/sample - loss: 0.0169 - accuracy: 0.9060\n",
      "Epoch 33/180\n",
      "1000/1000 [==============================] - 0s 72us/sample - loss: 0.0167 - accuracy: 0.9070\n",
      "Epoch 34/180\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0165 - accuracy: 0.9100\n",
      "Epoch 35/180\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0163 - accuracy: 0.9120\n",
      "Epoch 36/180\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0161 - accuracy: 0.9130\n",
      "Epoch 37/180\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0159 - accuracy: 0.9160\n",
      "Epoch 38/180\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0157 - accuracy: 0.9150\n",
      "Epoch 39/180\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0155 - accuracy: 0.9170\n",
      "Epoch 40/180\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0153 - accuracy: 0.9180\n",
      "Epoch 41/180\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0151 - accuracy: 0.9210\n",
      "Epoch 42/180\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0149 - accuracy: 0.9210\n",
      "Epoch 43/180\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0148 - accuracy: 0.9230\n",
      "Epoch 44/180\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0146 - accuracy: 0.9210\n",
      "Epoch 45/180\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0145 - accuracy: 0.9220\n",
      "Epoch 46/180\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0143 - accuracy: 0.9260\n",
      "Epoch 47/180\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0142 - accuracy: 0.9240\n",
      "Epoch 48/180\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0140 - accuracy: 0.9280\n",
      "Epoch 49/180\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0139 - accuracy: 0.9290\n",
      "Epoch 50/180\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0137 - accuracy: 0.9290\n",
      "Epoch 51/180\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0136 - accuracy: 0.9270\n",
      "Epoch 52/180\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0135 - accuracy: 0.9320\n",
      "Epoch 53/180\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0133 - accuracy: 0.9320\n",
      "Epoch 54/180\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0132 - accuracy: 0.9330\n",
      "Epoch 55/180\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0130 - accuracy: 0.9350\n",
      "Epoch 56/180\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0129 - accuracy: 0.9340\n",
      "Epoch 57/180\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0128 - accuracy: 0.9350\n",
      "Epoch 58/180\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0126 - accuracy: 0.9340\n",
      "Epoch 59/180\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0125 - accuracy: 0.9380\n",
      "Epoch 60/180\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0124 - accuracy: 0.9370\n",
      "Epoch 61/180\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0123 - accuracy: 0.9370\n",
      "Epoch 62/180\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0122 - accuracy: 0.9370\n",
      "Epoch 63/180\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0120 - accuracy: 0.9400\n",
      "Epoch 64/180\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0119 - accuracy: 0.9400\n",
      "Epoch 65/180\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0118 - accuracy: 0.9400\n",
      "Epoch 66/180\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0117 - accuracy: 0.9400\n",
      "Epoch 67/180\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.0116 - accuracy: 0.9400\n",
      "Epoch 68/180\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0115 - accuracy: 0.9430\n",
      "Epoch 69/180\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0114 - accuracy: 0.9450\n",
      "Epoch 70/180\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0113 - accuracy: 0.9440\n",
      "Epoch 71/180\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0112 - accuracy: 0.9440\n",
      "Epoch 72/180\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0111 - accuracy: 0.9450\n",
      "Epoch 73/180\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0110 - accuracy: 0.9460\n",
      "Epoch 74/180\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0108 - accuracy: 0.9460\n",
      "Epoch 75/180\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0108 - accuracy: 0.9480\n",
      "Epoch 76/180\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0106 - accuracy: 0.9470\n",
      "Epoch 77/180\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0106 - accuracy: 0.9470\n",
      "Epoch 78/180\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0105 - accuracy: 0.9440\n",
      "Epoch 79/180\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0104 - accuracy: 0.9480\n",
      "Epoch 80/180\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0103 - accuracy: 0.9490\n",
      "Epoch 81/180\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0102 - accuracy: 0.9520\n",
      "Epoch 82/180\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0101 - accuracy: 0.9520\n",
      "Epoch 83/180\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0100 - accuracy: 0.9510\n",
      "Epoch 84/180\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0099 - accuracy: 0.9520\n",
      "Epoch 85/180\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0098 - accuracy: 0.9540\n",
      "Epoch 86/180\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0097 - accuracy: 0.9530\n",
      "Epoch 87/180\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0097 - accuracy: 0.9530\n",
      "Epoch 88/180\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0096 - accuracy: 0.9560\n",
      "Epoch 89/180\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0095 - accuracy: 0.9540\n",
      "Epoch 90/180\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0094 - accuracy: 0.9540\n",
      "Epoch 91/180\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0093 - accuracy: 0.9550\n",
      "Epoch 92/180\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0093 - accuracy: 0.9560\n",
      "Epoch 93/180\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0092 - accuracy: 0.9570\n",
      "Epoch 94/180\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0091 - accuracy: 0.9570\n",
      "Epoch 95/180\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0090 - accuracy: 0.9580\n",
      "Epoch 96/180\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0089 - accuracy: 0.9600\n",
      "Epoch 97/180\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0089 - accuracy: 0.9590\n",
      "Epoch 98/180\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0088 - accuracy: 0.9590\n",
      "Epoch 99/180\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0087 - accuracy: 0.9590\n",
      "Epoch 100/180\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0086 - accuracy: 0.9620\n",
      "Epoch 101/180\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0086 - accuracy: 0.9600\n",
      "Epoch 102/180\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0085 - accuracy: 0.9640\n",
      "Epoch 103/180\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0084 - accuracy: 0.9620\n",
      "Epoch 104/180\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0084 - accuracy: 0.9630\n",
      "Epoch 105/180\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0083 - accuracy: 0.9630\n",
      "Epoch 106/180\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0082 - accuracy: 0.9650\n",
      "Epoch 107/180\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0081 - accuracy: 0.9640\n",
      "Epoch 108/180\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.0081 - accuracy: 0.9650\n",
      "Epoch 109/180\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0080 - accuracy: 0.9640\n",
      "Epoch 110/180\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0080 - accuracy: 0.9660\n",
      "Epoch 111/180\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0079 - accuracy: 0.9660\n",
      "Epoch 112/180\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0078 - accuracy: 0.9660\n",
      "Epoch 113/180\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0077 - accuracy: 0.9650\n",
      "Epoch 114/180\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.0077 - accuracy: 0.9660\n",
      "Epoch 115/180\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0076 - accuracy: 0.9660\n",
      "Epoch 116/180\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0076 - accuracy: 0.9670\n",
      "Epoch 117/180\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0075 - accuracy: 0.9660\n",
      "Epoch 118/180\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0074 - accuracy: 0.9660\n",
      "Epoch 119/180\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0074 - accuracy: 0.9680\n",
      "Epoch 120/180\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0073 - accuracy: 0.9670\n",
      "Epoch 121/180\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0073 - accuracy: 0.9670\n",
      "Epoch 122/180\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0072 - accuracy: 0.9680\n",
      "Epoch 123/180\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0072 - accuracy: 0.9670\n",
      "Epoch 124/180\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0071 - accuracy: 0.9680\n",
      "Epoch 125/180\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0071 - accuracy: 0.9690\n",
      "Epoch 126/180\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0070 - accuracy: 0.9690\n",
      "Epoch 127/180\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0070 - accuracy: 0.9700\n",
      "Epoch 128/180\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0069 - accuracy: 0.9680\n",
      "Epoch 129/180\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0069 - accuracy: 0.9680\n",
      "Epoch 130/180\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0068 - accuracy: 0.9690\n",
      "Epoch 131/180\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0068 - accuracy: 0.9690\n",
      "Epoch 132/180\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0067 - accuracy: 0.9700\n",
      "Epoch 133/180\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0067 - accuracy: 0.9710\n",
      "Epoch 134/180\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0066 - accuracy: 0.9710\n",
      "Epoch 135/180\n",
      "1000/1000 [==============================] - 0s 71us/sample - loss: 0.0066 - accuracy: 0.9710\n",
      "Epoch 136/180\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.0065 - accuracy: 0.9720\n",
      "Epoch 137/180\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 0.0065 - accuracy: 0.9740\n",
      "Epoch 138/180\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 0.0064 - accuracy: 0.9730\n",
      "Epoch 139/180\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0064 - accuracy: 0.9750\n",
      "Epoch 140/180\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 0.0064 - accuracy: 0.9740\n",
      "Epoch 141/180\n",
      "1000/1000 [==============================] - 0s 72us/sample - loss: 0.0063 - accuracy: 0.9760\n",
      "Epoch 142/180\n",
      "1000/1000 [==============================] - 0s 69us/sample - loss: 0.0062 - accuracy: 0.9730\n",
      "Epoch 143/180\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0062 - accuracy: 0.9760\n",
      "Epoch 144/180\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0062 - accuracy: 0.9750\n",
      "Epoch 145/180\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0061 - accuracy: 0.9750\n",
      "Epoch 146/180\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0061 - accuracy: 0.9750\n",
      "Epoch 147/180\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0060 - accuracy: 0.9750\n",
      "Epoch 148/180\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0060 - accuracy: 0.9760\n",
      "Epoch 149/180\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 0.0059 - accuracy: 0.9770\n",
      "Epoch 150/180\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0059 - accuracy: 0.9760\n",
      "Epoch 151/180\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0059 - accuracy: 0.9760\n",
      "Epoch 152/180\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0058 - accuracy: 0.9760\n",
      "Epoch 153/180\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.0058 - accuracy: 0.9770\n",
      "Epoch 154/180\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0057 - accuracy: 0.9770\n",
      "Epoch 155/180\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0057 - accuracy: 0.9770\n",
      "Epoch 156/180\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0057 - accuracy: 0.9770\n",
      "Epoch 157/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0056 - accuracy: 0.9780\n",
      "Epoch 158/180\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0056 - accuracy: 0.9770\n",
      "Epoch 159/180\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0056 - accuracy: 0.9770\n",
      "Epoch 160/180\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0055 - accuracy: 0.9770\n",
      "Epoch 161/180\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0055 - accuracy: 0.9780\n",
      "Epoch 162/180\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0055 - accuracy: 0.9770\n",
      "Epoch 163/180\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0054 - accuracy: 0.9780\n",
      "Epoch 164/180\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0054 - accuracy: 0.9770\n",
      "Epoch 165/180\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0054 - accuracy: 0.9780\n",
      "Epoch 166/180\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0053 - accuracy: 0.9780\n",
      "Epoch 167/180\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0053 - accuracy: 0.9780\n",
      "Epoch 168/180\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0053 - accuracy: 0.9780\n",
      "Epoch 169/180\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0052 - accuracy: 0.9780\n",
      "Epoch 170/180\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0052 - accuracy: 0.9780\n",
      "Epoch 171/180\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0052 - accuracy: 0.9780\n",
      "Epoch 172/180\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0051 - accuracy: 0.9780\n",
      "Epoch 173/180\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0051 - accuracy: 0.9780\n",
      "Epoch 174/180\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0051 - accuracy: 0.9790\n",
      "Epoch 175/180\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0050 - accuracy: 0.9780\n",
      "Epoch 176/180\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0050 - accuracy: 0.9780\n",
      "Epoch 177/180\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0050 - accuracy: 0.9790\n",
      "Epoch 178/180\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0049 - accuracy: 0.9780\n",
      "Epoch 179/180\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0049 - accuracy: 0.9780\n",
      "Epoch 180/180\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0049 - accuracy: 0.9800\n",
      "Training date and time : \n",
      "2020-03-18 13:24:57\n",
      "Train on 1000 samples\n",
      "Epoch 1/210\n",
      "1000/1000 [==============================] - 0s 251us/sample - loss: 0.0304 - accuracy: 0.8300\n",
      "Epoch 2/210\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 0.0294 - accuracy: 0.8390\n",
      "Epoch 3/210\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.0285 - accuracy: 0.8400\n",
      "Epoch 4/210\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0276 - accuracy: 0.8550\n",
      "Epoch 5/210\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0269 - accuracy: 0.8550\n",
      "Epoch 6/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0262 - accuracy: 0.8590\n",
      "Epoch 7/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0255 - accuracy: 0.8630\n",
      "Epoch 8/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0248 - accuracy: 0.8650\n",
      "Epoch 9/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0242 - accuracy: 0.8700\n",
      "Epoch 10/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0236 - accuracy: 0.8720\n",
      "Epoch 11/210\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0231 - accuracy: 0.8800\n",
      "Epoch 12/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0226 - accuracy: 0.8800\n",
      "Epoch 13/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0221 - accuracy: 0.8850\n",
      "Epoch 14/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0216 - accuracy: 0.8920\n",
      "Epoch 15/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0212 - accuracy: 0.8940\n",
      "Epoch 16/210\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0208 - accuracy: 0.8960\n",
      "Epoch 17/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0204 - accuracy: 0.9010\n",
      "Epoch 18/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0200 - accuracy: 0.9000\n",
      "Epoch 19/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0196 - accuracy: 0.9020\n",
      "Epoch 20/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0193 - accuracy: 0.9050\n",
      "Epoch 21/210\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0189 - accuracy: 0.9060\n",
      "Epoch 22/210\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0186 - accuracy: 0.9080\n",
      "Epoch 23/210\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0183 - accuracy: 0.9130\n",
      "Epoch 24/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0180 - accuracy: 0.9130\n",
      "Epoch 25/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0177 - accuracy: 0.9140\n",
      "Epoch 26/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0174 - accuracy: 0.9180\n",
      "Epoch 27/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0171 - accuracy: 0.9200\n",
      "Epoch 28/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0169 - accuracy: 0.9170\n",
      "Epoch 29/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0166 - accuracy: 0.9240\n",
      "Epoch 30/210\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0163 - accuracy: 0.9210\n",
      "Epoch 31/210\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0161 - accuracy: 0.9240\n",
      "Epoch 32/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0159 - accuracy: 0.9270\n",
      "Epoch 33/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0157 - accuracy: 0.9260\n",
      "Epoch 34/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0154 - accuracy: 0.9290\n",
      "Epoch 35/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0152 - accuracy: 0.9270\n",
      "Epoch 36/210\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0150 - accuracy: 0.9310\n",
      "Epoch 37/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0148 - accuracy: 0.9320\n",
      "Epoch 38/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0146 - accuracy: 0.9320\n",
      "Epoch 39/210\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0144 - accuracy: 0.9320\n",
      "Epoch 40/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0142 - accuracy: 0.9340\n",
      "Epoch 41/210\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0141 - accuracy: 0.9350\n",
      "Epoch 42/210\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0139 - accuracy: 0.9360\n",
      "Epoch 43/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0137 - accuracy: 0.9360\n",
      "Epoch 44/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0136 - accuracy: 0.9360\n",
      "Epoch 45/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0134 - accuracy: 0.9370\n",
      "Epoch 46/210\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0132 - accuracy: 0.9370\n",
      "Epoch 47/210\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0131 - accuracy: 0.9380\n",
      "Epoch 48/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0129 - accuracy: 0.9370\n",
      "Epoch 49/210\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0128 - accuracy: 0.9400\n",
      "Epoch 50/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0126 - accuracy: 0.9370\n",
      "Epoch 51/210\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0125 - accuracy: 0.9410\n",
      "Epoch 52/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0123 - accuracy: 0.9370\n",
      "Epoch 53/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0122 - accuracy: 0.9460\n",
      "Epoch 54/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0120 - accuracy: 0.9410\n",
      "Epoch 55/210\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0119 - accuracy: 0.9430\n",
      "Epoch 56/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0118 - accuracy: 0.9480\n",
      "Epoch 57/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0116 - accuracy: 0.9470\n",
      "Epoch 58/210\n",
      "1000/1000 [==============================] - 0s 70us/sample - loss: 0.0115 - accuracy: 0.9470\n",
      "Epoch 59/210\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0114 - accuracy: 0.9450\n",
      "Epoch 60/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0113 - accuracy: 0.9470\n",
      "Epoch 61/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0112 - accuracy: 0.9510\n",
      "Epoch 62/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0111 - accuracy: 0.9490\n",
      "Epoch 63/210\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0109 - accuracy: 0.9510\n",
      "Epoch 64/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0108 - accuracy: 0.9510\n",
      "Epoch 65/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0107 - accuracy: 0.9520\n",
      "Epoch 66/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0106 - accuracy: 0.9510\n",
      "Epoch 67/210\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0105 - accuracy: 0.9530\n",
      "Epoch 68/210\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0104 - accuracy: 0.9530\n",
      "Epoch 69/210\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0103 - accuracy: 0.9540\n",
      "Epoch 70/210\n",
      "1000/1000 [==============================] - 0s 73us/sample - loss: 0.0102 - accuracy: 0.9550\n",
      "Epoch 71/210\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0100 - accuracy: 0.9560\n",
      "Epoch 72/210\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0100 - accuracy: 0.9570\n",
      "Epoch 73/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0099 - accuracy: 0.9560\n",
      "Epoch 74/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0098 - accuracy: 0.9560\n",
      "Epoch 75/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0097 - accuracy: 0.9570\n",
      "Epoch 76/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0096 - accuracy: 0.9610\n",
      "Epoch 77/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0095 - accuracy: 0.9580\n",
      "Epoch 78/210\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0094 - accuracy: 0.9590\n",
      "Epoch 79/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0093 - accuracy: 0.9610\n",
      "Epoch 80/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0092 - accuracy: 0.9600\n",
      "Epoch 81/210\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0091 - accuracy: 0.9620\n",
      "Epoch 82/210\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0091 - accuracy: 0.9620\n",
      "Epoch 83/210\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0090 - accuracy: 0.9610\n",
      "Epoch 84/210\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0089 - accuracy: 0.9630\n",
      "Epoch 85/210\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0088 - accuracy: 0.9590\n",
      "Epoch 86/210\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0087 - accuracy: 0.9640\n",
      "Epoch 87/210\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0087 - accuracy: 0.9610\n",
      "Epoch 88/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0085 - accuracy: 0.9640\n",
      "Epoch 89/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0085 - accuracy: 0.9650\n",
      "Epoch 90/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0084 - accuracy: 0.9650\n",
      "Epoch 91/210\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0083 - accuracy: 0.9640\n",
      "Epoch 92/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0082 - accuracy: 0.9650\n",
      "Epoch 93/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0082 - accuracy: 0.9650\n",
      "Epoch 94/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0081 - accuracy: 0.9650\n",
      "Epoch 95/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0080 - accuracy: 0.9650\n",
      "Epoch 96/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0080 - accuracy: 0.9650\n",
      "Epoch 97/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0079 - accuracy: 0.9650\n",
      "Epoch 98/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0078 - accuracy: 0.9650\n",
      "Epoch 99/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0078 - accuracy: 0.9650\n",
      "Epoch 100/210\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0077 - accuracy: 0.9660\n",
      "Epoch 101/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0076 - accuracy: 0.9660\n",
      "Epoch 102/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0076 - accuracy: 0.9670\n",
      "Epoch 103/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0075 - accuracy: 0.9660\n",
      "Epoch 104/210\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0074 - accuracy: 0.9660\n",
      "Epoch 105/210\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0074 - accuracy: 0.9680\n",
      "Epoch 106/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0073 - accuracy: 0.9680\n",
      "Epoch 107/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0072 - accuracy: 0.9680\n",
      "Epoch 108/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0071 - accuracy: 0.9690\n",
      "Epoch 109/210\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0071 - accuracy: 0.9700\n",
      "Epoch 110/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0071 - accuracy: 0.9690\n",
      "Epoch 111/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0070 - accuracy: 0.9690\n",
      "Epoch 112/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0069 - accuracy: 0.9700\n",
      "Epoch 113/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0069 - accuracy: 0.9690\n",
      "Epoch 114/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0068 - accuracy: 0.9720\n",
      "Epoch 115/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0068 - accuracy: 0.9720\n",
      "Epoch 116/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0067 - accuracy: 0.9710\n",
      "Epoch 117/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0066 - accuracy: 0.9700\n",
      "Epoch 118/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0066 - accuracy: 0.9710\n",
      "Epoch 119/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0065 - accuracy: 0.9720\n",
      "Epoch 120/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0064 - accuracy: 0.9730\n",
      "Epoch 121/210\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0064 - accuracy: 0.9720\n",
      "Epoch 122/210\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0063 - accuracy: 0.9700\n",
      "Epoch 123/210\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0063 - accuracy: 0.9720\n",
      "Epoch 124/210\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0062 - accuracy: 0.9730\n",
      "Epoch 125/210\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0062 - accuracy: 0.9740\n",
      "Epoch 126/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0061 - accuracy: 0.9730\n",
      "Epoch 127/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0061 - accuracy: 0.9750\n",
      "Epoch 128/210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0061 - accuracy: 0.9750\n",
      "Epoch 129/210\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0060 - accuracy: 0.9740\n",
      "Epoch 130/210\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0059 - accuracy: 0.9750\n",
      "Epoch 131/210\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0059 - accuracy: 0.9770\n",
      "Epoch 132/210\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0058 - accuracy: 0.9760\n",
      "Epoch 133/210\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0058 - accuracy: 0.9770\n",
      "Epoch 134/210\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0057 - accuracy: 0.9770\n",
      "Epoch 135/210\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0057 - accuracy: 0.9770\n",
      "Epoch 136/210\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0056 - accuracy: 0.9780\n",
      "Epoch 137/210\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0056 - accuracy: 0.9780\n",
      "Epoch 138/210\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0055 - accuracy: 0.9780\n",
      "Epoch 139/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0055 - accuracy: 0.9790\n",
      "Epoch 140/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0055 - accuracy: 0.9790\n",
      "Epoch 141/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0054 - accuracy: 0.9790\n",
      "Epoch 142/210\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0054 - accuracy: 0.9810\n",
      "Epoch 143/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0053 - accuracy: 0.9800\n",
      "Epoch 144/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0053 - accuracy: 0.9810\n",
      "Epoch 145/210\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0052 - accuracy: 0.9810\n",
      "Epoch 146/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0052 - accuracy: 0.9810\n",
      "Epoch 147/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0051 - accuracy: 0.9820\n",
      "Epoch 148/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0051 - accuracy: 0.9830\n",
      "Epoch 149/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0050 - accuracy: 0.9820\n",
      "Epoch 150/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0050 - accuracy: 0.9820\n",
      "Epoch 151/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0050 - accuracy: 0.9820\n",
      "Epoch 152/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0049 - accuracy: 0.9830\n",
      "Epoch 153/210\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0049 - accuracy: 0.9830\n",
      "Epoch 154/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0049 - accuracy: 0.9830\n",
      "Epoch 155/210\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0048 - accuracy: 0.9840\n",
      "Epoch 156/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0048 - accuracy: 0.9830\n",
      "Epoch 157/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0047 - accuracy: 0.9840\n",
      "Epoch 158/210\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0047 - accuracy: 0.9840\n",
      "Epoch 159/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0047 - accuracy: 0.9840\n",
      "Epoch 160/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0046 - accuracy: 0.9840\n",
      "Epoch 161/210\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0046 - accuracy: 0.9850\n",
      "Epoch 162/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0046 - accuracy: 0.9850\n",
      "Epoch 163/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0045 - accuracy: 0.9850\n",
      "Epoch 164/210\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0045 - accuracy: 0.9860\n",
      "Epoch 165/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0044 - accuracy: 0.9850\n",
      "Epoch 166/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0044 - accuracy: 0.9860\n",
      "Epoch 167/210\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0044 - accuracy: 0.9860\n",
      "Epoch 168/210\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0043 - accuracy: 0.9860\n",
      "Epoch 169/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0043 - accuracy: 0.9860\n",
      "Epoch 170/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0043 - accuracy: 0.9860\n",
      "Epoch 171/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0042 - accuracy: 0.9860\n",
      "Epoch 172/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0042 - accuracy: 0.9870\n",
      "Epoch 173/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0042 - accuracy: 0.9870\n",
      "Epoch 174/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0041 - accuracy: 0.9870\n",
      "Epoch 175/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0041 - accuracy: 0.9870\n",
      "Epoch 176/210\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0041 - accuracy: 0.9870\n",
      "Epoch 177/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0040 - accuracy: 0.9870\n",
      "Epoch 178/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0040 - accuracy: 0.9870\n",
      "Epoch 179/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0040 - accuracy: 0.9870\n",
      "Epoch 180/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0039 - accuracy: 0.9870\n",
      "Epoch 181/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0039 - accuracy: 0.9870\n",
      "Epoch 182/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0039 - accuracy: 0.9870\n",
      "Epoch 183/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0039 - accuracy: 0.9870\n",
      "Epoch 184/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0038 - accuracy: 0.9870\n",
      "Epoch 185/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0038 - accuracy: 0.9870\n",
      "Epoch 186/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0038 - accuracy: 0.9870\n",
      "Epoch 187/210\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0037 - accuracy: 0.9870\n",
      "Epoch 188/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0037 - accuracy: 0.9870\n",
      "Epoch 189/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0037 - accuracy: 0.9870\n",
      "Epoch 190/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0036 - accuracy: 0.9870\n",
      "Epoch 191/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0036 - accuracy: 0.9880\n",
      "Epoch 192/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0036 - accuracy: 0.9870\n",
      "Epoch 193/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0036 - accuracy: 0.9880\n",
      "Epoch 194/210\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0035 - accuracy: 0.9870\n",
      "Epoch 195/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0035 - accuracy: 0.9880\n",
      "Epoch 196/210\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0035 - accuracy: 0.9880\n",
      "Epoch 197/210\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0035 - accuracy: 0.9870\n",
      "Epoch 198/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0034 - accuracy: 0.9880\n",
      "Epoch 199/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0034 - accuracy: 0.9880\n",
      "Epoch 200/210\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0034 - accuracy: 0.9880\n",
      "Epoch 201/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0034 - accuracy: 0.9880\n",
      "Epoch 202/210\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0033 - accuracy: 0.9880\n",
      "Epoch 203/210\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0033 - accuracy: 0.9890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204/210\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0033 - accuracy: 0.9890\n",
      "Epoch 205/210\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0033 - accuracy: 0.9890\n",
      "Epoch 206/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0033 - accuracy: 0.9890\n",
      "Epoch 207/210\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0032 - accuracy: 0.9900\n",
      "Epoch 208/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0032 - accuracy: 0.9900\n",
      "Epoch 209/210\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0032 - accuracy: 0.9900\n",
      "Epoch 210/210\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0032 - accuracy: 0.9900\n",
      "Training date and time : \n",
      "2020-03-18 13:25:08\n",
      "Train on 1000 samples\n",
      "Epoch 1/240\n",
      "1000/1000 [==============================] - 0s 223us/sample - loss: 0.0365 - accuracy: 0.7980\n",
      "Epoch 2/240\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0354 - accuracy: 0.8040\n",
      "Epoch 3/240\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0345 - accuracy: 0.8030\n",
      "Epoch 4/240\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0336 - accuracy: 0.8100\n",
      "Epoch 5/240\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0327 - accuracy: 0.8220\n",
      "Epoch 6/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0320 - accuracy: 0.8230\n",
      "Epoch 7/240\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0312 - accuracy: 0.8300\n",
      "Epoch 8/240\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0304 - accuracy: 0.8380\n",
      "Epoch 9/240\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0297 - accuracy: 0.8430\n",
      "Epoch 10/240\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0290 - accuracy: 0.8460\n",
      "Epoch 11/240\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0284 - accuracy: 0.8550\n",
      "Epoch 12/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0278 - accuracy: 0.8580\n",
      "Epoch 13/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0272 - accuracy: 0.8580\n",
      "Epoch 14/240\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0266 - accuracy: 0.8680\n",
      "Epoch 15/240\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0260 - accuracy: 0.8680\n",
      "Epoch 16/240\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0255 - accuracy: 0.8760\n",
      "Epoch 17/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0250 - accuracy: 0.8850\n",
      "Epoch 18/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0245 - accuracy: 0.8780\n",
      "Epoch 19/240\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0240 - accuracy: 0.8830\n",
      "Epoch 20/240\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0236 - accuracy: 0.8800\n",
      "Epoch 21/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0232 - accuracy: 0.8890\n",
      "Epoch 22/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0227 - accuracy: 0.8870\n",
      "Epoch 23/240\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0223 - accuracy: 0.8910\n",
      "Epoch 24/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0219 - accuracy: 0.8940\n",
      "Epoch 25/240\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0215 - accuracy: 0.8930\n",
      "Epoch 26/240\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0212 - accuracy: 0.8970\n",
      "Epoch 27/240\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0209 - accuracy: 0.8990\n",
      "Epoch 28/240\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0206 - accuracy: 0.8970\n",
      "Epoch 29/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0202 - accuracy: 0.9020\n",
      "Epoch 30/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0200 - accuracy: 0.9000\n",
      "Epoch 31/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0196 - accuracy: 0.9010\n",
      "Epoch 32/240\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0193 - accuracy: 0.8980\n",
      "Epoch 33/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0191 - accuracy: 0.9010\n",
      "Epoch 34/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0188 - accuracy: 0.9020\n",
      "Epoch 35/240\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0185 - accuracy: 0.9060\n",
      "Epoch 36/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0183 - accuracy: 0.9050\n",
      "Epoch 37/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0180 - accuracy: 0.9080\n",
      "Epoch 38/240\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0178 - accuracy: 0.9100\n",
      "Epoch 39/240\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0175 - accuracy: 0.9080\n",
      "Epoch 40/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0173 - accuracy: 0.9110\n",
      "Epoch 41/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0171 - accuracy: 0.9100\n",
      "Epoch 42/240\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0169 - accuracy: 0.9190\n",
      "Epoch 43/240\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0167 - accuracy: 0.9130\n",
      "Epoch 44/240\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0164 - accuracy: 0.9150\n",
      "Epoch 45/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0162 - accuracy: 0.9130\n",
      "Epoch 46/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0161 - accuracy: 0.9150\n",
      "Epoch 47/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0159 - accuracy: 0.9150\n",
      "Epoch 48/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0157 - accuracy: 0.9200\n",
      "Epoch 49/240\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0155 - accuracy: 0.9160\n",
      "Epoch 50/240\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.90 - 0s 49us/sample - loss: 0.0153 - accuracy: 0.9190\n",
      "Epoch 51/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0151 - accuracy: 0.9230\n",
      "Epoch 52/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0150 - accuracy: 0.9220\n",
      "Epoch 53/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0148 - accuracy: 0.9240\n",
      "Epoch 54/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0146 - accuracy: 0.9230\n",
      "Epoch 55/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0144 - accuracy: 0.9260\n",
      "Epoch 56/240\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0143 - accuracy: 0.9240\n",
      "Epoch 57/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0141 - accuracy: 0.9280\n",
      "Epoch 58/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0140 - accuracy: 0.9300\n",
      "Epoch 59/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0138 - accuracy: 0.9270\n",
      "Epoch 60/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0137 - accuracy: 0.9270\n",
      "Epoch 61/240\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0135 - accuracy: 0.9330\n",
      "Epoch 62/240\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0134 - accuracy: 0.9360\n",
      "Epoch 63/240\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0132 - accuracy: 0.9350\n",
      "Epoch 64/240\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0131 - accuracy: 0.9360\n",
      "Epoch 65/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0130 - accuracy: 0.9350\n",
      "Epoch 66/240\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0129 - accuracy: 0.9360\n",
      "Epoch 67/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0127 - accuracy: 0.9390\n",
      "Epoch 68/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0126 - accuracy: 0.9370\n",
      "Epoch 69/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0125 - accuracy: 0.9400\n",
      "Epoch 70/240\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0124 - accuracy: 0.9420\n",
      "Epoch 71/240\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0123 - accuracy: 0.9420\n",
      "Epoch 72/240\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0122 - accuracy: 0.9420\n",
      "Epoch 73/240\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0120 - accuracy: 0.9450\n",
      "Epoch 74/240\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0119 - accuracy: 0.9450\n",
      "Epoch 75/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0118 - accuracy: 0.9430\n",
      "Epoch 76/240\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0117 - accuracy: 0.9440\n",
      "Epoch 77/240\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0116 - accuracy: 0.9440\n",
      "Epoch 78/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0115 - accuracy: 0.9460\n",
      "Epoch 79/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0114 - accuracy: 0.9480\n",
      "Epoch 80/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0113 - accuracy: 0.9450\n",
      "Epoch 81/240\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0112 - accuracy: 0.9480\n",
      "Epoch 82/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0111 - accuracy: 0.9470\n",
      "Epoch 83/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0110 - accuracy: 0.9480\n",
      "Epoch 84/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0109 - accuracy: 0.9490\n",
      "Epoch 85/240\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0108 - accuracy: 0.9490\n",
      "Epoch 86/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0107 - accuracy: 0.9510\n",
      "Epoch 87/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0106 - accuracy: 0.9480\n",
      "Epoch 88/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0105 - accuracy: 0.9530\n",
      "Epoch 89/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0104 - accuracy: 0.9520\n",
      "Epoch 90/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0104 - accuracy: 0.9520\n",
      "Epoch 91/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0102 - accuracy: 0.9520\n",
      "Epoch 92/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0102 - accuracy: 0.9530\n",
      "Epoch 93/240\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0101 - accuracy: 0.9530\n",
      "Epoch 94/240\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0100 - accuracy: 0.9540\n",
      "Epoch 95/240\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0099 - accuracy: 0.9540\n",
      "Epoch 96/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0098 - accuracy: 0.9530\n",
      "Epoch 97/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0097 - accuracy: 0.9570\n",
      "Epoch 98/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0097 - accuracy: 0.9550\n",
      "Epoch 99/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0096 - accuracy: 0.9570\n",
      "Epoch 100/240\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0095 - accuracy: 0.9570\n",
      "Epoch 101/240\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0094 - accuracy: 0.9540\n",
      "Epoch 102/240\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0094 - accuracy: 0.9560\n",
      "Epoch 103/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0093 - accuracy: 0.9550\n",
      "Epoch 104/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0092 - accuracy: 0.9570\n",
      "Epoch 105/240\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0091 - accuracy: 0.9560\n",
      "Epoch 106/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0090 - accuracy: 0.9560\n",
      "Epoch 107/240\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.0090 - accuracy: 0.9580\n",
      "Epoch 108/240\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0089 - accuracy: 0.9580\n",
      "Epoch 109/240\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0088 - accuracy: 0.9570\n",
      "Epoch 110/240\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0088 - accuracy: 0.9590\n",
      "Epoch 111/240\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0087 - accuracy: 0.9570\n",
      "Epoch 112/240\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0086 - accuracy: 0.9590\n",
      "Epoch 113/240\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0086 - accuracy: 0.9570\n",
      "Epoch 114/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0085 - accuracy: 0.9580\n",
      "Epoch 115/240\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0085 - accuracy: 0.9600\n",
      "Epoch 116/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0084 - accuracy: 0.9580\n",
      "Epoch 117/240\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0083 - accuracy: 0.9600\n",
      "Epoch 118/240\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0082 - accuracy: 0.9600\n",
      "Epoch 119/240\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0082 - accuracy: 0.9590\n",
      "Epoch 120/240\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0081 - accuracy: 0.9610\n",
      "Epoch 121/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0081 - accuracy: 0.9620\n",
      "Epoch 122/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0080 - accuracy: 0.9630\n",
      "Epoch 123/240\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0079 - accuracy: 0.9670\n",
      "Epoch 124/240\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0079 - accuracy: 0.9640\n",
      "Epoch 125/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0078 - accuracy: 0.9630\n",
      "Epoch 126/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0078 - accuracy: 0.9660\n",
      "Epoch 127/240\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0077 - accuracy: 0.9670\n",
      "Epoch 128/240\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0076 - accuracy: 0.9660\n",
      "Epoch 129/240\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0076 - accuracy: 0.9660\n",
      "Epoch 130/240\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0075 - accuracy: 0.9690\n",
      "Epoch 131/240\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0075 - accuracy: 0.9670\n",
      "Epoch 132/240\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0074 - accuracy: 0.9680\n",
      "Epoch 133/240\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0074 - accuracy: 0.9680\n",
      "Epoch 134/240\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0073 - accuracy: 0.9680\n",
      "Epoch 135/240\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0073 - accuracy: 0.9690\n",
      "Epoch 136/240\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0072 - accuracy: 0.9690\n",
      "Epoch 137/240\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0072 - accuracy: 0.9690\n",
      "Epoch 138/240\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0071 - accuracy: 0.9690\n",
      "Epoch 139/240\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0071 - accuracy: 0.9700\n",
      "Epoch 140/240\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0070 - accuracy: 0.9700\n",
      "Epoch 141/240\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0070 - accuracy: 0.9700\n",
      "Epoch 142/240\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0069 - accuracy: 0.9710\n",
      "Epoch 143/240\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0069 - accuracy: 0.9700\n",
      "Epoch 144/240\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0068 - accuracy: 0.9710\n",
      "Epoch 145/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0068 - accuracy: 0.9710\n",
      "Epoch 146/240\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0067 - accuracy: 0.9720\n",
      "Epoch 147/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0067 - accuracy: 0.9710\n",
      "Epoch 148/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0066 - accuracy: 0.9730\n",
      "Epoch 149/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0066 - accuracy: 0.9740\n",
      "Epoch 150/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0065 - accuracy: 0.9720\n",
      "Epoch 151/240\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0065 - accuracy: 0.9730\n",
      "Epoch 152/240\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0064 - accuracy: 0.9730\n",
      "Epoch 153/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0064 - accuracy: 0.9730\n",
      "Epoch 154/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0064 - accuracy: 0.9730\n",
      "Epoch 155/240\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0063 - accuracy: 0.9750\n",
      "Epoch 156/240\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0063 - accuracy: 0.9730\n",
      "Epoch 157/240\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0062 - accuracy: 0.9730\n",
      "Epoch 158/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0062 - accuracy: 0.9750\n",
      "Epoch 159/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0061 - accuracy: 0.9740\n",
      "Epoch 160/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0061 - accuracy: 0.9730\n",
      "Epoch 161/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0061 - accuracy: 0.9730\n",
      "Epoch 162/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0060 - accuracy: 0.9740\n",
      "Epoch 163/240\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0060 - accuracy: 0.9730\n",
      "Epoch 164/240\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0060 - accuracy: 0.9750\n",
      "Epoch 165/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0059 - accuracy: 0.9740\n",
      "Epoch 166/240\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0059 - accuracy: 0.9740\n",
      "Epoch 167/240\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.98 - 0s 51us/sample - loss: 0.0058 - accuracy: 0.9760\n",
      "Epoch 168/240\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0058 - accuracy: 0.9750\n",
      "Epoch 169/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0058 - accuracy: 0.9760\n",
      "Epoch 170/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0057 - accuracy: 0.9760\n",
      "Epoch 171/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0057 - accuracy: 0.9750\n",
      "Epoch 172/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0057 - accuracy: 0.9760\n",
      "Epoch 173/240\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0056 - accuracy: 0.9750\n",
      "Epoch 174/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0056 - accuracy: 0.9760\n",
      "Epoch 175/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0055 - accuracy: 0.9750\n",
      "Epoch 176/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0055 - accuracy: 0.9770\n",
      "Epoch 177/240\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0055 - accuracy: 0.9740\n",
      "Epoch 178/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0054 - accuracy: 0.9770\n",
      "Epoch 179/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0054 - accuracy: 0.9780\n",
      "Epoch 180/240\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0054 - accuracy: 0.9770\n",
      "Epoch 181/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0053 - accuracy: 0.9770\n",
      "Epoch 182/240\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0053 - accuracy: 0.9780\n",
      "Epoch 183/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0052 - accuracy: 0.9780\n",
      "Epoch 184/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0052 - accuracy: 0.9790\n",
      "Epoch 185/240\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0052 - accuracy: 0.9800\n",
      "Epoch 186/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0052 - accuracy: 0.9790\n",
      "Epoch 187/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0051 - accuracy: 0.9800\n",
      "Epoch 188/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0051 - accuracy: 0.9790\n",
      "Epoch 189/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0051 - accuracy: 0.9800\n",
      "Epoch 190/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0051 - accuracy: 0.9790\n",
      "Epoch 191/240\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0050 - accuracy: 0.9800\n",
      "Epoch 192/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0050 - accuracy: 0.9800\n",
      "Epoch 193/240\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0049 - accuracy: 0.9800\n",
      "Epoch 194/240\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0049 - accuracy: 0.9810\n",
      "Epoch 195/240\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0049 - accuracy: 0.9810\n",
      "Epoch 196/240\n",
      "1000/1000 [==============================] - 0s 77us/sample - loss: 0.0049 - accuracy: 0.9800\n",
      "Epoch 197/240\n",
      "1000/1000 [==============================] - 0s 72us/sample - loss: 0.0048 - accuracy: 0.9810\n",
      "Epoch 198/240\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0048 - accuracy: 0.9810\n",
      "Epoch 199/240\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0048 - accuracy: 0.9810\n",
      "Epoch 200/240\n",
      "1000/1000 [==============================] - 0s 72us/sample - loss: 0.0047 - accuracy: 0.9810\n",
      "Epoch 201/240\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.0047 - accuracy: 0.9810\n",
      "Epoch 202/240\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0047 - accuracy: 0.9810\n",
      "Epoch 203/240\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0046 - accuracy: 0.9810\n",
      "Epoch 204/240\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0046 - accuracy: 0.9810\n",
      "Epoch 205/240\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0046 - accuracy: 0.9810\n",
      "Epoch 206/240\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0045 - accuracy: 0.9810\n",
      "Epoch 207/240\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0045 - accuracy: 0.9810\n",
      "Epoch 208/240\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0045 - accuracy: 0.9810\n",
      "Epoch 209/240\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0045 - accuracy: 0.9810\n",
      "Epoch 210/240\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0044 - accuracy: 0.9830\n",
      "Epoch 211/240\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0044 - accuracy: 0.9820\n",
      "Epoch 212/240\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0044 - accuracy: 0.9830\n",
      "Epoch 213/240\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0044 - accuracy: 0.9830\n",
      "Epoch 214/240\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0043 - accuracy: 0.9840\n",
      "Epoch 215/240\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0043 - accuracy: 0.9840\n",
      "Epoch 216/240\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0043 - accuracy: 0.9840\n",
      "Epoch 217/240\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0043 - accuracy: 0.9840\n",
      "Epoch 218/240\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0042 - accuracy: 0.9840\n",
      "Epoch 219/240\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0042 - accuracy: 0.9840\n",
      "Epoch 220/240\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0042 - accuracy: 0.9840\n",
      "Epoch 221/240\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0042 - accuracy: 0.9840\n",
      "Epoch 222/240\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0041 - accuracy: 0.9840\n",
      "Epoch 223/240\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0041 - accuracy: 0.9840\n",
      "Epoch 224/240\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0041 - accuracy: 0.9840\n",
      "Epoch 225/240\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 0.0041 - accuracy: 0.9840\n",
      "Epoch 226/240\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0040 - accuracy: 0.9840\n",
      "Epoch 227/240\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0040 - accuracy: 0.9840\n",
      "Epoch 228/240\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0040 - accuracy: 0.9840\n",
      "Epoch 229/240\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 0.0040 - accuracy: 0.9840\n",
      "Epoch 230/240\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0039 - accuracy: 0.9840\n",
      "Epoch 231/240\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0039 - accuracy: 0.9840\n",
      "Epoch 232/240\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0039 - accuracy: 0.9840\n",
      "Epoch 233/240\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0039 - accuracy: 0.9840\n",
      "Epoch 234/240\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0039 - accuracy: 0.9840\n",
      "Epoch 235/240\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0038 - accuracy: 0.9840\n",
      "Epoch 236/240\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0038 - accuracy: 0.9840\n",
      "Epoch 237/240\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0038 - accuracy: 0.9840\n",
      "Epoch 238/240\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 0.0038 - accuracy: 0.9840\n",
      "Epoch 239/240\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.0038 - accuracy: 0.9840\n",
      "Epoch 240/240\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0037 - accuracy: 0.9840\n",
      "Training date and time : \n",
      "2020-03-18 13:25:21\n",
      "Train on 1000 samples\n",
      "Epoch 1/270\n",
      "1000/1000 [==============================] - 0s 257us/sample - loss: 0.0345 - accuracy: 0.8030\n",
      "Epoch 2/270\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0337 - accuracy: 0.8100\n",
      "Epoch 3/270\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0328 - accuracy: 0.8120\n",
      "Epoch 4/270\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0321 - accuracy: 0.8160\n",
      "Epoch 5/270\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0314 - accuracy: 0.8230\n",
      "Epoch 6/270\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0307 - accuracy: 0.8190\n",
      "Epoch 7/270\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0301 - accuracy: 0.8280\n",
      "Epoch 8/270\n",
      "1000/1000 [==============================] - 0s 79us/sample - loss: 0.0295 - accuracy: 0.8290\n",
      "Epoch 9/270\n",
      "1000/1000 [==============================] - 0s 78us/sample - loss: 0.0289 - accuracy: 0.8340\n",
      "Epoch 10/270\n",
      "1000/1000 [==============================] - 0s 69us/sample - loss: 0.0283 - accuracy: 0.8380\n",
      "Epoch 11/270\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.0277 - accuracy: 0.8400\n",
      "Epoch 12/270\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0272 - accuracy: 0.8450\n",
      "Epoch 13/270\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0267 - accuracy: 0.8480\n",
      "Epoch 14/270\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0262 - accuracy: 0.8500\n",
      "Epoch 15/270\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0258 - accuracy: 0.8560\n",
      "Epoch 16/270\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0253 - accuracy: 0.8570\n",
      "Epoch 17/270\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0249 - accuracy: 0.8610\n",
      "Epoch 18/270\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0244 - accuracy: 0.8640\n",
      "Epoch 19/270\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0240 - accuracy: 0.8640\n",
      "Epoch 20/270\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0236 - accuracy: 0.8660\n",
      "Epoch 21/270\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0232 - accuracy: 0.8690\n",
      "Epoch 22/270\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0229 - accuracy: 0.8750\n",
      "Epoch 23/270\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0225 - accuracy: 0.8790\n",
      "Epoch 24/270\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0222 - accuracy: 0.8830\n",
      "Epoch 25/270\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0219 - accuracy: 0.8820\n",
      "Epoch 26/270\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0215 - accuracy: 0.8880\n",
      "Epoch 27/270\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0212 - accuracy: 0.8870\n",
      "Epoch 28/270\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0209 - accuracy: 0.8900\n",
      "Epoch 29/270\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0206 - accuracy: 0.8950\n",
      "Epoch 30/270\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0203 - accuracy: 0.8940\n",
      "Epoch 31/270\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0201 - accuracy: 0.8970\n",
      "Epoch 32/270\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0198 - accuracy: 0.8960\n",
      "Epoch 33/270\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0196 - accuracy: 0.8970\n",
      "Epoch 34/270\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0193 - accuracy: 0.8990\n",
      "Epoch 35/270\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0190 - accuracy: 0.8990\n",
      "Epoch 36/270\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0188 - accuracy: 0.8980\n",
      "Epoch 37/270\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.0186 - accuracy: 0.8990\n",
      "Epoch 38/270\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.0184 - accuracy: 0.9010\n",
      "Epoch 39/270\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0182 - accuracy: 0.9000\n",
      "Epoch 40/270\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.0179 - accuracy: 0.9020\n",
      "Epoch 41/270\n",
      "1000/1000 [==============================] - 0s 73us/sample - loss: 0.0177 - accuracy: 0.9020\n",
      "Epoch 42/270\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0176 - accuracy: 0.9030\n",
      "Epoch 43/270\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.0173 - accuracy: 0.9050\n",
      "Epoch 44/270\n",
      "1000/1000 [==============================] - 0s 74us/sample - loss: 0.0172 - accuracy: 0.9080\n",
      "Epoch 45/270\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0170 - accuracy: 0.9070\n",
      "Epoch 46/270\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.0168 - accuracy: 0.9080\n",
      "Epoch 47/270\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0166 - accuracy: 0.9090\n",
      "Epoch 48/270\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.0165 - accuracy: 0.9090\n",
      "Epoch 49/270\n",
      "1000/1000 [==============================] - 0s 70us/sample - loss: 0.0162 - accuracy: 0.9110\n",
      "Epoch 50/270\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0161 - accuracy: 0.9090\n",
      "Epoch 51/270\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0159 - accuracy: 0.9120\n",
      "Epoch 52/270\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0158 - accuracy: 0.9130\n",
      "Epoch 53/270\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0156 - accuracy: 0.9100\n",
      "Epoch 54/270\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0155 - accuracy: 0.9140\n",
      "Epoch 55/270\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0153 - accuracy: 0.9140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/270\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0152 - accuracy: 0.9170\n",
      "Epoch 57/270\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0150 - accuracy: 0.9160\n",
      "Epoch 58/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0148 - accuracy: 0.9150\n",
      "Epoch 59/270\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0147 - accuracy: 0.9180\n",
      "Epoch 60/270\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0146 - accuracy: 0.9190\n",
      "Epoch 61/270\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0145 - accuracy: 0.9200\n",
      "Epoch 62/270\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0143 - accuracy: 0.9200\n",
      "Epoch 63/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0142 - accuracy: 0.9210\n",
      "Epoch 64/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0141 - accuracy: 0.9220\n",
      "Epoch 65/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0139 - accuracy: 0.9220\n",
      "Epoch 66/270\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0138 - accuracy: 0.9190\n",
      "Epoch 67/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0137 - accuracy: 0.9220\n",
      "Epoch 68/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0136 - accuracy: 0.9230\n",
      "Epoch 69/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0134 - accuracy: 0.9250\n",
      "Epoch 70/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0133 - accuracy: 0.9230\n",
      "Epoch 71/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0132 - accuracy: 0.9230\n",
      "Epoch 72/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0131 - accuracy: 0.9250\n",
      "Epoch 73/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0130 - accuracy: 0.9260\n",
      "Epoch 74/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0128 - accuracy: 0.9250\n",
      "Epoch 75/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0127 - accuracy: 0.9280\n",
      "Epoch 76/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0126 - accuracy: 0.9260\n",
      "Epoch 77/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0125 - accuracy: 0.9260\n",
      "Epoch 78/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0124 - accuracy: 0.9300\n",
      "Epoch 79/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0123 - accuracy: 0.9310\n",
      "Epoch 80/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0122 - accuracy: 0.9310\n",
      "Epoch 81/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0121 - accuracy: 0.9310\n",
      "Epoch 82/270\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0120 - accuracy: 0.9310\n",
      "Epoch 83/270\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0119 - accuracy: 0.9370\n",
      "Epoch 84/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0118 - accuracy: 0.9320\n",
      "Epoch 85/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0117 - accuracy: 0.9350\n",
      "Epoch 86/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0116 - accuracy: 0.9340\n",
      "Epoch 87/270\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0115 - accuracy: 0.9420\n",
      "Epoch 88/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0114 - accuracy: 0.9390\n",
      "Epoch 89/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0113 - accuracy: 0.9410\n",
      "Epoch 90/270\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0112 - accuracy: 0.9420\n",
      "Epoch 91/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0111 - accuracy: 0.9440\n",
      "Epoch 92/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0110 - accuracy: 0.9440\n",
      "Epoch 93/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0109 - accuracy: 0.9430\n",
      "Epoch 94/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0108 - accuracy: 0.9450\n",
      "Epoch 95/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0107 - accuracy: 0.9420\n",
      "Epoch 96/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0106 - accuracy: 0.9440\n",
      "Epoch 97/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0105 - accuracy: 0.9480\n",
      "Epoch 98/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0105 - accuracy: 0.9460\n",
      "Epoch 99/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0104 - accuracy: 0.9460\n",
      "Epoch 100/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0103 - accuracy: 0.9470\n",
      "Epoch 101/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0102 - accuracy: 0.9460\n",
      "Epoch 102/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0101 - accuracy: 0.9530\n",
      "Epoch 103/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0100 - accuracy: 0.9480\n",
      "Epoch 104/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0100 - accuracy: 0.9480\n",
      "Epoch 105/270\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0099 - accuracy: 0.9540\n",
      "Epoch 106/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0098 - accuracy: 0.9510\n",
      "Epoch 107/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0097 - accuracy: 0.9540\n",
      "Epoch 108/270\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.0097 - accuracy: 0.9520\n",
      "Epoch 109/270\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0096 - accuracy: 0.9550\n",
      "Epoch 110/270\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0095 - accuracy: 0.9560\n",
      "Epoch 111/270\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0094 - accuracy: 0.9570\n",
      "Epoch 112/270\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0093 - accuracy: 0.9570\n",
      "Epoch 113/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0093 - accuracy: 0.9590\n",
      "Epoch 114/270\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0092 - accuracy: 0.9600\n",
      "Epoch 115/270\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0091 - accuracy: 0.9600\n",
      "Epoch 116/270\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0091 - accuracy: 0.9610\n",
      "Epoch 117/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0090 - accuracy: 0.9610\n",
      "Epoch 118/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0089 - accuracy: 0.9590\n",
      "Epoch 119/270\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0089 - accuracy: 0.9610\n",
      "Epoch 120/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0088 - accuracy: 0.9610\n",
      "Epoch 121/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0087 - accuracy: 0.9620\n",
      "Epoch 122/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0087 - accuracy: 0.9620\n",
      "Epoch 123/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0086 - accuracy: 0.9620\n",
      "Epoch 124/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0085 - accuracy: 0.9630\n",
      "Epoch 125/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0085 - accuracy: 0.9620\n",
      "Epoch 126/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0084 - accuracy: 0.9630\n",
      "Epoch 127/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0083 - accuracy: 0.9630\n",
      "Epoch 128/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0083 - accuracy: 0.9630\n",
      "Epoch 129/270\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0082 - accuracy: 0.9630\n",
      "Epoch 130/270\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0082 - accuracy: 0.9650\n",
      "Epoch 131/270\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0081 - accuracy: 0.9650\n",
      "Epoch 132/270\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0080 - accuracy: 0.9650\n",
      "Epoch 133/270\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0080 - accuracy: 0.9640\n",
      "Epoch 134/270\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0079 - accuracy: 0.9640\n",
      "Epoch 135/270\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0079 - accuracy: 0.9670\n",
      "Epoch 136/270\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0078 - accuracy: 0.9660\n",
      "Epoch 137/270\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0077 - accuracy: 0.9680\n",
      "Epoch 138/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0077 - accuracy: 0.9670\n",
      "Epoch 139/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0076 - accuracy: 0.9670\n",
      "Epoch 140/270\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0076 - accuracy: 0.9670\n",
      "Epoch 141/270\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0075 - accuracy: 0.9670\n",
      "Epoch 142/270\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0074 - accuracy: 0.9680\n",
      "Epoch 143/270\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0074 - accuracy: 0.9680\n",
      "Epoch 144/270\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0073 - accuracy: 0.9680\n",
      "Epoch 145/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0073 - accuracy: 0.9670\n",
      "Epoch 146/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0072 - accuracy: 0.9700\n",
      "Epoch 147/270\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0072 - accuracy: 0.9690\n",
      "Epoch 148/270\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0071 - accuracy: 0.9690\n",
      "Epoch 149/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0071 - accuracy: 0.9700\n",
      "Epoch 150/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0070 - accuracy: 0.9690\n",
      "Epoch 151/270\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0069 - accuracy: 0.9710\n",
      "Epoch 152/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0069 - accuracy: 0.9700\n",
      "Epoch 153/270\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0069 - accuracy: 0.9700\n",
      "Epoch 154/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0068 - accuracy: 0.9720\n",
      "Epoch 155/270\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0067 - accuracy: 0.9710\n",
      "Epoch 156/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0067 - accuracy: 0.9710\n",
      "Epoch 157/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0066 - accuracy: 0.9720\n",
      "Epoch 158/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0066 - accuracy: 0.9730\n",
      "Epoch 159/270\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0066 - accuracy: 0.9720\n",
      "Epoch 160/270\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0065 - accuracy: 0.9730\n",
      "Epoch 161/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0065 - accuracy: 0.9720\n",
      "Epoch 162/270\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0064 - accuracy: 0.9730\n",
      "Epoch 163/270\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0064 - accuracy: 0.9730\n",
      "Epoch 164/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0063 - accuracy: 0.9730\n",
      "Epoch 165/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0063 - accuracy: 0.9730\n",
      "Epoch 166/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0062 - accuracy: 0.9750\n",
      "Epoch 167/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0062 - accuracy: 0.9750\n",
      "Epoch 168/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0061 - accuracy: 0.9740\n",
      "Epoch 169/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0061 - accuracy: 0.9770\n",
      "Epoch 170/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0060 - accuracy: 0.9750\n",
      "Epoch 171/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0060 - accuracy: 0.9760\n",
      "Epoch 172/270\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0060 - accuracy: 0.9780\n",
      "Epoch 173/270\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0059 - accuracy: 0.9760\n",
      "Epoch 174/270\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0059 - accuracy: 0.9760\n",
      "Epoch 175/270\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0058 - accuracy: 0.9770\n",
      "Epoch 176/270\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0058 - accuracy: 0.9780\n",
      "Epoch 177/270\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0058 - accuracy: 0.9780\n",
      "Epoch 178/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0057 - accuracy: 0.9800\n",
      "Epoch 179/270\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0057 - accuracy: 0.9790\n",
      "Epoch 180/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0057 - accuracy: 0.9800\n",
      "Epoch 181/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0056 - accuracy: 0.9810\n",
      "Epoch 182/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0056 - accuracy: 0.9800\n",
      "Epoch 183/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0055 - accuracy: 0.9800\n",
      "Epoch 184/270\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0055 - accuracy: 0.9800\n",
      "Epoch 185/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0055 - accuracy: 0.9800\n",
      "Epoch 186/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0054 - accuracy: 0.9810\n",
      "Epoch 187/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0054 - accuracy: 0.9810\n",
      "Epoch 188/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0054 - accuracy: 0.9810\n",
      "Epoch 189/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0054 - accuracy: 0.9800\n",
      "Epoch 190/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0053 - accuracy: 0.9810\n",
      "Epoch 191/270\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0053 - accuracy: 0.9820\n",
      "Epoch 192/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0052 - accuracy: 0.9810\n",
      "Epoch 193/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0052 - accuracy: 0.9810\n",
      "Epoch 194/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0052 - accuracy: 0.9820\n",
      "Epoch 195/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0051 - accuracy: 0.9820\n",
      "Epoch 196/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0051 - accuracy: 0.9820\n",
      "Epoch 197/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0051 - accuracy: 0.9830\n",
      "Epoch 198/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0051 - accuracy: 0.9830\n",
      "Epoch 199/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0050 - accuracy: 0.9830\n",
      "Epoch 200/270\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0050 - accuracy: 0.9830\n",
      "Epoch 201/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0050 - accuracy: 0.9830\n",
      "Epoch 202/270\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0049 - accuracy: 0.9820\n",
      "Epoch 203/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0049 - accuracy: 0.9830\n",
      "Epoch 204/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0049 - accuracy: 0.9830\n",
      "Epoch 205/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0049 - accuracy: 0.9830\n",
      "Epoch 206/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0048 - accuracy: 0.9830\n",
      "Epoch 207/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0048 - accuracy: 0.9830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/270\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0048 - accuracy: 0.9830\n",
      "Epoch 209/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0047 - accuracy: 0.9830\n",
      "Epoch 210/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0047 - accuracy: 0.9830\n",
      "Epoch 211/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0047 - accuracy: 0.9830\n",
      "Epoch 212/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0047 - accuracy: 0.9830\n",
      "Epoch 213/270\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0046 - accuracy: 0.9840\n",
      "Epoch 214/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0046 - accuracy: 0.9830\n",
      "Epoch 215/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0046 - accuracy: 0.9830\n",
      "Epoch 216/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0046 - accuracy: 0.9840\n",
      "Epoch 217/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0046 - accuracy: 0.9840\n",
      "Epoch 218/270\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0045 - accuracy: 0.9840\n",
      "Epoch 219/270\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0045 - accuracy: 0.9840\n",
      "Epoch 220/270\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0045 - accuracy: 0.9840\n",
      "Epoch 221/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0045 - accuracy: 0.9840\n",
      "Epoch 222/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0044 - accuracy: 0.9840\n",
      "Epoch 223/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0044 - accuracy: 0.9840\n",
      "Epoch 224/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0044 - accuracy: 0.9840\n",
      "Epoch 225/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0044 - accuracy: 0.9840\n",
      "Epoch 226/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0044 - accuracy: 0.9840\n",
      "Epoch 227/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0043 - accuracy: 0.9840\n",
      "Epoch 228/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0043 - accuracy: 0.9840\n",
      "Epoch 229/270\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0043 - accuracy: 0.9840\n",
      "Epoch 230/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0043 - accuracy: 0.9840\n",
      "Epoch 231/270\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0042 - accuracy: 0.9840\n",
      "Epoch 232/270\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0042 - accuracy: 0.9840\n",
      "Epoch 233/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0042 - accuracy: 0.9840\n",
      "Epoch 234/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0042 - accuracy: 0.9840\n",
      "Epoch 235/270\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0042 - accuracy: 0.9840\n",
      "Epoch 236/270\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0042 - accuracy: 0.9840\n",
      "Epoch 237/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0041 - accuracy: 0.9840\n",
      "Epoch 238/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0041 - accuracy: 0.9840\n",
      "Epoch 239/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0041 - accuracy: 0.9840\n",
      "Epoch 240/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0041 - accuracy: 0.9840\n",
      "Epoch 241/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0041 - accuracy: 0.9840\n",
      "Epoch 242/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0040 - accuracy: 0.9840\n",
      "Epoch 243/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0040 - accuracy: 0.9840\n",
      "Epoch 244/270\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0040 - accuracy: 0.9840\n",
      "Epoch 245/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0040 - accuracy: 0.9840\n",
      "Epoch 246/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0040 - accuracy: 0.9840\n",
      "Epoch 247/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0040 - accuracy: 0.9840\n",
      "Epoch 248/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0040 - accuracy: 0.9840\n",
      "Epoch 249/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0039 - accuracy: 0.9840\n",
      "Epoch 250/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0039 - accuracy: 0.9840\n",
      "Epoch 251/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0039 - accuracy: 0.9840\n",
      "Epoch 252/270\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0039 - accuracy: 0.9840\n",
      "Epoch 253/270\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0039 - accuracy: 0.9840\n",
      "Epoch 254/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0039 - accuracy: 0.9840\n",
      "Epoch 255/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0038 - accuracy: 0.9840\n",
      "Epoch 256/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0038 - accuracy: 0.9840\n",
      "Epoch 257/270\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0038 - accuracy: 0.9840\n",
      "Epoch 258/270\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0038 - accuracy: 0.9840\n",
      "Epoch 259/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0038 - accuracy: 0.9840\n",
      "Epoch 260/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0038 - accuracy: 0.9840\n",
      "Epoch 261/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0038 - accuracy: 0.9840\n",
      "Epoch 262/270\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0037 - accuracy: 0.9840\n",
      "Epoch 263/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0037 - accuracy: 0.9840\n",
      "Epoch 264/270\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0037 - accuracy: 0.9840\n",
      "Epoch 265/270\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0037 - accuracy: 0.9840\n",
      "Epoch 266/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0037 - accuracy: 0.9840\n",
      "Epoch 267/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0037 - accuracy: 0.9840\n",
      "Epoch 268/270\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0037 - accuracy: 0.9840\n",
      "Epoch 269/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0037 - accuracy: 0.9840\n",
      "Epoch 270/270\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0036 - accuracy: 0.9840\n",
      "Training date and time : \n",
      "2020-03-18 13:25:35\n",
      "Train on 1000 samples\n",
      "Epoch 1/300\n",
      "1000/1000 [==============================] - 0s 190us/sample - loss: 0.0308 - accuracy: 0.8320\n",
      "Epoch 2/300\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0298 - accuracy: 0.8370\n",
      "Epoch 3/300\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0289 - accuracy: 0.8430\n",
      "Epoch 4/300\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0280 - accuracy: 0.8510\n",
      "Epoch 5/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0271 - accuracy: 0.8520\n",
      "Epoch 6/300\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0264 - accuracy: 0.8640\n",
      "Epoch 7/300\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0256 - accuracy: 0.8650\n",
      "Epoch 8/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0250 - accuracy: 0.8740\n",
      "Epoch 9/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0243 - accuracy: 0.8730\n",
      "Epoch 10/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0238 - accuracy: 0.8810\n",
      "Epoch 11/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0232 - accuracy: 0.8800\n",
      "Epoch 12/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0227 - accuracy: 0.8810\n",
      "Epoch 13/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0221 - accuracy: 0.8830\n",
      "Epoch 14/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0217 - accuracy: 0.8870\n",
      "Epoch 15/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0212 - accuracy: 0.8880\n",
      "Epoch 16/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0208 - accuracy: 0.8920\n",
      "Epoch 17/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0204 - accuracy: 0.8930\n",
      "Epoch 18/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0200 - accuracy: 0.8960\n",
      "Epoch 19/300\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0196 - accuracy: 0.8970\n",
      "Epoch 20/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0192 - accuracy: 0.9040\n",
      "Epoch 21/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0189 - accuracy: 0.9030\n",
      "Epoch 22/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0186 - accuracy: 0.9050\n",
      "Epoch 23/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0182 - accuracy: 0.9060\n",
      "Epoch 24/300\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0179 - accuracy: 0.9080\n",
      "Epoch 25/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0176 - accuracy: 0.9120\n",
      "Epoch 26/300\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0173 - accuracy: 0.9140\n",
      "Epoch 27/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0171 - accuracy: 0.9180\n",
      "Epoch 28/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0168 - accuracy: 0.9190\n",
      "Epoch 29/300\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0166 - accuracy: 0.9180\n",
      "Epoch 30/300\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0163 - accuracy: 0.9230\n",
      "Epoch 31/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0161 - accuracy: 0.9240\n",
      "Epoch 32/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0159 - accuracy: 0.9220\n",
      "Epoch 33/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0156 - accuracy: 0.9230\n",
      "Epoch 34/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0154 - accuracy: 0.9240\n",
      "Epoch 35/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0152 - accuracy: 0.9250\n",
      "Epoch 36/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0150 - accuracy: 0.9280\n",
      "Epoch 37/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0148 - accuracy: 0.9270\n",
      "Epoch 38/300\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0146 - accuracy: 0.9270\n",
      "Epoch 39/300\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0144 - accuracy: 0.9280\n",
      "Epoch 40/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0142 - accuracy: 0.9280\n",
      "Epoch 41/300\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0141 - accuracy: 0.9280\n",
      "Epoch 42/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0139 - accuracy: 0.9300\n",
      "Epoch 43/300\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0137 - accuracy: 0.9300\n",
      "Epoch 44/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0136 - accuracy: 0.9310\n",
      "Epoch 45/300\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0134 - accuracy: 0.9320\n",
      "Epoch 46/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0133 - accuracy: 0.9300\n",
      "Epoch 47/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0132 - accuracy: 0.9340\n",
      "Epoch 48/300\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0130 - accuracy: 0.9300\n",
      "Epoch 49/300\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0128 - accuracy: 0.9330\n",
      "Epoch 50/300\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0127 - accuracy: 0.9350\n",
      "Epoch 51/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0126 - accuracy: 0.9340\n",
      "Epoch 52/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0124 - accuracy: 0.9330\n",
      "Epoch 53/300\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0123 - accuracy: 0.9350\n",
      "Epoch 54/300\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0122 - accuracy: 0.9350\n",
      "Epoch 55/300\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0120 - accuracy: 0.9370\n",
      "Epoch 56/300\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0119 - accuracy: 0.9380\n",
      "Epoch 57/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0118 - accuracy: 0.9380\n",
      "Epoch 58/300\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0117 - accuracy: 0.9380\n",
      "Epoch 59/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0116 - accuracy: 0.9380\n",
      "Epoch 60/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0114 - accuracy: 0.9380\n",
      "Epoch 61/300\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0113 - accuracy: 0.9380\n",
      "Epoch 62/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0112 - accuracy: 0.9380\n",
      "Epoch 63/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0111 - accuracy: 0.9400\n",
      "Epoch 64/300\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0110 - accuracy: 0.9400\n",
      "Epoch 65/300\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0109 - accuracy: 0.9410\n",
      "Epoch 66/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0108 - accuracy: 0.9410\n",
      "Epoch 67/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0107 - accuracy: 0.9420\n",
      "Epoch 68/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0106 - accuracy: 0.9410\n",
      "Epoch 69/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0105 - accuracy: 0.9420\n",
      "Epoch 70/300\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0104 - accuracy: 0.9430\n",
      "Epoch 71/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0103 - accuracy: 0.9440\n",
      "Epoch 72/300\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0102 - accuracy: 0.9430\n",
      "Epoch 73/300\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0102 - accuracy: 0.9440\n",
      "Epoch 74/300\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0101 - accuracy: 0.9460\n",
      "Epoch 75/300\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0100 - accuracy: 0.9450\n",
      "Epoch 76/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0099 - accuracy: 0.9470\n",
      "Epoch 77/300\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0098 - accuracy: 0.9460\n",
      "Epoch 78/300\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0097 - accuracy: 0.9480\n",
      "Epoch 79/300\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0096 - accuracy: 0.9500\n",
      "Epoch 80/300\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0095 - accuracy: 0.9500\n",
      "Epoch 81/300\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0095 - accuracy: 0.9490\n",
      "Epoch 82/300\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0094 - accuracy: 0.9520\n",
      "Epoch 83/300\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0093 - accuracy: 0.9510\n",
      "Epoch 84/300\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0092 - accuracy: 0.9520\n",
      "Epoch 85/300\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0091 - accuracy: 0.9520\n",
      "Epoch 86/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0091 - accuracy: 0.9540\n",
      "Epoch 87/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0090 - accuracy: 0.9520\n",
      "Epoch 88/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0089 - accuracy: 0.9540\n",
      "Epoch 89/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0089 - accuracy: 0.9560\n",
      "Epoch 90/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0088 - accuracy: 0.9540\n",
      "Epoch 91/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0087 - accuracy: 0.9540\n",
      "Epoch 92/300\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0087 - accuracy: 0.9550\n",
      "Epoch 93/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0086 - accuracy: 0.9570\n",
      "Epoch 94/300\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0085 - accuracy: 0.9560\n",
      "Epoch 95/300\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0085 - accuracy: 0.9580\n",
      "Epoch 96/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0084 - accuracy: 0.9580\n",
      "Epoch 97/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0083 - accuracy: 0.9590\n",
      "Epoch 98/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0083 - accuracy: 0.9610\n",
      "Epoch 99/300\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0082 - accuracy: 0.9600\n",
      "Epoch 100/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0081 - accuracy: 0.9620\n",
      "Epoch 101/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0081 - accuracy: 0.9600\n",
      "Epoch 102/300\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0080 - accuracy: 0.9620\n",
      "Epoch 103/300\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0080 - accuracy: 0.9630\n",
      "Epoch 104/300\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0079 - accuracy: 0.9620\n",
      "Epoch 105/300\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0079 - accuracy: 0.9610\n",
      "Epoch 106/300\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0078 - accuracy: 0.9620\n",
      "Epoch 107/300\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0077 - accuracy: 0.9610\n",
      "Epoch 108/300\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0077 - accuracy: 0.9630\n",
      "Epoch 109/300\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0076 - accuracy: 0.9630\n",
      "Epoch 110/300\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0076 - accuracy: 0.9640\n",
      "Epoch 111/300\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0075 - accuracy: 0.9630\n",
      "Epoch 112/300\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0075 - accuracy: 0.9640\n",
      "Epoch 113/300\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0074 - accuracy: 0.9650\n",
      "Epoch 114/300\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0074 - accuracy: 0.9640\n",
      "Epoch 115/300\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0073 - accuracy: 0.9650\n",
      "Epoch 116/300\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0073 - accuracy: 0.9650\n",
      "Epoch 117/300\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0072 - accuracy: 0.9660\n",
      "Epoch 118/300\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0072 - accuracy: 0.9660\n",
      "Epoch 119/300\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0071 - accuracy: 0.9670\n",
      "Epoch 120/300\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0071 - accuracy: 0.9680\n",
      "Epoch 121/300\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0070 - accuracy: 0.9670\n",
      "Epoch 122/300\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0070 - accuracy: 0.9670\n",
      "Epoch 123/300\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0069 - accuracy: 0.9670\n",
      "Epoch 124/300\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0069 - accuracy: 0.9680\n",
      "Epoch 125/300\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0069 - accuracy: 0.9680\n",
      "Epoch 126/300\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0068 - accuracy: 0.9690\n",
      "Epoch 127/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0068 - accuracy: 0.9700\n",
      "Epoch 128/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0067 - accuracy: 0.9710\n",
      "Epoch 129/300\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0067 - accuracy: 0.9710\n",
      "Epoch 130/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0066 - accuracy: 0.9700\n",
      "Epoch 131/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0066 - accuracy: 0.9710\n",
      "Epoch 132/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0066 - accuracy: 0.9720\n",
      "Epoch 133/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0065 - accuracy: 0.9730\n",
      "Epoch 134/300\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0065 - accuracy: 0.9730\n",
      "Epoch 135/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0064 - accuracy: 0.9720\n",
      "Epoch 136/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0064 - accuracy: 0.9740\n",
      "Epoch 137/300\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0064 - accuracy: 0.9720\n",
      "Epoch 138/300\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0063 - accuracy: 0.9730\n",
      "Epoch 139/300\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0063 - accuracy: 0.9730\n",
      "Epoch 140/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0063 - accuracy: 0.9740\n",
      "Epoch 141/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0062 - accuracy: 0.9730\n",
      "Epoch 142/300\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0062 - accuracy: 0.9740\n",
      "Epoch 143/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0061 - accuracy: 0.9740\n",
      "Epoch 144/300\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0061 - accuracy: 0.9750\n",
      "Epoch 145/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0061 - accuracy: 0.9730\n",
      "Epoch 146/300\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0060 - accuracy: 0.9750\n",
      "Epoch 147/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0060 - accuracy: 0.9750\n",
      "Epoch 148/300\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0060 - accuracy: 0.9750\n",
      "Epoch 149/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0059 - accuracy: 0.9750\n",
      "Epoch 150/300\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0059 - accuracy: 0.9750\n",
      "Epoch 151/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0059 - accuracy: 0.9760\n",
      "Epoch 152/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0058 - accuracy: 0.9760\n",
      "Epoch 153/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0058 - accuracy: 0.9760\n",
      "Epoch 154/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0058 - accuracy: 0.9770\n",
      "Epoch 155/300\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0057 - accuracy: 0.9750\n",
      "Epoch 156/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0057 - accuracy: 0.9760\n",
      "Epoch 157/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0057 - accuracy: 0.9760\n",
      "Epoch 158/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0056 - accuracy: 0.9760\n",
      "Epoch 159/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0056 - accuracy: 0.9770\n",
      "Epoch 160/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0056 - accuracy: 0.9760\n",
      "Epoch 161/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0055 - accuracy: 0.9770\n",
      "Epoch 162/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0055 - accuracy: 0.9770\n",
      "Epoch 163/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0055 - accuracy: 0.9770\n",
      "Epoch 164/300\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0055 - accuracy: 0.9770\n",
      "Epoch 165/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0054 - accuracy: 0.9770\n",
      "Epoch 166/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0054 - accuracy: 0.9770\n",
      "Epoch 167/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0054 - accuracy: 0.9770\n",
      "Epoch 168/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0053 - accuracy: 0.9770\n",
      "Epoch 169/300\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0053 - accuracy: 0.9770\n",
      "Epoch 170/300\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0053 - accuracy: 0.9770\n",
      "Epoch 171/300\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0053 - accuracy: 0.9770\n",
      "Epoch 172/300\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.0052 - accuracy: 0.9770\n",
      "Epoch 173/300\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0052 - accuracy: 0.9770\n",
      "Epoch 174/300\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0052 - accuracy: 0.9760\n",
      "Epoch 175/300\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0052 - accuracy: 0.9770\n",
      "Epoch 176/300\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0051 - accuracy: 0.9770\n",
      "Epoch 177/300\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0051 - accuracy: 0.9770\n",
      "Epoch 178/300\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0051 - accuracy: 0.9770\n",
      "Epoch 179/300\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0051 - accuracy: 0.9770\n",
      "Epoch 180/300\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0050 - accuracy: 0.9780\n",
      "Epoch 181/300\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0050 - accuracy: 0.9770\n",
      "Epoch 182/300\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0050 - accuracy: 0.9780\n",
      "Epoch 183/300\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0050 - accuracy: 0.9780\n",
      "Epoch 184/300\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0049 - accuracy: 0.9780\n",
      "Epoch 185/300\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0049 - accuracy: 0.9780\n",
      "Epoch 186/300\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0049 - accuracy: 0.9780\n",
      "Epoch 187/300\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0049 - accuracy: 0.9780\n",
      "Epoch 188/300\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0048 - accuracy: 0.9780\n",
      "Epoch 189/300\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0048 - accuracy: 0.9780\n",
      "Epoch 190/300\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0048 - accuracy: 0.9780\n",
      "Epoch 191/300\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0048 - accuracy: 0.9780\n",
      "Epoch 192/300\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0047 - accuracy: 0.9780\n",
      "Epoch 193/300\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0047 - accuracy: 0.9790\n",
      "Epoch 194/300\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0047 - accuracy: 0.9780\n",
      "Epoch 195/300\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0047 - accuracy: 0.9780\n",
      "Epoch 196/300\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0047 - accuracy: 0.9790\n",
      "Epoch 197/300\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0046 - accuracy: 0.9790\n",
      "Epoch 198/300\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0046 - accuracy: 0.9780\n",
      "Epoch 199/300\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0046 - accuracy: 0.9780\n",
      "Epoch 200/300\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0046 - accuracy: 0.9790\n",
      "Epoch 201/300\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0045 - accuracy: 0.9790\n",
      "Epoch 202/300\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0045 - accuracy: 0.9790\n",
      "Epoch 203/300\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0045 - accuracy: 0.9790\n",
      "Epoch 204/300\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0045 - accuracy: 0.9790\n",
      "Epoch 205/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0045 - accuracy: 0.9790\n",
      "Epoch 206/300\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0044 - accuracy: 0.9790\n",
      "Epoch 207/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0044 - accuracy: 0.9790\n",
      "Epoch 208/300\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 51us/sample - loss: 0.0044 - accuracy: 0.9790\n",
      "Epoch 209/300\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0044 - accuracy: 0.9790\n",
      "Epoch 210/300\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0044 - accuracy: 0.9790\n",
      "Epoch 211/300\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0044 - accuracy: 0.9790\n",
      "Epoch 212/300\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0043 - accuracy: 0.9790\n",
      "Epoch 213/300\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0043 - accuracy: 0.9790\n",
      "Epoch 214/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0043 - accuracy: 0.9790\n",
      "Epoch 215/300\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0043 - accuracy: 0.9790\n",
      "Epoch 216/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0043 - accuracy: 0.9790\n",
      "Epoch 217/300\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0042 - accuracy: 0.9790\n",
      "Epoch 218/300\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0042 - accuracy: 0.9790\n",
      "Epoch 219/300\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0042 - accuracy: 0.9790\n",
      "Epoch 220/300\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0042 - accuracy: 0.9790\n",
      "Epoch 221/300\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0042 - accuracy: 0.9800\n",
      "Epoch 222/300\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0041 - accuracy: 0.9800\n",
      "Epoch 223/300\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0041 - accuracy: 0.9800\n",
      "Epoch 224/300\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0041 - accuracy: 0.9800\n",
      "Epoch 225/300\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0041 - accuracy: 0.9810\n",
      "Epoch 226/300\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0040 - accuracy: 0.9810\n",
      "Epoch 227/300\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0040 - accuracy: 0.9810\n",
      "Epoch 228/300\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0040 - accuracy: 0.9810\n",
      "Epoch 229/300\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0040 - accuracy: 0.9820\n",
      "Epoch 230/300\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0040 - accuracy: 0.9810\n",
      "Epoch 231/300\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0040 - accuracy: 0.9810\n",
      "Epoch 232/300\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0039 - accuracy: 0.9820\n",
      "Epoch 233/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0039 - accuracy: 0.9810\n",
      "Epoch 234/300\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0039 - accuracy: 0.9810\n",
      "Epoch 235/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0039 - accuracy: 0.9820\n",
      "Epoch 236/300\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0039 - accuracy: 0.9830\n",
      "Epoch 237/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0038 - accuracy: 0.9820\n",
      "Epoch 238/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0038 - accuracy: 0.9830\n",
      "Epoch 239/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0038 - accuracy: 0.9830\n",
      "Epoch 240/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0038 - accuracy: 0.9830\n",
      "Epoch 241/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0038 - accuracy: 0.9830\n",
      "Epoch 242/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0038 - accuracy: 0.9830\n",
      "Epoch 243/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0037 - accuracy: 0.9830\n",
      "Epoch 244/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0037 - accuracy: 0.9830\n",
      "Epoch 245/300\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0037 - accuracy: 0.9830\n",
      "Epoch 246/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0037 - accuracy: 0.9830\n",
      "Epoch 247/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0037 - accuracy: 0.9830\n",
      "Epoch 248/300\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0037 - accuracy: 0.9830\n",
      "Epoch 249/300\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0036 - accuracy: 0.9840\n",
      "Epoch 250/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0036 - accuracy: 0.9840\n",
      "Epoch 251/300\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0036 - accuracy: 0.9840\n",
      "Epoch 252/300\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0036 - accuracy: 0.9840\n",
      "Epoch 253/300\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0036 - accuracy: 0.9840\n",
      "Epoch 254/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0036 - accuracy: 0.9840\n",
      "Epoch 255/300\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0035 - accuracy: 0.9840\n",
      "Epoch 256/300\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0035 - accuracy: 0.9840\n",
      "Epoch 257/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0035 - accuracy: 0.9840\n",
      "Epoch 258/300\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0035 - accuracy: 0.9840\n",
      "Epoch 259/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0035 - accuracy: 0.9840\n",
      "Epoch 260/300\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0035 - accuracy: 0.9840\n",
      "Epoch 261/300\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0035 - accuracy: 0.9850\n",
      "Epoch 262/300\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0034 - accuracy: 0.9850\n",
      "Epoch 263/300\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0034 - accuracy: 0.9850\n",
      "Epoch 264/300\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0034 - accuracy: 0.9850\n",
      "Epoch 265/300\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0034 - accuracy: 0.9850\n",
      "Epoch 266/300\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0034 - accuracy: 0.9850\n",
      "Epoch 267/300\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0034 - accuracy: 0.9850\n",
      "Epoch 268/300\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0034 - accuracy: 0.9850\n",
      "Epoch 269/300\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0033 - accuracy: 0.9850\n",
      "Epoch 270/300\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0033 - accuracy: 0.9850\n",
      "Epoch 271/300\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0033 - accuracy: 0.9850\n",
      "Epoch 272/300\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0033 - accuracy: 0.9850\n",
      "Epoch 273/300\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.0033 - accuracy: 0.9850\n",
      "Epoch 274/300\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.0033 - accuracy: 0.9850\n",
      "Epoch 275/300\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0033 - accuracy: 0.9850\n",
      "Epoch 276/300\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0032 - accuracy: 0.9850\n",
      "Epoch 277/300\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0032 - accuracy: 0.9850\n",
      "Epoch 278/300\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0032 - accuracy: 0.9850\n",
      "Epoch 279/300\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0032 - accuracy: 0.9850\n",
      "Epoch 280/300\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0032 - accuracy: 0.9850\n",
      "Epoch 281/300\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0032 - accuracy: 0.9850\n",
      "Epoch 282/300\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0032 - accuracy: 0.9850\n",
      "Epoch 283/300\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0032 - accuracy: 0.9850\n",
      "Epoch 284/300\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0031 - accuracy: 0.9850\n",
      "Epoch 285/300\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0031 - accuracy: 0.9850\n",
      "Epoch 286/300\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0031 - accuracy: 0.9860\n",
      "Epoch 287/300\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 0.0031 - accuracy: 0.9860\n",
      "Epoch 288/300\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0031 - accuracy: 0.9860\n",
      "Epoch 289/300\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0031 - accuracy: 0.9860\n",
      "Epoch 290/300\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0031 - accuracy: 0.9860\n",
      "Epoch 291/300\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0031 - accuracy: 0.9860\n",
      "Epoch 292/300\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0031 - accuracy: 0.9860\n",
      "Epoch 293/300\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0031 - accuracy: 0.9860\n",
      "Epoch 294/300\n",
      "1000/1000 [==============================] - 0s 72us/sample - loss: 0.0030 - accuracy: 0.9860\n",
      "Epoch 295/300\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.0030 - accuracy: 0.9860\n",
      "Epoch 296/300\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0030 - accuracy: 0.9860\n",
      "Epoch 297/300\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0030 - accuracy: 0.9860\n",
      "Epoch 298/300\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0030 - accuracy: 0.9860\n",
      "Epoch 299/300\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0030 - accuracy: 0.9860\n",
      "Epoch 300/300\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0030 - accuracy: 0.9860\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(model_list)):\n",
    "    compile_model(model_list[i])\n",
    "    fit_model_with_datasets(model_list[i], (i+1)*30, x_train_list[i], y_train_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see how these models are different from each other, compared to the base model(before training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.833560255530756, 2.1611296127084643, 3.1768366515170783, 4.657467506360263, 5.5076206885278225, 6.224924594163895, 7.1884405836462975, 9.359470788389444, 9.887856163084507, 8.878572824411094]\n"
     ]
    }
   ],
   "source": [
    "dists = [l2_distance(standard_model, m) for m in model_list]\n",
    "print(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_list = list(np.arange(0, 1.05, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_combs(model_list):\n",
    "    combs = list()\n",
    "    l = len(model_list)\n",
    "    for i in range(l):\n",
    "        for j in range(l):\n",
    "            if i > j:\n",
    "                combs.append([model_list[i], model_list[j]])\n",
    "    return combs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_weights_list_per_pi = list()\n",
    "dist_list = list()\n",
    "for model_comp in model_combs(model_list):\n",
    "    if model_comp[0] is model_comp[1]:    #disregard same models\n",
    "        continue\n",
    "    weights = [model_comp[0].get_weights(), model_comp[1].get_weights()]\n",
    "    agg_weights_list = list()\n",
    "    for theta in theta_list:\n",
    "        agg_weights = list()\n",
    "        for weights_list_tuple in zip(*weights):\n",
    "            agg_weights.append(np.array([np.average(np.array(w), axis=0, weights=[1. - theta, theta]) for w in zip(*weights_list_tuple)]))\n",
    "        agg_weights_list.append(agg_weights)\n",
    "    dist_list.append(l2_distance(model_comp[0], model_comp[1]))\n",
    "    agg_weights_list_per_pi.append(agg_weights_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this has to be nC_2\n",
    "len(dist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_weights_list_per_pi_sorted = [x for _,x in sorted(zip(dist_list,agg_weights_list_per_pi))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.meshgrid(np.array(theta_list), np.array(sorted(dist_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.zeros(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0196 - accuracy: 0.8754\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0196 - accuracy: 0.8763\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0197 - accuracy: 0.8764\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0197 - accuracy: 0.8766\n",
      "10000/10000 [==============================] - 0s 40us/sample - loss: 0.0198 - accuracy: 0.8755\n",
      "10000/10000 [==============================] - 0s 36us/sample - loss: 0.0199 - accuracy: 0.8773\n",
      "10000/10000 [==============================] - 0s 41us/sample - loss: 0.0201 - accuracy: 0.8770\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0202 - accuracy: 0.8756\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0203 - accuracy: 0.8741\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0205 - accuracy: 0.8727\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0207 - accuracy: 0.8720\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0209 - accuracy: 0.8713\n",
      "10000/10000 [==============================] - 0s 35us/sample - loss: 0.0211 - accuracy: 0.8698\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0214 - accuracy: 0.8688\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0216 - accuracy: 0.8675\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0219 - accuracy: 0.8662\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0222 - accuracy: 0.8646\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0225 - accuracy: 0.8635\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0229 - accuracy: 0.8607\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0232 - accuracy: 0.8587\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0236 - accuracy: 0.8566\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0183 - accuracy: 0.8816\n",
      "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0182 - accuracy: 0.8827\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0181 - accuracy: 0.8830\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0180 - accuracy: 0.8842\n",
      "10000/10000 [==============================] - 0s 37us/sample - loss: 0.0179 - accuracy: 0.8846\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0179 - accuracy: 0.8840\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0178 - accuracy: 0.8841\n",
      "10000/10000 [==============================] - 0s 39us/sample - loss: 0.0178 - accuracy: 0.8849\n",
      "10000/10000 [==============================] - 0s 43us/sample - loss: 0.0178 - accuracy: 0.8860\n",
      "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0179 - accuracy: 0.8863\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0179 - accuracy: 0.8871\n",
      "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0180 - accuracy: 0.8861\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0181 - accuracy: 0.8862\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0182 - accuracy: 0.8854\n",
      "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0183 - accuracy: 0.8844\n",
      "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0185 - accuracy: 0.8837\n",
      "10000/10000 [==============================] - 0s 37us/sample - loss: 0.0187 - accuracy: 0.8820\n",
      "10000/10000 [==============================] - 0s 47us/sample - loss: 0.0189 - accuracy: 0.8803\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0191 - accuracy: 0.8793\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0193 - accuracy: 0.8776\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0196 - accuracy: 0.8754\n",
      "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0183 - accuracy: 0.8816\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0183 - accuracy: 0.8817\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0183 - accuracy: 0.8810\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0183 - accuracy: 0.8812\n",
      "10000/10000 [==============================] - 0s 47us/sample - loss: 0.0184 - accuracy: 0.8816\n",
      "10000/10000 [==============================] - 0s 47us/sample - loss: 0.0185 - accuracy: 0.8822\n",
      "10000/10000 [==============================] - 0s 45us/sample - loss: 0.0186 - accuracy: 0.8821\n",
      "10000/10000 [==============================] - 0s 35us/sample - loss: 0.0188 - accuracy: 0.8820\n",
      "10000/10000 [==============================] - 1s 52us/sample - loss: 0.0190 - accuracy: 0.8805\n",
      "10000/10000 [==============================] - 1s 52us/sample - loss: 0.0192 - accuracy: 0.8787\n",
      "10000/10000 [==============================] - 1s 67us/sample - loss: 0.0194 - accuracy: 0.8779\n",
      "10000/10000 [==============================] - 0s 46us/sample - loss: 0.0197 - accuracy: 0.8777\n",
      "10000/10000 [==============================] - 1s 51us/sample - loss: 0.0200 - accuracy: 0.8768\n",
      "10000/10000 [==============================] - 1s 53us/sample - loss: 0.0203 - accuracy: 0.8754\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0207 - accuracy: 0.8732\n",
      "10000/10000 [==============================] - 0s 35us/sample - loss: 0.0211 - accuracy: 0.8718\n",
      "10000/10000 [==============================] - 0s 47us/sample - loss: 0.0215 - accuracy: 0.8698\n",
      "10000/10000 [==============================] - 0s 43us/sample - loss: 0.0220 - accuracy: 0.8678\n",
      "10000/10000 [==============================] - 1s 55us/sample - loss: 0.0225 - accuracy: 0.8644\n",
      "10000/10000 [==============================] - 1s 54us/sample - loss: 0.0230 - accuracy: 0.8613\n",
      "10000/10000 [==============================] - 0s 38us/sample - loss: 0.0236 - accuracy: 0.8566\n",
      "10000/10000 [==============================] - 0s 35us/sample - loss: 0.0181 - accuracy: 0.8806\n",
      "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0179 - accuracy: 0.8813\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0178 - accuracy: 0.8829\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0177 - accuracy: 0.8838\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0176 - accuracy: 0.8844\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0175 - accuracy: 0.8843\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0175 - accuracy: 0.8848\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0175 - accuracy: 0.8852\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0175 - accuracy: 0.8857\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0175 - accuracy: 0.8855\n",
      "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0176 - accuracy: 0.8863\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0177 - accuracy: 0.8868\n",
      "10000/10000 [==============================] - 0s 48us/sample - loss: 0.0178 - accuracy: 0.8865\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0179 - accuracy: 0.8854\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0181 - accuracy: 0.8850\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0183 - accuracy: 0.8837\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0185 - accuracy: 0.8827\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0187 - accuracy: 0.8812\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0190 - accuracy: 0.8802\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0193 - accuracy: 0.8780\n",
      "10000/10000 [==============================] - 0s 36us/sample - loss: 0.0196 - accuracy: 0.8754\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0181 - accuracy: 0.8806\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0178 - accuracy: 0.8819\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0176 - accuracy: 0.8841\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0175 - accuracy: 0.8846\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0173 - accuracy: 0.8861\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0172 - accuracy: 0.8864\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0171 - accuracy: 0.8861\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0170 - accuracy: 0.8876\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.8883\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0170 - accuracy: 0.8885\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.8891\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0170 - accuracy: 0.8899\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.8899\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0171 - accuracy: 0.8898\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0172 - accuracy: 0.8883\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0173 - accuracy: 0.8870\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0175 - accuracy: 0.8861\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0176 - accuracy: 0.8851\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0178 - accuracy: 0.8829\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0181 - accuracy: 0.8821\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0183 - accuracy: 0.8816\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0181 - accuracy: 0.8806\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0180 - accuracy: 0.8808\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0180 - accuracy: 0.8812\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0181 - accuracy: 0.8808\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0181 - accuracy: 0.8804\n",
      "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0182 - accuracy: 0.8810\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0183 - accuracy: 0.8809\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0185 - accuracy: 0.8802\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0186 - accuracy: 0.8804\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0188 - accuracy: 0.8796\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0191 - accuracy: 0.8787\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0194 - accuracy: 0.8775\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0197 - accuracy: 0.8763\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0200 - accuracy: 0.8753\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0204 - accuracy: 0.8738\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0209 - accuracy: 0.8717\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0213 - accuracy: 0.8691\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0218 - accuracy: 0.8665\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0224 - accuracy: 0.8637\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0230 - accuracy: 0.8599\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0236 - accuracy: 0.8566\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0175 - accuracy: 0.8842\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0174 - accuracy: 0.8855\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0172 - accuracy: 0.8867\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0171 - accuracy: 0.8874\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0171 - accuracy: 0.8879\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.8892\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.8894\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.8911\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0170 - accuracy: 0.8907\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0171 - accuracy: 0.8911\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0171 - accuracy: 0.8915\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0173 - accuracy: 0.8907\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0174 - accuracy: 0.8896\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0176 - accuracy: 0.8890\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0178 - accuracy: 0.8873\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0180 - accuracy: 0.8867\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0183 - accuracy: 0.8854\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0185 - accuracy: 0.8839\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0189 - accuracy: 0.8817\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0192 - accuracy: 0.8785\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0196 - accuracy: 0.8754\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0175 - accuracy: 0.8842\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0173 - accuracy: 0.8853\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0171 - accuracy: 0.8864\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0169 - accuracy: 0.8877\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0168 - accuracy: 0.8899\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0167 - accuracy: 0.8898\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0166 - accuracy: 0.8908\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0165 - accuracy: 0.8919\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0165 - accuracy: 0.8926\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0165 - accuracy: 0.8934\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0165 - accuracy: 0.8933\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0165 - accuracy: 0.8926\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0166 - accuracy: 0.8918\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0167 - accuracy: 0.8913\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0169 - accuracy: 0.8905\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0170 - accuracy: 0.8896\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0172 - accuracy: 0.8878\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0175 - accuracy: 0.8860\n",
      "10000/10000 [==============================] - 1s 50us/sample - loss: 0.0177 - accuracy: 0.8842\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0180 - accuracy: 0.8833\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0183 - accuracy: 0.8816\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0175 - accuracy: 0.8842\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0173 - accuracy: 0.8851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0171 - accuracy: 0.8870\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0169 - accuracy: 0.8890\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0167 - accuracy: 0.8899\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0166 - accuracy: 0.8906\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0165 - accuracy: 0.8914\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0164 - accuracy: 0.8918\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0164 - accuracy: 0.8920\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0164 - accuracy: 0.8913\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0164 - accuracy: 0.8910\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0164 - accuracy: 0.8908\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0165 - accuracy: 0.8898\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0166 - accuracy: 0.8898\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0167 - accuracy: 0.8899\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0168 - accuracy: 0.8881\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.8871\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0172 - accuracy: 0.8854\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0175 - accuracy: 0.8839\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0178 - accuracy: 0.8826\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0181 - accuracy: 0.8806\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0177 - accuracy: 0.8799\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0174 - accuracy: 0.8821\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0171 - accuracy: 0.8847\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0169 - accuracy: 0.8868\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0167 - accuracy: 0.8883\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0166 - accuracy: 0.8901\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0164 - accuracy: 0.8913\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0164 - accuracy: 0.8930\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0163 - accuracy: 0.8945\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0163 - accuracy: 0.8937\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0163 - accuracy: 0.8937\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0164 - accuracy: 0.8945\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0164 - accuracy: 0.8938\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0166 - accuracy: 0.8922\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0167 - accuracy: 0.8908\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0169 - accuracy: 0.8891\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0171 - accuracy: 0.8882\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0174 - accuracy: 0.8869\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0177 - accuracy: 0.8855\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0180 - accuracy: 0.8836\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0183 - accuracy: 0.8816\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0175 - accuracy: 0.8842\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0174 - accuracy: 0.8850\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0174 - accuracy: 0.8866\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0173 - accuracy: 0.8870\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0173 - accuracy: 0.8873\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0174 - accuracy: 0.8883\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0175 - accuracy: 0.8880\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0176 - accuracy: 0.8888\n",
      "10000/10000 [==============================] - 1s 53us/sample - loss: 0.0178 - accuracy: 0.8876\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0180 - accuracy: 0.8871\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0182 - accuracy: 0.8867\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0186 - accuracy: 0.8851\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0189 - accuracy: 0.8830\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0193 - accuracy: 0.8810\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0198 - accuracy: 0.8782\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0203 - accuracy: 0.8751\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0208 - accuracy: 0.8714\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0214 - accuracy: 0.8685\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0221 - accuracy: 0.8642\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0228 - accuracy: 0.8615\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0236 - accuracy: 0.8566\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0177 - accuracy: 0.8799\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0175 - accuracy: 0.8817\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0173 - accuracy: 0.8838\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0172 - accuracy: 0.8849\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0171 - accuracy: 0.8868\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0170 - accuracy: 0.8886\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0169 - accuracy: 0.8893\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0169 - accuracy: 0.8902\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0169 - accuracy: 0.8908\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.8904\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0171 - accuracy: 0.8910\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0172 - accuracy: 0.8899\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0173 - accuracy: 0.8888\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0175 - accuracy: 0.8874\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0177 - accuracy: 0.8864\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0179 - accuracy: 0.8854\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0182 - accuracy: 0.8844\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0185 - accuracy: 0.8836\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0188 - accuracy: 0.8820\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0192 - accuracy: 0.8789\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0196 - accuracy: 0.8754\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0177 - accuracy: 0.8799\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0174 - accuracy: 0.8816\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0172 - accuracy: 0.8842\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.8854\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0169 - accuracy: 0.8871\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0167 - accuracy: 0.8887\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0166 - accuracy: 0.8898\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0165 - accuracy: 0.8908\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0165 - accuracy: 0.8915\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0165 - accuracy: 0.8924\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0165 - accuracy: 0.8922\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0165 - accuracy: 0.8909\n",
      "10000/10000 [==============================] - 0s 35us/sample - loss: 0.0166 - accuracy: 0.8898\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0167 - accuracy: 0.8894\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0168 - accuracy: 0.8884\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0169 - accuracy: 0.8872\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0171 - accuracy: 0.8848\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0173 - accuracy: 0.8843\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0175 - accuracy: 0.8840\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0178 - accuracy: 0.8820\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0181 - accuracy: 0.8806\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0177 - accuracy: 0.8799\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0176 - accuracy: 0.8814\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0175 - accuracy: 0.8817s - loss: 0.0173 - accuracy: 0.88\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0175 - accuracy: 0.8829\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0175 - accuracy: 0.8834\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0176 - accuracy: 0.8840\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0177 - accuracy: 0.8852\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0178 - accuracy: 0.8852\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0180 - accuracy: 0.8842\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0182 - accuracy: 0.8841\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0184 - accuracy: 0.8832\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0187 - accuracy: 0.8813\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0191 - accuracy: 0.8784\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0195 - accuracy: 0.8762\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0199 - accuracy: 0.8749\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0204 - accuracy: 0.8720\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0210 - accuracy: 0.8697\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0216 - accuracy: 0.8662\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0222 - accuracy: 0.8631\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0229 - accuracy: 0.8596\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0236 - accuracy: 0.8566\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0178 - accuracy: 0.8814\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0175 - accuracy: 0.8835\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0173 - accuracy: 0.8849\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0171 - accuracy: 0.8864\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0169 - accuracy: 0.8879\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0167 - accuracy: 0.8896\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0166 - accuracy: 0.8905\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0165 - accuracy: 0.8900\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0165 - accuracy: 0.8901\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0165 - accuracy: 0.8920\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0165 - accuracy: 0.8919\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0165 - accuracy: 0.8925\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0166 - accuracy: 0.8917\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0167 - accuracy: 0.8912\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0168 - accuracy: 0.8906\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.8888\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0172 - accuracy: 0.8874\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0174 - accuracy: 0.8864\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0177 - accuracy: 0.8841\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0180 - accuracy: 0.8831\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0183 - accuracy: 0.8816\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0178 - accuracy: 0.8814\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0176 - accuracy: 0.8834\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0174 - accuracy: 0.8849\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0172 - accuracy: 0.8859\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.8868\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0169 - accuracy: 0.8876\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0169 - accuracy: 0.8881\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0168 - accuracy: 0.8892\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0168 - accuracy: 0.8890\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0168 - accuracy: 0.8904\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0169 - accuracy: 0.8903\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.8901\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0171 - accuracy: 0.8895\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0173 - accuracy: 0.8887\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0175 - accuracy: 0.8882\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0178 - accuracy: 0.8872\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0181 - accuracy: 0.8856\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0184 - accuracy: 0.8841\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0187 - accuracy: 0.8810\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0191 - accuracy: 0.8787\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0196 - accuracy: 0.8754\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0177 - accuracy: 0.8799\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0173 - accuracy: 0.8831\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0170 - accuracy: 0.8860\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0167 - accuracy: 0.8884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0165 - accuracy: 0.8900\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0163 - accuracy: 0.8925\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0161 - accuracy: 0.8941\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0160 - accuracy: 0.8949\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0159 - accuracy: 0.8957\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0158 - accuracy: 0.8957\n",
      "10000/10000 [==============================] - 1s 60us/sample - loss: 0.0158 - accuracy: 0.8951\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0158 - accuracy: 0.8960\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0159 - accuracy: 0.8957\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0160 - accuracy: 0.8957\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0161 - accuracy: 0.8934\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0163 - accuracy: 0.8930\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0164 - accuracy: 0.8901\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0167 - accuracy: 0.8883\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0169 - accuracy: 0.8869\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0172 - accuracy: 0.8855\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0175 - accuracy: 0.8842\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0178 - accuracy: 0.8814\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0175 - accuracy: 0.8832\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0173 - accuracy: 0.8841\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0171 - accuracy: 0.8861\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0169 - accuracy: 0.8867\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0167 - accuracy: 0.8885\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0165 - accuracy: 0.8892\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0164 - accuracy: 0.8896\n",
      "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0163 - accuracy: 0.8899\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0163 - accuracy: 0.8917\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0163 - accuracy: 0.8924\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0163 - accuracy: 0.8934\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0163 - accuracy: 0.8939\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0163 - accuracy: 0.8932\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0164 - accuracy: 0.8916\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0165 - accuracy: 0.8911\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0167 - accuracy: 0.8897\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0168 - accuracy: 0.8890\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0170 - accuracy: 0.8867\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0172 - accuracy: 0.8854\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0175 - accuracy: 0.8842\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0178 - accuracy: 0.8814\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0175 - accuracy: 0.8833\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0172 - accuracy: 0.8851\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0170 - accuracy: 0.8865\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0167 - accuracy: 0.8874\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0166 - accuracy: 0.8889\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0164 - accuracy: 0.8902\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0163 - accuracy: 0.8915\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0162 - accuracy: 0.8923\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0162 - accuracy: 0.8925\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0161 - accuracy: 0.8936\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0162 - accuracy: 0.8930\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0162 - accuracy: 0.8928\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0163 - accuracy: 0.8917\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0165 - accuracy: 0.8909\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0166 - accuracy: 0.8905\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0168 - accuracy: 0.8888\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0171 - accuracy: 0.8865\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0174 - accuracy: 0.8846\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0177 - accuracy: 0.8829\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0181 - accuracy: 0.8806\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0178 - accuracy: 0.8814\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0176 - accuracy: 0.8833\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0175 - accuracy: 0.8857\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0174 - accuracy: 0.8866\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0173 - accuracy: 0.8863\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0173 - accuracy: 0.8867\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0173 - accuracy: 0.8870\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0174 - accuracy: 0.8875\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0176 - accuracy: 0.8875\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0177 - accuracy: 0.8873\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0180 - accuracy: 0.8863\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0183 - accuracy: 0.8851\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0186 - accuracy: 0.8835\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0190 - accuracy: 0.8818\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0195 - accuracy: 0.8796\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0200 - accuracy: 0.8759\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0206 - accuracy: 0.8730\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0213 - accuracy: 0.8694\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0220 - accuracy: 0.8654\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0227 - accuracy: 0.8614\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0236 - accuracy: 0.8566\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0180 - accuracy: 0.8781\n",
      "10000/10000 [==============================] - 1s 63us/sample - loss: 0.0177 - accuracy: 0.8800\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0174 - accuracy: 0.8823\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0172 - accuracy: 0.8846\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0169 - accuracy: 0.8864\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0168 - accuracy: 0.8882\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0166 - accuracy: 0.8891\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0165 - accuracy: 0.8908\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0164 - accuracy: 0.8915\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0163 - accuracy: 0.8920\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0163 - accuracy: 0.8918\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0164 - accuracy: 0.8917\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0164 - accuracy: 0.8913\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0165 - accuracy: 0.8912\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0166 - accuracy: 0.8908\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0168 - accuracy: 0.8896\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0170 - accuracy: 0.8887\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0173 - accuracy: 0.8874\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0176 - accuracy: 0.8852\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0179 - accuracy: 0.8826\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0183 - accuracy: 0.8816\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0178 - accuracy: 0.8814\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0175 - accuracy: 0.8839\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0172 - accuracy: 0.8855\n",
      "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0169 - accuracy: 0.8877\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0167 - accuracy: 0.8890\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0165 - accuracy: 0.8906\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0163 - accuracy: 0.8912\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0162 - accuracy: 0.8918\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0161 - accuracy: 0.8936\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0160 - accuracy: 0.8940\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0160 - accuracy: 0.8944\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0160 - accuracy: 0.8945\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0160 - accuracy: 0.8956\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0161 - accuracy: 0.8951\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0162 - accuracy: 0.8939\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0164 - accuracy: 0.8920\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0165 - accuracy: 0.8896\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0168 - accuracy: 0.8871\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.8851\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0173 - accuracy: 0.8833\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0177 - accuracy: 0.8799\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0180 - accuracy: 0.8781\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0177 - accuracy: 0.8806\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0174 - accuracy: 0.8832\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0171 - accuracy: 0.8859\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0169 - accuracy: 0.8878\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0167 - accuracy: 0.8890\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0165 - accuracy: 0.8896\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0164 - accuracy: 0.8913\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0163 - accuracy: 0.8917\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0162 - accuracy: 0.8919\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0162 - accuracy: 0.8922\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0162 - accuracy: 0.8937\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0163 - accuracy: 0.8937\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0163 - accuracy: 0.8931\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0165 - accuracy: 0.8910\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0166 - accuracy: 0.8891\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0168 - accuracy: 0.8884\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0171 - accuracy: 0.8866\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0174 - accuracy: 0.8851\n",
      "10000/10000 [==============================] - 0s 36us/sample - loss: 0.0177 - accuracy: 0.8834\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0181 - accuracy: 0.8806\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0180 - accuracy: 0.8781\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0177 - accuracy: 0.8803\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0174 - accuracy: 0.8832\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0172 - accuracy: 0.8855\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.8877\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0168 - accuracy: 0.8890\n",
      "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0167 - accuracy: 0.8900\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0166 - accuracy: 0.8908\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0166 - accuracy: 0.8910\n",
      "10000/10000 [==============================] - 1s 53us/sample - loss: 0.0166 - accuracy: 0.8925\n",
      "10000/10000 [==============================] - 0s 37us/sample - loss: 0.0166 - accuracy: 0.8915\n",
      "10000/10000 [==============================] - 0s 38us/sample - loss: 0.0167 - accuracy: 0.8906\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0168 - accuracy: 0.8900\n",
      "10000/10000 [==============================] - 0s 39us/sample - loss: 0.0170 - accuracy: 0.8900\n",
      "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0172 - accuracy: 0.8902\n",
      "10000/10000 [==============================] - 0s 43us/sample - loss: 0.0175 - accuracy: 0.8884\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0178 - accuracy: 0.8862\n",
      "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0182 - accuracy: 0.8843\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0186 - accuracy: 0.8823\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0191 - accuracy: 0.8799\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0196 - accuracy: 0.8754\n",
      "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0167 - accuracy: 0.8865\n",
      "10000/10000 [==============================] - 0s 46us/sample - loss: 0.0165 - accuracy: 0.8878\n",
      "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0163 - accuracy: 0.8905\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0161 - accuracy: 0.8911\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0160 - accuracy: 0.8918\n",
      "10000/10000 [==============================] - 0s 44us/sample - loss: 0.0158 - accuracy: 0.8937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 35us/sample - loss: 0.0158 - accuracy: 0.8943\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0157 - accuracy: 0.8956\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0157 - accuracy: 0.8970\n",
      "10000/10000 [==============================] - 0s 36us/sample - loss: 0.0157 - accuracy: 0.8980\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0158 - accuracy: 0.8985\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0159 - accuracy: 0.8974\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0160 - accuracy: 0.8956\n",
      "10000/10000 [==============================] - 0s 36us/sample - loss: 0.0162 - accuracy: 0.8949\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0164 - accuracy: 0.8941\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0166 - accuracy: 0.8925\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0169 - accuracy: 0.8906\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0172 - accuracy: 0.8881\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0175 - accuracy: 0.8864\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0179 - accuracy: 0.8838\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0183 - accuracy: 0.8816\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0167 - accuracy: 0.8865\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0165 - accuracy: 0.8875\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0164 - accuracy: 0.8891\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0163 - accuracy: 0.8894\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0162 - accuracy: 0.8899\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0162 - accuracy: 0.8913\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0161 - accuracy: 0.8925\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0162 - accuracy: 0.8934\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0162 - accuracy: 0.8935\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0163 - accuracy: 0.8929\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0164 - accuracy: 0.8921\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0166 - accuracy: 0.8921\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0168 - accuracy: 0.8917\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0170 - accuracy: 0.8907\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0172 - accuracy: 0.8890\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0175 - accuracy: 0.8880\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0179 - accuracy: 0.8870\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0182 - accuracy: 0.8845\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0187 - accuracy: 0.8829\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0191 - accuracy: 0.8790\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0196 - accuracy: 0.8754\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0167 - accuracy: 0.8865\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0165 - accuracy: 0.8878\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0163 - accuracy: 0.8894\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0161 - accuracy: 0.8894\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0160 - accuracy: 0.8903\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0159 - accuracy: 0.8908\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0158 - accuracy: 0.8921\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0158 - accuracy: 0.8917\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0158 - accuracy: 0.8918\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0158 - accuracy: 0.8914\n",
      "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0158 - accuracy: 0.8917\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0159 - accuracy: 0.8925\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0160 - accuracy: 0.8923\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0162 - accuracy: 0.8920\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0163 - accuracy: 0.8918\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0165 - accuracy: 0.8907\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0168 - accuracy: 0.8894\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0171 - accuracy: 0.8863\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0174 - accuracy: 0.8842\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0177 - accuracy: 0.8827\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0181 - accuracy: 0.8806\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0180 - accuracy: 0.8781\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0176 - accuracy: 0.8815\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0173 - accuracy: 0.8831\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0170 - accuracy: 0.8855\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0168 - accuracy: 0.8878\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0166 - accuracy: 0.8905\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0164 - accuracy: 0.8916\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0162 - accuracy: 0.8932\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0161 - accuracy: 0.8944\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0160 - accuracy: 0.8946\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0160 - accuracy: 0.8959\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0160 - accuracy: 0.8952\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0160 - accuracy: 0.8941\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0160 - accuracy: 0.8925\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0161 - accuracy: 0.8918\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0163 - accuracy: 0.8922\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0164 - accuracy: 0.8916\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0166 - accuracy: 0.8897\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0169 - accuracy: 0.8881\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0172 - accuracy: 0.8861\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0175 - accuracy: 0.8842\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0167 - accuracy: 0.8865\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0164 - accuracy: 0.8894\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0162 - accuracy: 0.8908\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0160 - accuracy: 0.8923\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0158 - accuracy: 0.8933\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0156 - accuracy: 0.8949\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0155 - accuracy: 0.8958\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0154 - accuracy: 0.8963\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0154 - accuracy: 0.8962\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0153 - accuracy: 0.8968\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0154 - accuracy: 0.8965\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0154 - accuracy: 0.8974\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0155 - accuracy: 0.8971\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0156 - accuracy: 0.8953\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0158 - accuracy: 0.8946\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0160 - accuracy: 0.8931\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0162 - accuracy: 0.8936\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0165 - accuracy: 0.8915\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0168 - accuracy: 0.8890\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0171 - accuracy: 0.8855\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0175 - accuracy: 0.8842\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0180 - accuracy: 0.8818\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0176 - accuracy: 0.8845\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0173 - accuracy: 0.8861\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0170 - accuracy: 0.8893\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0168 - accuracy: 0.8903\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0166 - accuracy: 0.8908\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0164 - accuracy: 0.8930\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0163 - accuracy: 0.8933\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0162 - accuracy: 0.8935\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0162 - accuracy: 0.8934\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0162 - accuracy: 0.8939\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0162 - accuracy: 0.8946\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0163 - accuracy: 0.8939\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0164 - accuracy: 0.8924\n",
      "10000/10000 [==============================] - 0s 36us/sample - loss: 0.0165 - accuracy: 0.8917\n",
      "10000/10000 [==============================] - 0s 36us/sample - loss: 0.0167 - accuracy: 0.8905\n",
      "10000/10000 [==============================] - 0s 35us/sample - loss: 0.0170 - accuracy: 0.8886\n",
      "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0173 - accuracy: 0.8868\n",
      "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0176 - accuracy: 0.8854\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0179 - accuracy: 0.8832\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0183 - accuracy: 0.8816\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0180 - accuracy: 0.8781\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0176 - accuracy: 0.8811\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0172 - accuracy: 0.8835\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0169 - accuracy: 0.8856\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0166 - accuracy: 0.8880\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0163 - accuracy: 0.8906\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0161 - accuracy: 0.8908\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0159 - accuracy: 0.8936\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0157 - accuracy: 0.8941\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0156 - accuracy: 0.8956\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0156 - accuracy: 0.8953\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0155 - accuracy: 0.8965\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0156 - accuracy: 0.8964\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0157 - accuracy: 0.8948\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0158 - accuracy: 0.8945\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0160 - accuracy: 0.8936\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0162 - accuracy: 0.8915\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0165 - accuracy: 0.8906\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0168 - accuracy: 0.8865\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0172 - accuracy: 0.8828\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0177 - accuracy: 0.8799\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0180 - accuracy: 0.8818\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0177 - accuracy: 0.8831\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0175 - accuracy: 0.8853\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0173 - accuracy: 0.8865\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0171 - accuracy: 0.8878\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.8891\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0168 - accuracy: 0.8905\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0168 - accuracy: 0.8907\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0167 - accuracy: 0.8906\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0168 - accuracy: 0.8910\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0168 - accuracy: 0.8910\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0169 - accuracy: 0.8910\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.8903\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0172 - accuracy: 0.8899\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0174 - accuracy: 0.8881\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0177 - accuracy: 0.8869\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0180 - accuracy: 0.8860\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0183 - accuracy: 0.8844\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0187 - accuracy: 0.8817\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0191 - accuracy: 0.8790\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0196 - accuracy: 0.8754\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0167 - accuracy: 0.8865\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0164 - accuracy: 0.8885\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0162 - accuracy: 0.8906\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0160 - accuracy: 0.8921\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0158 - accuracy: 0.8930\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0156 - accuracy: 0.8953\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0155 - accuracy: 0.8966\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0154 - accuracy: 0.8988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0154 - accuracy: 0.8993\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0154 - accuracy: 0.8988\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0154 - accuracy: 0.8983\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0154 - accuracy: 0.8975\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0155 - accuracy: 0.8977\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0157 - accuracy: 0.8971\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0159 - accuracy: 0.8963\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0161 - accuracy: 0.8943\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0163 - accuracy: 0.8911\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0166 - accuracy: 0.8887\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0169 - accuracy: 0.8860\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0173 - accuracy: 0.8830\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0177 - accuracy: 0.8799\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0180 - accuracy: 0.8781\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0178 - accuracy: 0.8790\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0176 - accuracy: 0.8819\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0174 - accuracy: 0.8838\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0173 - accuracy: 0.8854\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0173 - accuracy: 0.8859\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0172 - accuracy: 0.8861\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0173 - accuracy: 0.8858\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0174 - accuracy: 0.8863\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0175 - accuracy: 0.8857\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0177 - accuracy: 0.8859\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0180 - accuracy: 0.8849\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0183 - accuracy: 0.8820\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0187 - accuracy: 0.8790\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0192 - accuracy: 0.8775\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0197 - accuracy: 0.8747\n",
      "10000/10000 [==============================] - 0s 35us/sample - loss: 0.0204 - accuracy: 0.8722\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0210 - accuracy: 0.8690\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0218 - accuracy: 0.8649\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0227 - accuracy: 0.8605\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0236 - accuracy: 0.8566\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0180 - accuracy: 0.8781\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0176 - accuracy: 0.8811\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0172 - accuracy: 0.8829\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0169 - accuracy: 0.8861\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0166 - accuracy: 0.8886\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0163 - accuracy: 0.8915\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0161 - accuracy: 0.8934\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0160 - accuracy: 0.8953\n",
      "10000/10000 [==============================] - 0s 36us/sample - loss: 0.0158 - accuracy: 0.8959\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0158 - accuracy: 0.8956\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0157 - accuracy: 0.8952\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0157 - accuracy: 0.8945\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0158 - accuracy: 0.8952\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0159 - accuracy: 0.8936\n",
      "10000/10000 [==============================] - 0s 35us/sample - loss: 0.0160 - accuracy: 0.8925\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0162 - accuracy: 0.8926\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0164 - accuracy: 0.8905\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0167 - accuracy: 0.8882\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0170 - accuracy: 0.8866\n",
      "10000/10000 [==============================] - 0s 42us/sample - loss: 0.0174 - accuracy: 0.8842\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0178 - accuracy: 0.8814\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0180 - accuracy: 0.8818\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0177 - accuracy: 0.8833\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0174 - accuracy: 0.8845\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0171 - accuracy: 0.8866\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0169 - accuracy: 0.8886\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0167 - accuracy: 0.8897\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0165 - accuracy: 0.8903\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0164 - accuracy: 0.8923\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0163 - accuracy: 0.8933\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0162 - accuracy: 0.8929\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0162 - accuracy: 0.8912\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0163 - accuracy: 0.8908\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0163 - accuracy: 0.8917\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0164 - accuracy: 0.8915\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0165 - accuracy: 0.8913\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0167 - accuracy: 0.8891\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0169 - accuracy: 0.8875\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0171 - accuracy: 0.8852\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0174 - accuracy: 0.8851\n",
      "10000/10000 [==============================] - 0s 36us/sample - loss: 0.0177 - accuracy: 0.8825\n",
      "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0181 - accuracy: 0.8806\n",
      "10000/10000 [==============================] - 0s 38us/sample - loss: 0.0167 - accuracy: 0.8865\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0166 - accuracy: 0.8872\n",
      "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0166 - accuracy: 0.8880\n",
      "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0166 - accuracy: 0.8891\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0166 - accuracy: 0.8892\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0167 - accuracy: 0.8894\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0168 - accuracy: 0.8893\n",
      "10000/10000 [==============================] - 0s 35us/sample - loss: 0.0169 - accuracy: 0.8895\n",
      "10000/10000 [==============================] - 0s 44us/sample - loss: 0.0171 - accuracy: 0.8887\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0174 - accuracy: 0.8876\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0176 - accuracy: 0.8866\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0180 - accuracy: 0.8845\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0184 - accuracy: 0.8826\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0188 - accuracy: 0.8804\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0193 - accuracy: 0.8777\n",
      "10000/10000 [==============================] - 0s 25us/sample - loss: 0.0199 - accuracy: 0.8744\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0205 - accuracy: 0.8715\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0212 - accuracy: 0.8676\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0219 - accuracy: 0.8643\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0227 - accuracy: 0.8608\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0236 - accuracy: 0.8566\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0167 - accuracy: 0.8865\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0164 - accuracy: 0.8894\n",
      "10000/10000 [==============================] - 0s 35us/sample - loss: 0.0161 - accuracy: 0.8917\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0159 - accuracy: 0.8930\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0157 - accuracy: 0.8962\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0155 - accuracy: 0.8965\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0154 - accuracy: 0.8975\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0153 - accuracy: 0.8982\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0153 - accuracy: 0.8994\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0153 - accuracy: 0.9003\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0153 - accuracy: 0.8985\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0154 - accuracy: 0.8985\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0155 - accuracy: 0.8982\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0156 - accuracy: 0.8967\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0158 - accuracy: 0.8954\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0161 - accuracy: 0.8937\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0163 - accuracy: 0.8913\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0166 - accuracy: 0.8889\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0170 - accuracy: 0.8869\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0174 - accuracy: 0.8845\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0178 - accuracy: 0.8814\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0180 - accuracy: 0.8818\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0176 - accuracy: 0.8841\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0173 - accuracy: 0.8872\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0170 - accuracy: 0.8881\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0167 - accuracy: 0.8897\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0165 - accuracy: 0.8916\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0163 - accuracy: 0.8934\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0162 - accuracy: 0.8940\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0161 - accuracy: 0.8948\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0160 - accuracy: 0.8953\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0159 - accuracy: 0.8952\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0159 - accuracy: 0.8955\n",
      "10000/10000 [==============================] - 0s 25us/sample - loss: 0.0160 - accuracy: 0.8960\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0161 - accuracy: 0.8960\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0162 - accuracy: 0.8943\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0163 - accuracy: 0.8924\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0165 - accuracy: 0.8906\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0167 - accuracy: 0.8880\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0170 - accuracy: 0.8851\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0173 - accuracy: 0.8824\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0177 - accuracy: 0.8799\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0180 - accuracy: 0.8818\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0176 - accuracy: 0.8844\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0173 - accuracy: 0.8872\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0170 - accuracy: 0.8897\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0167 - accuracy: 0.8919\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0164 - accuracy: 0.8927\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0162 - accuracy: 0.8924\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0161 - accuracy: 0.8946\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0160 - accuracy: 0.8954\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0159 - accuracy: 0.8961\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0158 - accuracy: 0.8953\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0158 - accuracy: 0.8946\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0159 - accuracy: 0.8951\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0159 - accuracy: 0.8949\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0161 - accuracy: 0.8954\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0162 - accuracy: 0.8936\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0164 - accuracy: 0.8914\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0166 - accuracy: 0.8897\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0169 - accuracy: 0.8885\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0172 - accuracy: 0.8866\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0175 - accuracy: 0.8842\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0180 - accuracy: 0.8818\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0178 - accuracy: 0.8836\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0176 - accuracy: 0.8848\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0175 - accuracy: 0.8866\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0174 - accuracy: 0.8873\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0173 - accuracy: 0.8879\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0173 - accuracy: 0.8868\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0174 - accuracy: 0.8859\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0175 - accuracy: 0.8866\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0176 - accuracy: 0.8858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0179 - accuracy: 0.8858\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0181 - accuracy: 0.8848\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0185 - accuracy: 0.8832\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0189 - accuracy: 0.8810\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0193 - accuracy: 0.8787\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0199 - accuracy: 0.8754\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0205 - accuracy: 0.8724\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0211 - accuracy: 0.8703\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0219 - accuracy: 0.8658\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0227 - accuracy: 0.8625\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0236 - accuracy: 0.8566\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0180 - accuracy: 0.8818\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0176 - accuracy: 0.8842\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0172 - accuracy: 0.8858\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0169 - accuracy: 0.8886\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0166 - accuracy: 0.8904\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0164 - accuracy: 0.8920\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0162 - accuracy: 0.8932\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0161 - accuracy: 0.8939\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0160 - accuracy: 0.8939\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0159 - accuracy: 0.8944\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0159 - accuracy: 0.8938\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0159 - accuracy: 0.8939\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0159 - accuracy: 0.8936\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0160 - accuracy: 0.8937\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0162 - accuracy: 0.8929\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0164 - accuracy: 0.8930\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0166 - accuracy: 0.8904\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0168 - accuracy: 0.8882\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0171 - accuracy: 0.8849\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0174 - accuracy: 0.8836\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0178 - accuracy: 0.8814\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0180 - accuracy: 0.8781\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0175 - accuracy: 0.8820\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0171 - accuracy: 0.8847\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0167 - accuracy: 0.8884\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0164 - accuracy: 0.8894\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0161 - accuracy: 0.8909\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0158 - accuracy: 0.8934\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0156 - accuracy: 0.8952\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0155 - accuracy: 0.8969\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0153 - accuracy: 0.8980\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0152 - accuracy: 0.8982\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0152 - accuracy: 0.8990\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0152 - accuracy: 0.8984\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0152 - accuracy: 0.8992\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0153 - accuracy: 0.8979\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0154 - accuracy: 0.8955\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0156 - accuracy: 0.8940\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0158 - accuracy: 0.8922\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0161 - accuracy: 0.8905\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0164 - accuracy: 0.8893\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0167 - accuracy: 0.8865\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0180 - accuracy: 0.8818\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0176 - accuracy: 0.8843\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0172 - accuracy: 0.8882\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0168 - accuracy: 0.8896\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0165 - accuracy: 0.8913\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0162 - accuracy: 0.8926\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0160 - accuracy: 0.8935\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0158 - accuracy: 0.8954\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0156 - accuracy: 0.8971\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0155 - accuracy: 0.8977\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0154 - accuracy: 0.8982\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0154 - accuracy: 0.8969\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0154 - accuracy: 0.8973\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0154 - accuracy: 0.8979\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0155 - accuracy: 0.8975\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0156 - accuracy: 0.8959\n",
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0158 - accuracy: 0.8932\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0159 - accuracy: 0.8910\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0162 - accuracy: 0.8890\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0164 - accuracy: 0.8877\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0167 - accuracy: 0.8865\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0180 - accuracy: 0.8781\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0175 - accuracy: 0.8812\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0170 - accuracy: 0.8851\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0166 - accuracy: 0.8865\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0163 - accuracy: 0.8897\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0160 - accuracy: 0.8912\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0157 - accuracy: 0.8940\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0155 - accuracy: 0.8964\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0153 - accuracy: 0.8975\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0152 - accuracy: 0.8994\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0151 - accuracy: 0.8993\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0151 - accuracy: 0.8987\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0152 - accuracy: 0.8992\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0153 - accuracy: 0.8978\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0155 - accuracy: 0.8975\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0158 - accuracy: 0.8970\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0161 - accuracy: 0.8942\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0165 - accuracy: 0.8925\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0169 - accuracy: 0.8893\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0174 - accuracy: 0.8858\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.0180 - accuracy: 0.8818\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for agg_weights_list in agg_weights_list_per_pi_sorted:\n",
    "    j = 0\n",
    "    for agg_weights in agg_weights_list:\n",
    "        aggr_model = keras.models.clone_model(model1)\n",
    "        aggr_model.set_weights(agg_weights)\n",
    "        compile_model(aggr_model)\n",
    "        score = aggr_model.evaluate(x_test, y_test);\n",
    "        Z[i][j] = score[0]\n",
    "        j += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.12319672, 1.8045518 , 1.83714838, 2.56356047, 2.76844229,\n",
       "       2.90052548, 3.20018156, 3.32719045, 3.5900788 , 3.70995607,\n",
       "       3.72406281, 3.77123254, 4.20566905, 4.2524348 , 4.49181236,\n",
       "       4.54761059, 4.77603233, 4.99507455, 5.03904904, 5.19949657,\n",
       "       5.3928762 , 5.57907511, 5.67356965, 5.70356409, 5.80986644,\n",
       "       5.88694958, 5.9424064 , 5.9749352 , 6.08781665, 6.46575839,\n",
       "       6.56181736, 6.60883471, 6.61429605, 6.61892595, 6.64419901,\n",
       "       6.67157162, 6.75039822, 6.89765469, 7.03153941, 7.16969066,\n",
       "       7.38397396, 7.67740569, 7.798422  , 8.24861365, 9.04946144])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sorted(dist_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADnCAYAAAApSCziAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztnXl8lNW9/99n9uwJSdgSlCUIhH13QVvQCkXBW0XEVqwV661Ltbbe4v1dL7VUW7frUlF7a9GivQUVrSgqBbdXF62gsqNChAgJBLJvs8+c3x+TWTOTmSQzmRly3q/X88rkmfOc5/skM5/n+3zP93yPkFKiUCgUiuSjSbYBCoVCofCgBFmhUChSBCXICoVCkSIoQVYoFIoUQQmyQqFQpAi6KO+rFAyFQhErItkGpDvKQ1YoFIoUQQmyQqFQpAhKkBUKhSJFUIKsUCgUKYISZIVCoUgRlCArFApFiqAEWaFQKFIEJcgKhUKRIihBVigUihRBCbJCoVCkCEqQFQqFIkVQgqxQKBQpghJkhUKhSBGUICsUCkWKoARZoVAoUgQlyAqFQpEiKEFWKBSKFEEJskKhUKQISpAVCoUiRVCCrFAoFCmCEmSFQqFIEZQgKxQKRYqgBFmhUChSBCXICoVCkSIoQVYoFIoUQQmyQqFQpAhKkBUKhSJFUIKsUCgUKYISZIVCoUgRlCArFApFiqAEWaFQKFIEJcgKhUKRIihBVigUihRBCbJCoVCkCEqQFQqFIkVQgqxQKBQpghJkhUKhSBGUICsUCkWKoARZoVAoUgQlyAqFQpEiKEFWKJKAlBKbzYbD4Ui2KYoUQgmyQtHHSCmxWCyYzWYuvPDCZJujSCGUICsUfYjb7aa9vZ3Kykq0Wi0nT55MtkmKFEIJskLRR7hcLlpbWzl69Cg1NTUIIZJtkiLFUIKsUPQBdrudL7/8EoCampokW6NIVZQgKxQJREqJ1Wqlvb2dmpoaNBr1lVNERn06UgSXy4WUMinnllLicrmScm7wxFXdbnfSzp+oa5dS0t7ejtVqVbFiRUzokm1AOmCz2RIuGHv27GHUqFFkZWUl9DzhsNvt7N27l+nTp/f5uQEOHTpEfn4+xcXFSTn/Rx99xDnnnBP3fqWU2O12Tp06xfHjx+Pev+L0QwlyDLjd7oQ/agohEEIk5ZFWo9Ek7dyA79zJPn+88T7xKDFWxIoKWaQZxgcuia3dw5cG/Yy7HT8+r+fH/vvZ0dsMzu9+vwU5PTEnuI/c2J9QjCZTr8+nUASiBFmh6KA7YqxQJAIlyIoeY7xrXs+P/dk34miJQnF6oARZkRzabMm2oFeocIUiEShBTiNijR8r+oizCpNtgeI0Q2VZKE4L4jGg16PzTirBtqc6Kec+HVkghKxLQL+fwl+llAsS0HVcUYKsUKAG9FKFOiH4xBR/WRIWR1HcO00ASpAVikBmliTbgv6NBjBq49+vJT3qTitBVpw+XHBmn5xGDeglECHAkABBThOUICuSwznDk21BZ7rjHXsH9MrUwF5c0QjI0CfbiqShBPk0JFGz8+JGLGJ8cVnCzfAyd8G3enagEuP4I0hMyCJNUIKcZljOHx1TrmL7nNGJ/ed+czTsOJrIMyj6IypkoTidabtgDP33AVCRdqiQhSJdsJw/OtkmBHNB34UV+ozyrkuAdhrQG1GQQGP6IcpDVihOA3qbYeEd0DPF4J2dVajix4lCgxJkheK0YPawbh/SqwkhyjuOP0KFLBSKtMZYkNNnOcjxxOl0Yrfbk21GaqFRIQtFGmHJNBLNp2ufk2Kx5nRh2tDuH1OS1+1DpJQ4nU62bNmiFj0NRdCvBVl9GtIQ4/8uSbYJPca7WkjLhNLE9P+Dmd0/KMYJIUaTqVcV3qSUHD9+HLPZjMvl4uKLL0an8/tEW7ZsYcyYMZSVlXH//fd3Ot5ms3HVVVdRVlbG7NmzqaysBGDbtm1Mnz6diRMnMn36dN577z0AzGYzl1xyCWPHjmX8+PHcddddPba9z9AIyNDFf0sTlCArUpPzhift1FGXp+rmgJ53sVOz2YzFYiEjIwOTyYTBYPC1cblc3HLLLbz99tscOHCA9evXc+DAgaB+1q5dS0FBARUVFdxxxx2sXLkSgKKiIt544w327t3LunXrWL58ue+YO++8ky+++IKdO3fyz3/+k7fffrtbtvc53iyLeG9pQvrcOpLIqVOnEn4Oi8VCXV0dbW1tYd8/c92KoLS3mpqaiH0VBbQpjNIWPLFMm80WtV2QPTHYEek4r3fsPdZ7zS6XK6hdrH0HRY+nDI39uLNGdd45blCQbRHPEzCgZ3xkMV9/9/ed2kspaWlpwWw2o9PpyMzMZNSoUTQ0NHRqu337dsrKyhg5ciQAy5YtY9OmTZSXl/vabNq0iXvuuQeAJUuWcOuttyKlZOrUqb4248ePx2KxYLPZyMzMZO7cuQAYDAamTZtGVVVVxL9HSiAEGPqvLPXfK+8GFosFt9ud0HO4XC4sFkuQKHVFe3t7xPeKAtoURmnrPbfL5Yrazkv5Y9dy9LaLOOPQiZiPCYf3WIfDgdVqRavVhn2/p/12i5D4cUx9lOTB0Lwu22s0GjIzMxFCdNlVdXU1w4b5s0RKS0v5+OOPI7bR6XTk5eVRX19PUZG/suQrr7zCtGnTMBqNQcc2NTXxxhtvcPvtt0e/rmSiARJQfjNd6L9X3g3OPPPMhA++tLW1MWzYMLKzsyO22X/WGYysOgnAqFFhvLsOnLWwa+wIZuSPwlHfdVsAu91OS0tL1Hbh6Mkxoce6XC4KCgooLg6YlPFOD/oePxSMuu4dFyF+3N1zh2svpcRsNvfJExbA/v37WblyJVu3bg3a73Q6ufrqq7ntttt8HnjKoiaGKE5ndo0dQQ+GuWLi4IQzSZlksx7kIHeH3g7oRaOkpIRjx475fq+qqqKkpCRsm9LSUpxOJ83NzRQWFvraf+c73+H555/vdHO48cYbGT16ND/5yU8SZn/c0IjYJuecpqhBvTRj36gzorbZNXZEH1iS3oSdENIRP+6SssKETAiZOXMmhw4d4siRI9jtdjZs2MDixYuD2ixevJh169YBsHHjRubNm4cQgqamJi655BLuv/9+zjsveEDy7rvvprm5mcceeyzuNicEIUCvjf+WJihBVqQ/AZNCTgzrwUo9Pc0/7ogfU9j75Z90Oh1r1qxh/vz5jBs3jqVLlzJ+/HhWrVrF66+/DsCKFSuor6+nrKyMRx55xJcat2bNGioqKli9ejVTpkxhypQpnDp1iqqqKu677z4OHDjAtGnTmDJlCn/4wx96bWtC8eYhqywLhaLvqDhzCOMT0O+QihpssXYcIX7sHtENUY+DGHtZuHAhCxcuDNq3evVq32uTycTLL7/c6bi7776bu+++O2yfUsq42dcnCAHG/itLykNW9C0xFKc3Ds6Pubt4rzYdTozVkk19SJJCFkKIBUKIL4UQFUKITjNohBBGIcSLHe9/LIQY3rH/W0KIT4UQezt+zgs4ZnrH/gohxG9FtFQblCCnDd0tvVnc0pogS3pPxZlDorZpn5zYQbpORIsfd1HhraUgcmaMopsI+lyQhRBa4Eng20A5cLUQojyk2QqgUUpZBjwKPNCxvw5YJKWcCHwfeCHgmKeBHwKjO7YF0S6//z4bKE5LTo4cRDT/OmhAr7vx4xEFPapfoYiR5GRZzAIqpJSHAYQQG4DLgMCpkpcB93S83gisEUIIKeXOgDb7gQwhhBEYAORKKf/V0efzwL8BXU6VVB6yovt8czRflHrir8a75kVp3HecHBlDlkQXdCt2PDQvrvFjRQdCgE4b/w2KhBCfBGw3Bpy1BDgW8HtVxz7CtZFSOoFmIPSR6QrgMymlraN94LTIcH12QnnIaUjD7FFRK771O8Z309MNHNCLJd0tAi0F2bTkZNL1OiOKmPHGkONPnZRyRiI6BhBCjMcTxri4N/0oDzmN+KI4NtH5vLAby9n3goNDoseC05ETgwPqVMQ4oFf75apEmdO/EHiyLOK9dU01EDhoUdqxL2wbIYQOyAPqO34vBf4CXCul/CqgfWBJw3B9dkIJ8mnKF0M84n1gQA9ybNONbszSixY/DhRjH94BPbVCSMKRQuDUaeO+RWEHMFoIMUIIYQCWAa+HtHkdz6AdwBLgPSmlFELkA28Cd0kp/+m7DilPAC1CiLM7siuuBTZFM0SFLBRJoXJAcULykHtKzPFj74SQwqyg7IrmbBW2iAdSCBx9PLNOSukUQtwK/BXQAs9KKfcLIVYDn0gpXwfWAi8IISqABjyiDXArUAasEkJ4H5MullKeAm4G/ghk4BnMi1r7VAlymrD/rOhTptOBuBemD1m6qXpwYdQsi3jFjwFacjJpzs7sVR8KP1KAIwnlN6WUbwFvhexbFfDaClwZ5rh7gXsj9PkJMKE7dqiQRZrxRUH6xm29q4XEwlfD0/c6FT0nSSGLlEF5yGmA8YFLYMWFyTYjblQOSMzDffXgblRj6yJ+fLKogCK6V+HNYjREb6SIihQCm77/ylL/vXJFjzk6KTWKbgauNh1LDnLYCm/EED/2DuhFiB8r4ocU4EojjzbeKEE+jVmnezVhfX+VU8wwSyNcUJawcySEKPHjk0WxZ1J448cWowFzyAodih7SEbLoryhBVqQeF3dT5Ls7KSQMYdPdFH2OWwjs/ThkoQb10oQviodSYfDHXo3/uyRi28+1A/vCJCqyen6eqozECODx/Bj6DYgfd2u6dBQ+bn0ybn31VyTg0GrjvqUL/fdWpDg9iOPSTd5wRV12jn9AL0L8ODRcYdeqr1JcEAKXtv/6if33ytOI0NKbXS3jZHz4Ut/rLzWpN1UhltKbAJWF8bW904BeQPw4XLhia+Nv43p+RWxIIbDrdHHf0oX0sVTRIxwivvdc44/Pg9su6tnBMRSn7w1RwxURVgiJF7Y0+uKnKt6QRX9FfYIUfU7c4scBs/RizkGOED8ODFd0F7tWp8Q4TkghcClBVihix1sLORWpMeWBK/b2MWdXdBE/9uLQhBcSKSVutxspJdXV1dhsNtxuN5s2baK5uTl2Y/sBErArQVZ0xY4dO3C5uvEt7wEWi4XW1lY0ms4hhrPBl2FxWFvIWE4A8OGHH3ZqO2uOJ94cmAERrl0gUkosFkvUdgBzO35+rR3AYNnKwQlnUh3DcYHHhtpltVqpqanh0KFDQe2i2eNtFzopJPS4uQu+FXxglPoVtRkdXnLggF6MvOl6noKP/Wl7LpcLi8WCRqPx/W+1Wi06nY5LLrmEX/3qV762W7Zs4fbbb8flcnHDDTdw113BS7vZbDauvfZaPv30UwoLC3nxxRcZPnw427Zt46677sJut2MwGHjooYeYN8+zcMCnn37Kddddh8ViYeHChTz++OPEsLRb0pBC4IxwY+sPKEGOgZkzZ4YVyniye/duRo0aRXZ25xlge+v+FfaYc889t9M+5786r0ocrl0gdrudPXv2MGNGDPW718dmR1gO+gfKjotc/r3juIMHD1JQUEBxccdA3u+62W8s9oTEj+MdrnBotLg74vXe80spMZvN7Nq1y9e+pKSE48ePA6ALCHO4XC5uueUWtm3bRmlpKTNnzmTx4sWUl/uXdlu7di0FBQVUVFSwYcMGVq5cyYsvvkhRURFvvPEGQ4cOZd++fcyfP5/qak/p3ZtuuolnnnmG2bNns3DhQrZs2cK3v/3tbl9nXyGF6NcxZJVlkUZUOmJ7vD5i7ptJDpUM6JPzhMO32nR3JoV0d/28CHQ1O8/dQ+9z+/btlJWVMXLkSAwGA8uWLWPTpuDyuZs2beL73/eU5F2yZAnvvvsuUkqmTp3K0KGeaxs/fjwWiwWbzcaJEydoaWnh7LPPRgjBtddey2uvvebr74ILLqClpQWA3/3udzz22GPY7fYe2R8vJJ7QT7y3dEEJ8mlMpSVqIco+J9bCQkczuy/2NaYYQgsR0t283rEvXBFKQPw4HG6h6bEYA1RXVzNsmD+nurS01Oflhmuj0+nIy8ujvr4+qM0rr7zCtGnTMBqNVFdXU1paGrHP5uZmcnNz+fTTT3nmmWdobGzkhz/8YY+vIR5IPCGLeG/pggpZKLrHN0dHbxMBby3k4yI3Xtb48Ka81eqyaNjzXwwYf19Mx0WqXdGkzwieEBIBb7jCi0ZK3nQ9zyXaa7thfXzYv38/K1euZOvWrTG11+v1OJ1Onn/+eVauXMnSpUtjC1slECnAkeDwYCqjBPk0Y9fYEck2ofecNzy2dhFm6VUPKvQFU4y5WV3GjwPxesdN+oyopw6dnef1jjXSHfXYcJSUlHDsmH/h46qqKkpKSsK2KS0txel00tzcTGFhoa/9d77zHZ5//nlGjRrla19VVRWxz9tuu43JkydjtVq5//77AWhra+uR/fFCInBo+q8s9d9bUZpgfOASvige2il+3DB7VNzP9azuLzyr+wsA6zUvRWz3VU73ZtE9YHynR/Y8o4+8BNmfmp7xvQ7NQa7J84dq1rf83vMiJH4cLlwRC974sZfAwTyNlDH3E8rMmTM5dOgQR44cwW63s2HDBhYvXhzUZvHixaxbtw6AjRs3Mm/ePIQQNDU1cckll3D//fdz3nnn+doPGTKE3Nxc/vWvfyGl5Pnnn+eyyy7zvX/ttdfy8ccfs2/fPjIyMqioqOCcc87p8TXEA4nAKbRx39IFJchpSCqsGnLc7gk79HTl6VOO8PWEX9C+0mObvNQZI9QqDkl3CxeuCOsdR4gfh04G8XrH39ZdF7uxHeh0OtasWcP8+fMZN24cS5cuZfz48axatYrXX/est7lixQrq6+spKyvjkUce8Xm1a9asoaKigtWrVzNlyhSmTJnCqVOnAHjqqae44YYbKCsrY9SoUZ0yLLKzs8nI8FxzWVkZzz33XLdtjydSgE1o476lC/332UARlgy3I679eb1j47+fje2Hc+LaN3TOQW6Qmeh1boiQLBAtXOGlTWOMGD8ODFd4B/N64x17WbhwIQsXLgzat3r1at9rk8nEyy93Tmu8++67ufvuu8P2OWPGDPbt2xf2vQsuuIDNmzeTm5vL7373O6xWKzfffDMGQ/JWP5EIXHGe7p9O9N8rT0OOtUZ/tP68MH6z6P6gf63L96ut3c/b7Q7HNZEH065Z3HldyVqdp4BQo+g6BhwpXOH1jts0kYvNh4YrvPTGO04WqZllQb8OWSgPOc04astnpK6+yzZfN+YyJ0ELIfdm+aaKM4d0WceiN+GKcClvr/J/1Bpyw+YfB4YrIqa6BRC6urQ3XBHoHaeTGEOKZlkg0irEEG+Uh5ziWM4fTYWhOCbvOJBKOYDq5sR6sLHytTM4HzpS/DiQrrxjgAe2PBRxUkir29R5Z5Tp0l683nE7fi85dP28wHAF9DyzItl4syw2b97MokWLgNTIsnCijfuWLihBVvg4rImtYtrX2uBJG8a75nX7XHW26KllkXhZbAj6PbTspl2G/wKGxo/DhSsCWfWfP4FCfx3lwNl5nuyK9PWOITWzLABcaOK+pQsqZHGa0dvlmw7ri8AGB/UDKXE3xcmq6GwZ/DcAqnS9m10Y1jsOILS6W2C4Ipx37CU0XBHoHaejGAM0NDTw6KOPcurUKcrLy7n22muTnmXhRmBLI4823qTPrUORUpxo93iO0dbV84UrElScPjAHuUF2DpzXiSxW/XZV0L6TRQVRveN2qadd6gGC0t0CJ4Po3C6fMKcjy5YtIycnh0WLFmE2m5kzZw7bt29Ptln92kNOH0v7KfvP8i/XVNvc88f87tDVpJBATrZ1f+Swq2nTXu+4fbJnBt5JZ+RY8wkZHGP2Zlh48Q3oAauf/t+w6W6xeMeB8ePQcAWQlCnS8aK2tpaf//znXHrppfznf/4nb7zxBrfddltSbZKAQ2rivkVDCLFACPGlEKJCCHFXmPeNQogXO97/WAgxvGN/oRDifSFEmxBiTcgxVwsh9goh9gghtgghoq6oqwQ5Dah0FASJ8WFtYZfr6lXXJCjFgu4Vpw+doectLBQaP/543N7eGxZAizN82lq4YvSRvGMAo/DXwPamu3nDFTp3Yutj9wUDBgxg717/337kyJGYzeYkWtQxdVrq4r51hRBCCzwJfBsoB64WQpSHNFsBNEopy4BHgQc69luB/wbuDOlTBzwOzJVSTgL2ALdGu34VQz7NCCy9eaoxA2JLLgjLYRHjskhROGHu7Ok2WYyg71l/1YY8kP5JIYEpb+HE+JZ/v4Mntr4AdA5XQHjvOPCL7I0f27WeQkLpmHMcjqeeeoorrriC888/n4kTJ7J//35fHYxkIRE4Y/Bo48wsoEJKeRhACLEBuAw4ENDmMuCejtcbgTVCCCGlbAf+IYQoIxjRsWUJIeqBXKAimiHKQ05jjP+7JK79VVpjq6PsnTbt44LQz2L38YYralw9T9WLNqAXSGjusVeMvd6xF2/8OFzt43Rl+fLlPPLII1RVVfHee+8xd+5camtrmTp1KuvXh1mBoA+RMmEhiyIhxCcB240Bpy0BjgX8XtWxj3BtpJROoBmI6LFIKR3ATcBe4Dgez3tttOtXHnKK80WxP9fW6dJwvDWbM4yJy374yjaAkZo6Km0FDDG0RGzX0G4iy+iIWqQ+nHccSG9rV4Rbadrq1ILOM6BX787kia0vxBSu8Iqx1zP2ps8Fhiu8pLN3/IMf/IDdu3fzwgsvsHv3bpqbmykvL8dut/PGG29w5ZVXJs02T8giIVkWdVLKPpv1IoTQ4xHkqcBh4AngP4HOU0wDUIKcBnR3UkiiMP74PHjw+z061lsLuSu83vHyGSsocFqpt2Z0Cmt4cpDzOGUPHsQLzbDwDugBLJ/7Qx78fGPEcEVoqAL8YhwarjgdmDdvnm/NPQCn08nnn3/O7t272b59e5IFGRzuPn9wrwYCa7mWduwL16aqIz6cB3Q1ZXYKgJTyKwAhxEtAp8HCUFTIIk2obYztcfzrRo8QVVn8wvOwMbaC5V4O6mPLZa5v7dqm0Bl64Jml12Qx0mbxK21vc48DMyysTi1WV9d+Rm1GTkTvGPxi7JKCx864sFO4Ip2943DodDomTpzINddcw0MPPZRUW6QU2N3auG9R2AGMFkKMEEIYgGXA6yFtXge83sgS4D0pu6woVQ2UCyG8tWq/BXwezRDlIacRDU0GBuZborY7ecoI4xJjw1c5xdDNBIOaJo+XWZVRAE7//nDhilPW2DNEQusgR8quePDzjWH3h/OOA8U4qK3B0y6d847TAQm43H27KraU0imEuBX4K6AFnpVS7hdCrAY+kVK+jif++4IQogJowCPaAAghKvEM2hmEEP8GXCylPCCE+CXwNyGEA/gauC6aLUqQUxjjA5dQseqnPT6+rt4vNlc792Fza3nV0HOlvuKx33ERFb5JIV3xgPEdCOMhRyKWwbxbtTuAUWTJziVCAwf0bE6PqNa7M2lymLip7Lvc0/Q2ddk5Eb3jwNSoUDEOnAySznnH6YCEZGRZIKV8C3grZN+qgNdWIGwsR0o5PML+3+FbQz021O0+DQidEHLUlp+QIvXVzcEDcF0tktrU6i9DeXBC5ApwXu84EoHhCq933GDxXG+T1S+yHjEO039IlTdvuKJOdH3T8HrHoaGKQDHO0jrI0jp4r2AMoLzjvkBKgd2pjfuWLqhP2GlG6KSQQyI4Hny5veswVnXHAOLXTcEe63dde3nltf/p3D7GmsgVZ3puIN5JIWab3+vsyju+VbsjSIzLdHUA1Jo7T+iwdnzxpBRUOWJYgboDb6jCpHH6RDhL29kLV95x4pHSM6gX7y1dUCGLGKisrKSr+P0CZw5bdK29OkdrayvHjh0LWq1hxPmjfWvptbTqyMlycqopg6E5/hKJX331VUhP0YUo9BiXy9UxQ8sTk620FXRuO9zzI7DSW1OLAYZEsKPcn/J2siEDivzTpr0DeuEG87zecb019mnigRkW3nBFZUse4wrqaHUYaLMZgsIVXu+4RXo8cI2QmIQzqM8ZjqMcMAzGKv2lNjv/rbtGSonL5cLlcqHRaBCib2Oj6YhE4EojAY03SpBjIDMzykBTs0eU/57X87q4Op2OjIwMTKbYJzc0zB5FVlbIo3nAzNfW1vCPav8xzM5TDX7RdTqdaLXh2/r773pKbSc7ukksg3knrVmcJItsvcd7DcxBDh3QyzXasLp1FJvMFJvMbJDTPW+4IFfYIp7D7taysupM/j7kqG+fQ2qYXnsx9OASzWYzDocDl8uFEILKysou/979HSnB7lSCrOiCgQMHotF4PiRXOzuvTzajo2TIHb05SVE20IZBGzAZY9D14IIJQ+uZMNSf8uhwa9hmH80SPmbw4MFB3Zzc38qY0a3sPlrEkrmVHLPkUJzZRmV9Lk6XhmFFHk/+5gGNvgE+u93OjQWWsOvQ3VTQRIbOI4Bnz72Hb/I1De0mzBYdGo3/qSHUjq+dVXSF3eERpMBwhdc7bmg1km+y0mr1x3dPWsOrYa0uyzMShCd+LKVAiO6tb+dNi3rUOduzI/hScKHpdH2xIKXEbDZz4sQJANxuNyaTCafTic1m45133sHlSv+aGPFEAg5X/xXk/nvlPSCcGCeTGTnBGRjfavE/Uk8bXut7vfbA5C77mXysEYCaBo+X+vHhQdQ0ZOIIyN90uLUMzDFzsD041exkW2aXK0+fbAgOPTRZjEHxY+jaOz5uyQ4rxg3t/ieJ0CnTOYbgO4uU4UMF3hxVh9T4xbiDK6Uvq4lzrUci2tcdNBqPsJtMJrKyspg6dWqXobD+iJQClyv+W7qgBPk0wSvGY0Z3Hcs+Vuf3SKMN8HlxhCTWn1ng8eLNltgeuxsaDb5Kb4FE8o67YmSWf9r4HdX+Je2tTi02p5ZcoyccodW4I04QCZws4JAavvv3rlfaXqRZ3uX7PaWwsBBdwHTsLVu2MGbMGMrKyrj//vs7tbfZbFx11VWUlZUxe/ZsKisrAaivr2fu3LlkZ2dz663BBcXWr1/PxIkTmTRpEgsWLKCuri4h1xIvpPSMA8R7SxeUIKcx00ecAuDcWk+88+0Da7pqHpZxX50M+r26Pthb1WnCx8XPGVPDOeNPkW108JT7XC6zfOl7z1t205vRMLe9AAAgAElEQVTyds6kWtZYzmVXk/+x3+n0eC1deccWa4gn3ZrJv2r8tT1WjvowaEAv0BP2DgxZXTqaHYagDfwFbNa4ZkY8/y9s3+Q39jkR348nLpeLW265hbfffpsDBw6wfv16Dhw4ENRm7dq1FBQUUFFRwR133MHKlSsBMJlM/OpXv+Lhhx8Oau90Orn99tt5//332bNnD5MmTWLNmu5/RvoSCcpDVqQvXjGORlOb3/MM9JK9nGjo3aAcwLfbKvh2m7/CYH6WnTHDmoPaGHUuhhWFX0jT6x23tOuDcpDBI8ZeQlPeWpxGrC6dzzt+UT8eh9RgdXX2jNrtBl/B8q7EuK/Zvn07ZWVljBw5EoPBwLJly9i0aVNQm02bNvH973tm7y5ZsoR3330XKSVZWVnMmTOn04CwlBIpJe3t7UgpaWlpYejQ8AvDpgpSChxOTdy3dEEN6qUwNW1+kQxMdYvErrEjIHKBNqpPZVIyMHK2RF29kUEDo0/NjsYH9cOjthkzrImvWvJxuTW4OzzbATm2oJ8D8y00tpt87wfS0q7n7l3fYPl0jxdp0HQ9ONZuNwT9nkpiDFBdXc2wYf76NqWlpXz88ccR2+h0OvLy8qivr6eoKPxCFHq9nqeffpqJEyeSlZXF6NGjefLJJxN3EXFASnA40kdA403/vfIesF43oU/OU9OWFSTGkfZ9eiRyEaDPKjvHbAMJ5yW7AqIT44c1dHr/RHMWDZYMX7y3LwjNmKhv8Xv6t8/4hFa3yTchBDzeMYC24zirS+sTY7NDx7DslpQT40ThcDh4+umn2blzJ8ePH2fSpEn85je/SbZZXaI8ZEVC+fKkP1dWKyRlAyPXMj5cl0d+VufcM02AKNW0ZWG2d/63HT2ZzedjS4I85OMtWUHTRvNyHEFecjhR9vLBzqF8c+px3+8nmkPKXVoyyDR0PRjWFe02PSZ991K+7A4NORkO6ltN5GQ4ePloOd7ZzMPyW7E6db5ynTrhxuXWoO2IgZsdOtpt+pQV45KSEo4d89dIr6qqoqSkJGyb0tJSnE4nzc3NFBZGXtVl165dAL5VQJYuXRp2sDClkOBMo5hvvFGC3AMCRba7VJwKXx8iMKc3kNoWT1xwUF74UMLxU57YqtHQu3zW4yc9Xu/JUxkUF1mD3gsVY59trZ5jinMs2MPEawOpacwkK8OBXtvzyTPRCDdF1uXWYHZ4PuYfFkdehzDZzJw5k0OHDnHkyBFKSkrYsGEDf/7zn4PaLF68mHXr1nHOOeewceNG5s2b1+Xsv5KSEg4cOEBtbS3FxcVs27aNceMSVAYwTkgJDnv6eLTxRglyN+mNGMdCU7vB5yV7xVgrJHUtJopyrZ3aZ5hcWKweMfxc6wlhNDUbyMryTwU+fjyDoUM9gh7qJXdFdZNn6nOgh97U7o/F6nUeca1tzcDh1GC1axk6ILjfmsbwWRRtFj0OlwabvWshz8kMM1slDFanjreyRvt+N+lcNNsN6IXHxqY2o6dAYoqi0+lYs2YN8+fPx+Vycf311zN+/HhWrVrFjBkzWLx4MStWrGD58uWUlZUxYMAANmzY4Dt++PDhtLS0YLfbee2119i6dSvl5eX84he/4IILLkCv13PmmWfyxz/+MXkXGQNSgsOpPGRFiuEVY/AUpy8usEYU5Z4QTpTlSQMM8Qjg6BGdRwdrG03k5/gFstWsJyczOGxxvCHTJ8qBYhzoHbdZ9Cwc8RXvVg+PaqfFpsOgj+5Vh3rHJo2TZjwZFe02PTuGRl+xJNksXLiQhQsXBu1bvXq177XJZOLll18Oe6w3JzmUH/3oR/zoRz+Km42Jxi0FdpvykBUpRKAYNzQZaWnVURzimB87mYXRECxUgStOd5fyUU3sqh7kC1fs21HIhJn+6dqhK5a0tBswRIgBH++Y8acJcHQaWoxkmTxeu8WuZbDsegJLS7snGJyV6aS53UBxfvgbkbddV+GI/jxqn3ZIf456f0QJcorx9fEshg7yhBcamjwZBeZ2LfXNRgrzbNS1mKhvDp7NVlNjRKeTTBvRub+qk574b2jYorlVT/WpTPJyPB7upx8NJFLwIFCMWzpCFo3NekxGzxE5mQ5qG03kZIUf5KttNJKb7X9v3/AhvGFtxGzT0W6O7SNY22QKm+Cv17tpa9d32p+ttXMSz40hHbxjRQcSdAm4gTqjN0kJlCAniMpjnQfCtCGfs+Gl/txit1twrKZzvLWlVYf1whxGfh49VOFdT8/LiXqPDQUD7DQ2GDq194qxl8JTwcJWU+cZtPPGir1YrFpqpg1g+H7PNNxWs+e4k3UmBoUMCNY2Bt88LB0x40Wa5fyi0zqSfloDPOSuCCfGADkaK1ohqajJD16+UpHSCCnQ2+LvIStB7geEE91uHV8VvEKHNkD4vN6xl9ZWj/AU5vlLRx6rymBYaefsi+ZWfdCgXiyUjGnDUe2vdVw0ovOgX229kUHF/vNbLFryQjLnAkXZK8ZNjR7bNRoZMXzQGkFY2806mlv1DMi309zauY3J6KZyfOeJEatsc7la7GPnsNSemaYIRkjQJyBk0fvpTn2DEuRu0lsRjgWvGLe06jC3ezzK2ln5jPzcU8GtMM/WKWwBntVC8vM6ZyVY92fDEHunsEVX2D/LxTDNP7BX27E+n8Wqxdox6GKza2huNZCXY4+50JA7YAFLq00bVojNZk9fVovGFwZpaOrs4ZuMbixdnLevJvIo4oeQoO3HMX8lyCmOIWDEuTXAQ6ypMflyl4tqPGKVP6Lz9OqaGiP5QMYJA5YhkVPILH8v8H0YautMGIH6OiOFRTafGPv6nObxpJvOzWP4/jqaWw1YrVpMJs8g38k6T8xZp5M+7xg8g2uHxoSfXegVYfAIsc6hIWdA1zcNi0WLNcYbgSI9EG6B0dp/B/X6760oRXF+7Ynber3jloWRPfL8Ko9Q5pwdPPvP1uFVe1edbir0C9vx4+GnPbeMNZPT4Be31jM8oYn6Or8Yu+sMPu/YS6CH2nYqfOlMU4OetrbO936XS2A2a4M8YqtFg/XCHNoWeK7batXS1KinqVFPS3PwBtB8fgonFyu6jZCgc4i4b+mC8pATTOZXfgF06v0TLFzDOw/SecU4Eu3tWnKihBrixdDdmRyf7I8ju+s6hwyCaNCDTtJ2ykj2QI+Ye73jzDYtLYOCwxWBWC0ekdc5ND4hjoaxRYtVp4q7n254Bbm/ogQ5jgSKbzS0lZ3XzvMKdkur599iCPFGzXNzKN7uIifHQd5JQ6djT/5rAIPObkAbkp884nO/XaFhC29c2XDUxIkRdvgkH1u2i6/HW8is0+MocvjEOLdRh2VgsE22MNNcfZ5yhgtTg57MVg217VrvGqo+3G7hC0/onIKmSztnmdgcGnKbPH8PR4gA2+z994t7uiIkGPpxyEIJcg/ojvD2FHO7lkg+aWurHh1QXKUn1M+2bR5IdpEThvm929YCFzmN/tBC4OBeJMo/yqZynBV9nR6nXpLb2PVHJbvZ039TYefsji9u1pG/OXz8WOfQ8NnIagoKCoCuFzo1hcSLGy+LvjCqIr3wDOopQVbESKLFePBRA8eHeB75NREe8WPFccpAUXOwiEUb3PNSOa5zSCWrWcPRWcHFkZwOAWgwugVujSS/XucTZVODnsw2z/nDPYbqdJK2BVkcPBjZDpdTQ1bH6tk2k8RkVsMepzPCLdD34ycf9enuI0orDAw5EiUOG4I1o/PU5PZ2v8Dmn9JyrMp/g8iv01FUrSO/Lvg+O+CkjsITOgpOxXb/zW3UMXpnBvl1nr668o7bvuEZVMts1QR54V4yWz0fsbrvdL6RfT5qUEz2mMwahFuQ06xB74Aj1+s5cn34vGVFeuMNWcR7i3peIRYIIb4UQlQIIe4K875RCPFix/sfCyGGd+wvFEK8L4RoE0KsCTnGIIT4vRDioBDiCyHEFdHsUB5ygiitCC++4UT5xAiPxzr4aEch9XYtBpsmbIaFxqahHRh5Mvy/7h/3AegoP9y1fd6wRcYJAyf1bgYGiHhbnovq0fagD3JWs4aslvApZk6HILdeS2uB5waSX+/pS+MWfHFz7z5ihZ9kY7D2vh9FeiAk6PrYQxZCaIEngW8BVcAOIcTrUsrARQ1XAI1SyjIhxDLgAeAqwAr8NzChYwvkv4BTUsqzhBAaYABRUJ/yGHA6nWg0Hk+v8iotw1/s7LlGEuBY8Iq0wxQ8aOV0do7HNl1kJPfvnvhv7RlO8quMNJ40kF+nI7tJ6zumvsEzsDbgpI78U1rcWig84f93WzomikQKwJjMgsxWLW15Lp8YZ7aIsDYBmNoFdFTD8ApzpGsIxe1243K5OrU9MS0bpgHImPrpKVImpn8pJW534uo/n44Id1IG9WYBFVLKwwBCiA3AZUCgIF8G3NPxeiOwRgghpJTtwD+EEGVh+r0eGAsgpXQDUZf8VoIcA3v27An5Yk3ukQAbrQKbqetUraIqHRUTPN7lZ599FraNxjaenPqOQbQiJ22D7L4whe8YzeigUEN2o4a2gvDiMPCz4CncOY1aBn2tp2mQi+xmLTaTG71V8PDl2wlv0lgMVoE1K/jaMls1Ea8hELPZTF1dHUePxrZga7wxm80x2dldpJTYbDZcLhd6vb7LYvIKDx4POSFdFwkhPgn4/fdSyt93vC4BjgW8VwXMDjne10ZK6RRCNOPJGworskII72DLr4QQ3wS+Am6VUp4M196LEuQYmDZtms9DBih9u/v5rwMrPX9qe4bk5Jlde2ML1uXz3rIWZs2aFb7Blvawu03twn/MJ42+/dmNGkxtgraA6pyBg3s2k6Sp0MHoPR5/ubXAxQcPSc5Z1ZEfbBd8tBo8jkRn2gC+IbngLr+X3J7nxmAVka8hgIMHD1JQUEBxcdfrACaKDz/8MCY7u4uUkra2Nnbs2IHZbMZoDD9xRuEngSGLOinljER0HAEdUAp8KKX8qRDip8DDwPJoBykSgFeAwzHo6+D3vAJdVOXfbzd2/aib0+gRy+IqPU2lNrKbguO7LY16ivEM/HnJbtTg/Zc3DnSSccJA0Qk9ZxzQ89FC/4QTb6w4q0XQnivRx/gImdmiwZrlD1fs+ama1qzRaDAajej1eqxWK59//jlSSuUtR0C4BQZLn/9tqgmuCVjasS9cmyohhA7IA+qJTD1gBl7t+P1lPHHoLlFZFnFkYKXOt3WHQV/rfCKdf1JDbq2GzKzIa+R1rNuJqc3zwfVOoQ4VzpF7jL52r/6fi8zm8B/07AYN+fV6Mls0ZLb4PxLvPCbJavF6x9HZ8pQbU7sgp1Hry65QeNBoNGRkZDBgwADMZjMOhwMp1UzDUITbE7KI9xaFHcBoIcQIIYQBWAa8HtLmdeD7Ha+XAO/JLv6BHe+9AXyzY9eFBMekw6I85F7QXeEtOqrh+JjYFiNtODv8YqgA33zZk2qms3s84NpSj3erjdK1qU108pK95NdqMbV74sCBwv7OY90Tjb/dDxfcJbBmKQ8wFCEEgwYN4uuvv8Zms7Fjxw4yM9XklkCSkWXRERO+Ffgrnpjbs1LK/UKI1cAnUsrXgbXAC0KICqABj2h7bBaiEs+KjQYhxL8BF3dkaKzsOOYxoBb4QTRblCD3gO4IcdHRYE9xQHXw7w0lnUMTkTxZL68/51fey7/nCQt4shz85HUM6GU3anwf8D9vcnL597S+WHLBKU8GhqlNUFylY8tTbhbcrOGDh3rnuRmsoteTWk5nhBCYTCZyc3OpqalJtjkphXCDIQnFi6WUbwFvhexbFfDaClwZ4djhEfZ/DVzQHTuUICeAUBHuikCBNudJcmu796if2Ry9/Usv+z3hQC+5fkjnwcV4xO88XrUKWURjzJgx5OaqanWBJMNDTiXUtyYOFB3VBG3hyD8hPFtN5D+51zPujofwp80Oiqs8s9ZaCv3etneKceOgYA/8z5ucnTxwgwV+/f3tAGhii6goEsCWLVsYM2YMZWVl3H///Z3et9lsXHXVVZSVlTF79mzfStP19fXMnTuX7Oxsbr311qBj7HY7N954I2eddRZjx47llVde6YtL6TkyKTHklEF5yD0kFi84/0T4O32oKDcNDhZNnY1uo7cKKsttgGcgT7gFDUOclH1qAIJVNtBLzq3T8NTWdvbs8bz32vNKkZOBy+XilltuYdu2bZSWljJz5kwWL15MeXm5r83atWspKCigoqKCDRs2sHLlSl588UVMJhO/+tWv2LdvH/v27Qvq97777mPgwIEcPHgQt9tNQ0NDX19at9AkKWSRKihB7gFdiXEkEc5u8OzX2aGtMDhGGyjQbi08cqB7t3RvalvV9/x5rjlNnj5f/b/OAhsaS1Ykn+3bt1NWVsbIkSMBWLZsGZs2bQoS5E2bNnHPPfcAsGTJEm699VaklGRlZTFnzhwqKio69fvss8/yxRdfAJ5Mj6KizusPphQSdAlY5DRdUIIcByKJMPiFOGhfffC+UIGOBw6D7LJqltdLzm5QUatUoLq6mmHD/KmwpaWlfPzxxxHb6HQ68vLyqK+vjyiyTU2elWT++7//mw8++IBRo0axZs0aBg2KrahTMkjgTL20QH0be8Cz7zr8MeEwYpzdIHwbgKnVv2U2+zdf+3rh23ryuFZQo6EgJAwSrYShN5bszWVWnH44nU6qqqo499xz+eyzzzjnnHO48847k21Wl3izLOK9pQvKQ44ToZ6wqdX/WuOCu6zBgeFfZwVPozXneX72JH786v+5fOlvXmKZJWdq69kNQBF/SkpKOHbMX06hqqqKkpKSsG1KS0txOp00NzdTWFgY2pWPwsJCMjMzufzyywG48sorWbt2bWIuIE4Id8++A6cLSpCj4HQ6aW1tJScnp9N7XYnwXa3BShda9Cvw/ftz/DXXWorpUYWwzGY9bnf31tv70188z4Z2uzuplcm85072+RPVdyzMnDmTQ4cOceTIEUpKStiwYQN//vOfg9osXryYdevWcc4557Bx40bmzZvX5RRsIQSLFi3igw8+YN68ebz77rtBMelUpEZ++tdfW0QiAt1RK62lAkqQu6C+vp7vfve7LF26lCuuCK4tnd3gEVGvCN9RF7Lyczfu8j+uaWfXrl1MmjQJg8HQrWO9PPOyrUfHgafamRACW087iANmszmp529oaCArK7YFVmPFK8ben12Jp06nY82aNcyfPx+Xy8X111/P+PHjWbVqFTNmzGDx4sWsWLGC5cuXU1ZWxoABA9iwYYPv+OHDh9PS0oLdbue1115j69atlJeX88ADD7B8+XJ+8pOfUFxczHPPPRfXa4w3UsoFybYhmYgod/B+O9n+vPPOY+fOnQwePJjMzEwyMzPD5ob2FiklVqsVnU6HXp+cVTDsdo+nbDD0vKZzb3C5XNjtdjIyEr9WYaTzW61WMjIygqr6xQshhM8DnzVrFjt27AA8XvGMGTP48ssv437OJKEGJHqJGtQLQUrJ1KlT2blzJ8OGDUOv1ydMjMEjhkKIpIkxeARJq01eZTaNRoPb7U5asR2tVovRaMRqtSbEBiml7++rCtYrukKFLAJwu92cddZZnDp1iuHDh5OdnZ0wIQZPfNrlciXNMwR//DQRnmGsCCHQarW4XC50uuR8JHU6HW63G6vVislkint5TLfbjVbrWdFFld9UREJ5yB1cdNFFFBYW0trayhlnnJFwMXa73dhstoR8+buDVxySLRA6nQ6XK7mzBA0GA0IIXwgn3rjdbnbv3o1Go1GlNxVhUR4ycMEFF/Dpp58ycOBAiouLEyrE4BFBi8WCyWRKqmcKJNUrDUSr1WKz2ZK+qobRaMRiseBwOBIWRpJSotFocDi6lxWjOP3p1x7yggULmDhxIp988gklJSUUFxfzwAMP+DzGRG1PPvkkra2t6HS6hJ8r2vanP/2JpqampNuh0Wh4+eWXqampSbodmZmZvPDCCxw+fDhh5wHYuXNnkr8BilSj32dZuN1uLrroIlpaWvrsnBaLJalx40C8nrpXJJKJ1WpFr9cndYDRi81mQ6fTJdyWyspK6urSIkU2FpL/IUpz+r0gKxSKuKEEuZf065CFQqFQpBJKkBUKhSJFUIKsUCgUKcJpKcjXX389AwcOZMKECWHfl1Jy2223UVZWxqRJk/jss8/62EKFQqHozGknyFu2bGHbtm0Yjcawo9dHjx5l8uTJ/PGPfyQjI4PrrruOm266KQmWKhQKRTCnVZaFy+XirLPOYtu2bTidTp/3G1hy8MYbb+Tzzz/n5ptvZvLkySxcuBCj0cgHH3zAkCFDkmi9QpH2qCyLXnLaeMhbtmxhxIgRnDhxgpdeegmDwUBeXh6bNm3ytXnppZd4+eWX2b59O88++yzNzc0MHTqU0tJSqqurk2i9QqFQnCaC/Oabb7J48WIsFgvl5eWsX7+eQ4cOodfrfUJ76NAhVq5cSVNTEzqdjp07d7Jw4UKeeOKJJFuvUCgUHtI6ZLFlyxZuu+02Dh8+zLBhw/jNb37DzTffzPe//330ej2///3v0Wg0lJaW0tjY6KvolZuby//7f/+P4cOHs2LFClwulwpZKBS9R4UseknaecjeerIul4tbbrmFX//615SXl9Pc3Izb7aaoqIjq6mpqamrQaDTcfvvt7NmzB6vVisPhoKqqioaGBh555BHOPvtsmpqayMzMVGKsUCiSTvLLfHUDbyH1LVu2sGLFChobG/nLX/5CcXExRqORw4cP09TUxHvvvUdTUxMul4t7772X+vp6LBYLZrOZvLw8Lr/8cp577jmGDRtGbW1tUJxZoVAokkVaecjeIubLli1Dr9dTXl7Oe++95yssXlNTw7XXXktzczM6nY57772XdevWsXbtWnJzc5k/fz6jRo3ib3/7G0IIMjMzefPNN5k5c2afXcOjjz7K+PHjmTBhAldffTVWq7XPzh1KU1MTS5YsYezYsYwbN46PPvooabaA54Y7depULr300qTacezYMebOnUt5eTnjx4/n8ccfT6o9iv5DynvITqfTV6/X5XKxdOlScnNz+dnPfsYDDzzAyJEjOXr0KK2trbS0tDBo0CA0Gg1r167le9/7HvX19ZjNZux2O1u3bsXpdJKfn09mZiYfffRRl8uox5vq6mp++9vfcuDAATIyMli6dCkbNmzguuuu6zMbArn99ttZsGABGzduxG63Yzabk2KHl8cff5xx48b1aeW9cOh0Ov7nf/6HadOm0drayvTp0/nWt76V8is2K9KflPaQLRYLb7zxBuBZlbihoYHJkydz4YUX8vbbb9PW1kZTUxOnTp3i/PPP56233uLee+8lOzubb3zjG6xatYonn3wSvV7P7t27ufHGG9FqtWRnZ/P444/3qRh7cTqdWCwWnE4nZrOZoUOH9rkNAM3Nzfztb39jxYoVgGe1jPz8/KTYAlBVVcWbb77JDTfckDQbvAwZMoRp06YBkJOTw7hx41RapKJPSGlBBjh16hTLli1j1qxZtLe3M3LkSHbt2sXUqVMZMGCAr57v5s2bycjIYNWqVQwZMoSHH36YAQMGsG7dOgYPHszAgQN55JFHmDlzJhs2bGDZsmV9fi0lJSXceeednHHGGQwZMoS8vDwuvvjiPrcD4MiRIxQXF/ODH/yAqVOncsMNN9De3p4UWwB+8pOf8OCDDyZ9BZVQKisr2blzJ7Nnz062KYp+QGp9+jvwpuJlZGSwb98+3n33XZ544gmGDx/OqFGjaGxsZPbs2axZs4aamhqam5v5j//4D44ePYrNZkOv13PVVVexefNm2traOH78OBdddBGLFy/mgw8+YMaMGUm5rsbGRjZt2sSRI0c4fvw47e3t/OlPf0qKLU6nk88++4ybbrqJnTt3kpWVlfClqyKxefNmBg4cyPTp05Ny/ki0tbVxxRVX8Nhjj5Gbm5tscxT9gJSLIXtXQPYuvrlo0SKOHj1KW1sbAGPHjqW5uZktW7bw2WefkZOTw9atW5k8eTIAq1evZtCgQaxbt4533nmHDRs28Oqrr/LSSy8l87IAeOeddxgxYgTFxcUAXH755Xz44Ydcc801fW5LaWkppaWlPs9vyZIlSRPkf/7zn7z++uu89dZbWK1WWlpauOaaa5J2swJwOBxcccUVfO973+Pyyy9Pmh2KfoaUsqstKRw+fFjOnz9fPvzww/L999+XX3zxhRw+fLg8dOiQlFLKxx57TA4ZMkQWFBTIe++9V0op5d133y03bdokpZTSYrHIJUuWyFGjRsmZM2fKr776KlmXEsS//vUvWV5eLtvb26Xb7ZbXXnut/O1vf5s0e+bMmSO/+OILKaWUv/jFL+Sdd96ZNFu8vP/++/KSSy5Jqg1ut1suX75c3n777Um1Iw2Jpidqi7Kl3Ey9vXv38sMf/pAf//jHtLW18Ze//IUtW7bw4IMPcvDgQS6++GLsdnuQV+nNT04HfvGLX/Diiy+i0+mYOnUqf/jDH5K20vKuXbu44YYbsNvtjBw5kueee46CgoKk2OLlgw8+4OGHH2bz5s1Js+Ef//gH559/PhMnTvTFtH/961+zcOHCpNmUJqiZer0k5QT5o48+or29nYEDB/K9732PVatWceWVV3LixAnuu+8+tm7dyvr161Mu3qhQKJQg95aUE+S1a9eyatUqzjjjDB5++GHOO+88vv76a84880zAk/6WmZnpizErFIqUQX0he0lSsixOnjzJL3/5SwAaGhp49NFHef/99wG4+OKLmT59Or/5zW8477zzOHLkCDfffDO7du0CIDMzE7fbrcRYoVCcdvS5IEspaWho4Pjx47z00ktceumlbN++nXXr1vHKK68wcOBAJk6cyPr16/mv//ovFi1axKJFi5gyZYrf6BTLVU13brjhBjZv3syHH37IqlWrIrarqqrixRdf7EPLFIr+RZ8q21dffcWOHTsYN24cgwYN4rPPPuO2225j/fr1LFiwgN27d+NyuVixYgUXXnghdZ4eMJ8AAATvSURBVHV1PPHEE/zoRz8C/PnJiviyc+dOpkyZwrnnnsvq1asjtnv33XfV+oMKRQLpU0F2u928/PLLXHPNNfzzn/9k27ZtvnKao0aNoq6ujj179jBy5EiWLl3K008/zdy5c/0pISpMERcOHjzInDlzmDhxIvfddx81NTWUlpZy5ZVX8ve//x2AdevWMX36dCZNmsScOXP4xz/+wU9/+lM2btzIlClTOHz4MBs3buTss89m8uTJzJkzh9raWsCTX3333XdzwQUXcMYZZ/DOO+8AcPz4ca644gqmTp3K2LFj2b59O+CZNXjZZZcxY8YMZs2axZdffpmcP4xCkWyi5MXFlSNHjsiysjK5YMECKaWUjz/+uJw7d67v/V/+8pdy3rx58T6tIgCr1SrLy8vlxx9/LKWU8qabbvL9zceOHSubmppkS0uLHDdunLTZbFJKKRsbG6WUUs6fP1/u3bvX11ddXZ3v9T333CPXrFkjpZSyrKxMPvTQQ1JKKV999VV53XXXSYfDISdNmiTfeOMNKaWU7e3tsqWlRdrtdjlv3jxZUVEhpZTyzTfflNddd10i/wSKxJH0PN503/rUQzYYDCxatMiX63rbbbcxYsQInnnmGQBWrVqVtMpn/YXXXnvN54kCjB8/nsmTJ2O1WrHb7eTl5aHVarFYLPzsZz/jk08+8RUd+vLLLxk7dqyvrz/+8Y/MmjWLyZMn89RTT2EymTCbzTQ3N3PHHXcAnhlv+fn5vPbaa4wbN85XWjMzM5OcnBxee+019u/fzxVXXMGUKVP4+c9/jslk6uO/ikKRGvSpIA8dOpRHHnkEp9PpiwtfddVVHDp0iMrKSgCWL1/elyb1O/bu3RuUw/3pp58yZcoU9u/f7ysvmZmZyb59+zjvvPO48cYbeeqpp6irqyMvL89XCvX5559n+/btvPfee+zevZsxY8Ywfvx4Dhw4wPTp030Tdfbs2cOECRPYtWsXZ599did7du/ezX333ceuXbvYtWsX+/bt4+mnn+6Dv4RCkXr0qSDLjkG5Z555hoqKCt577z22bt1KfX09RUVFfWlKv6WwsJB9+/YBHjFev349kydPZu/evUyaNAnwLAiblZXFsmXLuPTSS7FarVRWVgaVCt27dy/nnnsu2dnZvPLKK3z44YdMnDiRvXv3BmXE7Nmzh0mTJjF48GD279/v2++NNw8ZMoS//vWvvrGEvXv3qsFbRb+lTwVZCIGUkry8PG699VbuuOMOjhw5wtNPP012dnZfmtJvWb58Obt27WLKlCk8+OCD5OfnU15eHiTI9913H2PGjGHatGm+PPCxY8dSV1fHhAkT+PDDD7nuuut46qmnmDVrFjt37mTkyJFkZWV1EuR9+/YxYcIErrvuOk6ePMn48eOZMmWKb3WS66+/Hrfbzbhx45gyZQoPPPCAGrxV9FuSOlMvcAZeOtWjUCgUYVF30l6SElOnlRgrFKcFSpB7SUoIskKhOC1QgtxL1BxkhUKhSBGUICsUCkWKoARZoVAoUgQlyAqFQpEiKEFWKBSKFEEJskKhUKQISpAVCoUiRVCCrFAoFCmCEmSFQqFIEZQgKxQKRYqgBFmhUChSBCXICoVCkSLooryvioUoFApFH6E8ZIVCoUgRlCArFApFiqAEWaFQKFIEJcgKhUKRIihBVigUihRBCbJCoVCkCP8fHnBNfMwe88UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=cm.rainbow,\n",
    "                       linewidth=0, antialiased=False)\n",
    "ax.set_xlabel('$theta$')\n",
    "ax.set_ylabel('$distance$')\n",
    "ax.set_zlabel('$loss$')\n",
    "# Customize the z axis.\n",
    "# ax.set_xlim(0.051, 0.054)\n",
    "# ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "# ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "ax.view_init(0, 180)\n",
    "# ax.view_init(0, 0)\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "plt.savefig('fig1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22029afd0>]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([2, 1, 3, 4], [1, 4, 9, 16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How much are they similar to each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_distance(model1, model2):\n",
    "    w = zip(model1.get_weights(), model2.get_weights())\n",
    "    lw = list(w)\n",
    "    sums = 0\n",
    "    i = 0\n",
    "    for ww in lw:\n",
    "        i += 1\n",
    "        sums += np.average(np.absolute(ww[0] - ww[1]))\n",
    "    return sums / i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05077916461353501"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_distance(model1, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_max = 0\n",
    "i = 0\n",
    "for ww in lw:\n",
    "    i += 1\n",
    "    cur_max = max(np.max(np.absolute(ww[0] - ww[1])), cur_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13698825"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pi_list = list(np.arange(0, 1.05, 0.05)) # P for perturbations\n",
    "\n",
    "weights = [model1.get_weights(), model2.get_weights()]\n",
    "model_weights_list = list()\n",
    "for pi in pi_list:\n",
    "    agg_weights = list()\n",
    "    for weights_list_tuple in zip(*weights):\n",
    "        agg_weights.append(np.array([np.average(np.array(w), axis=0, weights=[1. - pi, pi]) for w in zip(*weights_list_tuple)]))\n",
    "    model_weights_list.append(agg_weights)\n",
    "    \n",
    "model_list2 = list()\n",
    "for _ in range(len(pi_list)):\n",
    "    model_list2.append(tf.keras.models.clone_model(model1))\n",
    "    \n",
    "for i in range(len(model_list)):\n",
    "    model_list2[i].set_weights(model_weights_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([average_distance(model1, m) for m in model_list2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### backup results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## @TODO Experiment with pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model1 = tf.keras.models.clone_model(model1)\n",
    "pretrained_model2 = tf.keras.models.clone_model(model1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "personalized.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
