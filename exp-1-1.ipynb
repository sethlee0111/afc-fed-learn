{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d6n47ueeqbXb"
   },
   "source": [
    "## Personalized Learning (Localized Learning?)\n",
    "\n",
    "#### This notebook includes the following online models;\n",
    "1. A single global model with all data\n",
    "2. Multiple local models (starting from a single global model)\n",
    "   1. that are updated with new data\n",
    "   2. that exchanges data in clusters\n",
    "   3. that exchanges parameters in clusters\n",
    "\n",
    "  \n",
    "#### The dataset that is used for this project is [CIFAR-100 dataset][1]\n",
    "* Has 100 classes containing 600 images each\n",
    "\n",
    "#### New data are fed by the following rules;\n",
    "1. Distributed, according to superclasses\n",
    "  * Clusters will only be updated with data that belongs to a specific superclass\n",
    "  * We update the NN by\n",
    "    1. Changing all parameters of the NN\n",
    "    2. Only changing the last few layers, as in many MTL models\n",
    "2. Randomly (why?)\n",
    "\n",
    "#### We expect to find an answer to the following research questions with this project;\n",
    "1. If models are updated with data (or parameters) that are shared within a cluster, can the model perform good enough with the labels that count?\n",
    "  * For example, the performance of the cluster that are updated with \"Vehicles\" superclass is only assessed with the labels that corresponds to the superclass.\n",
    "  \n",
    "[1]: https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oji0BTfoqbXc"
   },
   "source": [
    "#### Questions\n",
    "\n",
    "Retraining: how does it work <br>\n",
    "How do we compare these models?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mr4-uY0LqbXd"
   },
   "source": [
    "### Implementation with Custom Neural Network and EMNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tGoXLnOyqbXe",
    "outputId": "9ccd7215-80bf-4a0a-b852-8896b17c38f1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.lines as mlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E2faBs1yqbXj"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 50\n",
    "epochs = 20\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QXfylSWLqbXl"
   },
   "source": [
    "#### Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test_orig) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_dataset_size = 6000\n",
    "local_dataset_size = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/seth/projects/fed-learn-experiment/utils.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_a, y_train_a = utils.filter_data_by_labels(x_train, y_train, np.arange(2), TRAIN_DATA_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_b, y_train_b = utils.filter_data_by_labels(x_train, y_train, np.arange(2)+8, TRAIN_DATA_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_a, y_test_a = utils.filter_data_by_labels(x_test, y_test_orig, np.arange(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_b, y_test_b = utils.filter_data_by_labels(x_test, y_test_orig, np.arange(2)+8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "num_classes = 10\n",
    "y_train_a = keras.utils.to_categorical(y_train_a, num_classes)\n",
    "y_train_b = keras.utils.to_categorical(y_train_b, num_classes)\n",
    "y_test_a = keras.utils.to_categorical(y_test_a, num_classes)\n",
    "y_test_b = keras.utils.to_categorical(y_test_b, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = keras.utils.to_categorical(y_test_orig, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models and compile & fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_model():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=input_shape))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):  \n",
    "    # initiate SGD optimizer\n",
    "    opt = keras.optimizers.SGD(lr=0.1)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model_lr(model):  \n",
    "    # initiate SGD optimizer\n",
    "    opt = keras.optimizers.SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_global(model, epochs):\n",
    "    now = datetime.datetime.now()\n",
    "    print (\"Training date and time : \")\n",
    "    print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    return model.fit(X_global, Y_global,\n",
    "                      batch_size=100,\n",
    "                      epochs=40,\n",
    "                      shuffle=True, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_with_datasets(model, epochs, x_train, y_train):\n",
    "    now = datetime.datetime.now()\n",
    "    print (\"Training date and time : \")\n",
    "    print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    return model.fit(x_train, y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hist_to_dict(d, hist):\n",
    "    if 'loss' not in d:\n",
    "        d['loss'] = hist[0]\n",
    "    else:\n",
    "        d['loss'] = np.append(d['loss'], hist[0])\n",
    "    if 'acc' not in d:\n",
    "        d['acc'] = hist[1]\n",
    "    else:\n",
    "        d['acc'] = np.append(d['acc'], hist[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx, ty = utils.filter_data_by_labels(x_test, y_test_orig, np.arange(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5139"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx, ty = utils.filter_data_by_labels(x_test, y_test_orig, np.arange(5)+5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4861"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = utils.filter_data_by_labels(x_train, y_train, np.arange(5)+5, 20, 1, 1011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 9, 6, 4, 3, 3, 1, 0, 6, 7, 9, 9, 0, 4, 2, 3, 1, 5, 7, 5],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training date and time : \n",
      "2020-09-07 16:53:55\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 1s 993us/sample - loss: 0.0905 - acc: 0.1050\n",
      "[0.09012510870695115, 0.1105]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:01\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0901 - acc: 0.1150\n",
      "[0.08976169431209564, 0.1171]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:02\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0897 - acc: 0.1167\n",
      "[0.08942312107086181, 0.1279]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:03\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 80us/sample - loss: 0.0893 - acc: 0.1317\n",
      "[0.08909897447824477, 0.1415]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:03\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0889 - acc: 0.1483\n",
      "[0.0887814815878868, 0.1565]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:04\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0886 - acc: 0.1667\n",
      "[0.08846602684259415, 0.1769]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:05\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0882 - acc: 0.1833\n",
      "[0.08815062389373779, 0.1957]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:06\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 75us/sample - loss: 0.0878 - acc: 0.2117\n",
      "[0.08783095638751984, 0.2191]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:06\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 77us/sample - loss: 0.0875 - acc: 0.2400\n",
      "[0.08750529798269271, 0.2423]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:07\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0871 - acc: 0.2633\n",
      "[0.08717058262825013, 0.2694]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:08\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0867 - acc: 0.2933\n",
      "[0.08682651505470276, 0.2902]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:08\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 81us/sample - loss: 0.0863 - acc: 0.3150\n",
      "[0.08646891453266144, 0.3128]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:09\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0859 - acc: 0.3533\n",
      "[0.08609695200920105, 0.3327]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:10\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0855 - acc: 0.3683\n",
      "[0.08570995762348176, 0.35]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:10\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 77us/sample - loss: 0.0850 - acc: 0.3767\n",
      "[0.08530386133193969, 0.3665]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:11\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0846 - acc: 0.4033\n",
      "[0.08487901270389557, 0.3813]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:12\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0841 - acc: 0.4217\n",
      "[0.08443259174823761, 0.3935]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:13\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 75us/sample - loss: 0.0836 - acc: 0.4283\n",
      "[0.08396254856586456, 0.4046]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:13\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0830 - acc: 0.4433\n",
      "[0.0834663524389267, 0.4132]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:14\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 84us/sample - loss: 0.0824 - acc: 0.4500\n",
      "[0.08294256123304367, 0.4205]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:15\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0818 - acc: 0.4583\n",
      "[0.08239055256843567, 0.4275]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:15\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0812 - acc: 0.4683\n",
      "[0.08180719668865204, 0.4338]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:16\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0805 - acc: 0.4817\n",
      "[0.08119253306388854, 0.4389]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:17\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0798 - acc: 0.4817\n",
      "[0.08054189978837967, 0.4448]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:17\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.0791 - acc: 0.4883\n",
      "[0.07985562417507172, 0.4518]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:18\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0783 - acc: 0.4967\n",
      "[0.0791324354171753, 0.4611]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:19\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0774 - acc: 0.5117\n",
      "[0.07837455075979233, 0.4688]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:20\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0766 - acc: 0.5267\n",
      "[0.07758271932601929, 0.4789]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:20\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0757 - acc: 0.5350\n",
      "[0.07675531442165374, 0.4909]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:21\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.0747 - acc: 0.5350\n",
      "[0.0758988495349884, 0.5046]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:22\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0737 - acc: 0.5600\n",
      "[0.07501266498565674, 0.5151]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:22\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0727 - acc: 0.5650\n",
      "[0.07409552683830262, 0.5269]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:23\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0717 - acc: 0.5700\n",
      "[0.07315473361015319, 0.5398]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:24\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0707 - acc: 0.5750\n",
      "[0.0721864408493042, 0.548]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:24\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0696 - acc: 0.5900\n",
      "[0.07120132415294647, 0.5556]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:25\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0685 - acc: 0.5950\n",
      "[0.07019983967542648, 0.5619]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:26\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0674 - acc: 0.6017\n",
      "[0.06918722028732299, 0.5668]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:26\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0663 - acc: 0.6150\n",
      "[0.06817016800642013, 0.5706]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:27\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0651 - acc: 0.6167\n",
      "[0.06714320675134659, 0.5781]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:28\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0640 - acc: 0.6200\n",
      "[0.06612646207809449, 0.5834]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:29\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0629 - acc: 0.6233\n",
      "[0.06510340129733086, 0.5902]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:29\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0618 - acc: 0.6250\n",
      "[0.06409057677388191, 0.5937]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:30\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0607 - acc: 0.6267\n",
      "[0.06307980754375457, 0.5994]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:31\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0597 - acc: 0.6350\n",
      "[0.06208578138351441, 0.605]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:31\n",
      "Train on 600 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0586 - acc: 0.6417\n",
      "[0.06109259978532791, 0.6095]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:32\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0576 - acc: 0.6433\n",
      "[0.0601152607858181, 0.6143]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:33\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0566 - acc: 0.6517\n",
      "[0.05917518214583397, 0.6174]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:33\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.0556 - acc: 0.6633\n",
      "[0.058237419962882994, 0.622]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:34\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0546 - acc: 0.6600\n",
      "[0.05730512084960938, 0.6276]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:35\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0536 - acc: 0.6783\n",
      "[0.056425149977207184, 0.6315]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:35\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0527 - acc: 0.6783\n",
      "[0.05556362421512604, 0.6348]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:36\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0518 - acc: 0.6867\n",
      "[0.054713903319835666, 0.6398]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:37\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0509 - acc: 0.6917\n",
      "[0.053905264711380005, 0.6433]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:37\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.0500 - acc: 0.6950\n",
      "[0.053086793273687365, 0.6482]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:38\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0491 - acc: 0.7033\n",
      "[0.05231794903278351, 0.6528]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:39\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0483 - acc: 0.7050\n",
      "[0.05155316442847252, 0.66]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:39\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0474 - acc: 0.7100\n",
      "[0.05082198205590248, 0.6649]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:40\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0467 - acc: 0.7183\n",
      "[0.0500915013551712, 0.67]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:41\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0459 - acc: 0.7250\n",
      "[0.049380622977018354, 0.6755]\n",
      "Training date and time : \n",
      "2020-09-07 16:54:41\n",
      "Train on 600 samples\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.0451 - acc: 0.7367\n",
      "[0.048729597699642184, 0.6785]\n"
     ]
    }
   ],
   "source": [
    "x04, y04 = utils.filter_data_by_labels(x_train, y_train, np.arange(5)+5, 600, 1, 1000)\n",
    "y_test_one_hot = keras.utils.to_categorical(y_test_orig, 10)\n",
    "y04 = keras.utils.to_categorical(y04, 10)\n",
    "test_model = custom_model()\n",
    "compile_model(test_model)\n",
    "for e in range(60):\n",
    "    fit_model_with_datasets(test_model, 1, x04, y04)\n",
    "    res = test_model.evaluate(x=x_test, y=y_test_one_hot, verbose=0)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_losses_for_non_iid_spectrum(model, epochs, x_train, y_train, x_test, y_test, size, diff):\n",
    "    num_total_classes = 10 # todo np.unique(y_train)\n",
    "    \n",
    "    res = {}\n",
    "    res['model_aggr'] = {}\n",
    "    res['model_0to4'] = {}\n",
    "    res['model_5to9'] = {}\n",
    "    res['model_aggr']['test_all'] = {}\n",
    "    res['model_aggr']['test_0to4'] = {}\n",
    "    res['model_aggr']['test_5to9'] = {}\n",
    "    \n",
    "    res['model_0to4'] = copy.deepcopy(res['model_aggr'])\n",
    "    res['model_5to9'] = copy.deepcopy(res['model_aggr'])\n",
    "    \n",
    "    y_test_one_hot = keras.utils.to_categorical(y_test, num_total_classes)\n",
    "    tx1, ty1 = utils.filter_data_by_labels(x_test, y_test, np.arange(5), 1000)\n",
    "    tx2, ty2 = utils.filter_data_by_labels(x_test, y_test, np.arange(5)+5, 1000)\n",
    "    ty1 = keras.utils.to_categorical(ty1, num_total_classes)\n",
    "    ty2 = keras.utils.to_categorical(ty2, num_total_classes)\n",
    "    \n",
    "    for r in np.arange(1, 0-diff, -diff):\n",
    "        # get data\n",
    "        randseed = (int)(r * 1000) + 2\n",
    "        x1, y1 = utils.filter_data_by_labels(x_train, y_train, np.arange(5), size, r, randseed)\n",
    "        x2, y2 = utils.filter_data_by_labels(x_train, y_train, np.arange(5)+5, size, r, randseed+1000)\n",
    "\n",
    "        y1 = keras.utils.to_categorical(y1, num_total_classes)\n",
    "        y2 = keras.utils.to_categorical(y2, num_total_classes)\n",
    "        \n",
    "        # initialize models\n",
    "        model1 = keras.models.clone_model(model)\n",
    "        model2 = keras.models.clone_model(model)\n",
    "        model1.set_weights(model.get_weights())\n",
    "        model2.set_weights(model.get_weights())\n",
    "        compile_model(model1)\n",
    "        compile_model(model2)\n",
    "        \n",
    "        # fit\n",
    "        fit_model_with_datasets(model1, epochs, x1, y1)\n",
    "        fit_model_with_datasets(model2, epochs, x2, y2)\n",
    "        \n",
    "        #aggregate\n",
    "        weights = [model1.get_weights(), model2.get_weights()]\n",
    "        agg_weights = list()\n",
    "        theta = 0.5\n",
    "        for weights_list_tuple in zip(*weights):\n",
    "            agg_weights.append(np.array([np.average(np.array(w), axis=0, weights=[1. - theta, theta]) for w in zip(*weights_list_tuple)]))\n",
    "        aggr_model = keras.models.clone_model(model1)\n",
    "        aggr_model.set_weights(agg_weights)\n",
    "        compile_model(aggr_model)\n",
    "        \n",
    "        # test\n",
    "        add_hist_to_dict(res['model_0to4']['test_all'],\n",
    "                         model1.evaluate(x=x_test, y=y_test_one_hot, verbose=0))\n",
    "        add_hist_to_dict(res['model_0to4']['test_0to4'],\n",
    "                         model1.evaluate(x=tx1, y=ty1, verbose=0))\n",
    "        add_hist_to_dict(res['model_0to4']['test_5to9'],\n",
    "                         model1.evaluate(x=tx2, y=ty2, verbose=0))\n",
    "        \n",
    "        add_hist_to_dict(res['model_5to9']['test_all'],\n",
    "                         model2.evaluate(x=x_test, y=y_test_one_hot, verbose=0))\n",
    "        add_hist_to_dict(res['model_5to9']['test_0to4'],\n",
    "                         model2.evaluate(x=tx1, y=ty1, verbose=0))\n",
    "        add_hist_to_dict(res['model_5to9']['test_5to9'],\n",
    "                         model2.evaluate(x=tx2, y=ty2, verbose=0))\n",
    "        \n",
    "        add_hist_to_dict(res['model_aggr']['test_all'],\n",
    "                         aggr_model.evaluate(x=x_test, y=y_test_one_hot, verbose=0))\n",
    "        add_hist_to_dict(res['model_aggr']['test_0to4'],\n",
    "                         aggr_model.evaluate(x=tx1, y=ty1, verbose=0))\n",
    "        add_hist_to_dict(res['model_aggr']['test_5to9'],\n",
    "                         aggr_model.evaluate(x=tx2, y=ty2, verbose=0))\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_experiments(func, num, params):\n",
    "    shape = (len(np.arange(1, 0-params['diff'], -params['diff'])), 2)\n",
    "    res_sum = {}\n",
    "    for n in range(num):\n",
    "        print(\"------------- {}th experiment -------------\".format(n))\n",
    "        res = func(**params)\n",
    "        \n",
    "        for k in res: # for(models)\n",
    "            if k not in res_sum:\n",
    "                res_sum[k] = copy.deepcopy(res[k])\n",
    "            else:\n",
    "                for l in res_sum[k]: # for(test sets)\n",
    "                    for i in res_sum[k][l]: # for(metric)\n",
    "                        res_sum[k][l][i] += res[k][l][i]\n",
    "                    \n",
    "    for k in res_sum:\n",
    "        for l in res_sum[k]:\n",
    "            for i in res_sum[k][l]:\n",
    "                res_sum[k][l][i] /= num\n",
    "    \n",
    "    return res_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_model = custom_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'model': init_model,\n",
    "          'epochs': 20,\n",
    "          'x_train': x_train,\n",
    "          'y_train': y_train,\n",
    "          'x_test': x_test,\n",
    "          'y_test': y_test_orig,\n",
    "          'size': 600,\n",
    "          'diff': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mock_res(diff):\n",
    "    mock_res = {}\n",
    "    mock_res['model_aggr'] = {}\n",
    "    mock_res['model_0to4'] = {}\n",
    "    mock_res['model_5to9'] = {}\n",
    "    mock_res['model_aggr']['test_all'] = {'loss': np.array([1,1]), 'acc': np.array([3,3])}\n",
    "    mock_res['model_0to4']['test_all'] = {'loss': np.array([1,1]), 'acc': np.array([3,3])}\n",
    "    mock_res['model_5to9']['test_all'] = {'loss': np.array([1,1]), 'acc': np.array([3,3])}\n",
    "    mock_res['model_aggr']['test_0to4'] = {'loss': np.array([1,1]), 'acc': np.array([3,3])}\n",
    "    mock_res['model_0to4']['test_0to4'] = {'loss': np.array([1,1]), 'acc': np.array([3,3])}\n",
    "    mock_res['model_5to9']['test_0to4'] = {'loss': np.array([1,1]), 'acc': np.array([3,3])}\n",
    "    mock_res['model_aggr']['test_5to9'] = {'loss': np.array([1,1]), 'acc': np.array([3,3])}\n",
    "    mock_res['model_0to4']['test_5to9'] = {'loss': np.array([1,1]), 'acc': np.array([3,3])}\n",
    "    mock_res['model_5to9']['test_5to9'] = {'loss': np.array([1,1]), 'acc': np.array([3,3])}\n",
    "    \n",
    "    return mock_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- 0th experiment -------------\n",
      "------------- 1th experiment -------------\n",
      "------------- 2th experiment -------------\n",
      "------------- 3th experiment -------------\n",
      "------------- 4th experiment -------------\n",
      "------------- 5th experiment -------------\n",
      "------------- 6th experiment -------------\n",
      "------------- 7th experiment -------------\n",
      "------------- 8th experiment -------------\n",
      "------------- 9th experiment -------------\n"
     ]
    }
   ],
   "source": [
    "mock_res = multiple_experiments(get_mock_res, 10, {'diff': 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_aggr': {'test_all': {'loss': array([1., 1.]), 'acc': array([3., 3.])},\n",
       "  'test_0to4': {'loss': array([1., 1.]), 'acc': array([3., 3.])},\n",
       "  'test_5to9': {'loss': array([1., 1.]), 'acc': array([3., 3.])}},\n",
       " 'model_0to4': {'test_all': {'loss': array([1., 1.]), 'acc': array([3., 3.])},\n",
       "  'test_0to4': {'loss': array([1., 1.]), 'acc': array([3., 3.])},\n",
       "  'test_5to9': {'loss': array([1., 1.]), 'acc': array([3., 3.])}},\n",
       " 'model_5to9': {'test_all': {'loss': array([1., 1.]), 'acc': array([3., 3.])},\n",
       "  'test_0to4': {'loss': array([1., 1.]), 'acc': array([3., 3.])},\n",
       "  'test_5to9': {'loss': array([1., 1.]), 'acc': array([3., 3.])}}}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mock_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training date and time : \n",
      "2020-09-07 18:01:28\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0905 - acc: 0.1200\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 115us/sample - loss: 0.0899 - acc: 0.1333\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0894 - acc: 0.1450\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0890 - acc: 0.1467\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0885 - acc: 0.1567\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0881 - acc: 0.1850\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0877 - acc: 0.2133\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0872 - acc: 0.2333\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0868 - acc: 0.2533\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 84us/sample - loss: 0.0863 - acc: 0.2817\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0859 - acc: 0.3250\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0854 - acc: 0.3533\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0849 - acc: 0.3800\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0843 - acc: 0.4133\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0838 - acc: 0.4350\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0832 - acc: 0.4467\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0825 - acc: 0.4650\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0819 - acc: 0.4700\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0812 - acc: 0.4933\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0805 - acc: 0.5150\n",
      "Training date and time : \n",
      "2020-09-07 18:01:36\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0909 - acc: 0.1033\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0903 - acc: 0.1167\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0897 - acc: 0.1250\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0891 - acc: 0.1367\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 117us/sample - loss: 0.0886 - acc: 0.1667\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0881 - acc: 0.1867\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 84us/sample - loss: 0.0876 - acc: 0.2217\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0870 - acc: 0.2667\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0865 - acc: 0.2983\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0859 - acc: 0.3367\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0853 - acc: 0.3683\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0847 - acc: 0.4017\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0840 - acc: 0.4167\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0834 - acc: 0.4350\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0827 - acc: 0.4450\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0819 - acc: 0.4533\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0812 - acc: 0.4533\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0804 - acc: 0.4800\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0797 - acc: 0.4850\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0789 - acc: 0.5000\n",
      "Training date and time : \n",
      "2020-09-07 18:02:18\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0903 - acc: 0.1217\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 130us/sample - loss: 0.0896 - acc: 0.1333\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0889 - acc: 0.1450\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0883 - acc: 0.1667\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0877 - acc: 0.2000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0871 - acc: 0.2383\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0865 - acc: 0.2800\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0858 - acc: 0.3100\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0851 - acc: 0.3383\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 118us/sample - loss: 0.0844 - acc: 0.3700\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0836 - acc: 0.3983\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0828 - acc: 0.4133\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0819 - acc: 0.4333\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0811 - acc: 0.4483\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0802 - acc: 0.4650\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 85us/sample - loss: 0.0794 - acc: 0.4783\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0785 - acc: 0.4850\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0776 - acc: 0.5000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0767 - acc: 0.5117\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0758 - acc: 0.5183\n",
      "Training date and time : \n",
      "2020-09-07 18:02:26\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0909 - acc: 0.1150\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0903 - acc: 0.1183\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0898 - acc: 0.1300\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0893 - acc: 0.1367\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 85us/sample - loss: 0.0889 - acc: 0.1450\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 83us/sample - loss: 0.0884 - acc: 0.1583\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 75us/sample - loss: 0.0880 - acc: 0.1667\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0876 - acc: 0.1833\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0871 - acc: 0.2067\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0867 - acc: 0.2183\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 81us/sample - loss: 0.0863 - acc: 0.2600\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0858 - acc: 0.3000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0853 - acc: 0.3383\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0849 - acc: 0.3633\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 83us/sample - loss: 0.0844 - acc: 0.3867\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0839 - acc: 0.4133\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 115us/sample - loss: 0.0833 - acc: 0.4450\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0828 - acc: 0.4950\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0822 - acc: 0.5183\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0816 - acc: 0.5450\n",
      "Training date and time : \n",
      "2020-09-07 18:03:08\n",
      "Train on 600 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0899 - acc: 0.1383\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0893 - acc: 0.1483\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 85us/sample - loss: 0.0886 - acc: 0.1717\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 84us/sample - loss: 0.0880 - acc: 0.1750\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 85us/sample - loss: 0.0874 - acc: 0.1983\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 83us/sample - loss: 0.0867 - acc: 0.2367\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0860 - acc: 0.2767\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0853 - acc: 0.3267\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0845 - acc: 0.3683\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0836 - acc: 0.4033\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0827 - acc: 0.4117\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0818 - acc: 0.4233\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 77us/sample - loss: 0.0809 - acc: 0.4350\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0800 - acc: 0.4450\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 80us/sample - loss: 0.0790 - acc: 0.4617\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0781 - acc: 0.4700\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 84us/sample - loss: 0.0771 - acc: 0.4833\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 83us/sample - loss: 0.0762 - acc: 0.4950\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0752 - acc: 0.5117\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0742 - acc: 0.5317\n",
      "Training date and time : \n",
      "2020-09-07 18:03:16\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0914 - acc: 0.0917\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0906 - acc: 0.0933\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0899 - acc: 0.1067\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0893 - acc: 0.1300\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0887 - acc: 0.1600\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0882 - acc: 0.1967\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0876 - acc: 0.2217\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0871 - acc: 0.2433\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 80us/sample - loss: 0.0866 - acc: 0.2750\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 81us/sample - loss: 0.0861 - acc: 0.3083\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0856 - acc: 0.3150\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 75us/sample - loss: 0.0851 - acc: 0.3483\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0846 - acc: 0.3767\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0841 - acc: 0.3850\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0835 - acc: 0.3917\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0830 - acc: 0.4033\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 75us/sample - loss: 0.0824 - acc: 0.4183\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 81us/sample - loss: 0.0817 - acc: 0.4267\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 81us/sample - loss: 0.0811 - acc: 0.4483\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0804 - acc: 0.4700\n",
      "Training date and time : \n",
      "2020-09-07 18:03:57\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0904 - acc: 0.1117\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 84us/sample - loss: 0.0895 - acc: 0.1150\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 83us/sample - loss: 0.0888 - acc: 0.1467\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0881 - acc: 0.1600\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 81us/sample - loss: 0.0873 - acc: 0.1917\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0865 - acc: 0.2400\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0857 - acc: 0.2950\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 83us/sample - loss: 0.0848 - acc: 0.3583\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0839 - acc: 0.4117\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 75us/sample - loss: 0.0829 - acc: 0.4583\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 79us/sample - loss: 0.0818 - acc: 0.4683\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0808 - acc: 0.4717\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0797 - acc: 0.4933\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 80us/sample - loss: 0.0785 - acc: 0.5017\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0774 - acc: 0.5150\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 85us/sample - loss: 0.0762 - acc: 0.5267\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 85us/sample - loss: 0.0750 - acc: 0.5367\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0738 - acc: 0.5517\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0726 - acc: 0.5650\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 81us/sample - loss: 0.0713 - acc: 0.5683\n",
      "Training date and time : \n",
      "2020-09-07 18:04:05\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0912 - acc: 0.0950\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0903 - acc: 0.1067\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0896 - acc: 0.1317\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0890 - acc: 0.1750\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0884 - acc: 0.2017\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0878 - acc: 0.2317\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0873 - acc: 0.2467\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 84us/sample - loss: 0.0867 - acc: 0.2517\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0862 - acc: 0.2683\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0856 - acc: 0.2883\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0851 - acc: 0.2917\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0845 - acc: 0.3117\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 75us/sample - loss: 0.0839 - acc: 0.3167\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 81us/sample - loss: 0.0833 - acc: 0.3317\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0827 - acc: 0.3400\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0821 - acc: 0.3667\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 75us/sample - loss: 0.0814 - acc: 0.3867\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0806 - acc: 0.4183\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0799 - acc: 0.4333\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0791 - acc: 0.4500\n",
      "Training date and time : \n",
      "2020-09-07 18:04:46\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0887 - acc: 0.1633\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0880 - acc: 0.1733\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 81us/sample - loss: 0.0874 - acc: 0.1833\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0867 - acc: 0.2083\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0860 - acc: 0.2317\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 75us/sample - loss: 0.0853 - acc: 0.2567\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0845 - acc: 0.2867\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0837 - acc: 0.3167\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0829 - acc: 0.3467\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 81us/sample - loss: 0.0819 - acc: 0.3783\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0809 - acc: 0.4267\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0799 - acc: 0.4750\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 84us/sample - loss: 0.0788 - acc: 0.5150\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0776 - acc: 0.5283\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 77us/sample - loss: 0.0764 - acc: 0.5450\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 85us/sample - loss: 0.0751 - acc: 0.5667\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 79us/sample - loss: 0.0738 - acc: 0.5750\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 81us/sample - loss: 0.0724 - acc: 0.5817\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0710 - acc: 0.6017\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 77us/sample - loss: 0.0695 - acc: 0.6050\n",
      "Training date and time : \n",
      "2020-09-07 18:04:54\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0924 - acc: 0.0550\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 83us/sample - loss: 0.0913 - acc: 0.0600\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0904 - acc: 0.0917\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0896 - acc: 0.1317\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 81us/sample - loss: 0.0889 - acc: 0.1617\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 79us/sample - loss: 0.0882 - acc: 0.2033\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0875 - acc: 0.2250\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0869 - acc: 0.2433\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0862 - acc: 0.2750\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0854 - acc: 0.3000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0847 - acc: 0.3367\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 79us/sample - loss: 0.0839 - acc: 0.3483\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0831 - acc: 0.3633\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0823 - acc: 0.3800\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 83us/sample - loss: 0.0814 - acc: 0.3917\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0804 - acc: 0.4033\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0795 - acc: 0.4050\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 79us/sample - loss: 0.0785 - acc: 0.4133\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0774 - acc: 0.4233\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 79us/sample - loss: 0.0764 - acc: 0.4333\n",
      "Training date and time : \n",
      "2020-09-07 18:05:36\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0892 - acc: 0.1867\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0882 - acc: 0.1967\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0873 - acc: 0.2067\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 80us/sample - loss: 0.0862 - acc: 0.2300\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0850 - acc: 0.2767\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0836 - acc: 0.3617\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0821 - acc: 0.4133\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0804 - acc: 0.4483\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0787 - acc: 0.4483\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0770 - acc: 0.4567\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0754 - acc: 0.4733\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0739 - acc: 0.4933\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0724 - acc: 0.5150\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0710 - acc: 0.5467\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 84us/sample - loss: 0.0695 - acc: 0.5683\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 79us/sample - loss: 0.0681 - acc: 0.5833\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0667 - acc: 0.6033\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0653 - acc: 0.6183\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0639 - acc: 0.6383\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0625 - acc: 0.6600\n",
      "Training date and time : \n",
      "2020-09-07 18:05:44\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0925 - acc: 0.0433\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0912 - acc: 0.0667\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0901 - acc: 0.1067\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0892 - acc: 0.1583\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0883 - acc: 0.2033\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0875 - acc: 0.2333\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 85us/sample - loss: 0.0866 - acc: 0.2650\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0858 - acc: 0.2900\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0850 - acc: 0.3133\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 85us/sample - loss: 0.0842 - acc: 0.3233\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0834 - acc: 0.3383\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0825 - acc: 0.3433\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0817 - acc: 0.3617\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0808 - acc: 0.3767\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0798 - acc: 0.4000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0789 - acc: 0.4233\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0779 - acc: 0.4517\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0768 - acc: 0.4783\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0758 - acc: 0.5017\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 83us/sample - loss: 0.0746 - acc: 0.5350\n",
      "Training date and time : \n",
      "2020-09-07 18:06:26\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0881 - acc: 0.1883\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0870 - acc: 0.2167\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 80us/sample - loss: 0.0860 - acc: 0.2417\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0848 - acc: 0.2767\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0836 - acc: 0.3017\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0823 - acc: 0.3400\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 80us/sample - loss: 0.0809 - acc: 0.3950\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 81us/sample - loss: 0.0794 - acc: 0.4733\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 80us/sample - loss: 0.0777 - acc: 0.5300\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0759 - acc: 0.5767\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0740 - acc: 0.6133\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 77us/sample - loss: 0.0719 - acc: 0.6450\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0696 - acc: 0.6767\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 79us/sample - loss: 0.0672 - acc: 0.6917\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 77us/sample - loss: 0.0648 - acc: 0.7067\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 83us/sample - loss: 0.0623 - acc: 0.7150\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0598 - acc: 0.7217\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0574 - acc: 0.7383\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0550 - acc: 0.7433\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 84us/sample - loss: 0.0528 - acc: 0.7467\n",
      "Training date and time : \n",
      "2020-09-07 18:06:34\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0928 - acc: 0.0450\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 81us/sample - loss: 0.0914 - acc: 0.0633\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0902 - acc: 0.1067\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0891 - acc: 0.1750\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0881 - acc: 0.2217\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0872 - acc: 0.2483\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0862 - acc: 0.2683\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0853 - acc: 0.2850\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0844 - acc: 0.3000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0835 - acc: 0.3083\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0825 - acc: 0.3350\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 83us/sample - loss: 0.0815 - acc: 0.3517\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0805 - acc: 0.3867\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 85us/sample - loss: 0.0794 - acc: 0.4233\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0782 - acc: 0.4517\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 81us/sample - loss: 0.0769 - acc: 0.4850\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0756 - acc: 0.5167\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 85us/sample - loss: 0.0742 - acc: 0.5333\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0727 - acc: 0.5683\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0712 - acc: 0.5717\n",
      "Training date and time : \n",
      "2020-09-07 18:07:16\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0875 - acc: 0.2200\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0863 - acc: 0.2467\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0851 - acc: 0.2817\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0837 - acc: 0.3133\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0823 - acc: 0.3533\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0806 - acc: 0.3933\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0788 - acc: 0.4500\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 77us/sample - loss: 0.0768 - acc: 0.5150\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0746 - acc: 0.5450\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0722 - acc: 0.5750\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0698 - acc: 0.5933\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0673 - acc: 0.6150\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0649 - acc: 0.6217\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0625 - acc: 0.6350\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0602 - acc: 0.6350\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0579 - acc: 0.6550\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0559 - acc: 0.6667\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0539 - acc: 0.6867\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0520 - acc: 0.7000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0502 - acc: 0.7083\n",
      "Training date and time : \n",
      "2020-09-07 18:07:25\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0923 - acc: 0.0467\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0910 - acc: 0.0617\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0898 - acc: 0.1250\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0887 - acc: 0.1767\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0877 - acc: 0.2200\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0868 - acc: 0.2533\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0858 - acc: 0.2733\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0849 - acc: 0.2800\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0839 - acc: 0.2933\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0829 - acc: 0.3017\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 119us/sample - loss: 0.0819 - acc: 0.3150\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 122us/sample - loss: 0.0809 - acc: 0.3383\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0798 - acc: 0.3583\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0787 - acc: 0.3933\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0775 - acc: 0.4367\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0762 - acc: 0.4617\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0748 - acc: 0.4967\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0733 - acc: 0.5217\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0717 - acc: 0.5383\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0701 - acc: 0.5667\n",
      "Training date and time : \n",
      "2020-09-07 18:08:07\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0876 - acc: 0.1983\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0863 - acc: 0.2150\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0850 - acc: 0.2383\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0836 - acc: 0.2817\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0820 - acc: 0.3400\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0803 - acc: 0.4100\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 83us/sample - loss: 0.0783 - acc: 0.4900\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0762 - acc: 0.5667\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0738 - acc: 0.6233\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0712 - acc: 0.6867\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0684 - acc: 0.7267\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0655 - acc: 0.7583\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0625 - acc: 0.7700\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0595 - acc: 0.7750\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0564 - acc: 0.7950\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0534 - acc: 0.8067\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0504 - acc: 0.8117\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 80us/sample - loss: 0.0476 - acc: 0.8150\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0449 - acc: 0.8183\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 119us/sample - loss: 0.0425 - acc: 0.8217\n",
      "Training date and time : \n",
      "2020-09-07 18:08:16\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0933 - acc: 0.0317\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 79us/sample - loss: 0.0916 - acc: 0.0450\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0901 - acc: 0.1000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 84us/sample - loss: 0.0888 - acc: 0.1733\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 81us/sample - loss: 0.0874 - acc: 0.2300\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 80us/sample - loss: 0.0861 - acc: 0.2833\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 83us/sample - loss: 0.0848 - acc: 0.3267\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0834 - acc: 0.3717\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0820 - acc: 0.4100\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0805 - acc: 0.4433\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0789 - acc: 0.4733\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0772 - acc: 0.5017\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0753 - acc: 0.5250\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 85us/sample - loss: 0.0734 - acc: 0.5517\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0713 - acc: 0.5667\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0692 - acc: 0.5750\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0670 - acc: 0.5850\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0648 - acc: 0.5917\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0626 - acc: 0.6067\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0605 - acc: 0.6250\n",
      "Training date and time : \n",
      "2020-09-07 18:08:59\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0874 - acc: 0.2233\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0859 - acc: 0.2633\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0843 - acc: 0.2983\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0826 - acc: 0.3317\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0807 - acc: 0.3700\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0786 - acc: 0.4417\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0762 - acc: 0.5133\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0734 - acc: 0.5800\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 79us/sample - loss: 0.0705 - acc: 0.6417\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0673 - acc: 0.6800\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 85us/sample - loss: 0.0641 - acc: 0.7283\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0607 - acc: 0.7567\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0573 - acc: 0.7817\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0539 - acc: 0.8133\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0504 - acc: 0.8267\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0471 - acc: 0.8333\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0438 - acc: 0.8417\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 116us/sample - loss: 0.0408 - acc: 0.8500\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 124us/sample - loss: 0.0380 - acc: 0.8500\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0355 - acc: 0.8517\n",
      "Training date and time : \n",
      "2020-09-07 18:09:07\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0932 - acc: 0.0283\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0911 - acc: 0.0900\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0894 - acc: 0.1717\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0877 - acc: 0.2433\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0862 - acc: 0.3017\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0846 - acc: 0.3400\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0831 - acc: 0.3700\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0816 - acc: 0.3833\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0800 - acc: 0.4067\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0784 - acc: 0.4417\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0766 - acc: 0.4917\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0748 - acc: 0.5133\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0729 - acc: 0.5450\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 77us/sample - loss: 0.0707 - acc: 0.5700\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0684 - acc: 0.6033\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0660 - acc: 0.6200\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 83us/sample - loss: 0.0635 - acc: 0.6550\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0609 - acc: 0.6633\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0584 - acc: 0.6867\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0558 - acc: 0.7050\n",
      "Training date and time : \n",
      "2020-09-07 18:09:51\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0868 - acc: 0.2267\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0849 - acc: 0.2500\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0828 - acc: 0.2750\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 81us/sample - loss: 0.0804 - acc: 0.3267\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0775 - acc: 0.4317\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 83us/sample - loss: 0.0742 - acc: 0.5417\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0706 - acc: 0.5650\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0671 - acc: 0.5933\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 85us/sample - loss: 0.0636 - acc: 0.6400\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0602 - acc: 0.6817\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0568 - acc: 0.7450\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0533 - acc: 0.8083\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 80us/sample - loss: 0.0498 - acc: 0.8383\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0463 - acc: 0.8683\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0427 - acc: 0.8833\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0393 - acc: 0.8933\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0361 - acc: 0.8950\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0331 - acc: 0.9033\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 79us/sample - loss: 0.0304 - acc: 0.9050\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 79us/sample - loss: 0.0280 - acc: 0.9150\n",
      "Training date and time : \n",
      "2020-09-07 18:09:59\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0933 - acc: 0.0067\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0911 - acc: 0.0500\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 80us/sample - loss: 0.0892 - acc: 0.1517\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 84us/sample - loss: 0.0873 - acc: 0.2583\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0855 - acc: 0.3450\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0837 - acc: 0.3950\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0819 - acc: 0.4233\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0801 - acc: 0.4633\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0781 - acc: 0.5150\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0760 - acc: 0.5633\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0737 - acc: 0.6133\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0713 - acc: 0.6417\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0687 - acc: 0.6633\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0660 - acc: 0.6783\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0633 - acc: 0.6933\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0605 - acc: 0.7083\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0577 - acc: 0.7183\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0551 - acc: 0.7217\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0526 - acc: 0.7250\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 79us/sample - loss: 0.0502 - acc: 0.7383\n"
     ]
    }
   ],
   "source": [
    "res = get_losses_for_non_iid_spectrum(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- 0th experiment -------------\n",
      "Training date and time : \n",
      "2020-09-07 17:04:49\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 970us/sample - loss: 0.0905 - acc: 0.1200\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0899 - acc: 0.1333\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0894 - acc: 0.1450\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0890 - acc: 0.1467\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0885 - acc: 0.1567\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0881 - acc: 0.1850\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0877 - acc: 0.2133\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0872 - acc: 0.2333\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0868 - acc: 0.2533\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.0863 - acc: 0.2817\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0859 - acc: 0.3250\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.0854 - acc: 0.3533\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.0849 - acc: 0.3800\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0843 - acc: 0.4133\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0838 - acc: 0.4350\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0832 - acc: 0.4467\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0825 - acc: 0.4650\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0819 - acc: 0.4700\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0812 - acc: 0.4933\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0805 - acc: 0.5150\n",
      "Training date and time : \n",
      "2020-09-07 17:04:53\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 963us/sample - loss: 0.0909 - acc: 0.1033\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0903 - acc: 0.1167\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0897 - acc: 0.1250\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0891 - acc: 0.1367\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0886 - acc: 0.1667\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0881 - acc: 0.1867\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0876 - acc: 0.2217\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0870 - acc: 0.2667\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0865 - acc: 0.2983\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0859 - acc: 0.3367\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0853 - acc: 0.3683\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0847 - acc: 0.4017\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0840 - acc: 0.4167\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0834 - acc: 0.4350\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0827 - acc: 0.4450\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0819 - acc: 0.4533\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0812 - acc: 0.4533\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0804 - acc: 0.4800\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0797 - acc: 0.4850\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0789 - acc: 0.5000\n",
      "Training date and time : \n",
      "2020-09-07 17:05:16\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 987us/sample - loss: 0.0903 - acc: 0.1217\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0896 - acc: 0.1333\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0889 - acc: 0.1450\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0883 - acc: 0.1667\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.0877 - acc: 0.2000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0871 - acc: 0.2383\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.0865 - acc: 0.2800\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.0858 - acc: 0.3100\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.0851 - acc: 0.3383\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.0844 - acc: 0.3700\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0836 - acc: 0.3983\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.0828 - acc: 0.4133\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0819 - acc: 0.4333\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0811 - acc: 0.4483\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0802 - acc: 0.4650\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0794 - acc: 0.4783\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0785 - acc: 0.4850\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0776 - acc: 0.5000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0767 - acc: 0.5117\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0758 - acc: 0.5183\n",
      "Training date and time : \n",
      "2020-09-07 17:05:21\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 977us/sample - loss: 0.0909 - acc: 0.1150\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0903 - acc: 0.1183\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0898 - acc: 0.1300\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0893 - acc: 0.1367\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0889 - acc: 0.1450\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0884 - acc: 0.1583\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0880 - acc: 0.1667\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0876 - acc: 0.1833\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0871 - acc: 0.2067\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0867 - acc: 0.2183\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0863 - acc: 0.2600\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0858 - acc: 0.3000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0853 - acc: 0.3383\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0849 - acc: 0.3633\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0844 - acc: 0.3867\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0839 - acc: 0.4133\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0833 - acc: 0.4450\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0828 - acc: 0.4950\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0822 - acc: 0.5183\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0816 - acc: 0.5450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training date and time : \n",
      "2020-09-07 17:05:44\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 979us/sample - loss: 0.0899 - acc: 0.1383\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0893 - acc: 0.1483\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.0886 - acc: 0.1717\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0880 - acc: 0.1750\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0874 - acc: 0.1983\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0867 - acc: 0.2367\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0860 - acc: 0.2767\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0853 - acc: 0.3267\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0845 - acc: 0.3683\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0836 - acc: 0.4033\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 44us/sample - loss: 0.0827 - acc: 0.4117\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 44us/sample - loss: 0.0818 - acc: 0.4233\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0809 - acc: 0.4350\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.0800 - acc: 0.4450\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.0790 - acc: 0.4617\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0781 - acc: 0.4700\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0771 - acc: 0.4833\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0762 - acc: 0.4950\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0752 - acc: 0.5117\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0742 - acc: 0.5317\n",
      "Training date and time : \n",
      "2020-09-07 17:05:49\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 975us/sample - loss: 0.0914 - acc: 0.0917\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0906 - acc: 0.0933\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0899 - acc: 0.1067\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0893 - acc: 0.1300\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0887 - acc: 0.1600\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0882 - acc: 0.1967\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0876 - acc: 0.2217\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0871 - acc: 0.2433\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0866 - acc: 0.2750\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0861 - acc: 0.3083\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0856 - acc: 0.3150\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0851 - acc: 0.3483\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0846 - acc: 0.3767\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0841 - acc: 0.3850\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0835 - acc: 0.3917\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0830 - acc: 0.4033\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0824 - acc: 0.4183\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0817 - acc: 0.4267\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0811 - acc: 0.4483\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0804 - acc: 0.4700\n",
      "Training date and time : \n",
      "2020-09-07 17:06:12\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 989us/sample - loss: 0.0904 - acc: 0.1117\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0895 - acc: 0.1150\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0888 - acc: 0.1467\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0881 - acc: 0.1600\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0873 - acc: 0.1917\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.0865 - acc: 0.2400\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.0857 - acc: 0.2950\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0848 - acc: 0.3583\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.0839 - acc: 0.4117\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0829 - acc: 0.4583\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0818 - acc: 0.4683\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.0808 - acc: 0.4717\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0797 - acc: 0.4933\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0785 - acc: 0.5017\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0774 - acc: 0.5150\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0762 - acc: 0.5267\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0750 - acc: 0.5367\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0738 - acc: 0.5517\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0726 - acc: 0.5650\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0713 - acc: 0.5683\n",
      "Training date and time : \n",
      "2020-09-07 17:06:17\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 984us/sample - loss: 0.0912 - acc: 0.0950\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0903 - acc: 0.1067\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0896 - acc: 0.1317\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0890 - acc: 0.1750\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0884 - acc: 0.2017\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0878 - acc: 0.2317\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0873 - acc: 0.2467\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0867 - acc: 0.2517\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0862 - acc: 0.2683\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0856 - acc: 0.2883\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0851 - acc: 0.2917\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0845 - acc: 0.3117\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0839 - acc: 0.3167\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0833 - acc: 0.3317\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0827 - acc: 0.3400\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0821 - acc: 0.3667\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0814 - acc: 0.3867\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0806 - acc: 0.4183\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0799 - acc: 0.4333\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0791 - acc: 0.4500\n",
      "Training date and time : \n",
      "2020-09-07 17:06:41\n",
      "Train on 600 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 990us/sample - loss: 0.0887 - acc: 0.1633\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0880 - acc: 0.1733\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0874 - acc: 0.1833\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0867 - acc: 0.2083\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0860 - acc: 0.2317\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0853 - acc: 0.2567\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0845 - acc: 0.2867\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0837 - acc: 0.3167\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0829 - acc: 0.3467\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0819 - acc: 0.3783\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0809 - acc: 0.4267\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0799 - acc: 0.4750\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0788 - acc: 0.5150\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0776 - acc: 0.5283\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0764 - acc: 0.5450\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0751 - acc: 0.5667\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0738 - acc: 0.5750\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0724 - acc: 0.5817\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0710 - acc: 0.6017\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0695 - acc: 0.6050\n",
      "Training date and time : \n",
      "2020-09-07 17:06:46\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0924 - acc: 0.0550\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0913 - acc: 0.0600\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0904 - acc: 0.0917\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0896 - acc: 0.1317\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0889 - acc: 0.1617\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0882 - acc: 0.2033\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0875 - acc: 0.2250\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0869 - acc: 0.2433\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0862 - acc: 0.2750\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0854 - acc: 0.3000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0847 - acc: 0.3367\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0839 - acc: 0.3483\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0831 - acc: 0.3633\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0823 - acc: 0.3800\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0814 - acc: 0.3917\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0804 - acc: 0.4033\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0795 - acc: 0.4050\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0785 - acc: 0.4133\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0774 - acc: 0.4233\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0764 - acc: 0.4333\n",
      "Training date and time : \n",
      "2020-09-07 17:07:11\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0892 - acc: 0.1867\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0882 - acc: 0.1967\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.0873 - acc: 0.2067\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0862 - acc: 0.2300\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0850 - acc: 0.2767\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0836 - acc: 0.3617\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0821 - acc: 0.4133\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0804 - acc: 0.4483\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0787 - acc: 0.4483\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0770 - acc: 0.4567\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0754 - acc: 0.4733\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0739 - acc: 0.4933\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0724 - acc: 0.5150\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0710 - acc: 0.5467\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0695 - acc: 0.5683\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0681 - acc: 0.5833\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0667 - acc: 0.6033\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0653 - acc: 0.6183\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0639 - acc: 0.6383\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0625 - acc: 0.6600\n",
      "Training date and time : \n",
      "2020-09-07 17:07:15\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 996us/sample - loss: 0.0925 - acc: 0.0433\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0912 - acc: 0.0667\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0901 - acc: 0.1067\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0892 - acc: 0.1583\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0883 - acc: 0.2033\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0875 - acc: 0.2333\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0866 - acc: 0.2650\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0858 - acc: 0.2900\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0850 - acc: 0.3133\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0842 - acc: 0.3233\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0834 - acc: 0.3383\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0825 - acc: 0.3433\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0817 - acc: 0.3617\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0808 - acc: 0.3767\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0798 - acc: 0.4000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0789 - acc: 0.4233\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0779 - acc: 0.4517\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0768 - acc: 0.4783\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0758 - acc: 0.5017\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0746 - acc: 0.5350\n",
      "Training date and time : \n",
      "2020-09-07 17:07:40\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0881 - acc: 0.1883\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0870 - acc: 0.2167\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0860 - acc: 0.2417\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.0848 - acc: 0.2767\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0836 - acc: 0.3017\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0823 - acc: 0.3400\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0809 - acc: 0.3950\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0794 - acc: 0.4733\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0777 - acc: 0.5300\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.0759 - acc: 0.5767\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0740 - acc: 0.6133\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0719 - acc: 0.6450\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0696 - acc: 0.6767\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0672 - acc: 0.6917\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0648 - acc: 0.7067\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0623 - acc: 0.7150\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0598 - acc: 0.7217\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0574 - acc: 0.7383\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0550 - acc: 0.7433\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0528 - acc: 0.7467\n",
      "Training date and time : \n",
      "2020-09-07 17:07:44\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0928 - acc: 0.0450\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0914 - acc: 0.0633\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0902 - acc: 0.1067\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0891 - acc: 0.1750\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0881 - acc: 0.2217\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0872 - acc: 0.2483\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.0862 - acc: 0.2683\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0853 - acc: 0.2850\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0844 - acc: 0.3000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0835 - acc: 0.3083\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0825 - acc: 0.3350\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0815 - acc: 0.3517\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0805 - acc: 0.3867\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0794 - acc: 0.4233\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0782 - acc: 0.4517\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0769 - acc: 0.4850\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0756 - acc: 0.5167\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0742 - acc: 0.5333\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0727 - acc: 0.5683\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0712 - acc: 0.5717\n",
      "Training date and time : \n",
      "2020-09-07 17:08:09\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0875 - acc: 0.2200\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0863 - acc: 0.2467\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0851 - acc: 0.2817\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0837 - acc: 0.3133\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0823 - acc: 0.3533\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0806 - acc: 0.3933\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0788 - acc: 0.4500\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0768 - acc: 0.5150\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0746 - acc: 0.5450\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0722 - acc: 0.5750\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0698 - acc: 0.5933\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0673 - acc: 0.6150\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0649 - acc: 0.6217\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0625 - acc: 0.6350\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0602 - acc: 0.6350\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0579 - acc: 0.6550\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0559 - acc: 0.6667\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0539 - acc: 0.6867\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0520 - acc: 0.7000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0502 - acc: 0.7083\n",
      "Training date and time : \n",
      "2020-09-07 17:08:14\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0923 - acc: 0.0467\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0910 - acc: 0.0617\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0898 - acc: 0.1250\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0887 - acc: 0.1767\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0877 - acc: 0.2200\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0868 - acc: 0.2533\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0858 - acc: 0.2733\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0849 - acc: 0.2800\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0839 - acc: 0.2933\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0829 - acc: 0.3017\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0819 - acc: 0.3150\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0809 - acc: 0.3383\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0798 - acc: 0.3583\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0787 - acc: 0.3933\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0775 - acc: 0.4367\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0762 - acc: 0.4617\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0748 - acc: 0.4967\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0733 - acc: 0.5217\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0717 - acc: 0.5383\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0701 - acc: 0.5667\n",
      "Training date and time : \n",
      "2020-09-07 17:08:39\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0876 - acc: 0.1983\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0863 - acc: 0.2150\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0850 - acc: 0.2383\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0836 - acc: 0.2817\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.0820 - acc: 0.3400\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0803 - acc: 0.4100\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0783 - acc: 0.4900\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0762 - acc: 0.5667\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0738 - acc: 0.6233\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0712 - acc: 0.6867\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0684 - acc: 0.7267\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0655 - acc: 0.7583\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0625 - acc: 0.7700\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0595 - acc: 0.7750\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0564 - acc: 0.7950\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0534 - acc: 0.8067\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0504 - acc: 0.8117\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0476 - acc: 0.8150\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0449 - acc: 0.8183\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0425 - acc: 0.8217\n",
      "Training date and time : \n",
      "2020-09-07 17:08:44\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0933 - acc: 0.0317\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0916 - acc: 0.0450\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0901 - acc: 0.1000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0888 - acc: 0.1733\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0874 - acc: 0.2300\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0861 - acc: 0.2833\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.0848 - acc: 0.3267\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.0834 - acc: 0.3717\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0820 - acc: 0.4100\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.0805 - acc: 0.4433\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0789 - acc: 0.4733\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0772 - acc: 0.5017\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0753 - acc: 0.5250\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.0734 - acc: 0.5517\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0713 - acc: 0.5667\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0692 - acc: 0.5750\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0670 - acc: 0.5850\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0648 - acc: 0.5917\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0626 - acc: 0.6067\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0605 - acc: 0.6250\n",
      "Training date and time : \n",
      "2020-09-07 17:09:10\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0874 - acc: 0.2233\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0859 - acc: 0.2633\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0843 - acc: 0.2983\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0826 - acc: 0.3317\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0807 - acc: 0.3700\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 79us/sample - loss: 0.0786 - acc: 0.4417\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0762 - acc: 0.5133\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0734 - acc: 0.5800\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0705 - acc: 0.6417\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0673 - acc: 0.6800\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0641 - acc: 0.7283\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0607 - acc: 0.7567\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0573 - acc: 0.7817\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0539 - acc: 0.8133\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0504 - acc: 0.8267\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0471 - acc: 0.8333\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0438 - acc: 0.8417\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0408 - acc: 0.8500\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0380 - acc: 0.8500\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0355 - acc: 0.8517\n",
      "Training date and time : \n",
      "2020-09-07 17:09:15\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0932 - acc: 0.0283\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0911 - acc: 0.0900\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0894 - acc: 0.1717\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0877 - acc: 0.2433\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0862 - acc: 0.3017\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0846 - acc: 0.3400\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0831 - acc: 0.3700\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.0816 - acc: 0.3833\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0800 - acc: 0.4067\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0784 - acc: 0.4417\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0766 - acc: 0.4917\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0748 - acc: 0.5133\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0729 - acc: 0.5450\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0707 - acc: 0.5700\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0684 - acc: 0.6033\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0660 - acc: 0.6200\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0635 - acc: 0.6550\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0609 - acc: 0.6633\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 81us/sample - loss: 0.0584 - acc: 0.6867\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0558 - acc: 0.7050\n",
      "Training date and time : \n",
      "2020-09-07 17:09:40\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0868 - acc: 0.2267\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0849 - acc: 0.2500\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0828 - acc: 0.2750\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0804 - acc: 0.3267\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0775 - acc: 0.4317\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.0742 - acc: 0.5417\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0706 - acc: 0.5650\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0671 - acc: 0.5933\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0636 - acc: 0.6400\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0602 - acc: 0.6817\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0568 - acc: 0.7450\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0533 - acc: 0.8083\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0498 - acc: 0.8383\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0463 - acc: 0.8683\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0427 - acc: 0.8833\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0393 - acc: 0.8933\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0361 - acc: 0.8950\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0331 - acc: 0.9033\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0304 - acc: 0.9050\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0280 - acc: 0.9150\n",
      "Training date and time : \n",
      "2020-09-07 17:09:45\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0933 - acc: 0.0067\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0911 - acc: 0.0500\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0892 - acc: 0.1517\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0873 - acc: 0.2583\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0855 - acc: 0.3450\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0837 - acc: 0.3950\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0819 - acc: 0.4233\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0801 - acc: 0.4633\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0781 - acc: 0.5150\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0760 - acc: 0.5633\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0737 - acc: 0.6133\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0713 - acc: 0.6417\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0687 - acc: 0.6633\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0660 - acc: 0.6783\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0633 - acc: 0.6933\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0605 - acc: 0.7083\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0577 - acc: 0.7183\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0551 - acc: 0.7217\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0526 - acc: 0.7250\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0502 - acc: 0.7383\n",
      "------------- 1th experiment -------------\n",
      "Training date and time : \n",
      "2020-09-07 17:10:11\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0905 - acc: 0.1200\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0899 - acc: 0.1333\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 75us/sample - loss: 0.0894 - acc: 0.1450\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0890 - acc: 0.1467\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0885 - acc: 0.1567\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0881 - acc: 0.1850\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0877 - acc: 0.2133\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0872 - acc: 0.2333\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 77us/sample - loss: 0.0868 - acc: 0.2533\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 81us/sample - loss: 0.0863 - acc: 0.2817\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0859 - acc: 0.3250\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0854 - acc: 0.3533\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0849 - acc: 0.3800\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0843 - acc: 0.4133\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0838 - acc: 0.4350\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.0832 - acc: 0.4467\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0825 - acc: 0.4650\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0819 - acc: 0.4700\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0812 - acc: 0.4933\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0805 - acc: 0.5150\n",
      "Training date and time : \n",
      "2020-09-07 17:10:17\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0909 - acc: 0.1033\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0903 - acc: 0.1167\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0897 - acc: 0.1250\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0891 - acc: 0.1367\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0886 - acc: 0.1667\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0881 - acc: 0.1867\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0876 - acc: 0.2217\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0870 - acc: 0.2667\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0865 - acc: 0.2983\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0859 - acc: 0.3367\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0853 - acc: 0.3683\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0847 - acc: 0.4017\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 77us/sample - loss: 0.0840 - acc: 0.4167\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0834 - acc: 0.4350\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0827 - acc: 0.4450\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0819 - acc: 0.4533\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0812 - acc: 0.4533\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0804 - acc: 0.4800\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0797 - acc: 0.4850\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0789 - acc: 0.5000\n",
      "Training date and time : \n",
      "2020-09-07 17:10:43\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0903 - acc: 0.1217\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0896 - acc: 0.1333\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0889 - acc: 0.1450\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0883 - acc: 0.1667\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0877 - acc: 0.2000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0871 - acc: 0.2383\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0865 - acc: 0.2800\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0858 - acc: 0.3100\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0851 - acc: 0.3383\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0844 - acc: 0.3700\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0836 - acc: 0.3983\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0828 - acc: 0.4133\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0819 - acc: 0.4333\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0811 - acc: 0.4483\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0802 - acc: 0.4650\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0794 - acc: 0.4783\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0785 - acc: 0.4850\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0776 - acc: 0.5000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0767 - acc: 0.5117\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0758 - acc: 0.5183\n",
      "Training date and time : \n",
      "2020-09-07 17:10:48\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0909 - acc: 0.1150\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0903 - acc: 0.1183\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0898 - acc: 0.1300\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0893 - acc: 0.1367\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0889 - acc: 0.1450\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0884 - acc: 0.1583\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0880 - acc: 0.1667\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0876 - acc: 0.1833\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0871 - acc: 0.2067\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0867 - acc: 0.2183\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0863 - acc: 0.2600\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0858 - acc: 0.3000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0853 - acc: 0.3383\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0849 - acc: 0.3633\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0844 - acc: 0.3867\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0839 - acc: 0.4133\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0833 - acc: 0.4450\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0828 - acc: 0.4950\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0822 - acc: 0.5183\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0816 - acc: 0.5450\n",
      "Training date and time : \n",
      "2020-09-07 17:11:15\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0899 - acc: 0.1383\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0893 - acc: 0.1483\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0886 - acc: 0.1717\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0880 - acc: 0.1750\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.0874 - acc: 0.1983\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0867 - acc: 0.2367\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0860 - acc: 0.2767\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0853 - acc: 0.3267\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0845 - acc: 0.3683\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0836 - acc: 0.4033\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0827 - acc: 0.4117\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0818 - acc: 0.4233\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0809 - acc: 0.4350\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0800 - acc: 0.4450\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0790 - acc: 0.4617\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0781 - acc: 0.4700\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0771 - acc: 0.4833\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0762 - acc: 0.4950\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0752 - acc: 0.5117\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0742 - acc: 0.5317\n",
      "Training date and time : \n",
      "2020-09-07 17:11:20\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0914 - acc: 0.0917\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0906 - acc: 0.0933\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0899 - acc: 0.1067\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0893 - acc: 0.1300\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0887 - acc: 0.1600\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0882 - acc: 0.1967\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0876 - acc: 0.2217\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0871 - acc: 0.2433\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0866 - acc: 0.2750\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0861 - acc: 0.3083\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0856 - acc: 0.3150\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0851 - acc: 0.3483\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0846 - acc: 0.3767\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0841 - acc: 0.3850\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0835 - acc: 0.3917\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0830 - acc: 0.4033\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0824 - acc: 0.4183\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0817 - acc: 0.4267\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0811 - acc: 0.4483\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0804 - acc: 0.4700\n",
      "Training date and time : \n",
      "2020-09-07 17:11:47\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0904 - acc: 0.1117\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0895 - acc: 0.1150\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0888 - acc: 0.1467\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0881 - acc: 0.1600\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0873 - acc: 0.1917\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0865 - acc: 0.2400\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0857 - acc: 0.2950\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0848 - acc: 0.3583\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0839 - acc: 0.4117\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 77us/sample - loss: 0.0829 - acc: 0.4583\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0818 - acc: 0.4683\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0808 - acc: 0.4717\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0797 - acc: 0.4933\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0785 - acc: 0.5017\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0774 - acc: 0.5150\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0762 - acc: 0.5267\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0750 - acc: 0.5367\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0738 - acc: 0.5517\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0726 - acc: 0.5650\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0713 - acc: 0.5683\n",
      "Training date and time : \n",
      "2020-09-07 17:11:52\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0912 - acc: 0.0950\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0903 - acc: 0.1067\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0896 - acc: 0.1317\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0890 - acc: 0.1750\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0884 - acc: 0.2017\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0878 - acc: 0.2317\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0873 - acc: 0.2467\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0867 - acc: 0.2517\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0862 - acc: 0.2683\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0856 - acc: 0.2883\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0851 - acc: 0.2917\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0845 - acc: 0.3117\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0839 - acc: 0.3167\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0833 - acc: 0.3317\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0827 - acc: 0.3400\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0821 - acc: 0.3667\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0814 - acc: 0.3867\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0806 - acc: 0.4183\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0799 - acc: 0.4333\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0791 - acc: 0.4500\n",
      "Training date and time : \n",
      "2020-09-07 17:12:20\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0887 - acc: 0.1633\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0880 - acc: 0.1733\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.0874 - acc: 0.1833\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0867 - acc: 0.2083\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0860 - acc: 0.2317\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0853 - acc: 0.2567\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0845 - acc: 0.2867\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0837 - acc: 0.3167\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0829 - acc: 0.3467\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0819 - acc: 0.3783\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0809 - acc: 0.4267\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0799 - acc: 0.4750\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0788 - acc: 0.5150\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0776 - acc: 0.5283\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0764 - acc: 0.5450\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0751 - acc: 0.5667\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0738 - acc: 0.5750\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0724 - acc: 0.5817\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0710 - acc: 0.6017\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0695 - acc: 0.6050\n",
      "Training date and time : \n",
      "2020-09-07 17:12:25\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0924 - acc: 0.0550\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0913 - acc: 0.0600\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0904 - acc: 0.0917\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0896 - acc: 0.1317\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0889 - acc: 0.1617\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0882 - acc: 0.2033\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0875 - acc: 0.2250\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0869 - acc: 0.2433\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0862 - acc: 0.2750\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0854 - acc: 0.3000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0847 - acc: 0.3367\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0839 - acc: 0.3483\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0831 - acc: 0.3633\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0823 - acc: 0.3800\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0814 - acc: 0.3917\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0804 - acc: 0.4033\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0795 - acc: 0.4050\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0785 - acc: 0.4133\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0774 - acc: 0.4233\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0764 - acc: 0.4333\n",
      "Training date and time : \n",
      "2020-09-07 17:12:53\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0892 - acc: 0.1867\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0882 - acc: 0.1967\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0873 - acc: 0.2067\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0862 - acc: 0.2300\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.0850 - acc: 0.2767\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0836 - acc: 0.3617\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0821 - acc: 0.4133\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0804 - acc: 0.4483\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.0787 - acc: 0.4483\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.0770 - acc: 0.4567\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.0754 - acc: 0.4733\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0739 - acc: 0.4933\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0724 - acc: 0.5150\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.0710 - acc: 0.5467\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0695 - acc: 0.5683\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0681 - acc: 0.5833\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0667 - acc: 0.6033\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0653 - acc: 0.6183\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0639 - acc: 0.6383\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0625 - acc: 0.6600\n",
      "Training date and time : \n",
      "2020-09-07 17:12:58\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0925 - acc: 0.0433\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0912 - acc: 0.0667\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0901 - acc: 0.1067\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0892 - acc: 0.1583\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0883 - acc: 0.2033\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.0875 - acc: 0.2333\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0866 - acc: 0.2650\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0858 - acc: 0.2900\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0850 - acc: 0.3133\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0842 - acc: 0.3233\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0834 - acc: 0.3383\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0825 - acc: 0.3433\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 80us/sample - loss: 0.0817 - acc: 0.3617\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0808 - acc: 0.3767\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0798 - acc: 0.4000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0789 - acc: 0.4233\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0779 - acc: 0.4517\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0768 - acc: 0.4783\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0758 - acc: 0.5017\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0746 - acc: 0.5350\n",
      "Training date and time : \n",
      "2020-09-07 17:13:26\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0881 - acc: 0.1883\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0870 - acc: 0.2167\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0860 - acc: 0.2417\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0848 - acc: 0.2767\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0836 - acc: 0.3017\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0823 - acc: 0.3400\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0809 - acc: 0.3950\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0794 - acc: 0.4733\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0777 - acc: 0.5300\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0759 - acc: 0.5767\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0740 - acc: 0.6133\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0719 - acc: 0.6450\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0696 - acc: 0.6767\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0672 - acc: 0.6917\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0648 - acc: 0.7067\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0623 - acc: 0.7150\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0598 - acc: 0.7217\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0574 - acc: 0.7383\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0550 - acc: 0.7433\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0528 - acc: 0.7467\n",
      "Training date and time : \n",
      "2020-09-07 17:13:32\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0928 - acc: 0.0450\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 46us/sample - loss: 0.0914 - acc: 0.0633\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0902 - acc: 0.1067\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0891 - acc: 0.1750\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.0881 - acc: 0.2217\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.0872 - acc: 0.2483\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.0862 - acc: 0.2683\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0853 - acc: 0.2850\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0844 - acc: 0.3000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0835 - acc: 0.3083\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0825 - acc: 0.3350\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0815 - acc: 0.3517\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0805 - acc: 0.3867\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0794 - acc: 0.4233\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0782 - acc: 0.4517\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0769 - acc: 0.4850\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0756 - acc: 0.5167\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0742 - acc: 0.5333\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0727 - acc: 0.5683\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0712 - acc: 0.5717\n",
      "Training date and time : \n",
      "2020-09-07 17:13:59\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0875 - acc: 0.2200\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0863 - acc: 0.2467\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0851 - acc: 0.2817\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0837 - acc: 0.3133\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.0823 - acc: 0.3533\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0806 - acc: 0.3933\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.0788 - acc: 0.4500\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0768 - acc: 0.5150\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0746 - acc: 0.5450\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 44us/sample - loss: 0.0722 - acc: 0.5750\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.0698 - acc: 0.5933\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0673 - acc: 0.6150\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0649 - acc: 0.6217\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0625 - acc: 0.6350\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0602 - acc: 0.6350\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0579 - acc: 0.6550\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0559 - acc: 0.6667\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0539 - acc: 0.6867\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0520 - acc: 0.7000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0502 - acc: 0.7083\n",
      "Training date and time : \n",
      "2020-09-07 17:14:05\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0923 - acc: 0.0467\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0910 - acc: 0.0617\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0898 - acc: 0.1250\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0887 - acc: 0.1767\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0877 - acc: 0.2200\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0868 - acc: 0.2533\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0858 - acc: 0.2733\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.0849 - acc: 0.2800\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 79us/sample - loss: 0.0839 - acc: 0.2933\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0829 - acc: 0.3017\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0819 - acc: 0.3150\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0809 - acc: 0.3383\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0798 - acc: 0.3583\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0787 - acc: 0.3933\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0775 - acc: 0.4367\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0762 - acc: 0.4617\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0748 - acc: 0.4967\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0733 - acc: 0.5217\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0717 - acc: 0.5383\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0701 - acc: 0.5667\n",
      "Training date and time : \n",
      "2020-09-07 17:14:33\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0876 - acc: 0.1983\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0863 - acc: 0.2150\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0850 - acc: 0.2383\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0836 - acc: 0.2817\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0820 - acc: 0.3400\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0803 - acc: 0.4100\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0783 - acc: 0.4900\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0762 - acc: 0.5667\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0738 - acc: 0.6233\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0712 - acc: 0.6867\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0684 - acc: 0.7267\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0655 - acc: 0.7583\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0625 - acc: 0.7700\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0595 - acc: 0.7750\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0564 - acc: 0.7950\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0534 - acc: 0.8067\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0504 - acc: 0.8117\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0476 - acc: 0.8150\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0449 - acc: 0.8183\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0425 - acc: 0.8217\n",
      "Training date and time : \n",
      "2020-09-07 17:14:39\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0933 - acc: 0.0317\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0916 - acc: 0.0450\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0901 - acc: 0.1000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0888 - acc: 0.1733\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0874 - acc: 0.2300\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0861 - acc: 0.2833\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0848 - acc: 0.3267\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0834 - acc: 0.3717\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0820 - acc: 0.4100\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0805 - acc: 0.4433\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0789 - acc: 0.4733\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0772 - acc: 0.5017\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0753 - acc: 0.5250\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0734 - acc: 0.5517\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0713 - acc: 0.5667\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0692 - acc: 0.5750\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0670 - acc: 0.5850\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0648 - acc: 0.5917\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0626 - acc: 0.6067\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0605 - acc: 0.6250\n",
      "Training date and time : \n",
      "2020-09-07 17:15:08\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0874 - acc: 0.2233\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0859 - acc: 0.2633\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0843 - acc: 0.2983\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0826 - acc: 0.3317\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0807 - acc: 0.3700\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0786 - acc: 0.4417\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0762 - acc: 0.5133\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0734 - acc: 0.5800\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0705 - acc: 0.6417\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0673 - acc: 0.6800\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0641 - acc: 0.7283\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0607 - acc: 0.7567\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0573 - acc: 0.7817\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0539 - acc: 0.8133\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0504 - acc: 0.8267\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0471 - acc: 0.8333\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0438 - acc: 0.8417\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0408 - acc: 0.8500\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0380 - acc: 0.8500\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0355 - acc: 0.8517\n",
      "Training date and time : \n",
      "2020-09-07 17:15:14\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0932 - acc: 0.0283\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0911 - acc: 0.0900\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0894 - acc: 0.1717\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0877 - acc: 0.2433\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0862 - acc: 0.3017\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0846 - acc: 0.3400\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0831 - acc: 0.3700\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0816 - acc: 0.3833\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0800 - acc: 0.4067\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0784 - acc: 0.4417\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0766 - acc: 0.4917\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0748 - acc: 0.5133\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0729 - acc: 0.5450\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0707 - acc: 0.5700\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0684 - acc: 0.6033\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0660 - acc: 0.6200\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0635 - acc: 0.6550\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0609 - acc: 0.6633\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0584 - acc: 0.6867\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0558 - acc: 0.7050\n",
      "Training date and time : \n",
      "2020-09-07 17:15:43\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0868 - acc: 0.2267\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0849 - acc: 0.2500\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0828 - acc: 0.2750\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0804 - acc: 0.3267\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0775 - acc: 0.4317\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0742 - acc: 0.5417\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0706 - acc: 0.5650\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0671 - acc: 0.5933\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0636 - acc: 0.6400\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0602 - acc: 0.6817\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0568 - acc: 0.7450\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0533 - acc: 0.8083\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0498 - acc: 0.8383\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0463 - acc: 0.8683\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0427 - acc: 0.8833\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0393 - acc: 0.8933\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0361 - acc: 0.8950\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0331 - acc: 0.9033\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0304 - acc: 0.9050\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0280 - acc: 0.9150\n",
      "Training date and time : \n",
      "2020-09-07 17:15:48\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0933 - acc: 0.0067\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0911 - acc: 0.0500\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0892 - acc: 0.1517\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0873 - acc: 0.2583\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0855 - acc: 0.3450\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0837 - acc: 0.3950\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0819 - acc: 0.4233\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0801 - acc: 0.4633\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0781 - acc: 0.5150\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 79us/sample - loss: 0.0760 - acc: 0.5633\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0737 - acc: 0.6133\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0713 - acc: 0.6417\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0687 - acc: 0.6633\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0660 - acc: 0.6783\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0633 - acc: 0.6933\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0605 - acc: 0.7083\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0577 - acc: 0.7183\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0551 - acc: 0.7217\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0526 - acc: 0.7250\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0502 - acc: 0.7383\n",
      "------------- 2th experiment -------------\n",
      "Training date and time : \n",
      "2020-09-07 17:16:17\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0905 - acc: 0.1200\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0899 - acc: 0.1333\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0894 - acc: 0.1450\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0890 - acc: 0.1467\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0885 - acc: 0.1567\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0881 - acc: 0.1850\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0877 - acc: 0.2133\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0872 - acc: 0.2333\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0868 - acc: 0.2533\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0863 - acc: 0.2817\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0859 - acc: 0.3250\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0854 - acc: 0.3533\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0849 - acc: 0.3800\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0843 - acc: 0.4133\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0838 - acc: 0.4350\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0832 - acc: 0.4467\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0825 - acc: 0.4650\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0819 - acc: 0.4700\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0812 - acc: 0.4933\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0805 - acc: 0.5150\n",
      "Training date and time : \n",
      "2020-09-07 17:16:23\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0909 - acc: 0.1033\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0903 - acc: 0.1167\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0897 - acc: 0.1250\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0891 - acc: 0.1367\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0886 - acc: 0.1667\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0881 - acc: 0.1867\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0876 - acc: 0.2217\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0870 - acc: 0.2667\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0865 - acc: 0.2983\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0859 - acc: 0.3367\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0853 - acc: 0.3683\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0847 - acc: 0.4017\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0840 - acc: 0.4167\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0834 - acc: 0.4350\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0827 - acc: 0.4450\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0819 - acc: 0.4533\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0812 - acc: 0.4533\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0804 - acc: 0.4800\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0797 - acc: 0.4850\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0789 - acc: 0.5000\n",
      "Training date and time : \n",
      "2020-09-07 17:16:53\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0903 - acc: 0.1217\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0896 - acc: 0.1333\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0889 - acc: 0.1450\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0883 - acc: 0.1667\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0877 - acc: 0.2000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0871 - acc: 0.2383\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0865 - acc: 0.2800\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0858 - acc: 0.3100\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0851 - acc: 0.3383\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0844 - acc: 0.3700\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0836 - acc: 0.3983\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0828 - acc: 0.4133\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0819 - acc: 0.4333\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0811 - acc: 0.4483\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0802 - acc: 0.4650\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0794 - acc: 0.4783\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0785 - acc: 0.4850\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0776 - acc: 0.5000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0767 - acc: 0.5117\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0758 - acc: 0.5183\n",
      "Training date and time : \n",
      "2020-09-07 17:16:58\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0909 - acc: 0.1150\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0903 - acc: 0.1183\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0898 - acc: 0.1300\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0893 - acc: 0.1367\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0889 - acc: 0.1450\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0884 - acc: 0.1583\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0880 - acc: 0.1667\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0876 - acc: 0.1833\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0871 - acc: 0.2067\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0867 - acc: 0.2183\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0863 - acc: 0.2600\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0858 - acc: 0.3000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0853 - acc: 0.3383\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0849 - acc: 0.3633\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0844 - acc: 0.3867\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0839 - acc: 0.4133\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0833 - acc: 0.4450\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0828 - acc: 0.4950\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0822 - acc: 0.5183\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0816 - acc: 0.5450\n",
      "Training date and time : \n",
      "2020-09-07 17:17:29\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0899 - acc: 0.1383\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0893 - acc: 0.1483\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0886 - acc: 0.1717\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0880 - acc: 0.1750\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0874 - acc: 0.1983\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0867 - acc: 0.2367\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0860 - acc: 0.2767\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0853 - acc: 0.3267\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0845 - acc: 0.3683\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0836 - acc: 0.4033\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0827 - acc: 0.4117\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0818 - acc: 0.4233\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0809 - acc: 0.4350\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0800 - acc: 0.4450\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0790 - acc: 0.4617\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0781 - acc: 0.4700\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0771 - acc: 0.4833\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.0762 - acc: 0.4950\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0752 - acc: 0.5117\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0742 - acc: 0.5317\n",
      "Training date and time : \n",
      "2020-09-07 17:17:34\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0914 - acc: 0.0917\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0906 - acc: 0.0933\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0899 - acc: 0.1067\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0893 - acc: 0.1300\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0887 - acc: 0.1600\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0882 - acc: 0.1967\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0876 - acc: 0.2217\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0871 - acc: 0.2433\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0866 - acc: 0.2750\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0861 - acc: 0.3083\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0856 - acc: 0.3150\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0851 - acc: 0.3483\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0846 - acc: 0.3767\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0841 - acc: 0.3850\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0835 - acc: 0.3917\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0830 - acc: 0.4033\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0824 - acc: 0.4183\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0817 - acc: 0.4267\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0811 - acc: 0.4483\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0804 - acc: 0.4700\n",
      "Training date and time : \n",
      "2020-09-07 17:18:04\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0904 - acc: 0.1117\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0895 - acc: 0.1150\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0888 - acc: 0.1467\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0881 - acc: 0.1600\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0873 - acc: 0.1917\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0865 - acc: 0.2400\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0857 - acc: 0.2950\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0848 - acc: 0.3583\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0839 - acc: 0.4117\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.0829 - acc: 0.4583\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0818 - acc: 0.4683\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0808 - acc: 0.4717\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0797 - acc: 0.4933\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0785 - acc: 0.5017\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0774 - acc: 0.5150\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0762 - acc: 0.5267\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0750 - acc: 0.5367\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0738 - acc: 0.5517\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0726 - acc: 0.5650\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0713 - acc: 0.5683\n",
      "Training date and time : \n",
      "2020-09-07 17:18:10\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0912 - acc: 0.0950\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0903 - acc: 0.1067\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 83us/sample - loss: 0.0896 - acc: 0.1317\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 83us/sample - loss: 0.0890 - acc: 0.1750\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0884 - acc: 0.2017\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0878 - acc: 0.2317\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0873 - acc: 0.2467\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 85us/sample - loss: 0.0867 - acc: 0.2517\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0862 - acc: 0.2683\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 80us/sample - loss: 0.0856 - acc: 0.2883\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0851 - acc: 0.2917\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0845 - acc: 0.3117\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0839 - acc: 0.3167\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0833 - acc: 0.3317\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0827 - acc: 0.3400\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0821 - acc: 0.3667\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0814 - acc: 0.3867\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0806 - acc: 0.4183\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 85us/sample - loss: 0.0799 - acc: 0.4333\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 75us/sample - loss: 0.0791 - acc: 0.4500\n",
      "Training date and time : \n",
      "2020-09-07 17:18:42\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0887 - acc: 0.1633\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0880 - acc: 0.1733\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0874 - acc: 0.1833\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0867 - acc: 0.2083\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0860 - acc: 0.2317\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0853 - acc: 0.2567\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0845 - acc: 0.2867\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0837 - acc: 0.3167\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0829 - acc: 0.3467\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0819 - acc: 0.3783\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0809 - acc: 0.4267\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0799 - acc: 0.4750\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0788 - acc: 0.5150\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0776 - acc: 0.5283\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0764 - acc: 0.5450\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0751 - acc: 0.5667\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0738 - acc: 0.5750\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 79us/sample - loss: 0.0724 - acc: 0.5817\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0710 - acc: 0.6017\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0695 - acc: 0.6050\n",
      "Training date and time : \n",
      "2020-09-07 17:18:48\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0924 - acc: 0.0550\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0913 - acc: 0.0600\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0904 - acc: 0.0917\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0896 - acc: 0.1317\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0889 - acc: 0.1617\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0882 - acc: 0.2033\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0875 - acc: 0.2250\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0869 - acc: 0.2433\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0862 - acc: 0.2750\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0854 - acc: 0.3000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0847 - acc: 0.3367\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0839 - acc: 0.3483\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0831 - acc: 0.3633\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0823 - acc: 0.3800\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0814 - acc: 0.3917\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0804 - acc: 0.4033\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0795 - acc: 0.4050\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0785 - acc: 0.4133\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0774 - acc: 0.4233\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0764 - acc: 0.4333\n",
      "Training date and time : \n",
      "2020-09-07 17:19:20\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0892 - acc: 0.1867\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0882 - acc: 0.1967\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 77us/sample - loss: 0.0873 - acc: 0.2067\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0862 - acc: 0.2300\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 80us/sample - loss: 0.0850 - acc: 0.2767\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0836 - acc: 0.3617\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0821 - acc: 0.4133\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0804 - acc: 0.4483\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0787 - acc: 0.4483\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0770 - acc: 0.4567\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0754 - acc: 0.4733\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 77us/sample - loss: 0.0739 - acc: 0.4933\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0724 - acc: 0.5150\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0710 - acc: 0.5467\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0695 - acc: 0.5683\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0681 - acc: 0.5833\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0667 - acc: 0.6033\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0653 - acc: 0.6183\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0639 - acc: 0.6383\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0625 - acc: 0.6600\n",
      "Training date and time : \n",
      "2020-09-07 17:19:26\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0925 - acc: 0.0433\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0912 - acc: 0.0667\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0901 - acc: 0.1067\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0892 - acc: 0.1583\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0883 - acc: 0.2033\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0875 - acc: 0.2333\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0866 - acc: 0.2650\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0858 - acc: 0.2900\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0850 - acc: 0.3133\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0842 - acc: 0.3233\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0834 - acc: 0.3383\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0825 - acc: 0.3433\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0817 - acc: 0.3617\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0808 - acc: 0.3767\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0798 - acc: 0.4000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0789 - acc: 0.4233\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0779 - acc: 0.4517\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0768 - acc: 0.4783\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0758 - acc: 0.5017\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0746 - acc: 0.5350\n",
      "Training date and time : \n",
      "2020-09-07 17:19:58\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0881 - acc: 0.1883\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0870 - acc: 0.2167\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0860 - acc: 0.2417\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0848 - acc: 0.2767\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 81us/sample - loss: 0.0836 - acc: 0.3017\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.0823 - acc: 0.3400\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0809 - acc: 0.3950\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0794 - acc: 0.4733\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0777 - acc: 0.5300\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0759 - acc: 0.5767\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0740 - acc: 0.6133\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0719 - acc: 0.6450\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0696 - acc: 0.6767\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0672 - acc: 0.6917\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0648 - acc: 0.7067\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0623 - acc: 0.7150\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0598 - acc: 0.7217\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0574 - acc: 0.7383\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0550 - acc: 0.7433\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0528 - acc: 0.7467\n",
      "Training date and time : \n",
      "2020-09-07 17:20:04\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0928 - acc: 0.0450\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0914 - acc: 0.0633\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0902 - acc: 0.1067\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0891 - acc: 0.1750\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0881 - acc: 0.2217\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0872 - acc: 0.2483\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0862 - acc: 0.2683\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0853 - acc: 0.2850\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0844 - acc: 0.3000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0835 - acc: 0.3083\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0825 - acc: 0.3350\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0815 - acc: 0.3517\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0805 - acc: 0.3867\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0794 - acc: 0.4233\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0782 - acc: 0.4517\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0769 - acc: 0.4850\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0756 - acc: 0.5167\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0742 - acc: 0.5333\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0727 - acc: 0.5683\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0712 - acc: 0.5717\n",
      "Training date and time : \n",
      "2020-09-07 17:20:36\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0875 - acc: 0.2200\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0863 - acc: 0.2467\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0851 - acc: 0.2817\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0837 - acc: 0.3133\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0823 - acc: 0.3533\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0806 - acc: 0.3933\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0788 - acc: 0.4500\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0768 - acc: 0.5150\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0746 - acc: 0.5450\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0722 - acc: 0.5750\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0698 - acc: 0.5933\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0673 - acc: 0.6150\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0649 - acc: 0.6217\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0625 - acc: 0.6350\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.0602 - acc: 0.6350\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0579 - acc: 0.6550\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0559 - acc: 0.6667\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0539 - acc: 0.6867\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0520 - acc: 0.7000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0502 - acc: 0.7083\n",
      "Training date and time : \n",
      "2020-09-07 17:20:42\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0923 - acc: 0.0467\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0910 - acc: 0.0617\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0898 - acc: 0.1250\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0887 - acc: 0.1767\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0877 - acc: 0.2200\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0868 - acc: 0.2533\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0858 - acc: 0.2733\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0849 - acc: 0.2800\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0839 - acc: 0.2933\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0829 - acc: 0.3017\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0819 - acc: 0.3150\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0809 - acc: 0.3383\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0798 - acc: 0.3583\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0787 - acc: 0.3933\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0775 - acc: 0.4367\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0762 - acc: 0.4617\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0748 - acc: 0.4967\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0733 - acc: 0.5217\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0717 - acc: 0.5383\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0701 - acc: 0.5667\n",
      "Training date and time : \n",
      "2020-09-07 17:21:14\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0876 - acc: 0.1983\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0863 - acc: 0.2150\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0850 - acc: 0.2383\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0836 - acc: 0.2817\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0820 - acc: 0.3400\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0803 - acc: 0.4100\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0783 - acc: 0.4900\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0762 - acc: 0.5667\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0738 - acc: 0.6233\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0712 - acc: 0.6867\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0684 - acc: 0.7267\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0655 - acc: 0.7583\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0625 - acc: 0.7700\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0595 - acc: 0.7750\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0564 - acc: 0.7950\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0534 - acc: 0.8067\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0504 - acc: 0.8117\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0476 - acc: 0.8150\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0449 - acc: 0.8183\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0425 - acc: 0.8217\n",
      "Training date and time : \n",
      "2020-09-07 17:21:20\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0933 - acc: 0.0317\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0916 - acc: 0.0450\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0901 - acc: 0.1000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0888 - acc: 0.1733\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0874 - acc: 0.2300\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0861 - acc: 0.2833\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0848 - acc: 0.3267\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0834 - acc: 0.3717\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0820 - acc: 0.4100\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0805 - acc: 0.4433\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0789 - acc: 0.4733\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0772 - acc: 0.5017\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0753 - acc: 0.5250\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0734 - acc: 0.5517\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0713 - acc: 0.5667\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0692 - acc: 0.5750\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0670 - acc: 0.5850\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0648 - acc: 0.5917\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0626 - acc: 0.6067\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0605 - acc: 0.6250\n",
      "Training date and time : \n",
      "2020-09-07 17:21:52\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0874 - acc: 0.2233\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0859 - acc: 0.2633\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0843 - acc: 0.2983\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0826 - acc: 0.3317\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0807 - acc: 0.3700\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0786 - acc: 0.4417\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0762 - acc: 0.5133\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0734 - acc: 0.5800\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0705 - acc: 0.6417\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0673 - acc: 0.6800\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0641 - acc: 0.7283\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0607 - acc: 0.7567\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0573 - acc: 0.7817\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0539 - acc: 0.8133\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0504 - acc: 0.8267\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0471 - acc: 0.8333\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0438 - acc: 0.8417\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0408 - acc: 0.8500\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0380 - acc: 0.8500\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0355 - acc: 0.8517\n",
      "Training date and time : \n",
      "2020-09-07 17:21:59\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0932 - acc: 0.0283\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0911 - acc: 0.0900\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0894 - acc: 0.1717\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0877 - acc: 0.2433\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0862 - acc: 0.3017\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0846 - acc: 0.3400\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0831 - acc: 0.3700\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0816 - acc: 0.3833\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0800 - acc: 0.4067\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0784 - acc: 0.4417\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0766 - acc: 0.4917\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0748 - acc: 0.5133\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0729 - acc: 0.5450\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0707 - acc: 0.5700\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0684 - acc: 0.6033\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0660 - acc: 0.6200\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0635 - acc: 0.6550\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0609 - acc: 0.6633\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0584 - acc: 0.6867\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0558 - acc: 0.7050\n",
      "Training date and time : \n",
      "2020-09-07 17:22:31\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0868 - acc: 0.2267\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0849 - acc: 0.2500\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0828 - acc: 0.2750\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0804 - acc: 0.3267\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0775 - acc: 0.4317\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0742 - acc: 0.5417\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0706 - acc: 0.5650\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0671 - acc: 0.5933\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0636 - acc: 0.6400\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0602 - acc: 0.6817\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0568 - acc: 0.7450\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0533 - acc: 0.8083\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0498 - acc: 0.8383\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0463 - acc: 0.8683\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0427 - acc: 0.8833\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0393 - acc: 0.8933\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0361 - acc: 0.8950\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0331 - acc: 0.9033\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0304 - acc: 0.9050\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0280 - acc: 0.9150\n",
      "Training date and time : \n",
      "2020-09-07 17:22:38\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0933 - acc: 0.0067\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0911 - acc: 0.0500\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0892 - acc: 0.1517\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0873 - acc: 0.2583\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0855 - acc: 0.3450\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0837 - acc: 0.3950\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0819 - acc: 0.4233\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0801 - acc: 0.4633\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.0781 - acc: 0.5150\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0760 - acc: 0.5633\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0737 - acc: 0.6133\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0713 - acc: 0.6417\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0687 - acc: 0.6633\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0660 - acc: 0.6783\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0633 - acc: 0.6933\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0605 - acc: 0.7083\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0577 - acc: 0.7183\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0551 - acc: 0.7217\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0526 - acc: 0.7250\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0502 - acc: 0.7383\n",
      "------------- 3th experiment -------------\n",
      "Training date and time : \n",
      "2020-09-07 17:23:11\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0905 - acc: 0.1200\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 83us/sample - loss: 0.0899 - acc: 0.1333\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 83us/sample - loss: 0.0894 - acc: 0.1450\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0890 - acc: 0.1467\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0885 - acc: 0.1567\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 81us/sample - loss: 0.0881 - acc: 0.1850\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0877 - acc: 0.2133\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0872 - acc: 0.2333\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0868 - acc: 0.2533\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0863 - acc: 0.2817\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0859 - acc: 0.3250\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0854 - acc: 0.3550\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0849 - acc: 0.3800\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0843 - acc: 0.4133\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0838 - acc: 0.4350\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0832 - acc: 0.4467\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0825 - acc: 0.4650\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0819 - acc: 0.4700\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0812 - acc: 0.4933\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0805 - acc: 0.5150\n",
      "Training date and time : \n",
      "2020-09-07 17:23:18\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0909 - acc: 0.1033\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0903 - acc: 0.1167\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0897 - acc: 0.1250\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0891 - acc: 0.1367\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0886 - acc: 0.1667\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0881 - acc: 0.1867\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0876 - acc: 0.2217\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0870 - acc: 0.2667\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0865 - acc: 0.2983\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0859 - acc: 0.3367\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0853 - acc: 0.3683\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0847 - acc: 0.4017\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0840 - acc: 0.4167\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0834 - acc: 0.4350\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0827 - acc: 0.4450\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0819 - acc: 0.4533\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0812 - acc: 0.4533\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0804 - acc: 0.4800\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0797 - acc: 0.4850\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0789 - acc: 0.5000\n",
      "Training date and time : \n",
      "2020-09-07 17:23:51\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0903 - acc: 0.1217\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0896 - acc: 0.1333\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0889 - acc: 0.1450\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0883 - acc: 0.1667\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0877 - acc: 0.2000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0871 - acc: 0.2383\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0865 - acc: 0.2800\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0858 - acc: 0.3100\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0851 - acc: 0.3383\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0844 - acc: 0.3700\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0836 - acc: 0.3983\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0828 - acc: 0.4133\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0819 - acc: 0.4333\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0811 - acc: 0.4483\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0802 - acc: 0.4650\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0794 - acc: 0.4783\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0785 - acc: 0.4850\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0776 - acc: 0.5000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0767 - acc: 0.5117\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0758 - acc: 0.5183\n",
      "Training date and time : \n",
      "2020-09-07 17:23:58\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0909 - acc: 0.1150\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0903 - acc: 0.1183\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0898 - acc: 0.1300\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0893 - acc: 0.1367\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0889 - acc: 0.1450\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0884 - acc: 0.1583\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0880 - acc: 0.1667\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 84us/sample - loss: 0.0876 - acc: 0.1833\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0871 - acc: 0.2067\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0867 - acc: 0.2183\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0863 - acc: 0.2600\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0858 - acc: 0.3000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0853 - acc: 0.3383\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0849 - acc: 0.3633\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0844 - acc: 0.3867\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0839 - acc: 0.4133\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0833 - acc: 0.4450\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0828 - acc: 0.4950\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0822 - acc: 0.5183\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0816 - acc: 0.5450\n",
      "Training date and time : \n",
      "2020-09-07 17:24:31\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0899 - acc: 0.1383\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0893 - acc: 0.1483\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0886 - acc: 0.1717\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0880 - acc: 0.1750\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0874 - acc: 0.1983\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0867 - acc: 0.2367\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0860 - acc: 0.2767\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0853 - acc: 0.3267\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0845 - acc: 0.3683\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0836 - acc: 0.4033\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0827 - acc: 0.4117\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0818 - acc: 0.4233\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0809 - acc: 0.4350\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0800 - acc: 0.4450\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0790 - acc: 0.4617\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0781 - acc: 0.4700\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0771 - acc: 0.4833\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0762 - acc: 0.4950\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0752 - acc: 0.5117\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0742 - acc: 0.5317\n",
      "Training date and time : \n",
      "2020-09-07 17:24:38\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0914 - acc: 0.0917\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0906 - acc: 0.0933\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0899 - acc: 0.1067\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0893 - acc: 0.1300\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0887 - acc: 0.1600\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0882 - acc: 0.1967\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0876 - acc: 0.2217\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0871 - acc: 0.2433\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0866 - acc: 0.2750\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0861 - acc: 0.3083\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0856 - acc: 0.3150\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0851 - acc: 0.3483\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0846 - acc: 0.3767\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0841 - acc: 0.3850\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0835 - acc: 0.3917\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0830 - acc: 0.4033\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0824 - acc: 0.4183\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0817 - acc: 0.4267\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0811 - acc: 0.4483\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0804 - acc: 0.4700\n",
      "Training date and time : \n",
      "2020-09-07 17:25:11\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0904 - acc: 0.1117\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0895 - acc: 0.1150\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0888 - acc: 0.1467\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0881 - acc: 0.1600\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0873 - acc: 0.1917\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0865 - acc: 0.2400\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0857 - acc: 0.2950\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0848 - acc: 0.3583\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0839 - acc: 0.4117\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0829 - acc: 0.4583\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0818 - acc: 0.4683\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0808 - acc: 0.4717\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0797 - acc: 0.4933\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0785 - acc: 0.5017\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0774 - acc: 0.5150\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0762 - acc: 0.5267\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0750 - acc: 0.5367\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0738 - acc: 0.5517\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0726 - acc: 0.5650\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0713 - acc: 0.5683\n",
      "Training date and time : \n",
      "2020-09-07 17:25:18\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0912 - acc: 0.0950\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0903 - acc: 0.1067\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0896 - acc: 0.1317\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0890 - acc: 0.1750\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0884 - acc: 0.2017\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0878 - acc: 0.2317\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0873 - acc: 0.2467\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0867 - acc: 0.2517\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0862 - acc: 0.2683\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0856 - acc: 0.2883\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0851 - acc: 0.2917\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0845 - acc: 0.3117\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0839 - acc: 0.3167\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0833 - acc: 0.3317\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0827 - acc: 0.3400\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0821 - acc: 0.3667\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0814 - acc: 0.3867\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0806 - acc: 0.4183\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0799 - acc: 0.4333\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0791 - acc: 0.4500\n",
      "Training date and time : \n",
      "2020-09-07 17:25:52\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0887 - acc: 0.1633\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0880 - acc: 0.1733\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0874 - acc: 0.1833\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0867 - acc: 0.2083\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 81us/sample - loss: 0.0860 - acc: 0.2317\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0853 - acc: 0.2567\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0845 - acc: 0.2867\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0837 - acc: 0.3167\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0829 - acc: 0.3467\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0819 - acc: 0.3783\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0809 - acc: 0.4267\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0799 - acc: 0.4750\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0788 - acc: 0.5150\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0776 - acc: 0.5283\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0764 - acc: 0.5450\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0751 - acc: 0.5667\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0738 - acc: 0.5750\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0724 - acc: 0.5817\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0710 - acc: 0.6017\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0695 - acc: 0.6050\n",
      "Training date and time : \n",
      "2020-09-07 17:25:59\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0924 - acc: 0.0550\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0913 - acc: 0.0600\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0904 - acc: 0.0917\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0896 - acc: 0.1317\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0889 - acc: 0.1617\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0882 - acc: 0.2033\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0875 - acc: 0.2250\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0869 - acc: 0.2433\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0862 - acc: 0.2750\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0854 - acc: 0.3000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0847 - acc: 0.3367\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0839 - acc: 0.3483\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0831 - acc: 0.3633\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0823 - acc: 0.3800\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0814 - acc: 0.3917\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0804 - acc: 0.4033\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0795 - acc: 0.4050\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0785 - acc: 0.4133\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0774 - acc: 0.4233\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0764 - acc: 0.4333\n",
      "Training date and time : \n",
      "2020-09-07 17:26:33\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0892 - acc: 0.1867\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0882 - acc: 0.1967\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0873 - acc: 0.2067\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0862 - acc: 0.2300\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0850 - acc: 0.2767\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0836 - acc: 0.3617\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0821 - acc: 0.4133\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0804 - acc: 0.4483\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0787 - acc: 0.4483\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0770 - acc: 0.4567\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0754 - acc: 0.4733\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0739 - acc: 0.4933\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0724 - acc: 0.5150\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0710 - acc: 0.5467\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0695 - acc: 0.5683\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0681 - acc: 0.5833\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 77us/sample - loss: 0.0667 - acc: 0.6033\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0653 - acc: 0.6183\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0639 - acc: 0.6383\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0625 - acc: 0.6600\n",
      "Training date and time : \n",
      "2020-09-07 17:26:40\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0925 - acc: 0.0433\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0912 - acc: 0.0667\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0901 - acc: 0.1067\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0892 - acc: 0.1583\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0883 - acc: 0.2033\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0875 - acc: 0.2333\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0866 - acc: 0.2650\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0858 - acc: 0.2900\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0850 - acc: 0.3133\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0842 - acc: 0.3233\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0834 - acc: 0.3383\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0825 - acc: 0.3433\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0817 - acc: 0.3617\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0808 - acc: 0.3767\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0798 - acc: 0.4000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0789 - acc: 0.4233\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0779 - acc: 0.4517\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0768 - acc: 0.4783\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0758 - acc: 0.5017\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0746 - acc: 0.5350\n",
      "Training date and time : \n",
      "2020-09-07 17:27:15\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0881 - acc: 0.1883\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0870 - acc: 0.2167\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0860 - acc: 0.2417\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 79us/sample - loss: 0.0848 - acc: 0.2767\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0836 - acc: 0.3017\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0823 - acc: 0.3400\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0809 - acc: 0.3950\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0794 - acc: 0.4733\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0777 - acc: 0.5300\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0759 - acc: 0.5767\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0740 - acc: 0.6133\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0719 - acc: 0.6450\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0696 - acc: 0.6767\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0672 - acc: 0.6917\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0648 - acc: 0.7067\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0623 - acc: 0.7150\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0598 - acc: 0.7217\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0574 - acc: 0.7383\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 75us/sample - loss: 0.0550 - acc: 0.7433\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0528 - acc: 0.7467\n",
      "Training date and time : \n",
      "2020-09-07 17:27:22\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0928 - acc: 0.0450\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0914 - acc: 0.0633\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0902 - acc: 0.1067\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0891 - acc: 0.1750\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0881 - acc: 0.2217\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0872 - acc: 0.2483\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0862 - acc: 0.2683\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0853 - acc: 0.2850\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0844 - acc: 0.3000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0835 - acc: 0.3083\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0825 - acc: 0.3350\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0815 - acc: 0.3517\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0805 - acc: 0.3867\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0794 - acc: 0.4233\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0782 - acc: 0.4517\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0769 - acc: 0.4850\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0756 - acc: 0.5167\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0742 - acc: 0.5333\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0727 - acc: 0.5683\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0712 - acc: 0.5717\n",
      "Training date and time : \n",
      "2020-09-07 17:27:58\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0875 - acc: 0.2200\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0863 - acc: 0.2467\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0851 - acc: 0.2817\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0837 - acc: 0.3133\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0823 - acc: 0.3533\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0806 - acc: 0.3933\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0788 - acc: 0.4500\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0768 - acc: 0.5150\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0746 - acc: 0.5450\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0722 - acc: 0.5750\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0698 - acc: 0.5933\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0673 - acc: 0.6150\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0649 - acc: 0.6217\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0625 - acc: 0.6350\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0602 - acc: 0.6350\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 81us/sample - loss: 0.0579 - acc: 0.6550\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 77us/sample - loss: 0.0559 - acc: 0.6667\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0539 - acc: 0.6867\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.0520 - acc: 0.7000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0502 - acc: 0.7083\n",
      "Training date and time : \n",
      "2020-09-07 17:28:05\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0923 - acc: 0.0467\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0910 - acc: 0.0617\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0898 - acc: 0.1250\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0887 - acc: 0.1767\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0877 - acc: 0.2200\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0868 - acc: 0.2533\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0858 - acc: 0.2733\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0849 - acc: 0.2800\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0839 - acc: 0.2933\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0829 - acc: 0.3017\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0819 - acc: 0.3150\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0809 - acc: 0.3383\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0798 - acc: 0.3583\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0787 - acc: 0.3933\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0775 - acc: 0.4367\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0762 - acc: 0.4617\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0748 - acc: 0.4967\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0733 - acc: 0.5217\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0717 - acc: 0.5383\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0701 - acc: 0.5667\n",
      "Training date and time : \n",
      "2020-09-07 17:28:40\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0876 - acc: 0.1983\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0863 - acc: 0.2150\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0850 - acc: 0.2383\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0836 - acc: 0.2817\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0820 - acc: 0.3400\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0803 - acc: 0.4100\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0783 - acc: 0.4900\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0762 - acc: 0.5667\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0738 - acc: 0.6233\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0712 - acc: 0.6867\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0684 - acc: 0.7267\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0655 - acc: 0.7583\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0625 - acc: 0.7700\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0595 - acc: 0.7750\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0564 - acc: 0.7950\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0534 - acc: 0.8067\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0504 - acc: 0.8117\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0476 - acc: 0.8150\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0449 - acc: 0.8183\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0425 - acc: 0.8217\n",
      "Training date and time : \n",
      "2020-09-07 17:28:47\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0933 - acc: 0.0317\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0916 - acc: 0.0450\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0901 - acc: 0.1000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0888 - acc: 0.1733\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0874 - acc: 0.2300\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0861 - acc: 0.2833\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0848 - acc: 0.3267\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0834 - acc: 0.3717\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0820 - acc: 0.4100\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0805 - acc: 0.4433\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0789 - acc: 0.4733\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0772 - acc: 0.5017\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0753 - acc: 0.5250\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0734 - acc: 0.5517\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0713 - acc: 0.5667\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.0692 - acc: 0.5750\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0670 - acc: 0.5850\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0648 - acc: 0.5917\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0626 - acc: 0.6067\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0605 - acc: 0.6250\n",
      "Training date and time : \n",
      "2020-09-07 17:29:22\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 1ms/sample - loss: 0.0874 - acc: 0.2233\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0859 - acc: 0.2633\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0843 - acc: 0.2983\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0826 - acc: 0.3317\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0807 - acc: 0.3700\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0786 - acc: 0.4417\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0762 - acc: 0.5133\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0734 - acc: 0.5800\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0705 - acc: 0.6417\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0673 - acc: 0.6800\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0641 - acc: 0.7283\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0607 - acc: 0.7567\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0573 - acc: 0.7817\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0539 - acc: 0.8133\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0504 - acc: 0.8267\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0471 - acc: 0.8333\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0438 - acc: 0.8417\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0408 - acc: 0.8500\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0380 - acc: 0.8500\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0355 - acc: 0.8517\n",
      "Training date and time : \n",
      "2020-09-07 17:29:29\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0932 - acc: 0.0283\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0911 - acc: 0.0900\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0894 - acc: 0.1717\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0877 - acc: 0.2433\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0862 - acc: 0.3017\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0846 - acc: 0.3400\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0831 - acc: 0.3700\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0816 - acc: 0.3833\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0800 - acc: 0.4067\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0784 - acc: 0.4417\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0766 - acc: 0.4917\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0748 - acc: 0.5133\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0729 - acc: 0.5450\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0707 - acc: 0.5700\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 77us/sample - loss: 0.0684 - acc: 0.6033\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0660 - acc: 0.6200\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 77us/sample - loss: 0.0635 - acc: 0.6550\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0609 - acc: 0.6633\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0584 - acc: 0.6867\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0558 - acc: 0.7050\n",
      "Training date and time : \n",
      "2020-09-07 17:30:04\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0868 - acc: 0.2267\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0849 - acc: 0.2500\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0828 - acc: 0.2750\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0804 - acc: 0.3267\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0775 - acc: 0.4317\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0742 - acc: 0.5417\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0706 - acc: 0.5650\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0671 - acc: 0.5933\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0636 - acc: 0.6400\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0602 - acc: 0.6817\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0568 - acc: 0.7450\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0533 - acc: 0.8083\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0498 - acc: 0.8383\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0463 - acc: 0.8683\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0427 - acc: 0.8833\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0393 - acc: 0.8933\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0361 - acc: 0.8950\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0331 - acc: 0.9033\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0304 - acc: 0.9050\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0280 - acc: 0.9150\n",
      "Training date and time : \n",
      "2020-09-07 17:30:11\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0933 - acc: 0.0067\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0911 - acc: 0.0500\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0892 - acc: 0.1517\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0873 - acc: 0.2583\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0855 - acc: 0.3450\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0837 - acc: 0.3950\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0819 - acc: 0.4233\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0801 - acc: 0.4633\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0781 - acc: 0.5150\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0760 - acc: 0.5633\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0737 - acc: 0.6133\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0713 - acc: 0.6417\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0687 - acc: 0.6633\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0660 - acc: 0.6783\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0633 - acc: 0.6933\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0605 - acc: 0.7083\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0577 - acc: 0.7183\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0551 - acc: 0.7217\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0526 - acc: 0.7250\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0502 - acc: 0.7383\n",
      "------------- 4th experiment -------------\n",
      "Training date and time : \n",
      "2020-09-07 17:30:47\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0905 - acc: 0.1200\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0899 - acc: 0.1333\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0894 - acc: 0.1450\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0890 - acc: 0.1467\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0885 - acc: 0.1567\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0881 - acc: 0.1850\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0877 - acc: 0.2133\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0872 - acc: 0.2333\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0868 - acc: 0.2533\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0863 - acc: 0.2817\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0859 - acc: 0.3250\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0854 - acc: 0.3550\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0849 - acc: 0.3800\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0843 - acc: 0.4133\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 75us/sample - loss: 0.0838 - acc: 0.4350\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0832 - acc: 0.4467\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 77us/sample - loss: 0.0825 - acc: 0.4650\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0819 - acc: 0.4700\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 79us/sample - loss: 0.0812 - acc: 0.4933\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0805 - acc: 0.5150\n",
      "Training date and time : \n",
      "2020-09-07 17:30:54\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0909 - acc: 0.1033\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 84us/sample - loss: 0.0903 - acc: 0.1167\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 121us/sample - loss: 0.0897 - acc: 0.1250\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 140us/sample - loss: 0.0891 - acc: 0.1367\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 117us/sample - loss: 0.0886 - acc: 0.1667\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0881 - acc: 0.1867\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0876 - acc: 0.2217\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0870 - acc: 0.2667\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 129us/sample - loss: 0.0865 - acc: 0.2983\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 117us/sample - loss: 0.0859 - acc: 0.3367\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0853 - acc: 0.3683\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0847 - acc: 0.4017\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0840 - acc: 0.4167\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0834 - acc: 0.4350\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 128us/sample - loss: 0.0827 - acc: 0.4450\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0819 - acc: 0.4533\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0812 - acc: 0.4533\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 75us/sample - loss: 0.0804 - acc: 0.4800\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0797 - acc: 0.4850\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0789 - acc: 0.5000\n",
      "Training date and time : \n",
      "2020-09-07 17:31:31\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0903 - acc: 0.1217\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0896 - acc: 0.1333\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0889 - acc: 0.1450\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0883 - acc: 0.1667\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0877 - acc: 0.2000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.0871 - acc: 0.2383\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0865 - acc: 0.2800\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0858 - acc: 0.3100\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0851 - acc: 0.3383\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0844 - acc: 0.3700\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 79us/sample - loss: 0.0836 - acc: 0.3983\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0828 - acc: 0.4133\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0819 - acc: 0.4333\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0811 - acc: 0.4483\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0802 - acc: 0.4650\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0794 - acc: 0.4783\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0785 - acc: 0.4850\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0776 - acc: 0.5000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0767 - acc: 0.5117\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0758 - acc: 0.5183\n",
      "Training date and time : \n",
      "2020-09-07 17:31:39\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0909 - acc: 0.1150\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0903 - acc: 0.1183\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 81us/sample - loss: 0.0898 - acc: 0.1300\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0893 - acc: 0.1367\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 75us/sample - loss: 0.0889 - acc: 0.1450\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0884 - acc: 0.1583\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0880 - acc: 0.1667\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 75us/sample - loss: 0.0876 - acc: 0.1833\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0871 - acc: 0.2067\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0867 - acc: 0.2183\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0863 - acc: 0.2600\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0858 - acc: 0.3000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0853 - acc: 0.3383\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0849 - acc: 0.3633\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0844 - acc: 0.3867\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0839 - acc: 0.4133\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0833 - acc: 0.4450\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0828 - acc: 0.4950\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 85us/sample - loss: 0.0822 - acc: 0.5183\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0816 - acc: 0.5450\n",
      "Training date and time : \n",
      "2020-09-07 17:32:15\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0899 - acc: 0.1383\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0893 - acc: 0.1483\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0886 - acc: 0.1717\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0880 - acc: 0.1750\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0874 - acc: 0.1983\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0867 - acc: 0.2367\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0860 - acc: 0.2767\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0853 - acc: 0.3267\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0845 - acc: 0.3683\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0836 - acc: 0.4033\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0827 - acc: 0.4117\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0818 - acc: 0.4233\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0809 - acc: 0.4350\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0800 - acc: 0.4450\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0790 - acc: 0.4617\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0781 - acc: 0.4700\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0771 - acc: 0.4833\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0762 - acc: 0.4950\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0752 - acc: 0.5117\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0742 - acc: 0.5317\n",
      "Training date and time : \n",
      "2020-09-07 17:32:23\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0914 - acc: 0.0917\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0906 - acc: 0.0933\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0899 - acc: 0.1067\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0893 - acc: 0.1300\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0887 - acc: 0.1600\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0882 - acc: 0.1967\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0876 - acc: 0.2217\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0871 - acc: 0.2433\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0866 - acc: 0.2750\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0861 - acc: 0.3083\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0856 - acc: 0.3150\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0851 - acc: 0.3483\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0846 - acc: 0.3767\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0841 - acc: 0.3850\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0835 - acc: 0.3917\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0830 - acc: 0.4033\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0824 - acc: 0.4183\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0817 - acc: 0.4267\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0811 - acc: 0.4483\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0804 - acc: 0.4700\n",
      "Training date and time : \n",
      "2020-09-07 17:33:00\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0904 - acc: 0.1117\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0895 - acc: 0.1150\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0888 - acc: 0.1467\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0881 - acc: 0.1600\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0873 - acc: 0.1917\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0865 - acc: 0.2400\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0857 - acc: 0.2950\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0848 - acc: 0.3583\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0839 - acc: 0.4117\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0829 - acc: 0.4583\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0818 - acc: 0.4683\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0808 - acc: 0.4717\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0797 - acc: 0.4933\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0785 - acc: 0.5017\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0774 - acc: 0.5150\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0762 - acc: 0.5267\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0750 - acc: 0.5367\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0738 - acc: 0.5517\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0726 - acc: 0.5650\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0713 - acc: 0.5683\n",
      "Training date and time : \n",
      "2020-09-07 17:33:08\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0912 - acc: 0.0950\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0903 - acc: 0.1067\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0896 - acc: 0.1317\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0890 - acc: 0.1750\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0884 - acc: 0.2017\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0878 - acc: 0.2317\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0873 - acc: 0.2467\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0867 - acc: 0.2517\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0862 - acc: 0.2683\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0856 - acc: 0.2883\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0851 - acc: 0.2917\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0845 - acc: 0.3117\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0839 - acc: 0.3167\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0833 - acc: 0.3317\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0827 - acc: 0.3400\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0821 - acc: 0.3667\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0814 - acc: 0.3867\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0806 - acc: 0.4183\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0799 - acc: 0.4333\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0791 - acc: 0.4500\n",
      "Training date and time : \n",
      "2020-09-07 17:33:46\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0887 - acc: 0.1633\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0880 - acc: 0.1733\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0874 - acc: 0.1833\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0867 - acc: 0.2083\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0860 - acc: 0.2317\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0853 - acc: 0.2567\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0845 - acc: 0.2867\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0837 - acc: 0.3167\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0829 - acc: 0.3467\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0819 - acc: 0.3783\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0809 - acc: 0.4267\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0799 - acc: 0.4750\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0788 - acc: 0.5150\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0776 - acc: 0.5283\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0764 - acc: 0.5450\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0751 - acc: 0.5667\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0738 - acc: 0.5750\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0724 - acc: 0.5817\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0710 - acc: 0.6017\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0695 - acc: 0.6050\n",
      "Training date and time : \n",
      "2020-09-07 17:33:53\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0924 - acc: 0.0550\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0913 - acc: 0.0600\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0904 - acc: 0.0917\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0896 - acc: 0.1317\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0889 - acc: 0.1617\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0882 - acc: 0.2033\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0875 - acc: 0.2250\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0869 - acc: 0.2433\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0862 - acc: 0.2750\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0854 - acc: 0.3000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0847 - acc: 0.3367\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0839 - acc: 0.3483\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0831 - acc: 0.3633\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0823 - acc: 0.3800\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0814 - acc: 0.3917\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0804 - acc: 0.4033\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0795 - acc: 0.4050\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0785 - acc: 0.4133\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0774 - acc: 0.4233\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0764 - acc: 0.4333\n",
      "Training date and time : \n",
      "2020-09-07 17:34:31\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0892 - acc: 0.1867\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0882 - acc: 0.1967\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0873 - acc: 0.2067\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0862 - acc: 0.2300\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0850 - acc: 0.2767\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0836 - acc: 0.3617\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0821 - acc: 0.4133\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0804 - acc: 0.4483\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0787 - acc: 0.4483\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0770 - acc: 0.4567\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0754 - acc: 0.4733\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0739 - acc: 0.4933\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0724 - acc: 0.5150\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0710 - acc: 0.5467\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0695 - acc: 0.5683\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0681 - acc: 0.5833\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0667 - acc: 0.6033\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0653 - acc: 0.6183\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0639 - acc: 0.6383\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0625 - acc: 0.6600\n",
      "Training date and time : \n",
      "2020-09-07 17:34:38\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0925 - acc: 0.0433\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0912 - acc: 0.0667\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0901 - acc: 0.1067\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0892 - acc: 0.1583\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0883 - acc: 0.2033\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0875 - acc: 0.2333\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0866 - acc: 0.2650\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0858 - acc: 0.2900\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0850 - acc: 0.3133\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0842 - acc: 0.3233\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0834 - acc: 0.3383\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0825 - acc: 0.3433\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0817 - acc: 0.3617\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0808 - acc: 0.3767\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0798 - acc: 0.4000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.0789 - acc: 0.4233\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0779 - acc: 0.4517\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0768 - acc: 0.4783\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0758 - acc: 0.5017\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0746 - acc: 0.5350\n",
      "Training date and time : \n",
      "2020-09-07 17:35:16\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0881 - acc: 0.1883\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0870 - acc: 0.2167\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0860 - acc: 0.2417\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0848 - acc: 0.2767\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0836 - acc: 0.3017\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0823 - acc: 0.3400\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0809 - acc: 0.3950\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0794 - acc: 0.4733\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0777 - acc: 0.5300\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0759 - acc: 0.5767\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0740 - acc: 0.6133\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0719 - acc: 0.6450\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0696 - acc: 0.6767\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0672 - acc: 0.6917\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0648 - acc: 0.7067\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0623 - acc: 0.7150\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0598 - acc: 0.7217\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0574 - acc: 0.7383\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0550 - acc: 0.7433\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0528 - acc: 0.7467\n",
      "Training date and time : \n",
      "2020-09-07 17:35:24\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0928 - acc: 0.0450\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0914 - acc: 0.0633\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0902 - acc: 0.1067\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0891 - acc: 0.1750\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0881 - acc: 0.2217\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0872 - acc: 0.2483\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0862 - acc: 0.2683\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0853 - acc: 0.2850\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0844 - acc: 0.3000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0835 - acc: 0.3083\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0825 - acc: 0.3350\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0815 - acc: 0.3517\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 79us/sample - loss: 0.0805 - acc: 0.3867\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 77us/sample - loss: 0.0794 - acc: 0.4233\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0782 - acc: 0.4517\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 77us/sample - loss: 0.0769 - acc: 0.4850\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0756 - acc: 0.5167\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0742 - acc: 0.5333\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0727 - acc: 0.5683\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0712 - acc: 0.5717\n",
      "Training date and time : \n",
      "2020-09-07 17:36:02\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0875 - acc: 0.2200\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0863 - acc: 0.2467\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0851 - acc: 0.2817\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0837 - acc: 0.3133\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0823 - acc: 0.3533\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0806 - acc: 0.3933\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0788 - acc: 0.4500\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0768 - acc: 0.5150\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0746 - acc: 0.5450\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0722 - acc: 0.5750\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0698 - acc: 0.5933\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0673 - acc: 0.6150\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0649 - acc: 0.6217\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0625 - acc: 0.6350\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0602 - acc: 0.6350\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0579 - acc: 0.6550\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0559 - acc: 0.6667\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0539 - acc: 0.6867\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0520 - acc: 0.7000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0502 - acc: 0.7083\n",
      "Training date and time : \n",
      "2020-09-07 17:36:09\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0923 - acc: 0.0467\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0910 - acc: 0.0617\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0898 - acc: 0.1250\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0887 - acc: 0.1767\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0877 - acc: 0.2200\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0868 - acc: 0.2533\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 74us/sample - loss: 0.0858 - acc: 0.2733\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0849 - acc: 0.2800\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0839 - acc: 0.2933\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0829 - acc: 0.3017\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0819 - acc: 0.3150\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0809 - acc: 0.3383\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0798 - acc: 0.3583\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0787 - acc: 0.3933\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.0775 - acc: 0.4367\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.0762 - acc: 0.4617\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0748 - acc: 0.4967\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0733 - acc: 0.5217\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0717 - acc: 0.5383\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0701 - acc: 0.5667\n",
      "Training date and time : \n",
      "2020-09-07 17:36:48\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0876 - acc: 0.1983\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0863 - acc: 0.2150\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0850 - acc: 0.2383\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0836 - acc: 0.2817\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0820 - acc: 0.3400\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0803 - acc: 0.4100\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0783 - acc: 0.4900\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0762 - acc: 0.5667\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0738 - acc: 0.6233\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0712 - acc: 0.6867\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.0684 - acc: 0.7267\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0655 - acc: 0.7583\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0625 - acc: 0.7700\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0595 - acc: 0.7750\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0564 - acc: 0.7950\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0534 - acc: 0.8067\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0504 - acc: 0.8117\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0476 - acc: 0.8150\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0449 - acc: 0.8183\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0425 - acc: 0.8217\n",
      "Training date and time : \n",
      "2020-09-07 17:36:55\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0933 - acc: 0.0317\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0916 - acc: 0.0450\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0901 - acc: 0.1000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0888 - acc: 0.1733\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0874 - acc: 0.2300\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0861 - acc: 0.2833\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0848 - acc: 0.3267\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0834 - acc: 0.3717\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0820 - acc: 0.4100\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0805 - acc: 0.4433\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0789 - acc: 0.4733\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0772 - acc: 0.5017\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0753 - acc: 0.5250\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0734 - acc: 0.5517\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0713 - acc: 0.5667\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0692 - acc: 0.5750\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0670 - acc: 0.5850\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0648 - acc: 0.5917\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0626 - acc: 0.6067\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0605 - acc: 0.6250\n",
      "Training date and time : \n",
      "2020-09-07 17:37:34\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0874 - acc: 0.2233\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0859 - acc: 0.2633\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0843 - acc: 0.2983\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0826 - acc: 0.3317\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0807 - acc: 0.3700\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0786 - acc: 0.4417\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 75us/sample - loss: 0.0762 - acc: 0.5133\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0734 - acc: 0.5800\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0705 - acc: 0.6417\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0673 - acc: 0.6800\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 76us/sample - loss: 0.0641 - acc: 0.7283\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0607 - acc: 0.7567\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0573 - acc: 0.7817\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0539 - acc: 0.8133\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0504 - acc: 0.8267\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0471 - acc: 0.8333\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0438 - acc: 0.8417\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0408 - acc: 0.8500\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0380 - acc: 0.8500\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0355 - acc: 0.8517\n",
      "Training date and time : \n",
      "2020-09-07 17:37:42\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0932 - acc: 0.0283\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0911 - acc: 0.0900\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0894 - acc: 0.1717\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0877 - acc: 0.2433\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0862 - acc: 0.3017\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0846 - acc: 0.3400\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0831 - acc: 0.3700\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 71us/sample - loss: 0.0816 - acc: 0.3833\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0800 - acc: 0.4067\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0784 - acc: 0.4417\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0766 - acc: 0.4917\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 73us/sample - loss: 0.0748 - acc: 0.5133\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0729 - acc: 0.5450\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0707 - acc: 0.5700\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0684 - acc: 0.6033\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0660 - acc: 0.6200\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0635 - acc: 0.6550\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0609 - acc: 0.6633\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0584 - acc: 0.6867\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0558 - acc: 0.7050\n",
      "Training date and time : \n",
      "2020-09-07 17:38:21\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0868 - acc: 0.2267\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0849 - acc: 0.2500\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.0828 - acc: 0.2750\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0804 - acc: 0.3267\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0775 - acc: 0.4317\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0742 - acc: 0.5417\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0706 - acc: 0.5650\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0671 - acc: 0.5933\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0636 - acc: 0.6400\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0602 - acc: 0.6817\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0568 - acc: 0.7450\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0533 - acc: 0.8083\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 78us/sample - loss: 0.0498 - acc: 0.8383\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0463 - acc: 0.8683\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0427 - acc: 0.8833\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 70us/sample - loss: 0.0393 - acc: 0.8933\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 72us/sample - loss: 0.0361 - acc: 0.8950\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0331 - acc: 0.9033\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0304 - acc: 0.9050\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0280 - acc: 0.9150\n",
      "Training date and time : \n",
      "2020-09-07 17:38:28\n",
      "Train on 600 samples\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0933 - acc: 0.0067\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0911 - acc: 0.0500\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0892 - acc: 0.1517\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0873 - acc: 0.2583\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0855 - acc: 0.3450\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 66us/sample - loss: 0.0837 - acc: 0.3950\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0819 - acc: 0.4233\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 62us/sample - loss: 0.0801 - acc: 0.4633\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 68us/sample - loss: 0.0781 - acc: 0.5150\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0760 - acc: 0.5633\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0737 - acc: 0.6133\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0713 - acc: 0.6417\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 63us/sample - loss: 0.0687 - acc: 0.6633\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 60us/sample - loss: 0.0660 - acc: 0.6783\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 64us/sample - loss: 0.0633 - acc: 0.6933\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0605 - acc: 0.7083\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 67us/sample - loss: 0.0577 - acc: 0.7183\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 65us/sample - loss: 0.0551 - acc: 0.7217\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 69us/sample - loss: 0.0526 - acc: 0.7250\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 77us/sample - loss: 0.0502 - acc: 0.7383\n"
     ]
    }
   ],
   "source": [
    "res = multiple_experiments(get_losses_for_non_iid_spectrum, 5, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0774995 , 0.06750726, 0.0634514 , 0.06093475, 0.05733573,\n",
       "       0.05263903, 0.04174873, 0.04208819, 0.03487321, 0.03192197,\n",
       "       0.02948421])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['model_0to4']['test_0to4']['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as plot\n",
    "diff = list()\n",
    "for orig, aggr in zip(res['model_0to4']['test_0to4']['loss'], res['model_aggr']['test_0to4']['loss']):\n",
    "    diff.append(aggr - orig)\n",
    "plt.plot(np.arange(1, 0-0.1, -0.1), np.array(diff))\n",
    "plt.title(\"loss of an aggregated model - loss of an original 0to4 model\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"<-- (non-iid)   noise ratio   (iid) --->\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as plot\n",
    "diff = list()\n",
    "for orig, aggr in zip(res['model_5to9']['test_5to9']['loss'], res['model_aggr']['test_5to9']['loss']):\n",
    "    diff.append(aggr - orig)\n",
    "plt.plot(np.arange(1, 0-0.1, -0.1), np.array(diff))\n",
    "plt.title(\"loss of an aggregated model - loss of an original 5to9 model\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"<-- (non-iid)   noise ratio   (iid) --->\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as plot\n",
    "diff = list()\n",
    "for orig, aggr in zip(res['model_0to4']['test_all']['loss'], res['model_aggr']['test_all']['loss']):\n",
    "    diff.append(aggr - orig)\n",
    "plt.plot(np.arange(1, 0-0.1, -0.1), np.array(diff))\n",
    "plt.title(\"loss of an aggregated model - loss of an original 0to4 model\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"<-- (non-iid)   noise ratio   (iid) --->\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as plot\n",
    "diff = list()\n",
    "for orig, aggr in zip(res['model_5to9']['test_all']['loss'], res['model_aggr']['test_all']['loss']):\n",
    "    diff.append(aggr - orig)\n",
    "plt.plot(np.arange(1, 0-0.1, -0.1), np.array(diff))\n",
    "plt.title(\"loss of an aggregated model - loss of an original 5to9 model\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"<-- (non-iid)   noise ratio   (iid) --->\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between the 0to4 model and 5to9 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(res['model_0to4']['test_all']['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(res['model_5to9']['test_all']['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as plot\n",
    "plt.plot(np.arange(1, 0-0.1, -0.1), np.array([l[0] for l in hist_list]))\n",
    "plt.plot(np.arange(1, 0-0.1, -0.1), np.array([l[0] for l in hist0to4_list]))\n",
    "plt.plot(np.arange(1, 0-0.1, -0.1), np.array([l[0] for l in hist5to9_list]))\n",
    "plt.legend([\"all test\", \"0 - 4\", \"5 - 9\"])\n",
    "plt.title(\"loss of an aggregated model - loss of an original 0to4 model\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"<-- iid      noniid --->\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1 = custom_model()\n",
    "model2 = custom_model()\n",
    "model1.set_weights(init_model.get_weights())\n",
    "model2.set_weights(init_model.get_weights())\n",
    "compile_model(model1)\n",
    "compile_model(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_model(init_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training date and time : \n",
      "2020-09-01 09:14:11\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "900/900 [==============================] - 0s 150us/sample - loss: 0.0918 - acc: 0.0244 - val_loss: 0.0904 - val_acc: 0.0700\n",
      "Epoch 2/50\n",
      "900/900 [==============================] - 0s 44us/sample - loss: 0.0877 - acc: 0.2067 - val_loss: 0.0862 - val_acc: 0.2800\n",
      "Epoch 3/50\n",
      "900/900 [==============================] - 0s 44us/sample - loss: 0.0830 - acc: 0.4111 - val_loss: 0.0815 - val_acc: 0.3800\n",
      "Epoch 4/50\n",
      "900/900 [==============================] - 0s 44us/sample - loss: 0.0779 - acc: 0.4978 - val_loss: 0.0765 - val_acc: 0.4700\n",
      "Epoch 5/50\n",
      "900/900 [==============================] - 0s 40us/sample - loss: 0.0726 - acc: 0.5233 - val_loss: 0.0718 - val_acc: 0.4500\n",
      "Epoch 6/50\n",
      "900/900 [==============================] - 0s 43us/sample - loss: 0.0678 - acc: 0.5267 - val_loss: 0.0677 - val_acc: 0.4700\n",
      "Epoch 7/50\n",
      "900/900 [==============================] - 0s 40us/sample - loss: 0.0638 - acc: 0.5344 - val_loss: 0.0644 - val_acc: 0.4700\n",
      "Epoch 8/50\n",
      "900/900 [==============================] - 0s 38us/sample - loss: 0.0607 - acc: 0.5289 - val_loss: 0.0619 - val_acc: 0.4800\n",
      "Epoch 9/50\n",
      "900/900 [==============================] - 0s 40us/sample - loss: 0.0583 - acc: 0.5356 - val_loss: 0.0600 - val_acc: 0.4700\n",
      "Epoch 10/50\n",
      "900/900 [==============================] - 0s 43us/sample - loss: 0.0566 - acc: 0.5322 - val_loss: 0.0586 - val_acc: 0.4600\n",
      "Epoch 11/50\n",
      "900/900 [==============================] - 0s 42us/sample - loss: 0.0552 - acc: 0.5422 - val_loss: 0.0576 - val_acc: 0.4600\n",
      "Epoch 12/50\n",
      "900/900 [==============================] - 0s 41us/sample - loss: 0.0542 - acc: 0.5344 - val_loss: 0.0568 - val_acc: 0.4600\n",
      "Epoch 13/50\n",
      "900/900 [==============================] - 0s 38us/sample - loss: 0.0533 - acc: 0.5378 - val_loss: 0.0562 - val_acc: 0.4700\n",
      "Epoch 14/50\n",
      "900/900 [==============================] - 0s 39us/sample - loss: 0.0527 - acc: 0.5467 - val_loss: 0.0557 - val_acc: 0.4700\n",
      "Epoch 15/50\n",
      "900/900 [==============================] - 0s 38us/sample - loss: 0.0521 - acc: 0.5411 - val_loss: 0.0553 - val_acc: 0.4600\n",
      "Epoch 16/50\n",
      "900/900 [==============================] - 0s 41us/sample - loss: 0.0517 - acc: 0.5389 - val_loss: 0.0550 - val_acc: 0.4500\n",
      "Epoch 17/50\n",
      "900/900 [==============================] - 0s 38us/sample - loss: 0.0513 - acc: 0.5422 - val_loss: 0.0548 - val_acc: 0.4500\n",
      "Epoch 18/50\n",
      "900/900 [==============================] - 0s 40us/sample - loss: 0.0509 - acc: 0.5700 - val_loss: 0.0547 - val_acc: 0.4600\n",
      "Epoch 19/50\n",
      "900/900 [==============================] - 0s 40us/sample - loss: 0.0507 - acc: 0.5456 - val_loss: 0.0545 - val_acc: 0.4600\n",
      "Epoch 20/50\n",
      "900/900 [==============================] - 0s 40us/sample - loss: 0.0504 - acc: 0.5589 - val_loss: 0.0543 - val_acc: 0.4600\n",
      "Epoch 21/50\n",
      "900/900 [==============================] - 0s 41us/sample - loss: 0.0501 - acc: 0.5556 - val_loss: 0.0542 - val_acc: 0.4400\n",
      "Epoch 22/50\n",
      "900/900 [==============================] - 0s 40us/sample - loss: 0.0499 - acc: 0.5711 - val_loss: 0.0542 - val_acc: 0.4700\n",
      "Epoch 23/50\n",
      "900/900 [==============================] - 0s 42us/sample - loss: 0.0498 - acc: 0.5667 - val_loss: 0.0541 - val_acc: 0.4700\n",
      "Epoch 24/50\n",
      "900/900 [==============================] - 0s 39us/sample - loss: 0.0496 - acc: 0.5822 - val_loss: 0.0540 - val_acc: 0.4700\n",
      "Epoch 25/50\n",
      "900/900 [==============================] - 0s 44us/sample - loss: 0.0494 - acc: 0.5767 - val_loss: 0.0542 - val_acc: 0.4800\n",
      "Epoch 26/50\n",
      "900/900 [==============================] - 0s 41us/sample - loss: 0.0493 - acc: 0.5700 - val_loss: 0.0539 - val_acc: 0.4500\n",
      "Epoch 27/50\n",
      "900/900 [==============================] - 0s 37us/sample - loss: 0.0491 - acc: 0.5756 - val_loss: 0.0539 - val_acc: 0.4300\n",
      "Epoch 28/50\n",
      "900/900 [==============================] - 0s 39us/sample - loss: 0.0490 - acc: 0.5722 - val_loss: 0.0539 - val_acc: 0.4400\n",
      "Epoch 29/50\n",
      "900/900 [==============================] - 0s 41us/sample - loss: 0.0489 - acc: 0.5933 - val_loss: 0.0540 - val_acc: 0.4900\n",
      "Epoch 30/50\n",
      "900/900 [==============================] - 0s 37us/sample - loss: 0.0487 - acc: 0.5733 - val_loss: 0.0539 - val_acc: 0.4600\n",
      "Epoch 31/50\n",
      "900/900 [==============================] - 0s 34us/sample - loss: 0.0488 - acc: 0.5722 - val_loss: 0.0539 - val_acc: 0.4800\n",
      "Epoch 32/50\n",
      "900/900 [==============================] - 0s 33us/sample - loss: 0.0485 - acc: 0.5922 - val_loss: 0.0538 - val_acc: 0.4400\n",
      "Epoch 33/50\n",
      "900/900 [==============================] - 0s 36us/sample - loss: 0.0484 - acc: 0.5956 - val_loss: 0.0538 - val_acc: 0.4800\n",
      "Epoch 34/50\n",
      "900/900 [==============================] - 0s 35us/sample - loss: 0.0484 - acc: 0.5878 - val_loss: 0.0538 - val_acc: 0.4600\n",
      "Epoch 35/50\n",
      "900/900 [==============================] - 0s 35us/sample - loss: 0.0483 - acc: 0.5856 - val_loss: 0.0538 - val_acc: 0.4800\n",
      "Epoch 36/50\n",
      "900/900 [==============================] - 0s 33us/sample - loss: 0.0481 - acc: 0.5956 - val_loss: 0.0540 - val_acc: 0.5000\n",
      "Epoch 37/50\n",
      "900/900 [==============================] - 0s 35us/sample - loss: 0.0481 - acc: 0.5922 - val_loss: 0.0541 - val_acc: 0.5000\n",
      "Epoch 38/50\n",
      "900/900 [==============================] - 0s 36us/sample - loss: 0.0479 - acc: 0.5944 - val_loss: 0.0540 - val_acc: 0.4900\n",
      "Epoch 39/50\n",
      "900/900 [==============================] - 0s 38us/sample - loss: 0.0479 - acc: 0.5933 - val_loss: 0.0539 - val_acc: 0.4800\n",
      "Epoch 40/50\n",
      "900/900 [==============================] - 0s 41us/sample - loss: 0.0478 - acc: 0.5978 - val_loss: 0.0539 - val_acc: 0.4800\n",
      "Epoch 41/50\n",
      "900/900 [==============================] - 0s 40us/sample - loss: 0.0478 - acc: 0.6011 - val_loss: 0.0539 - val_acc: 0.4600\n",
      "Epoch 42/50\n",
      "900/900 [==============================] - 0s 38us/sample - loss: 0.0477 - acc: 0.6133 - val_loss: 0.0539 - val_acc: 0.4800\n",
      "Epoch 43/50\n",
      "900/900 [==============================] - 0s 39us/sample - loss: 0.0476 - acc: 0.6022 - val_loss: 0.0540 - val_acc: 0.4900\n",
      "Epoch 44/50\n",
      "900/900 [==============================] - 0s 39us/sample - loss: 0.0476 - acc: 0.6000 - val_loss: 0.0540 - val_acc: 0.5000\n",
      "Epoch 45/50\n",
      "900/900 [==============================] - 0s 41us/sample - loss: 0.0474 - acc: 0.6144 - val_loss: 0.0541 - val_acc: 0.4900\n",
      "Epoch 46/50\n",
      "900/900 [==============================] - 0s 37us/sample - loss: 0.0474 - acc: 0.6011 - val_loss: 0.0540 - val_acc: 0.4700\n",
      "Epoch 47/50\n",
      "900/900 [==============================] - 0s 44us/sample - loss: 0.0474 - acc: 0.6056 - val_loss: 0.0540 - val_acc: 0.5000\n",
      "Epoch 48/50\n",
      "900/900 [==============================] - 0s 48us/sample - loss: 0.0472 - acc: 0.6100 - val_loss: 0.0541 - val_acc: 0.4900\n",
      "Epoch 49/50\n",
      "900/900 [==============================] - 0s 49us/sample - loss: 0.0471 - acc: 0.6133 - val_loss: 0.0542 - val_acc: 0.4800\n",
      "Epoch 50/50\n",
      "900/900 [==============================] - 0s 39us/sample - loss: 0.0471 - acc: 0.6044 - val_loss: 0.0541 - val_acc: 0.4800\n"
     ]
    }
   ],
   "source": [
    "# test how the model converges according to the data size\n",
    "hist = fit_model_with_datasets(init_model, 50, x_train_a, y_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as plot\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.legend([\"loss\", \"val_loss\"])\n",
    "plt.title(\"loss for data size \" + str(TRAIN_DATA_SIZE))\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/seth/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/seth/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model1_list = list()\n",
    "for _ in range(9):\n",
    "    model1_list.append(tf.keras.models.clone_model(model1)) \n",
    "    model1_list[_].set_weights(model1.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training date and time : \n",
      "2020-08-31 14:38:07\n",
      "Train on 11398 samples, validate on 1267 samples\n",
      "Epoch 1/5\n",
      "11398/11398 [==============================] - 1s 56us/sample - loss: 0.0243 - acc: 0.8492 - val_loss: 0.0019 - val_acc: 0.9976\n",
      "Epoch 2/5\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 0.0013 - acc: 0.9974 - val_loss: 7.2349e-04 - val_acc: 0.9992\n",
      "Epoch 3/5\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 7.8100e-04 - acc: 0.9979 - val_loss: 4.4403e-04 - val_acc: 0.9992\n",
      "Epoch 4/5\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 6.0157e-04 - acc: 0.9978 - val_loss: 3.3499e-04 - val_acc: 0.9992\n",
      "Epoch 5/5\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 5.0733e-04 - acc: 0.9981 - val_loss: 2.6500e-04 - val_acc: 0.9992\n",
      "Training date and time : \n",
      "2020-08-31 14:38:09\n",
      "Train on 11398 samples, validate on 1267 samples\n",
      "Epoch 1/10\n",
      "11398/11398 [==============================] - 0s 43us/sample - loss: 0.0244 - acc: 0.8480 - val_loss: 0.0019 - val_acc: 0.9976\n",
      "Epoch 2/10\n",
      "11398/11398 [==============================] - 0s 30us/sample - loss: 0.0013 - acc: 0.9974 - val_loss: 7.1478e-04 - val_acc: 0.9992\n",
      "Epoch 3/10\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 7.8155e-04 - acc: 0.9977 - val_loss: 4.6037e-04 - val_acc: 0.9992\n",
      "Epoch 4/10\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 6.0132e-04 - acc: 0.9979 - val_loss: 3.3377e-04 - val_acc: 0.9992\n",
      "Epoch 5/10\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 5.0685e-04 - acc: 0.9981 - val_loss: 2.5803e-04 - val_acc: 0.9992\n",
      "Epoch 6/10\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 4.4699e-04 - acc: 0.9982 - val_loss: 2.1451e-04 - val_acc: 0.9992\n",
      "Epoch 7/10\n",
      "11398/11398 [==============================] - 0s 31us/sample - loss: 4.0484e-04 - acc: 0.9982 - val_loss: 1.7846e-04 - val_acc: 0.9992\n",
      "Epoch 8/10\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 3.7277e-04 - acc: 0.9983 - val_loss: 1.6061e-04 - val_acc: 0.9992\n",
      "Epoch 9/10\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 3.4820e-04 - acc: 0.9984 - val_loss: 1.4168e-04 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 3.2764e-04 - acc: 0.9985 - val_loss: 1.2183e-04 - val_acc: 1.0000\n",
      "Training date and time : \n",
      "2020-08-31 14:38:13\n",
      "Train on 11398 samples, validate on 1267 samples\n",
      "Epoch 1/15\n",
      "11398/11398 [==============================] - 0s 38us/sample - loss: 0.0245 - acc: 0.8496 - val_loss: 0.0019 - val_acc: 0.9976\n",
      "Epoch 2/15\n",
      "11398/11398 [==============================] - 0s 33us/sample - loss: 0.0013 - acc: 0.9973 - val_loss: 7.3591e-04 - val_acc: 0.9992\n",
      "Epoch 3/15\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 7.8587e-04 - acc: 0.9975 - val_loss: 4.5256e-04 - val_acc: 0.9992\n",
      "Epoch 4/15\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 6.0398e-04 - acc: 0.9978 - val_loss: 3.3305e-04 - val_acc: 0.9992\n",
      "Epoch 5/15\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 5.0724e-04 - acc: 0.9982 - val_loss: 2.7124e-04 - val_acc: 0.9992\n",
      "Epoch 6/15\n",
      "11398/11398 [==============================] - 0s 32us/sample - loss: 4.4773e-04 - acc: 0.9982 - val_loss: 2.1492e-04 - val_acc: 0.9992\n",
      "Epoch 7/15\n",
      "11398/11398 [==============================] - 0s 33us/sample - loss: 4.0542e-04 - acc: 0.9982 - val_loss: 1.8013e-04 - val_acc: 0.9992\n",
      "Epoch 8/15\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 3.7395e-04 - acc: 0.9983 - val_loss: 1.5678e-04 - val_acc: 1.0000\n",
      "Epoch 9/15\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 3.4761e-04 - acc: 0.9985 - val_loss: 1.4456e-04 - val_acc: 0.9992\n",
      "Epoch 10/15\n",
      "11398/11398 [==============================] - 0s 38us/sample - loss: 3.2791e-04 - acc: 0.9985 - val_loss: 1.2876e-04 - val_acc: 1.0000\n",
      "Epoch 11/15\n",
      "11398/11398 [==============================] - 0s 32us/sample - loss: 3.1075e-04 - acc: 0.9985 - val_loss: 1.1605e-04 - val_acc: 1.0000\n",
      "Epoch 12/15\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 2.9594e-04 - acc: 0.9985 - val_loss: 1.0120e-04 - val_acc: 1.0000\n",
      "Epoch 13/15\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 2.8192e-04 - acc: 0.9986 - val_loss: 9.4305e-05 - val_acc: 1.0000\n",
      "Epoch 14/15\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 2.7084e-04 - acc: 0.9986 - val_loss: 8.4934e-05 - val_acc: 1.0000\n",
      "Epoch 15/15\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 2.5834e-04 - acc: 0.9988 - val_loss: 7.6461e-05 - val_acc: 1.0000\n",
      "Training date and time : \n",
      "2020-08-31 14:38:20\n",
      "Train on 11398 samples, validate on 1267 samples\n",
      "Epoch 1/20\n",
      "11398/11398 [==============================] - 0s 38us/sample - loss: 0.0242 - acc: 0.8494 - val_loss: 0.0019 - val_acc: 0.9976\n",
      "Epoch 2/20\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 0.0013 - acc: 0.9975 - val_loss: 7.3124e-04 - val_acc: 0.9992\n",
      "Epoch 3/20\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 7.8113e-04 - acc: 0.9976 - val_loss: 4.4634e-04 - val_acc: 0.9992\n",
      "Epoch 4/20\n",
      "11398/11398 [==============================] - 0s 38us/sample - loss: 6.0167e-04 - acc: 0.9978 - val_loss: 3.3587e-04 - val_acc: 0.9992\n",
      "Epoch 5/20\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 5.0735e-04 - acc: 0.9982 - val_loss: 2.6767e-04 - val_acc: 0.9992\n",
      "Epoch 6/20\n",
      "11398/11398 [==============================] - 0s 31us/sample - loss: 4.4693e-04 - acc: 0.9982 - val_loss: 2.1655e-04 - val_acc: 0.9992\n",
      "Epoch 7/20\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 4.0492e-04 - acc: 0.9982 - val_loss: 1.8224e-04 - val_acc: 0.9992\n",
      "Epoch 8/20\n",
      "11398/11398 [==============================] - 0s 38us/sample - loss: 3.7379e-04 - acc: 0.9982 - val_loss: 1.5759e-04 - val_acc: 0.9992\n",
      "Epoch 9/20\n",
      "11398/11398 [==============================] - 0s 38us/sample - loss: 3.4800e-04 - acc: 0.9985 - val_loss: 1.3853e-04 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 3.2750e-04 - acc: 0.9985 - val_loss: 1.2414e-04 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "11398/11398 [==============================] - 0s 33us/sample - loss: 3.1040e-04 - acc: 0.9986 - val_loss: 1.1023e-04 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 2.9379e-04 - acc: 0.9986 - val_loss: 9.7487e-05 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 2.8208e-04 - acc: 0.9986 - val_loss: 9.3773e-05 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 2.6996e-04 - acc: 0.9986 - val_loss: 8.6858e-05 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "11398/11398 [==============================] - 0s 33us/sample - loss: 2.5890e-04 - acc: 0.9986 - val_loss: 7.7788e-05 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 2.4924e-04 - acc: 0.9987 - val_loss: 7.2257e-05 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 2.4062e-04 - acc: 0.9987 - val_loss: 6.8296e-05 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 2.3185e-04 - acc: 0.9988 - val_loss: 6.2961e-05 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 2.2456e-04 - acc: 0.9988 - val_loss: 6.0313e-05 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "11398/11398 [==============================] - 0s 33us/sample - loss: 2.1704e-04 - acc: 0.9989 - val_loss: 5.7266e-05 - val_acc: 1.0000\n",
      "Training date and time : \n",
      "2020-08-31 14:38:28\n",
      "Train on 11398 samples, validate on 1267 samples\n",
      "Epoch 1/25\n",
      "11398/11398 [==============================] - 1s 45us/sample - loss: 0.0244 - acc: 0.8472 - val_loss: 0.0019 - val_acc: 0.9976\n",
      "Epoch 2/25\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 0.0013 - acc: 0.9973 - val_loss: 7.1086e-04 - val_acc: 0.9992\n",
      "Epoch 3/25\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 7.8215e-04 - acc: 0.9975 - val_loss: 4.4228e-04 - val_acc: 0.9992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 6.0148e-04 - acc: 0.9980 - val_loss: 3.2990e-04 - val_acc: 0.9992\n",
      "Epoch 5/25\n",
      "11398/11398 [==============================] - 0s 30us/sample - loss: 5.0345e-04 - acc: 0.9981 - val_loss: 2.7718e-04 - val_acc: 0.9992\n",
      "Epoch 6/25\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 4.4706e-04 - acc: 0.9982 - val_loss: 2.1182e-04 - val_acc: 0.9992\n",
      "Epoch 7/25\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 4.0464e-04 - acc: 0.9982 - val_loss: 1.8118e-04 - val_acc: 0.9992\n",
      "Epoch 8/25\n",
      "11398/11398 [==============================] - 0s 33us/sample - loss: 3.7202e-04 - acc: 0.9983 - val_loss: 1.5216e-04 - val_acc: 1.0000\n",
      "Epoch 9/25\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 3.4813e-04 - acc: 0.9984 - val_loss: 1.3533e-04 - val_acc: 1.0000\n",
      "Epoch 10/25\n",
      "11398/11398 [==============================] - 0s 29us/sample - loss: 3.2718e-04 - acc: 0.9985 - val_loss: 1.2354e-04 - val_acc: 1.0000\n",
      "Epoch 11/25\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 3.0950e-04 - acc: 0.9985 - val_loss: 1.1204e-04 - val_acc: 1.0000\n",
      "Epoch 12/25\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 2.9419e-04 - acc: 0.9986 - val_loss: 9.8832e-05 - val_acc: 1.0000\n",
      "Epoch 13/25\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 2.8167e-04 - acc: 0.9986 - val_loss: 9.1215e-05 - val_acc: 1.0000\n",
      "Epoch 14/25\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 2.6841e-04 - acc: 0.9986 - val_loss: 8.1864e-05 - val_acc: 1.0000\n",
      "Epoch 15/25\n",
      "11398/11398 [==============================] - 0s 29us/sample - loss: 2.5866e-04 - acc: 0.9987 - val_loss: 7.8460e-05 - val_acc: 1.0000\n",
      "Epoch 16/25\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 2.4837e-04 - acc: 0.9987 - val_loss: 7.0840e-05 - val_acc: 1.0000\n",
      "Epoch 17/25\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 2.4039e-04 - acc: 0.9988 - val_loss: 6.6231e-05 - val_acc: 1.0000\n",
      "Epoch 18/25\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 2.3142e-04 - acc: 0.9989 - val_loss: 6.2539e-05 - val_acc: 1.0000\n",
      "Epoch 19/25\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 2.2359e-04 - acc: 0.9988 - val_loss: 6.0065e-05 - val_acc: 1.0000\n",
      "Epoch 20/25\n",
      "11398/11398 [==============================] - 0s 31us/sample - loss: 2.1654e-04 - acc: 0.9988 - val_loss: 5.6809e-05 - val_acc: 1.0000\n",
      "Epoch 21/25\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 2.0946e-04 - acc: 0.9989 - val_loss: 5.3352e-05 - val_acc: 1.0000\n",
      "Epoch 22/25\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 2.0379e-04 - acc: 0.9990 - val_loss: 5.0118e-05 - val_acc: 1.0000\n",
      "Epoch 23/25\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 1.9763e-04 - acc: 0.9989 - val_loss: 4.7848e-05 - val_acc: 1.0000\n",
      "Epoch 24/25\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 1.9202e-04 - acc: 0.9990 - val_loss: 4.6176e-05 - val_acc: 1.0000\n",
      "Epoch 25/25\n",
      "11398/11398 [==============================] - 0s 31us/sample - loss: 1.8669e-04 - acc: 0.9991 - val_loss: 4.4274e-05 - val_acc: 1.0000\n",
      "Training date and time : \n",
      "2020-08-31 14:38:38\n",
      "Train on 11398 samples, validate on 1267 samples\n",
      "Epoch 1/30\n",
      "11398/11398 [==============================] - 1s 44us/sample - loss: 0.0244 - acc: 0.8474 - val_loss: 0.0019 - val_acc: 0.9976\n",
      "Epoch 2/30\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 0.0013 - acc: 0.9973 - val_loss: 7.2434e-04 - val_acc: 0.9992\n",
      "Epoch 3/30\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 7.8082e-04 - acc: 0.9977 - val_loss: 4.4345e-04 - val_acc: 0.9992\n",
      "Epoch 4/30\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 6.0268e-04 - acc: 0.9979 - val_loss: 3.2757e-04 - val_acc: 0.9992\n",
      "Epoch 5/30\n",
      "11398/11398 [==============================] - 0s 32us/sample - loss: 5.0758e-04 - acc: 0.9980 - val_loss: 2.5890e-04 - val_acc: 0.9992\n",
      "Epoch 6/30\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 4.4671e-04 - acc: 0.9982 - val_loss: 2.0805e-04 - val_acc: 0.9992\n",
      "Epoch 7/30\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 4.0530e-04 - acc: 0.9982 - val_loss: 1.7585e-04 - val_acc: 0.9992\n",
      "Epoch 8/30\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 3.7311e-04 - acc: 0.9984 - val_loss: 1.5739e-04 - val_acc: 0.9992\n",
      "Epoch 9/30\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 3.4948e-04 - acc: 0.9983 - val_loss: 1.3931e-04 - val_acc: 1.0000\n",
      "Epoch 10/30\n",
      "11398/11398 [==============================] - 0s 31us/sample - loss: 3.2812e-04 - acc: 0.9985 - val_loss: 1.2208e-04 - val_acc: 1.0000\n",
      "Epoch 11/30\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 3.1066e-04 - acc: 0.9985 - val_loss: 1.1145e-04 - val_acc: 1.0000\n",
      "Epoch 12/30\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 2.9523e-04 - acc: 0.9986 - val_loss: 1.0493e-04 - val_acc: 1.0000\n",
      "Epoch 13/30\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 2.8282e-04 - acc: 0.9986 - val_loss: 9.3874e-05 - val_acc: 1.0000\n",
      "Epoch 14/30\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 2.7084e-04 - acc: 0.9987 - val_loss: 8.7103e-05 - val_acc: 1.0000\n",
      "Epoch 15/30\n",
      "11398/11398 [==============================] - 0s 32us/sample - loss: 2.6060e-04 - acc: 0.9987 - val_loss: 7.9357e-05 - val_acc: 1.0000\n",
      "Epoch 16/30\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 2.5116e-04 - acc: 0.9988 - val_loss: 7.3151e-05 - val_acc: 1.0000\n",
      "Epoch 17/30\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 2.4201e-04 - acc: 0.9987 - val_loss: 6.9345e-05 - val_acc: 1.0000\n",
      "Epoch 18/30\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 2.3385e-04 - acc: 0.9988 - val_loss: 6.4001e-05 - val_acc: 1.0000\n",
      "Epoch 19/30\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 2.2546e-04 - acc: 0.9989 - val_loss: 5.9268e-05 - val_acc: 1.0000\n",
      "Epoch 20/30\n",
      "11398/11398 [==============================] - 0s 30us/sample - loss: 2.1892e-04 - acc: 0.9989 - val_loss: 5.6553e-05 - val_acc: 1.0000\n",
      "Epoch 21/30\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 2.1188e-04 - acc: 0.9990 - val_loss: 5.3696e-05 - val_acc: 1.0000\n",
      "Epoch 22/30\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 2.0566e-04 - acc: 0.9990 - val_loss: 5.0762e-05 - val_acc: 1.0000\n",
      "Epoch 23/30\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 1.9915e-04 - acc: 0.9989 - val_loss: 4.9594e-05 - val_acc: 1.0000\n",
      "Epoch 24/30\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 1.9421e-04 - acc: 0.9990 - val_loss: 4.7709e-05 - val_acc: 1.0000\n",
      "Epoch 25/30\n",
      "11398/11398 [==============================] - 0s 29us/sample - loss: 1.8924e-04 - acc: 0.9991 - val_loss: 4.5440e-05 - val_acc: 1.0000\n",
      "Epoch 26/30\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 1.8414e-04 - acc: 0.9991 - val_loss: 4.2837e-05 - val_acc: 1.0000\n",
      "Epoch 27/30\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 1.7965e-04 - acc: 0.9992 - val_loss: 4.0600e-05 - val_acc: 1.0000\n",
      "Epoch 28/30\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 1.7558e-04 - acc: 0.9992 - val_loss: 3.8770e-05 - val_acc: 1.0000\n",
      "Epoch 29/30\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 1.7160e-04 - acc: 0.9993 - val_loss: 3.7378e-05 - val_acc: 1.0000\n",
      "Epoch 30/30\n",
      "11398/11398 [==============================] - 0s 31us/sample - loss: 1.6782e-04 - acc: 0.9993 - val_loss: 3.6239e-05 - val_acc: 1.0000\n",
      "Training date and time : \n",
      "2020-08-31 14:38:50\n",
      "Train on 11398 samples, validate on 1267 samples\n",
      "Epoch 1/35\n",
      "11398/11398 [==============================] - 1s 45us/sample - loss: 0.0243 - acc: 0.8499 - val_loss: 0.0020 - val_acc: 0.9976\n",
      "Epoch 2/35\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 0.0013 - acc: 0.9971 - val_loss: 7.1813e-04 - val_acc: 0.9992\n",
      "Epoch 3/35\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 7.8342e-04 - acc: 0.9976 - val_loss: 4.5317e-04 - val_acc: 0.9992\n",
      "Epoch 4/35\n",
      "11398/11398 [==============================] - 0s 32us/sample - loss: 6.0178e-04 - acc: 0.9980 - val_loss: 3.3052e-04 - val_acc: 0.9992\n",
      "Epoch 5/35\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 5.0646e-04 - acc: 0.9981 - val_loss: 2.6135e-04 - val_acc: 0.9992\n",
      "Epoch 6/35\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 4.4667e-04 - acc: 0.9982 - val_loss: 2.1359e-04 - val_acc: 0.9992\n",
      "Epoch 7/35\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 4.0432e-04 - acc: 0.9982 - val_loss: 1.7671e-04 - val_acc: 0.9992\n",
      "Epoch 8/35\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 3.7296e-04 - acc: 0.9982 - val_loss: 1.5355e-04 - val_acc: 1.0000\n",
      "Epoch 9/35\n",
      "11398/11398 [==============================] - 0s 31us/sample - loss: 3.4746e-04 - acc: 0.9985 - val_loss: 1.3699e-04 - val_acc: 1.0000\n",
      "Epoch 10/35\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 3.2659e-04 - acc: 0.9985 - val_loss: 1.2184e-04 - val_acc: 1.0000\n",
      "Epoch 11/35\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 3.1022e-04 - acc: 0.9985 - val_loss: 1.0842e-04 - val_acc: 1.0000\n",
      "Epoch 12/35\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 2.9533e-04 - acc: 0.9986 - val_loss: 9.8943e-05 - val_acc: 1.0000\n",
      "Epoch 13/35\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 2.8176e-04 - acc: 0.9987 - val_loss: 9.2968e-05 - val_acc: 1.0000\n",
      "Epoch 14/35\n",
      "11398/11398 [==============================] - 0s 31us/sample - loss: 2.7004e-04 - acc: 0.9987 - val_loss: 8.3064e-05 - val_acc: 1.0000\n",
      "Epoch 15/35\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 2.5887e-04 - acc: 0.9987 - val_loss: 7.7511e-05 - val_acc: 1.0000\n",
      "Epoch 16/35\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 2.4905e-04 - acc: 0.9987 - val_loss: 7.1333e-05 - val_acc: 1.0000\n",
      "Epoch 17/35\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 2.3993e-04 - acc: 0.9988 - val_loss: 6.6014e-05 - val_acc: 1.0000\n",
      "Epoch 18/35\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 2.3227e-04 - acc: 0.9987 - val_loss: 6.3606e-05 - val_acc: 1.0000\n",
      "Epoch 19/35\n",
      "11398/11398 [==============================] - 0s 30us/sample - loss: 2.2416e-04 - acc: 0.9989 - val_loss: 5.9690e-05 - val_acc: 1.0000\n",
      "Epoch 20/35\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 2.1697e-04 - acc: 0.9989 - val_loss: 5.5382e-05 - val_acc: 1.0000\n",
      "Epoch 21/35\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 2.1045e-04 - acc: 0.9989 - val_loss: 5.2696e-05 - val_acc: 1.0000\n",
      "Epoch 22/35\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 2.0409e-04 - acc: 0.9989 - val_loss: 4.9802e-05 - val_acc: 1.0000\n",
      "Epoch 23/35\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 1.9777e-04 - acc: 0.9990 - val_loss: 4.7510e-05 - val_acc: 1.0000\n",
      "Epoch 24/35\n",
      "11398/11398 [==============================] - 0s 31us/sample - loss: 1.9253e-04 - acc: 0.9990 - val_loss: 4.5629e-05 - val_acc: 1.0000\n",
      "Epoch 25/35\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 1.8741e-04 - acc: 0.9991 - val_loss: 4.3418e-05 - val_acc: 1.0000\n",
      "Epoch 26/35\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 1.8265e-04 - acc: 0.9992 - val_loss: 4.1370e-05 - val_acc: 1.0000\n",
      "Epoch 27/35\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 1.7827e-04 - acc: 0.9992 - val_loss: 3.9875e-05 - val_acc: 1.0000\n",
      "Epoch 28/35\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 1.7378e-04 - acc: 0.9992 - val_loss: 3.8342e-05 - val_acc: 1.0000\n",
      "Epoch 29/35\n",
      "11398/11398 [==============================] - 0s 31us/sample - loss: 1.6965e-04 - acc: 0.9994 - val_loss: 3.6595e-05 - val_acc: 1.0000\n",
      "Epoch 30/35\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 1.6686e-04 - acc: 0.9993 - val_loss: 3.5309e-05 - val_acc: 1.0000\n",
      "Epoch 31/35\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 1.6339e-04 - acc: 0.9994 - val_loss: 3.4198e-05 - val_acc: 1.0000\n",
      "Epoch 32/35\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 1.5997e-04 - acc: 0.9994 - val_loss: 3.2733e-05 - val_acc: 1.0000\n",
      "Epoch 33/35\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 1.5716e-04 - acc: 0.9994 - val_loss: 3.1740e-05 - val_acc: 1.0000\n",
      "Epoch 34/35\n",
      "11398/11398 [==============================] - 0s 32us/sample - loss: 1.5409e-04 - acc: 0.9995 - val_loss: 3.0584e-05 - val_acc: 1.0000\n",
      "Epoch 35/35\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 1.5213e-04 - acc: 0.9994 - val_loss: 2.9535e-05 - val_acc: 1.0000\n",
      "Training date and time : \n",
      "2020-08-31 14:39:05\n",
      "Train on 11398 samples, validate on 1267 samples\n",
      "Epoch 1/40\n",
      "11398/11398 [==============================] - 1s 46us/sample - loss: 0.0243 - acc: 0.8494 - val_loss: 0.0019 - val_acc: 0.9976\n",
      "Epoch 2/40\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 0.0013 - acc: 0.9973 - val_loss: 7.1326e-04 - val_acc: 0.9992\n",
      "Epoch 3/40\n",
      "11398/11398 [==============================] - 0s 31us/sample - loss: 7.8347e-04 - acc: 0.9975 - val_loss: 4.4742e-04 - val_acc: 0.9992\n",
      "Epoch 4/40\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 6.0244e-04 - acc: 0.9980 - val_loss: 3.3222e-04 - val_acc: 0.9992\n",
      "Epoch 5/40\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 5.0793e-04 - acc: 0.9981 - val_loss: 2.6222e-04 - val_acc: 0.9992\n",
      "Epoch 6/40\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 4.4765e-04 - acc: 0.9981 - val_loss: 2.1709e-04 - val_acc: 0.9992\n",
      "Epoch 7/40\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 4.0460e-04 - acc: 0.9982 - val_loss: 1.9119e-04 - val_acc: 0.9992\n",
      "Epoch 8/40\n",
      "11398/11398 [==============================] - 0s 31us/sample - loss: 3.7395e-04 - acc: 0.9983 - val_loss: 1.6279e-04 - val_acc: 0.9992\n",
      "Epoch 9/40\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 3.4840e-04 - acc: 0.9984 - val_loss: 1.4154e-04 - val_acc: 1.0000\n",
      "Epoch 10/40\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 3.2817e-04 - acc: 0.9985 - val_loss: 1.2527e-04 - val_acc: 1.0000\n",
      "Epoch 11/40\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 3.0904e-04 - acc: 0.9985 - val_loss: 1.1849e-04 - val_acc: 1.0000\n",
      "Epoch 12/40\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 2.9507e-04 - acc: 0.9986 - val_loss: 9.9855e-05 - val_acc: 1.0000\n",
      "Epoch 13/40\n",
      "11398/11398 [==============================] - 0s 32us/sample - loss: 2.8156e-04 - acc: 0.9987 - val_loss: 9.2027e-05 - val_acc: 1.0000\n",
      "Epoch 14/40\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 2.6937e-04 - acc: 0.9987 - val_loss: 8.2377e-05 - val_acc: 1.0000\n",
      "Epoch 15/40\n",
      "11398/11398 [==============================] - 0s 38us/sample - loss: 2.6062e-04 - acc: 0.9987 - val_loss: 7.7683e-05 - val_acc: 1.0000\n",
      "Epoch 16/40\n",
      "11398/11398 [==============================] - 0s 38us/sample - loss: 2.5020e-04 - acc: 0.9987 - val_loss: 7.2236e-05 - val_acc: 1.0000\n",
      "Epoch 17/40\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 2.4159e-04 - acc: 0.9987 - val_loss: 6.8384e-05 - val_acc: 1.0000\n",
      "Epoch 18/40\n",
      "11398/11398 [==============================] - 0s 33us/sample - loss: 2.3312e-04 - acc: 0.9988 - val_loss: 6.5011e-05 - val_acc: 1.0000\n",
      "Epoch 19/40\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 2.2552e-04 - acc: 0.9988 - val_loss: 6.1304e-05 - val_acc: 1.0000\n",
      "Epoch 20/40\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 2.1804e-04 - acc: 0.9989 - val_loss: 5.6764e-05 - val_acc: 1.0000\n",
      "Epoch 21/40\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 2.1126e-04 - acc: 0.9990 - val_loss: 5.3717e-05 - val_acc: 1.0000\n",
      "Epoch 22/40\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 2.0496e-04 - acc: 0.9990 - val_loss: 5.1254e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/40\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 1.9885e-04 - acc: 0.9990 - val_loss: 4.8737e-05 - val_acc: 1.0000\n",
      "Epoch 24/40\n",
      "11398/11398 [==============================] - 0s 37us/sample - loss: 1.9325e-04 - acc: 0.9990 - val_loss: 4.6999e-05 - val_acc: 1.0000\n",
      "Epoch 25/40\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 1.8807e-04 - acc: 0.9991 - val_loss: 4.4588e-05 - val_acc: 1.0000\n",
      "Epoch 26/40\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 1.8346e-04 - acc: 0.9992 - val_loss: 4.2402e-05 - val_acc: 1.0000\n",
      "Epoch 27/40\n",
      "11398/11398 [==============================] - 0s 33us/sample - loss: 1.7885e-04 - acc: 0.9992 - val_loss: 4.0222e-05 - val_acc: 1.0000\n",
      "Epoch 28/40\n",
      "11398/11398 [==============================] - 0s 32us/sample - loss: 1.7417e-04 - acc: 0.9993 - val_loss: 3.8217e-05 - val_acc: 1.0000\n",
      "Epoch 29/40\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 1.7058e-04 - acc: 0.9993 - val_loss: 3.7283e-05 - val_acc: 1.0000\n",
      "Epoch 30/40\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 1.6740e-04 - acc: 0.9994 - val_loss: 3.5528e-05 - val_acc: 1.0000\n",
      "Epoch 31/40\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 1.6363e-04 - acc: 0.9994 - val_loss: 3.4465e-05 - val_acc: 1.0000\n",
      "Epoch 32/40\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 1.6019e-04 - acc: 0.9994 - val_loss: 3.3156e-05 - val_acc: 1.0000\n",
      "Epoch 33/40\n",
      "11398/11398 [==============================] - 0s 32us/sample - loss: 1.5717e-04 - acc: 0.9994 - val_loss: 3.1878e-05 - val_acc: 1.0000\n",
      "Epoch 34/40\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 1.5440e-04 - acc: 0.9994 - val_loss: 3.0601e-05 - val_acc: 1.0000\n",
      "Epoch 35/40\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 1.5223e-04 - acc: 0.9994 - val_loss: 2.9601e-05 - val_acc: 1.0000\n",
      "Epoch 36/40\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 1.4912e-04 - acc: 0.9995 - val_loss: 2.8645e-05 - val_acc: 1.0000\n",
      "Epoch 37/40\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 1.4660e-04 - acc: 0.9995 - val_loss: 2.7730e-05 - val_acc: 1.0000\n",
      "Epoch 38/40\n",
      "11398/11398 [==============================] - 0s 32us/sample - loss: 1.4438e-04 - acc: 0.9994 - val_loss: 2.6879e-05 - val_acc: 1.0000\n",
      "Epoch 39/40\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 1.4218e-04 - acc: 0.9995 - val_loss: 2.6037e-05 - val_acc: 1.0000\n",
      "Epoch 40/40\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 1.4006e-04 - acc: 0.9995 - val_loss: 2.5235e-05 - val_acc: 1.0000\n",
      "Training date and time : \n",
      "2020-08-31 14:39:21\n",
      "Train on 11398 samples, validate on 1267 samples\n",
      "Epoch 1/45\n",
      "11398/11398 [==============================] - 0s 44us/sample - loss: 0.0243 - acc: 0.8480 - val_loss: 0.0019 - val_acc: 0.9976\n",
      "Epoch 2/45\n",
      "11398/11398 [==============================] - 0s 30us/sample - loss: 0.0013 - acc: 0.9974 - val_loss: 7.0562e-04 - val_acc: 0.9992\n",
      "Epoch 3/45\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 7.8220e-04 - acc: 0.9977 - val_loss: 4.5641e-04 - val_acc: 0.9992\n",
      "Epoch 4/45\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 5.9964e-04 - acc: 0.9978 - val_loss: 3.2075e-04 - val_acc: 0.9992\n",
      "Epoch 5/45\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 5.0668e-04 - acc: 0.9982 - val_loss: 2.6485e-04 - val_acc: 0.9992\n",
      "Epoch 6/45\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 4.4605e-04 - acc: 0.9981 - val_loss: 2.0996e-04 - val_acc: 0.9992\n",
      "Epoch 7/45\n",
      "11398/11398 [==============================] - 0s 30us/sample - loss: 4.0482e-04 - acc: 0.9983 - val_loss: 1.7609e-04 - val_acc: 0.9992\n",
      "Epoch 8/45\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 3.7337e-04 - acc: 0.9983 - val_loss: 1.5512e-04 - val_acc: 1.0000\n",
      "Epoch 9/45\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 3.4717e-04 - acc: 0.9985 - val_loss: 1.4006e-04 - val_acc: 1.0000\n",
      "Epoch 10/45\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 3.2742e-04 - acc: 0.9985 - val_loss: 1.2241e-04 - val_acc: 1.0000\n",
      "Epoch 11/45\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 3.1036e-04 - acc: 0.9985 - val_loss: 1.0961e-04 - val_acc: 1.0000\n",
      "Epoch 12/45\n",
      "11398/11398 [==============================] - 0s 31us/sample - loss: 2.9466e-04 - acc: 0.9986 - val_loss: 1.0414e-04 - val_acc: 1.0000\n",
      "Epoch 13/45\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 2.8308e-04 - acc: 0.9986 - val_loss: 9.3404e-05 - val_acc: 1.0000\n",
      "Epoch 14/45\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 2.7080e-04 - acc: 0.9986 - val_loss: 8.4504e-05 - val_acc: 1.0000\n",
      "Epoch 15/45\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 2.6055e-04 - acc: 0.9987 - val_loss: 7.8114e-05 - val_acc: 1.0000\n",
      "Epoch 16/45\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 2.5058e-04 - acc: 0.9987 - val_loss: 7.3783e-05 - val_acc: 1.0000\n",
      "Epoch 17/45\n",
      "11398/11398 [==============================] - 0s 32us/sample - loss: 2.4192e-04 - acc: 0.9987 - val_loss: 6.8065e-05 - val_acc: 1.0000\n",
      "Epoch 18/45\n",
      "11398/11398 [==============================] - 0s 32us/sample - loss: 2.3282e-04 - acc: 0.9988 - val_loss: 6.5096e-05 - val_acc: 1.0000\n",
      "Epoch 19/45\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 2.2540e-04 - acc: 0.9988 - val_loss: 6.1254e-05 - val_acc: 1.0000\n",
      "Epoch 20/45\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 2.1838e-04 - acc: 0.9989 - val_loss: 5.6721e-05 - val_acc: 1.0000\n",
      "Epoch 21/45\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 2.1150e-04 - acc: 0.9989 - val_loss: 5.3586e-05 - val_acc: 1.0000\n",
      "Epoch 22/45\n",
      "11398/11398 [==============================] - 0s 33us/sample - loss: 2.0494e-04 - acc: 0.9990 - val_loss: 5.0946e-05 - val_acc: 1.0000\n",
      "Epoch 23/45\n",
      "11398/11398 [==============================] - 0s 33us/sample - loss: 1.9912e-04 - acc: 0.9990 - val_loss: 4.8228e-05 - val_acc: 1.0000\n",
      "Epoch 24/45\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 1.9333e-04 - acc: 0.9990 - val_loss: 4.5591e-05 - val_acc: 1.0000\n",
      "Epoch 25/45\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 1.8862e-04 - acc: 0.9991 - val_loss: 4.3813e-05 - val_acc: 1.0000\n",
      "Epoch 26/45\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 1.8381e-04 - acc: 0.9991 - val_loss: 4.2048e-05 - val_acc: 1.0000\n",
      "Epoch 27/45\n",
      "11398/11398 [==============================] - 0s 33us/sample - loss: 1.7916e-04 - acc: 0.9991 - val_loss: 4.0506e-05 - val_acc: 1.0000\n",
      "Epoch 28/45\n",
      "11398/11398 [==============================] - 0s 31us/sample - loss: 1.7501e-04 - acc: 0.9992 - val_loss: 3.8827e-05 - val_acc: 1.0000\n",
      "Epoch 29/45\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 1.7074e-04 - acc: 0.9993 - val_loss: 3.6992e-05 - val_acc: 1.0000\n",
      "Epoch 30/45\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 1.6711e-04 - acc: 0.9993 - val_loss: 3.6054e-05 - val_acc: 1.0000\n",
      "Epoch 31/45\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 1.6375e-04 - acc: 0.9994 - val_loss: 3.4982e-05 - val_acc: 1.0000\n",
      "Epoch 32/45\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 1.6090e-04 - acc: 0.9994 - val_loss: 3.3431e-05 - val_acc: 1.0000\n",
      "Epoch 33/45\n",
      "11398/11398 [==============================] - 0s 31us/sample - loss: 1.5754e-04 - acc: 0.9994 - val_loss: 3.1941e-05 - val_acc: 1.0000\n",
      "Epoch 34/45\n",
      "11398/11398 [==============================] - 0s 36us/sample - loss: 1.5471e-04 - acc: 0.9994 - val_loss: 3.0802e-05 - val_acc: 1.0000\n",
      "Epoch 35/45\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 1.5178e-04 - acc: 0.9994 - val_loss: 2.9731e-05 - val_acc: 1.0000\n",
      "Epoch 36/45\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 1.4874e-04 - acc: 0.9995 - val_loss: 2.8871e-05 - val_acc: 1.0000\n",
      "Epoch 37/45\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 1.4694e-04 - acc: 0.9995 - val_loss: 2.7880e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/45\n",
      "11398/11398 [==============================] - 0s 29us/sample - loss: 1.4324e-04 - acc: 0.9994 - val_loss: 2.7025e-05 - val_acc: 1.0000\n",
      "Epoch 39/45\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 1.4272e-04 - acc: 0.9995 - val_loss: 2.6090e-05 - val_acc: 1.0000\n",
      "Epoch 40/45\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 1.4009e-04 - acc: 0.9995 - val_loss: 2.5283e-05 - val_acc: 1.0000\n",
      "Epoch 41/45\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 1.3808e-04 - acc: 0.9995 - val_loss: 2.4493e-05 - val_acc: 1.0000\n",
      "Epoch 42/45\n",
      "11398/11398 [==============================] - 0s 35us/sample - loss: 1.3606e-04 - acc: 0.9995 - val_loss: 2.3827e-05 - val_acc: 1.0000\n",
      "Epoch 43/45\n",
      "11398/11398 [==============================] - 0s 30us/sample - loss: 1.3423e-04 - acc: 0.9995 - val_loss: 2.3117e-05 - val_acc: 1.0000\n",
      "Epoch 44/45\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 1.3261e-04 - acc: 0.9995 - val_loss: 2.2469e-05 - val_acc: 1.0000\n",
      "Epoch 45/45\n",
      "11398/11398 [==============================] - 0s 34us/sample - loss: 1.3039e-04 - acc: 0.9995 - val_loss: 2.1821e-05 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(model1_list)):\n",
    "    compile_model(model1_list[i])\n",
    "    fit_model_with_datasets(model1_list[i], (i+1)*5, x_train_0_to_4, y_train_0_to_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training date and time : \n",
      "2020-08-31 14:39:39\n",
      "Train on 10620 samples, validate on 1180 samples\n",
      "Epoch 1/50\n",
      "10620/10620 [==============================] - 1s 48us/sample - loss: 0.0357 - acc: 0.8228 - val_loss: 0.0090 - val_acc: 0.9661\n",
      "Epoch 2/50\n",
      "10620/10620 [==============================] - 0s 33us/sample - loss: 0.0076 - acc: 0.9622 - val_loss: 0.0057 - val_acc: 0.9678\n",
      "Epoch 3/50\n",
      "10620/10620 [==============================] - 0s 32us/sample - loss: 0.0054 - acc: 0.9709 - val_loss: 0.0046 - val_acc: 0.9763\n",
      "Epoch 4/50\n",
      "10620/10620 [==============================] - 0s 35us/sample - loss: 0.0045 - acc: 0.9747 - val_loss: 0.0041 - val_acc: 0.9780\n",
      "Epoch 5/50\n",
      "10620/10620 [==============================] - 0s 35us/sample - loss: 0.0039 - acc: 0.9777 - val_loss: 0.0038 - val_acc: 0.9788\n",
      "Epoch 6/50\n",
      "10620/10620 [==============================] - 0s 36us/sample - loss: 0.0036 - acc: 0.9800 - val_loss: 0.0036 - val_acc: 0.9788\n",
      "Epoch 7/50\n",
      "10620/10620 [==============================] - 0s 36us/sample - loss: 0.0033 - acc: 0.9810 - val_loss: 0.0035 - val_acc: 0.9797\n",
      "Epoch 8/50\n",
      "10620/10620 [==============================] - 0s 30us/sample - loss: 0.0031 - acc: 0.9818 - val_loss: 0.0033 - val_acc: 0.9797\n",
      "Epoch 9/50\n",
      "10620/10620 [==============================] - 0s 35us/sample - loss: 0.0029 - acc: 0.9846 - val_loss: 0.0032 - val_acc: 0.9797\n",
      "Epoch 10/50\n",
      "10620/10620 [==============================] - 0s 37us/sample - loss: 0.0028 - acc: 0.9840 - val_loss: 0.0031 - val_acc: 0.9805\n",
      "Epoch 11/50\n",
      "10620/10620 [==============================] - 0s 35us/sample - loss: 0.0027 - acc: 0.9845 - val_loss: 0.0030 - val_acc: 0.9805\n",
      "Epoch 12/50\n",
      "10620/10620 [==============================] - 0s 35us/sample - loss: 0.0026 - acc: 0.9852 - val_loss: 0.0029 - val_acc: 0.9814\n",
      "Epoch 13/50\n",
      "10620/10620 [==============================] - 0s 31us/sample - loss: 0.0025 - acc: 0.9860 - val_loss: 0.0028 - val_acc: 0.9822\n",
      "Epoch 14/50\n",
      "10620/10620 [==============================] - 0s 33us/sample - loss: 0.0024 - acc: 0.9865 - val_loss: 0.0027 - val_acc: 0.9814\n",
      "Epoch 15/50\n",
      "10620/10620 [==============================] - 0s 36us/sample - loss: 0.0023 - acc: 0.9868 - val_loss: 0.0027 - val_acc: 0.9831\n",
      "Epoch 16/50\n",
      "10620/10620 [==============================] - 0s 36us/sample - loss: 0.0022 - acc: 0.9876 - val_loss: 0.0027 - val_acc: 0.9839\n",
      "Epoch 17/50\n",
      "10620/10620 [==============================] - 0s 36us/sample - loss: 0.0022 - acc: 0.9884 - val_loss: 0.0026 - val_acc: 0.9831\n",
      "Epoch 18/50\n",
      "10620/10620 [==============================] - 0s 35us/sample - loss: 0.0021 - acc: 0.9885 - val_loss: 0.0025 - val_acc: 0.9839\n",
      "Epoch 19/50\n",
      "10620/10620 [==============================] - 0s 31us/sample - loss: 0.0020 - acc: 0.9888 - val_loss: 0.0025 - val_acc: 0.9831\n",
      "Epoch 20/50\n",
      "10620/10620 [==============================] - 0s 36us/sample - loss: 0.0020 - acc: 0.9892 - val_loss: 0.0024 - val_acc: 0.9847\n",
      "Epoch 21/50\n",
      "10620/10620 [==============================] - 0s 35us/sample - loss: 0.0019 - acc: 0.9897 - val_loss: 0.0024 - val_acc: 0.9847\n",
      "Epoch 22/50\n",
      "10620/10620 [==============================] - 0s 35us/sample - loss: 0.0019 - acc: 0.9895 - val_loss: 0.0023 - val_acc: 0.9847\n",
      "Epoch 23/50\n",
      "10620/10620 [==============================] - 0s 36us/sample - loss: 0.0018 - acc: 0.9901 - val_loss: 0.0023 - val_acc: 0.9864\n",
      "Epoch 24/50\n",
      "10620/10620 [==============================] - 0s 32us/sample - loss: 0.0018 - acc: 0.9902 - val_loss: 0.0022 - val_acc: 0.9864\n",
      "Epoch 25/50\n",
      "10620/10620 [==============================] - 0s 34us/sample - loss: 0.0018 - acc: 0.9907 - val_loss: 0.0022 - val_acc: 0.9873\n",
      "Epoch 26/50\n",
      "10620/10620 [==============================] - 0s 36us/sample - loss: 0.0017 - acc: 0.9910 - val_loss: 0.0022 - val_acc: 0.9881\n",
      "Epoch 27/50\n",
      "10620/10620 [==============================] - 0s 36us/sample - loss: 0.0017 - acc: 0.9914 - val_loss: 0.0022 - val_acc: 0.9839\n",
      "Epoch 28/50\n",
      "10620/10620 [==============================] - 0s 36us/sample - loss: 0.0016 - acc: 0.9915 - val_loss: 0.0021 - val_acc: 0.9839\n",
      "Epoch 29/50\n",
      "10620/10620 [==============================] - 0s 34us/sample - loss: 0.0016 - acc: 0.9916 - val_loss: 0.0021 - val_acc: 0.9881\n",
      "Epoch 30/50\n",
      "10620/10620 [==============================] - 0s 33us/sample - loss: 0.0016 - acc: 0.9921 - val_loss: 0.0020 - val_acc: 0.9847\n",
      "Epoch 31/50\n",
      "10620/10620 [==============================] - 0s 36us/sample - loss: 0.0015 - acc: 0.9924 - val_loss: 0.0020 - val_acc: 0.9881\n",
      "Epoch 32/50\n",
      "10620/10620 [==============================] - 0s 36us/sample - loss: 0.0015 - acc: 0.9927 - val_loss: 0.0019 - val_acc: 0.9881\n",
      "Epoch 33/50\n",
      "10620/10620 [==============================] - 0s 35us/sample - loss: 0.0014 - acc: 0.9928 - val_loss: 0.0019 - val_acc: 0.9873\n",
      "Epoch 34/50\n",
      "10620/10620 [==============================] - 0s 36us/sample - loss: 0.0014 - acc: 0.9926 - val_loss: 0.0019 - val_acc: 0.9873\n",
      "Epoch 35/50\n",
      "10620/10620 [==============================] - 0s 30us/sample - loss: 0.0014 - acc: 0.9932 - val_loss: 0.0019 - val_acc: 0.9881\n",
      "Epoch 36/50\n",
      "10620/10620 [==============================] - 0s 36us/sample - loss: 0.0014 - acc: 0.9931 - val_loss: 0.0019 - val_acc: 0.9881\n",
      "Epoch 37/50\n",
      "10620/10620 [==============================] - 0s 35us/sample - loss: 0.0013 - acc: 0.9937 - val_loss: 0.0018 - val_acc: 0.9873\n",
      "Epoch 38/50\n",
      "10620/10620 [==============================] - 0s 36us/sample - loss: 0.0013 - acc: 0.9936 - val_loss: 0.0019 - val_acc: 0.9881\n",
      "Epoch 39/50\n",
      "10620/10620 [==============================] - 0s 36us/sample - loss: 0.0013 - acc: 0.9936 - val_loss: 0.0018 - val_acc: 0.9898\n",
      "Epoch 40/50\n",
      "10620/10620 [==============================] - 0s 32us/sample - loss: 0.0012 - acc: 0.9935 - val_loss: 0.0018 - val_acc: 0.9881\n",
      "Epoch 41/50\n",
      "10620/10620 [==============================] - 0s 33us/sample - loss: 0.0012 - acc: 0.9939 - val_loss: 0.0018 - val_acc: 0.9898\n",
      "Epoch 42/50\n",
      "10620/10620 [==============================] - 0s 36us/sample - loss: 0.0012 - acc: 0.9939 - val_loss: 0.0017 - val_acc: 0.9898\n",
      "Epoch 43/50\n",
      "10620/10620 [==============================] - 0s 35us/sample - loss: 0.0012 - acc: 0.9944 - val_loss: 0.0017 - val_acc: 0.9907\n",
      "Epoch 44/50\n",
      "10620/10620 [==============================] - 0s 36us/sample - loss: 0.0012 - acc: 0.9944 - val_loss: 0.0017 - val_acc: 0.9915\n",
      "Epoch 45/50\n",
      "10620/10620 [==============================] - 0s 35us/sample - loss: 0.0011 - acc: 0.9945 - val_loss: 0.0020 - val_acc: 0.9864\n",
      "Epoch 46/50\n",
      "10620/10620 [==============================] - 0s 31us/sample - loss: 0.0011 - acc: 0.9947 - val_loss: 0.0017 - val_acc: 0.9907\n",
      "Epoch 47/50\n",
      "10620/10620 [==============================] - 0s 36us/sample - loss: 0.0011 - acc: 0.9948 - val_loss: 0.0016 - val_acc: 0.9898\n",
      "Epoch 48/50\n",
      "10620/10620 [==============================] - 0s 35us/sample - loss: 0.0011 - acc: 0.9948 - val_loss: 0.0019 - val_acc: 0.9890\n",
      "Epoch 49/50\n",
      "10620/10620 [==============================] - 0s 36us/sample - loss: 0.0011 - acc: 0.9952 - val_loss: 0.0016 - val_acc: 0.9915\n",
      "Epoch 50/50\n",
      "10620/10620 [==============================] - 0s 36us/sample - loss: 0.0010 - acc: 0.9952 - val_loss: 0.0017 - val_acc: 0.9898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb2ce706668>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model_with_datasets(model2, 50, x_train_5_to_9, y_train_5_to_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_drift\n",
    "model_dists = [semantic_drift.l2_distance(init_model, m) for m in model1_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3300415,\n",
       " 1.424989,\n",
       " 1.4784721,\n",
       " 1.5186309,\n",
       " 1.5505308,\n",
       " 1.5796684,\n",
       " 1.6027185,\n",
       " 1.6240375,\n",
       " 1.643143]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate models (all of model1s and only the final model2(e=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_weights_list_per_pi = list()\n",
    "theta_list = [0, 0.5, 1]\n",
    "for m1 in model1_list:\n",
    "    weights = [m1.get_weights(), model2.get_weights()]\n",
    "    agg_weights_list = list()\n",
    "    for theta in theta_list:\n",
    "        agg_weights = list()\n",
    "        for weights_list_tuple in zip(*weights):\n",
    "            agg_weights.append(np.array([np.average(np.array(w), axis=0, weights=[1. - theta, theta]) for w in zip(*weights_list_tuple)]))\n",
    "        agg_weights_list.append(agg_weights)\n",
    "    agg_weights_list_per_pi.append(agg_weights_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.1497 - acc: 0.1958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14974196043014526, 0.1958]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x=x_test, y=y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.zeros(len(agg_weights_list_per_pi))\n",
    "A = np.zeros(len(agg_weights_list_per_pi))\n",
    "\n",
    "losses1 = list()\n",
    "accs1 = list()\n",
    "losses2 = list()\n",
    "accs2 = list()\n",
    "agg_accs = list()\n",
    "acc_losses = list()\n",
    "\n",
    "i = 0\n",
    "for agg_weights_list in agg_weights_list_per_pi:\n",
    "\n",
    "    aggr_model = keras.models.clone_model(model1)\n",
    "    aggr_model.set_weights(agg_weights_list[1])\n",
    "    compile_model(aggr_model)\n",
    "    score = aggr_model.evaluate(x=x_test, y=y_test, verbose=0)\n",
    "\n",
    "    aggr_model = keras.models.clone_model(model1)\n",
    "    aggr_model.set_weights(agg_weights_list[0])\n",
    "    compile_model(aggr_model)\n",
    "    comp_score1 = aggr_model.evaluate(x=x_test, y=y_test, verbose=0)\n",
    "\n",
    "    aggr_model = keras.models.clone_model(model1)\n",
    "    aggr_model.set_weights(agg_weights_list[2])\n",
    "    compile_model(aggr_model)\n",
    "    comp_score2 = aggr_model.evaluate(x=x_test, y=y_test, verbose=0)\n",
    "    \n",
    "    acc_losses.append(score[0])\n",
    "    agg_accs.append(score[1])\n",
    "    losses1.append(comp_score1[0])\n",
    "    accs1.append(comp_score1[1])\n",
    "    losses2.append(comp_score2[0])\n",
    "    accs2.append(comp_score2[1])\n",
    "    \n",
    "    B[i] = min(comp_score1[0], comp_score2[0]) - score[0]\n",
    "    A[i] = score[1] - max(comp_score1[1], comp_score2[1])\n",
    "    K.clear_session() #prevent memory leak https://github.com/keras-team/keras/issues/13118\n",
    "    i += 1\n",
    "    if i % 10 == 0:\n",
    "        print(\"{}th iteration\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as plot\n",
    "plt.plot(np.array(model_dists), np.array(acc_losses))\n",
    "plt.plot(np.array(model_dists), np.array(losses1))\n",
    "plt.plot(np.array(model_dists), np.array(losses2))\n",
    "plt.legend([\"aggregated\", \"model seq. w. 0,1\", \"model w. 8,9\"])\n",
    "plt.title(\"loss - all labels\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"l2 distance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as plot\n",
    "plt.plot(np.array(model_dists), np.array(B))\n",
    "plt.legend([\"iid test set\", \"test w. 0,1\", \"test w. 8,9\"])\n",
    "plt.ylabel(\"aggregation benefit in loss\")\n",
    "plt.xlabel(\"l2 distance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.zeros(len(agg_weights_list_per_pi))\n",
    "A = np.zeros(len(agg_weights_list_per_pi))\n",
    "\n",
    "losses1 = list()\n",
    "losses2 = list()\n",
    "agg_losses = list()\n",
    "\n",
    "i = 0\n",
    "for agg_weights_list in agg_weights_list_per_pi:\n",
    "\n",
    "    aggr_model = keras.models.clone_model(model1)\n",
    "    aggr_model.set_weights(agg_weights_list[1])\n",
    "    compile_model(aggr_model)\n",
    "    score = aggr_model.evaluate(x=x_test_0_to_4, y=y_test_0_to_4, verbose=0)\n",
    "\n",
    "    aggr_model = keras.models.clone_model(model1)\n",
    "    aggr_model.set_weights(agg_weights_list[0])\n",
    "    compile_model(aggr_model)\n",
    "    comp_score1 = aggr_model.evaluate(x=x_test_0_to_4, y=y_test_0_to_4, verbose=0)\n",
    "\n",
    "    aggr_model = keras.models.clone_model(model1)\n",
    "    aggr_model.set_weights(agg_weights_list[2])\n",
    "    compile_model(aggr_model)\n",
    "    comp_score2 = aggr_model.evaluate(x=x_test_0_to_4, y=y_test_0_to_4, verbose=0)\n",
    "    \n",
    "    agg_losses.append(score[0])\n",
    "    losses1.append(comp_score1[0])\n",
    "    losses2.append(comp_score2[0])\n",
    "    \n",
    "    B[i] = min(comp_score1[0], comp_score2[0]) - score[0]\n",
    "    A[i] = score[1] - max(comp_score1[1], comp_score2[1])\n",
    "    K.clear_session() #prevent memory leak https://github.com/keras-team/keras/issues/13118\n",
    "    i += 1\n",
    "    if i % 10 == 0:\n",
    "        print(\"{}th iteration\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as plot\n",
    "plt.plot(np.array(model_dists), np.array(acc_losses))\n",
    "plt.plot(np.array(model_dists), np.array(losses1))\n",
    "plt.plot(np.array(model_dists), np.array(losses2))\n",
    "plt.legend([\"aggregated model\", \"model 0,1\", \"model 8,9\"])\n",
    "plt.title(\"loss - 0 to 4\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"l2 distance (epochs for model 0,1 training)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.zeros(len(agg_weights_list_per_pi))\n",
    "A = np.zeros(len(agg_weights_list_per_pi))\n",
    "\n",
    "losses1 = list()\n",
    "accs1 = list()\n",
    "losses2 = list()\n",
    "accs2 = list()\n",
    "agg_accs = list()\n",
    "acc_losses = list()\n",
    "\n",
    "i = 0\n",
    "for agg_weights_list in agg_weights_list_per_pi:\n",
    "\n",
    "    aggr_model = keras.models.clone_model(model1)\n",
    "    aggr_model.set_weights(agg_weights_list[1])\n",
    "    compile_model(aggr_model)\n",
    "    score = aggr_model.evaluate(x=x_test_5_to_9, y=y_test_5_to_9, verbose=0)\n",
    "\n",
    "    aggr_model = keras.models.clone_model(model1)\n",
    "    aggr_model.set_weights(agg_weights_list[0])\n",
    "    compile_model(aggr_model)\n",
    "    comp_score1 = aggr_model.evaluate(x=x_test_5_to_9, y=y_test_5_to_9, verbose=0)\n",
    "\n",
    "    aggr_model = keras.models.clone_model(model1)\n",
    "    aggr_model.set_weights(agg_weights_list[2])\n",
    "    compile_model(aggr_model)\n",
    "    comp_score2 = aggr_model.evaluate(x=x_test_5_to_9, y=y_test_5_to_9, verbose=0)\n",
    "    \n",
    "    acc_losses.append(score[0])\n",
    "    agg_accs.append(score[1])\n",
    "    losses1.append(comp_score1[0])\n",
    "    accs1.append(comp_score1[1])\n",
    "    losses2.append(comp_score2[0])\n",
    "    accs2.append(comp_score2[1])\n",
    "    \n",
    "    B[i] = min(comp_score1[0], comp_score2[0]) - score[0]\n",
    "    A[i] = score[1] - max(comp_score1[1], comp_score2[1])\n",
    "    K.clear_session() #prevent memory leak https://github.com/keras-team/keras/issues/13118\n",
    "    i += 1\n",
    "    if i % 10 == 0:\n",
    "        print(\"{}th iteration\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as plot\n",
    "plt.plot(np.array(model_dists), np.array(acc_losses))\n",
    "plt.plot(np.array(model_dists), np.array(losses1))\n",
    "plt.plot(np.array(model_dists), np.array(losses2))\n",
    "plt.legend([\"aggregated model\", \"model 0,1\", \"model 8,9\"])\n",
    "plt.title(\"loss - 8,9\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"l2 distance (epochs for model 0,1 training)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "personalized.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
