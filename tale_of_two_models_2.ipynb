{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d6n47ueeqbXb"
   },
   "source": [
    "## Personalized Learning (Localized Learning?)\n",
    "\n",
    "#### This notebook includes the following online models;\n",
    "1. A single global model with all data\n",
    "2. Multiple local models (starting from a single global model)\n",
    "   1. that are updated with new data\n",
    "   2. that exchanges data in clusters\n",
    "   3. that exchanges parameters in clusters\n",
    "\n",
    "  \n",
    "#### The dataset that is used for this project is [CIFAR-100 dataset][1]\n",
    "* Has 100 classes containing 600 images each\n",
    "\n",
    "#### New data are fed by the following rules;\n",
    "1. Distributed, according to superclasses\n",
    "  * Clusters will only be updated with data that belongs to a specific superclass\n",
    "  * We update the NN by\n",
    "    1. Changing all parameters of the NN\n",
    "    2. Only changing the last few layers, as in many MTL models\n",
    "2. Randomly (why?)\n",
    "\n",
    "#### We expect to find an answer to the following research questions with this project;\n",
    "1. If models are updated with data (or parameters) that are shared within a cluster, can the model perform good enough with the labels that count?\n",
    "  * For example, the performance of the cluster that are updated with \"Vehicles\" superclass is only assessed with the labels that corresponds to the superclass.\n",
    "  \n",
    "[1]: https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oji0BTfoqbXc"
   },
   "source": [
    "#### Questions\n",
    "\n",
    "Retraining: how does it work <br>\n",
    "How do we compare these models?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mr4-uY0LqbXd"
   },
   "source": [
    "### Implementation with Custom Neural Network and MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tGoXLnOyqbXe",
    "outputId": "9ccd7215-80bf-4a0a-b852-8896b17c38f1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.lines as mlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E2faBs1yqbXj"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 50\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QXfylSWLqbXl"
   },
   "source": [
    "#### Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "V7iMvdGXqbXm",
    "outputId": "875da8c3-28b0-48cc-da41-b2d91add5cb3"
   },
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1 = x_train[-700:]\n",
    "y_train1 = y_train[-700:]\n",
    "x_train2 = x_train[:700]\n",
    "y_train2 = y_train[:700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve 10,000 samples for validation\n",
    "x_val1 = x_train1[-100:]\n",
    "y_val1 = y_train1[-100:]\n",
    "x_train1 = x_train1[:-100]\n",
    "y_train1 = y_train1[:-100]\n",
    "\n",
    "x_val2 = x_train2[-100:]\n",
    "y_val2 = y_train2[-100:]\n",
    "x_train2 = x_train2[:-100]\n",
    "y_train2 = y_train2[:-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (600, 28, 28, 1)\n",
      "600 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train1.shape)\n",
    "print(x_train1.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train1 = keras.utils.to_categorical(y_train1, num_classes)\n",
    "y_val1 = keras.utils.to_categorical(y_val1, num_classes)\n",
    "y_train2 = keras.utils.to_categorical(y_train2, num_classes)\n",
    "y_val2 = keras.utils.to_categorical(y_val2, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models and compile & fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_model():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=input_shape))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):  \n",
    "    # initiate SGD optimizer\n",
    "    opt = keras.optimizers.SGD(lr=0.1)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model_lr(model):  \n",
    "    # initiate SGD optimizer\n",
    "    opt = keras.optimizers.SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model1(model, epochs):\n",
    "    now = datetime.datetime.now()\n",
    "    print (\"Training date and time : \")\n",
    "    print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    return model.fit(x_train1, y_train1,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      validation_data=(x_val1, y_val1),\n",
    "                      shuffle=True, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model2(model, epochs):\n",
    "    now = datetime.datetime.now()\n",
    "    print (\"Training date and time : \")\n",
    "    print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    return model.fit(x_train2, y_train2,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      validation_data=(x_val2, y_val2),\n",
    "                      shuffle=True, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = custom_model()\n",
    "model1_clone = tf.keras.models.clone_model(model1)\n",
    "model1_clone.set_weights(model1.get_weights())\n",
    "model2 = tf.keras.models.clone_model(model1) # different initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a spectrum of models according to purturbations. Linear Interpolation with a granularity of 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pi_list = list(np.arange(0, 1.05, 0.05)) # P for perturbations\n",
    "\n",
    "weights = [model1.get_weights(), model2.get_weights()]\n",
    "model_weights_list = list()\n",
    "for pi in pi_list:\n",
    "    agg_weights = list()\n",
    "    for weights_list_tuple in zip(*weights):\n",
    "        agg_weights.append(np.array([np.average(np.array(w), axis=0, weights=[1. - pi, pi]) for w in zip(*weights_list_tuple)]))\n",
    "    model_weights_list.append(agg_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = list()\n",
    "for _ in range(len(pi_list)):\n",
    "    model_list.append(tf.keras.models.clone_model(model1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(model_list)):\n",
    "    model_list[i].set_weights(model_weights_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199210"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_list = []\n",
    "for m in model_list:\n",
    "    dist_list.append(semantic_drift.l2_distance(model1, m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have a spectrum of models from model1 to model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training date and time : \n",
      "2020-04-09 21:01:40\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/240\n",
      "600/600 [==============================] - 0s 649us/sample - loss: 0.0902 - accuracy: 0.1383 - val_loss: 0.0898 - val_accuracy: 0.1900\n",
      "Epoch 2/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0895 - accuracy: 0.1717 - val_loss: 0.0894 - val_accuracy: 0.2500\n",
      "Epoch 3/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0889 - accuracy: 0.2033 - val_loss: 0.0890 - val_accuracy: 0.2700\n",
      "Epoch 4/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0883 - accuracy: 0.2350 - val_loss: 0.0887 - val_accuracy: 0.2700\n",
      "Epoch 5/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0878 - accuracy: 0.2767 - val_loss: 0.0883 - val_accuracy: 0.3000\n",
      "Epoch 6/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0872 - accuracy: 0.3067 - val_loss: 0.0879 - val_accuracy: 0.2900\n",
      "Epoch 7/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0866 - accuracy: 0.3283 - val_loss: 0.0876 - val_accuracy: 0.2900\n",
      "Epoch 8/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0860 - accuracy: 0.3600 - val_loss: 0.0872 - val_accuracy: 0.3000\n",
      "Epoch 9/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0854 - accuracy: 0.3733 - val_loss: 0.0868 - val_accuracy: 0.3100\n",
      "Epoch 10/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0847 - accuracy: 0.3883 - val_loss: 0.0864 - val_accuracy: 0.3200\n",
      "Epoch 11/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0840 - accuracy: 0.4117 - val_loss: 0.0859 - val_accuracy: 0.3300\n",
      "Epoch 12/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0833 - accuracy: 0.4217 - val_loss: 0.0854 - val_accuracy: 0.3500\n",
      "Epoch 13/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0825 - accuracy: 0.4317 - val_loss: 0.0849 - val_accuracy: 0.3600\n",
      "Epoch 14/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0817 - accuracy: 0.4400 - val_loss: 0.0844 - val_accuracy: 0.4000\n",
      "Epoch 15/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0808 - accuracy: 0.4633 - val_loss: 0.0838 - val_accuracy: 0.4000\n",
      "Epoch 16/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0798 - accuracy: 0.4767 - val_loss: 0.0832 - val_accuracy: 0.4000\n",
      "Epoch 17/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0788 - accuracy: 0.4917 - val_loss: 0.0825 - val_accuracy: 0.4000\n",
      "Epoch 18/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0777 - accuracy: 0.5067 - val_loss: 0.0818 - val_accuracy: 0.4100\n",
      "Epoch 19/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0766 - accuracy: 0.5217 - val_loss: 0.0811 - val_accuracy: 0.4200\n",
      "Epoch 20/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0754 - accuracy: 0.5317 - val_loss: 0.0803 - val_accuracy: 0.4300\n",
      "Epoch 21/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0742 - accuracy: 0.5433 - val_loss: 0.0795 - val_accuracy: 0.4400\n",
      "Epoch 22/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0729 - accuracy: 0.5450 - val_loss: 0.0786 - val_accuracy: 0.4600\n",
      "Epoch 23/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0716 - accuracy: 0.5650 - val_loss: 0.0777 - val_accuracy: 0.4600\n",
      "Epoch 24/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0702 - accuracy: 0.5733 - val_loss: 0.0768 - val_accuracy: 0.4700\n",
      "Epoch 25/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0688 - accuracy: 0.5783 - val_loss: 0.0759 - val_accuracy: 0.4900\n",
      "Epoch 26/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0674 - accuracy: 0.5950 - val_loss: 0.0749 - val_accuracy: 0.5000\n",
      "Epoch 27/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0660 - accuracy: 0.6000 - val_loss: 0.0740 - val_accuracy: 0.5000\n",
      "Epoch 28/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0646 - accuracy: 0.6100 - val_loss: 0.0730 - val_accuracy: 0.5200\n",
      "Epoch 29/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0632 - accuracy: 0.6183 - val_loss: 0.0720 - val_accuracy: 0.5200\n",
      "Epoch 30/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0618 - accuracy: 0.6300 - val_loss: 0.0711 - val_accuracy: 0.5400\n",
      "Epoch 31/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0604 - accuracy: 0.6450 - val_loss: 0.0701 - val_accuracy: 0.5500\n",
      "Epoch 32/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0590 - accuracy: 0.6533 - val_loss: 0.0691 - val_accuracy: 0.5500\n",
      "Epoch 33/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0576 - accuracy: 0.6617 - val_loss: 0.0681 - val_accuracy: 0.5500\n",
      "Epoch 34/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0562 - accuracy: 0.6700 - val_loss: 0.0671 - val_accuracy: 0.5500\n",
      "Epoch 35/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0549 - accuracy: 0.6850 - val_loss: 0.0661 - val_accuracy: 0.5500\n",
      "Epoch 36/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0536 - accuracy: 0.6883 - val_loss: 0.0652 - val_accuracy: 0.5700\n",
      "Epoch 37/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0522 - accuracy: 0.7033 - val_loss: 0.0642 - val_accuracy: 0.5700\n",
      "Epoch 38/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0509 - accuracy: 0.7267 - val_loss: 0.0633 - val_accuracy: 0.5900\n",
      "Epoch 39/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0496 - accuracy: 0.7350 - val_loss: 0.0624 - val_accuracy: 0.6100\n",
      "Epoch 40/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0483 - accuracy: 0.7483 - val_loss: 0.0614 - val_accuracy: 0.6100\n",
      "Epoch 41/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0471 - accuracy: 0.7583 - val_loss: 0.0605 - val_accuracy: 0.6200\n",
      "Epoch 42/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0458 - accuracy: 0.7667 - val_loss: 0.0596 - val_accuracy: 0.6400\n",
      "Epoch 43/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0446 - accuracy: 0.7750 - val_loss: 0.0587 - val_accuracy: 0.6500\n",
      "Epoch 44/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0434 - accuracy: 0.7833 - val_loss: 0.0579 - val_accuracy: 0.6600\n",
      "Epoch 45/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0423 - accuracy: 0.7933 - val_loss: 0.0570 - val_accuracy: 0.6800\n",
      "Epoch 46/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0411 - accuracy: 0.7983 - val_loss: 0.0562 - val_accuracy: 0.6900\n",
      "Epoch 47/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0400 - accuracy: 0.8000 - val_loss: 0.0554 - val_accuracy: 0.7100\n",
      "Epoch 48/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0390 - accuracy: 0.8150 - val_loss: 0.0546 - val_accuracy: 0.7100\n",
      "Epoch 49/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0379 - accuracy: 0.8083 - val_loss: 0.0538 - val_accuracy: 0.7100\n",
      "Epoch 50/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0369 - accuracy: 0.8167 - val_loss: 0.0531 - val_accuracy: 0.7100\n",
      "Epoch 51/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0359 - accuracy: 0.8217 - val_loss: 0.0523 - val_accuracy: 0.7200\n",
      "Epoch 52/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0349 - accuracy: 0.8300 - val_loss: 0.0515 - val_accuracy: 0.7300\n",
      "Epoch 53/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0340 - accuracy: 0.8317 - val_loss: 0.0508 - val_accuracy: 0.7300\n",
      "Epoch 54/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0331 - accuracy: 0.8300 - val_loss: 0.0501 - val_accuracy: 0.7300\n",
      "Epoch 55/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0322 - accuracy: 0.8467 - val_loss: 0.0495 - val_accuracy: 0.7300\n",
      "Epoch 56/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0313 - accuracy: 0.8467 - val_loss: 0.0488 - val_accuracy: 0.7200\n",
      "Epoch 57/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0305 - accuracy: 0.8517 - val_loss: 0.0482 - val_accuracy: 0.7400\n",
      "Epoch 58/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0297 - accuracy: 0.8583 - val_loss: 0.0476 - val_accuracy: 0.7400\n",
      "Epoch 59/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0288 - accuracy: 0.8600 - val_loss: 0.0470 - val_accuracy: 0.7400\n",
      "Epoch 60/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0280 - accuracy: 0.8733 - val_loss: 0.0464 - val_accuracy: 0.7500\n",
      "Epoch 61/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0271 - accuracy: 0.8767 - val_loss: 0.0458 - val_accuracy: 0.7500\n",
      "Epoch 62/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0263 - accuracy: 0.8850 - val_loss: 0.0452 - val_accuracy: 0.7500\n",
      "Epoch 63/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0255 - accuracy: 0.8917 - val_loss: 0.0446 - val_accuracy: 0.7700\n",
      "Epoch 64/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0247 - accuracy: 0.8983 - val_loss: 0.0441 - val_accuracy: 0.7800\n",
      "Epoch 65/240\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0240 - accuracy: 0.9183 - val_loss: 0.0436 - val_accuracy: 0.7800\n",
      "Epoch 66/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0233 - accuracy: 0.9150 - val_loss: 0.0430 - val_accuracy: 0.7800\n",
      "Epoch 67/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0226 - accuracy: 0.9183 - val_loss: 0.0425 - val_accuracy: 0.7900\n",
      "Epoch 68/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0219 - accuracy: 0.9317 - val_loss: 0.0420 - val_accuracy: 0.7900\n",
      "Epoch 69/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0213 - accuracy: 0.9333 - val_loss: 0.0415 - val_accuracy: 0.7900\n",
      "Epoch 70/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0207 - accuracy: 0.9367 - val_loss: 0.0410 - val_accuracy: 0.7900\n",
      "Epoch 71/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0201 - accuracy: 0.9417 - val_loss: 0.0405 - val_accuracy: 0.7900\n",
      "Epoch 72/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0195 - accuracy: 0.9417 - val_loss: 0.0401 - val_accuracy: 0.7900\n",
      "Epoch 73/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0190 - accuracy: 0.9400 - val_loss: 0.0397 - val_accuracy: 0.7900\n",
      "Epoch 74/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0185 - accuracy: 0.9433 - val_loss: 0.0393 - val_accuracy: 0.7900\n",
      "Epoch 75/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0180 - accuracy: 0.9417 - val_loss: 0.0389 - val_accuracy: 0.7900\n",
      "Epoch 76/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0175 - accuracy: 0.9417 - val_loss: 0.0385 - val_accuracy: 0.8000\n",
      "Epoch 77/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0171 - accuracy: 0.9450 - val_loss: 0.0382 - val_accuracy: 0.8000\n",
      "Epoch 78/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0167 - accuracy: 0.9417 - val_loss: 0.0378 - val_accuracy: 0.8000\n",
      "Epoch 79/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0163 - accuracy: 0.9450 - val_loss: 0.0374 - val_accuracy: 0.8000\n",
      "Epoch 80/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0159 - accuracy: 0.9467 - val_loss: 0.0371 - val_accuracy: 0.8000\n",
      "Epoch 81/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0155 - accuracy: 0.9483 - val_loss: 0.0368 - val_accuracy: 0.8000\n",
      "Epoch 82/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0152 - accuracy: 0.9500 - val_loss: 0.0365 - val_accuracy: 0.8000\n",
      "Epoch 83/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0148 - accuracy: 0.9533 - val_loss: 0.0362 - val_accuracy: 0.8000\n",
      "Epoch 84/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0145 - accuracy: 0.9517 - val_loss: 0.0359 - val_accuracy: 0.8000\n",
      "Epoch 85/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0142 - accuracy: 0.9550 - val_loss: 0.0356 - val_accuracy: 0.8000\n",
      "Epoch 86/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0139 - accuracy: 0.9567 - val_loss: 0.0353 - val_accuracy: 0.8000\n",
      "Epoch 87/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0136 - accuracy: 0.9567 - val_loss: 0.0352 - val_accuracy: 0.8000\n",
      "Epoch 88/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0133 - accuracy: 0.9567 - val_loss: 0.0349 - val_accuracy: 0.8000\n",
      "Epoch 89/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0131 - accuracy: 0.9583 - val_loss: 0.0346 - val_accuracy: 0.8000\n",
      "Epoch 90/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0128 - accuracy: 0.9583 - val_loss: 0.0344 - val_accuracy: 0.8100\n",
      "Epoch 91/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0126 - accuracy: 0.9583 - val_loss: 0.0343 - val_accuracy: 0.8100\n",
      "Epoch 92/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0123 - accuracy: 0.9583 - val_loss: 0.0340 - val_accuracy: 0.8100\n",
      "Epoch 93/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0121 - accuracy: 0.9583 - val_loss: 0.0338 - val_accuracy: 0.8100\n",
      "Epoch 94/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0119 - accuracy: 0.9567 - val_loss: 0.0336 - val_accuracy: 0.8100\n",
      "Epoch 95/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0117 - accuracy: 0.9600 - val_loss: 0.0334 - val_accuracy: 0.8100\n",
      "Epoch 96/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0115 - accuracy: 0.9583 - val_loss: 0.0332 - val_accuracy: 0.8100\n",
      "Epoch 97/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0113 - accuracy: 0.9600 - val_loss: 0.0329 - val_accuracy: 0.8100\n",
      "Epoch 98/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0111 - accuracy: 0.9567 - val_loss: 0.0328 - val_accuracy: 0.8100\n",
      "Epoch 99/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0110 - accuracy: 0.9600 - val_loss: 0.0326 - val_accuracy: 0.8100\n",
      "Epoch 100/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0108 - accuracy: 0.9600 - val_loss: 0.0324 - val_accuracy: 0.8100\n",
      "Epoch 101/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0106 - accuracy: 0.9617 - val_loss: 0.0322 - val_accuracy: 0.8100\n",
      "Epoch 102/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0105 - accuracy: 0.9617 - val_loss: 0.0320 - val_accuracy: 0.8100\n",
      "Epoch 103/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0103 - accuracy: 0.9600 - val_loss: 0.0318 - val_accuracy: 0.8100\n",
      "Epoch 104/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0101 - accuracy: 0.9650 - val_loss: 0.0317 - val_accuracy: 0.8100\n",
      "Epoch 105/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0100 - accuracy: 0.9617 - val_loss: 0.0315 - val_accuracy: 0.8100\n",
      "Epoch 106/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0099 - accuracy: 0.9650 - val_loss: 0.0314 - val_accuracy: 0.8100\n",
      "Epoch 107/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0097 - accuracy: 0.9633 - val_loss: 0.0312 - val_accuracy: 0.8100\n",
      "Epoch 108/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0096 - accuracy: 0.9650 - val_loss: 0.0311 - val_accuracy: 0.8100\n",
      "Epoch 109/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0095 - accuracy: 0.9650 - val_loss: 0.0309 - val_accuracy: 0.8100\n",
      "Epoch 110/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0093 - accuracy: 0.9650 - val_loss: 0.0309 - val_accuracy: 0.8100\n",
      "Epoch 111/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0092 - accuracy: 0.9650 - val_loss: 0.0307 - val_accuracy: 0.8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0091 - accuracy: 0.9650 - val_loss: 0.0304 - val_accuracy: 0.8100\n",
      "Epoch 113/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0090 - accuracy: 0.9650 - val_loss: 0.0303 - val_accuracy: 0.8100\n",
      "Epoch 114/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0088 - accuracy: 0.9650 - val_loss: 0.0302 - val_accuracy: 0.8100\n",
      "Epoch 115/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0087 - accuracy: 0.9650 - val_loss: 0.0302 - val_accuracy: 0.8100\n",
      "Epoch 116/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0087 - accuracy: 0.9650 - val_loss: 0.0301 - val_accuracy: 0.8200\n",
      "Epoch 117/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0085 - accuracy: 0.9650 - val_loss: 0.0298 - val_accuracy: 0.8200\n",
      "Epoch 118/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0084 - accuracy: 0.9650 - val_loss: 0.0298 - val_accuracy: 0.8100\n",
      "Epoch 119/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0083 - accuracy: 0.9650 - val_loss: 0.0296 - val_accuracy: 0.8300\n",
      "Epoch 120/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0082 - accuracy: 0.9650 - val_loss: 0.0296 - val_accuracy: 0.8100\n",
      "Epoch 121/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0081 - accuracy: 0.9667 - val_loss: 0.0294 - val_accuracy: 0.8200\n",
      "Epoch 122/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0080 - accuracy: 0.9667 - val_loss: 0.0293 - val_accuracy: 0.8300\n",
      "Epoch 123/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0080 - accuracy: 0.9667 - val_loss: 0.0292 - val_accuracy: 0.8300\n",
      "Epoch 124/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0079 - accuracy: 0.9667 - val_loss: 0.0291 - val_accuracy: 0.8300\n",
      "Epoch 125/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0078 - accuracy: 0.9667 - val_loss: 0.0290 - val_accuracy: 0.8300\n",
      "Epoch 126/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0077 - accuracy: 0.9667 - val_loss: 0.0289 - val_accuracy: 0.8300\n",
      "Epoch 127/240\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0076 - accuracy: 0.9667 - val_loss: 0.0288 - val_accuracy: 0.8300\n",
      "Epoch 128/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0075 - accuracy: 0.9683 - val_loss: 0.0286 - val_accuracy: 0.8400\n",
      "Epoch 129/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0074 - accuracy: 0.9700 - val_loss: 0.0285 - val_accuracy: 0.8400\n",
      "Epoch 130/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0074 - accuracy: 0.9700 - val_loss: 0.0284 - val_accuracy: 0.8400\n",
      "Epoch 131/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0073 - accuracy: 0.9717 - val_loss: 0.0282 - val_accuracy: 0.8400\n",
      "Epoch 132/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0072 - accuracy: 0.9700 - val_loss: 0.0282 - val_accuracy: 0.8400\n",
      "Epoch 133/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0072 - accuracy: 0.9733 - val_loss: 0.0281 - val_accuracy: 0.8400\n",
      "Epoch 134/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0071 - accuracy: 0.9717 - val_loss: 0.0279 - val_accuracy: 0.8400\n",
      "Epoch 135/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0070 - accuracy: 0.9733 - val_loss: 0.0279 - val_accuracy: 0.8400\n",
      "Epoch 136/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0070 - accuracy: 0.9733 - val_loss: 0.0278 - val_accuracy: 0.8400\n",
      "Epoch 137/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0069 - accuracy: 0.9750 - val_loss: 0.0277 - val_accuracy: 0.8400\n",
      "Epoch 138/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0068 - accuracy: 0.9733 - val_loss: 0.0276 - val_accuracy: 0.8400\n",
      "Epoch 139/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0068 - accuracy: 0.9750 - val_loss: 0.0275 - val_accuracy: 0.8400\n",
      "Epoch 140/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0067 - accuracy: 0.9750 - val_loss: 0.0275 - val_accuracy: 0.8400\n",
      "Epoch 141/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0066 - accuracy: 0.9750 - val_loss: 0.0274 - val_accuracy: 0.8400\n",
      "Epoch 142/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0066 - accuracy: 0.9750 - val_loss: 0.0273 - val_accuracy: 0.8400\n",
      "Epoch 143/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0065 - accuracy: 0.9750 - val_loss: 0.0272 - val_accuracy: 0.8400\n",
      "Epoch 144/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0064 - accuracy: 0.9750 - val_loss: 0.0271 - val_accuracy: 0.8400\n",
      "Epoch 145/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0064 - accuracy: 0.9750 - val_loss: 0.0271 - val_accuracy: 0.8400\n",
      "Epoch 146/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0064 - accuracy: 0.9750 - val_loss: 0.0270 - val_accuracy: 0.8400\n",
      "Epoch 147/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0063 - accuracy: 0.9750 - val_loss: 0.0269 - val_accuracy: 0.8400\n",
      "Epoch 148/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0062 - accuracy: 0.9750 - val_loss: 0.0268 - val_accuracy: 0.8500\n",
      "Epoch 149/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0062 - accuracy: 0.9767 - val_loss: 0.0268 - val_accuracy: 0.8500\n",
      "Epoch 150/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0061 - accuracy: 0.9750 - val_loss: 0.0268 - val_accuracy: 0.8500\n",
      "Epoch 151/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0061 - accuracy: 0.9750 - val_loss: 0.0266 - val_accuracy: 0.8500\n",
      "Epoch 152/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0060 - accuracy: 0.9767 - val_loss: 0.0265 - val_accuracy: 0.8500\n",
      "Epoch 153/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0060 - accuracy: 0.9767 - val_loss: 0.0264 - val_accuracy: 0.8500\n",
      "Epoch 154/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0059 - accuracy: 0.9767 - val_loss: 0.0264 - val_accuracy: 0.8500\n",
      "Epoch 155/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0059 - accuracy: 0.9767 - val_loss: 0.0263 - val_accuracy: 0.8500\n",
      "Epoch 156/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0058 - accuracy: 0.9767 - val_loss: 0.0263 - val_accuracy: 0.8500\n",
      "Epoch 157/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0058 - accuracy: 0.9767 - val_loss: 0.0262 - val_accuracy: 0.8500\n",
      "Epoch 158/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0058 - accuracy: 0.9767 - val_loss: 0.0261 - val_accuracy: 0.8500\n",
      "Epoch 159/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0057 - accuracy: 0.9767 - val_loss: 0.0261 - val_accuracy: 0.8500\n",
      "Epoch 160/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0057 - accuracy: 0.9767 - val_loss: 0.0260 - val_accuracy: 0.8500\n",
      "Epoch 161/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0056 - accuracy: 0.9767 - val_loss: 0.0259 - val_accuracy: 0.8500\n",
      "Epoch 162/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0056 - accuracy: 0.9767 - val_loss: 0.0258 - val_accuracy: 0.8500\n",
      "Epoch 163/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0055 - accuracy: 0.9783 - val_loss: 0.0258 - val_accuracy: 0.8500\n",
      "Epoch 164/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0055 - accuracy: 0.9767 - val_loss: 0.0257 - val_accuracy: 0.8500\n",
      "Epoch 165/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0055 - accuracy: 0.9767 - val_loss: 0.0256 - val_accuracy: 0.8500\n",
      "Epoch 166/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0054 - accuracy: 0.9783 - val_loss: 0.0256 - val_accuracy: 0.8500\n",
      "Epoch 167/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0054 - accuracy: 0.9767 - val_loss: 0.0255 - val_accuracy: 0.8500\n",
      "Epoch 168/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0053 - accuracy: 0.9783 - val_loss: 0.0254 - val_accuracy: 0.8500\n",
      "Epoch 169/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0053 - accuracy: 0.9767 - val_loss: 0.0253 - val_accuracy: 0.8500\n",
      "Epoch 170/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0053 - accuracy: 0.9783 - val_loss: 0.0253 - val_accuracy: 0.8500\n",
      "Epoch 171/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0052 - accuracy: 0.9767 - val_loss: 0.0252 - val_accuracy: 0.8500\n",
      "Epoch 172/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0052 - accuracy: 0.9783 - val_loss: 0.0252 - val_accuracy: 0.8500\n",
      "Epoch 173/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0052 - accuracy: 0.9783 - val_loss: 0.0252 - val_accuracy: 0.8500\n",
      "Epoch 174/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0051 - accuracy: 0.9783 - val_loss: 0.0251 - val_accuracy: 0.8500\n",
      "Epoch 175/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0051 - accuracy: 0.9783 - val_loss: 0.0251 - val_accuracy: 0.8500\n",
      "Epoch 176/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0051 - accuracy: 0.9783 - val_loss: 0.0250 - val_accuracy: 0.8500\n",
      "Epoch 177/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0050 - accuracy: 0.9783 - val_loss: 0.0249 - val_accuracy: 0.8600\n",
      "Epoch 178/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0050 - accuracy: 0.9783 - val_loss: 0.0249 - val_accuracy: 0.8600\n",
      "Epoch 179/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0050 - accuracy: 0.9783 - val_loss: 0.0249 - val_accuracy: 0.8600\n",
      "Epoch 180/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0049 - accuracy: 0.9783 - val_loss: 0.0248 - val_accuracy: 0.8600\n",
      "Epoch 181/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0049 - accuracy: 0.9783 - val_loss: 0.0248 - val_accuracy: 0.8600\n",
      "Epoch 182/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0049 - accuracy: 0.9783 - val_loss: 0.0247 - val_accuracy: 0.8600\n",
      "Epoch 183/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0048 - accuracy: 0.9783 - val_loss: 0.0246 - val_accuracy: 0.8600\n",
      "Epoch 184/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0048 - accuracy: 0.9783 - val_loss: 0.0246 - val_accuracy: 0.8600\n",
      "Epoch 185/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0048 - accuracy: 0.9783 - val_loss: 0.0246 - val_accuracy: 0.8600\n",
      "Epoch 186/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0048 - accuracy: 0.9783 - val_loss: 0.0245 - val_accuracy: 0.8600\n",
      "Epoch 187/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0047 - accuracy: 0.9783 - val_loss: 0.0244 - val_accuracy: 0.8600\n",
      "Epoch 188/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0047 - accuracy: 0.9783 - val_loss: 0.0243 - val_accuracy: 0.8600\n",
      "Epoch 189/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0047 - accuracy: 0.9783 - val_loss: 0.0243 - val_accuracy: 0.8600\n",
      "Epoch 190/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0046 - accuracy: 0.9783 - val_loss: 0.0243 - val_accuracy: 0.8600\n",
      "Epoch 191/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0046 - accuracy: 0.9783 - val_loss: 0.0242 - val_accuracy: 0.8600\n",
      "Epoch 192/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0046 - accuracy: 0.9783 - val_loss: 0.0242 - val_accuracy: 0.8600\n",
      "Epoch 193/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0046 - accuracy: 0.9783 - val_loss: 0.0242 - val_accuracy: 0.8600\n",
      "Epoch 194/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0045 - accuracy: 0.9783 - val_loss: 0.0242 - val_accuracy: 0.8600\n",
      "Epoch 195/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0045 - accuracy: 0.9783 - val_loss: 0.0241 - val_accuracy: 0.8600\n",
      "Epoch 196/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0045 - accuracy: 0.9783 - val_loss: 0.0240 - val_accuracy: 0.8600\n",
      "Epoch 197/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0045 - accuracy: 0.9783 - val_loss: 0.0240 - val_accuracy: 0.8600\n",
      "Epoch 198/240\n",
      "600/600 [==============================] - 0s 113us/sample - loss: 0.0044 - accuracy: 0.9783 - val_loss: 0.0240 - val_accuracy: 0.8600\n",
      "Epoch 199/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0044 - accuracy: 0.9783 - val_loss: 0.0239 - val_accuracy: 0.8600\n",
      "Epoch 200/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0044 - accuracy: 0.9783 - val_loss: 0.0239 - val_accuracy: 0.8600\n",
      "Epoch 201/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0044 - accuracy: 0.9783 - val_loss: 0.0239 - val_accuracy: 0.8600\n",
      "Epoch 202/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0043 - accuracy: 0.9783 - val_loss: 0.0238 - val_accuracy: 0.8600\n",
      "Epoch 203/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0043 - accuracy: 0.9783 - val_loss: 0.0238 - val_accuracy: 0.8600\n",
      "Epoch 204/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0043 - accuracy: 0.9783 - val_loss: 0.0237 - val_accuracy: 0.8600\n",
      "Epoch 205/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0043 - accuracy: 0.9783 - val_loss: 0.0237 - val_accuracy: 0.8600\n",
      "Epoch 206/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0042 - accuracy: 0.9783 - val_loss: 0.0237 - val_accuracy: 0.8600\n",
      "Epoch 207/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0042 - accuracy: 0.9783 - val_loss: 0.0236 - val_accuracy: 0.8600\n",
      "Epoch 208/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0042 - accuracy: 0.9783 - val_loss: 0.0236 - val_accuracy: 0.8600\n",
      "Epoch 209/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0042 - accuracy: 0.9783 - val_loss: 0.0235 - val_accuracy: 0.8600\n",
      "Epoch 210/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0042 - accuracy: 0.9783 - val_loss: 0.0235 - val_accuracy: 0.8600\n",
      "Epoch 211/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0041 - accuracy: 0.9783 - val_loss: 0.0235 - val_accuracy: 0.8600\n",
      "Epoch 212/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0041 - accuracy: 0.9783 - val_loss: 0.0235 - val_accuracy: 0.8600\n",
      "Epoch 213/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0041 - accuracy: 0.9783 - val_loss: 0.0235 - val_accuracy: 0.8600\n",
      "Epoch 214/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0041 - accuracy: 0.9783 - val_loss: 0.0234 - val_accuracy: 0.8600\n",
      "Epoch 215/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0040 - accuracy: 0.9783 - val_loss: 0.0234 - val_accuracy: 0.8600\n",
      "Epoch 216/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0040 - accuracy: 0.9783 - val_loss: 0.0233 - val_accuracy: 0.8600\n",
      "Epoch 217/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0040 - accuracy: 0.9783 - val_loss: 0.0233 - val_accuracy: 0.8600\n",
      "Epoch 218/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0040 - accuracy: 0.9800 - val_loss: 0.0233 - val_accuracy: 0.8600\n",
      "Epoch 219/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0040 - accuracy: 0.9783 - val_loss: 0.0232 - val_accuracy: 0.8600\n",
      "Epoch 220/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0040 - accuracy: 0.9783 - val_loss: 0.0232 - val_accuracy: 0.8600\n",
      "Epoch 221/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0039 - accuracy: 0.9800 - val_loss: 0.0232 - val_accuracy: 0.8600\n",
      "Epoch 222/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0039 - accuracy: 0.9800 - val_loss: 0.0232 - val_accuracy: 0.8600\n",
      "Epoch 223/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0039 - accuracy: 0.9800 - val_loss: 0.0231 - val_accuracy: 0.8600\n",
      "Epoch 224/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0039 - accuracy: 0.9800 - val_loss: 0.0231 - val_accuracy: 0.8600\n",
      "Epoch 225/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0039 - accuracy: 0.9800 - val_loss: 0.0230 - val_accuracy: 0.8600\n",
      "Epoch 226/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0038 - accuracy: 0.9800 - val_loss: 0.0230 - val_accuracy: 0.8600\n",
      "Epoch 227/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0038 - accuracy: 0.9800 - val_loss: 0.0230 - val_accuracy: 0.8600\n",
      "Epoch 228/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0038 - accuracy: 0.9800 - val_loss: 0.0230 - val_accuracy: 0.8600\n",
      "Epoch 229/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0038 - accuracy: 0.9800 - val_loss: 0.0230 - val_accuracy: 0.8600\n",
      "Epoch 230/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0038 - accuracy: 0.9800 - val_loss: 0.0230 - val_accuracy: 0.8600\n",
      "Epoch 231/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0037 - accuracy: 0.9800 - val_loss: 0.0229 - val_accuracy: 0.8600\n",
      "Epoch 232/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0037 - accuracy: 0.9800 - val_loss: 0.0229 - val_accuracy: 0.8600\n",
      "Epoch 233/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0037 - accuracy: 0.9800 - val_loss: 0.0229 - val_accuracy: 0.8600\n",
      "Epoch 234/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0037 - accuracy: 0.9800 - val_loss: 0.0229 - val_accuracy: 0.8600\n",
      "Epoch 235/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0037 - accuracy: 0.9800 - val_loss: 0.0228 - val_accuracy: 0.8600\n",
      "Epoch 236/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0037 - accuracy: 0.9800 - val_loss: 0.0228 - val_accuracy: 0.8600\n",
      "Epoch 237/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0036 - accuracy: 0.9800 - val_loss: 0.0228 - val_accuracy: 0.8600\n",
      "Epoch 238/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0036 - accuracy: 0.9800 - val_loss: 0.0228 - val_accuracy: 0.8600\n",
      "Epoch 239/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0036 - accuracy: 0.9800 - val_loss: 0.0227 - val_accuracy: 0.8600\n",
      "Epoch 240/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0036 - accuracy: 0.9817 - val_loss: 0.0227 - val_accuracy: 0.8600\n",
      "Training date and time : \n",
      "2020-04-09 21:01:55\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/240\n",
      "600/600 [==============================] - 0s 663us/sample - loss: 0.0904 - accuracy: 0.1117 - val_loss: 0.0896 - val_accuracy: 0.1500\n",
      "Epoch 2/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0900 - accuracy: 0.1400 - val_loss: 0.0893 - val_accuracy: 0.1600\n",
      "Epoch 3/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0896 - accuracy: 0.1550 - val_loss: 0.0889 - val_accuracy: 0.2200\n",
      "Epoch 4/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0892 - accuracy: 0.1833 - val_loss: 0.0886 - val_accuracy: 0.2600\n",
      "Epoch 5/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0888 - accuracy: 0.2200 - val_loss: 0.0883 - val_accuracy: 0.2800\n",
      "Epoch 6/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0884 - accuracy: 0.2600 - val_loss: 0.0880 - val_accuracy: 0.2900\n",
      "Epoch 7/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0880 - accuracy: 0.2817 - val_loss: 0.0877 - val_accuracy: 0.3000\n",
      "Epoch 8/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0875 - accuracy: 0.3100 - val_loss: 0.0874 - val_accuracy: 0.3400\n",
      "Epoch 9/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0871 - accuracy: 0.3350 - val_loss: 0.0870 - val_accuracy: 0.3300\n",
      "Epoch 10/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0867 - accuracy: 0.3617 - val_loss: 0.0867 - val_accuracy: 0.3500\n",
      "Epoch 11/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0862 - accuracy: 0.3850 - val_loss: 0.0863 - val_accuracy: 0.3900\n",
      "Epoch 12/240\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0857 - accuracy: 0.4050 - val_loss: 0.0860 - val_accuracy: 0.4000\n",
      "Epoch 13/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0853 - accuracy: 0.4283 - val_loss: 0.0856 - val_accuracy: 0.4300\n",
      "Epoch 14/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0847 - accuracy: 0.4550 - val_loss: 0.0852 - val_accuracy: 0.4400\n",
      "Epoch 15/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0842 - accuracy: 0.4733 - val_loss: 0.0847 - val_accuracy: 0.4700\n",
      "Epoch 16/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0836 - accuracy: 0.4933 - val_loss: 0.0843 - val_accuracy: 0.4600\n",
      "Epoch 17/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0830 - accuracy: 0.5017 - val_loss: 0.0838 - val_accuracy: 0.4500\n",
      "Epoch 18/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0824 - accuracy: 0.5183 - val_loss: 0.0832 - val_accuracy: 0.4700\n",
      "Epoch 19/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0817 - accuracy: 0.5283 - val_loss: 0.0827 - val_accuracy: 0.4800\n",
      "Epoch 20/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0809 - accuracy: 0.5433 - val_loss: 0.0821 - val_accuracy: 0.4800\n",
      "Epoch 21/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0801 - accuracy: 0.5433 - val_loss: 0.0814 - val_accuracy: 0.4900\n",
      "Epoch 22/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0793 - accuracy: 0.5550 - val_loss: 0.0808 - val_accuracy: 0.5000\n",
      "Epoch 23/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0784 - accuracy: 0.5617 - val_loss: 0.0801 - val_accuracy: 0.5000\n",
      "Epoch 24/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0775 - accuracy: 0.5667 - val_loss: 0.0793 - val_accuracy: 0.5100\n",
      "Epoch 25/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0765 - accuracy: 0.5700 - val_loss: 0.0785 - val_accuracy: 0.5200\n",
      "Epoch 26/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0754 - accuracy: 0.5783 - val_loss: 0.0777 - val_accuracy: 0.5200\n",
      "Epoch 27/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0744 - accuracy: 0.5817 - val_loss: 0.0768 - val_accuracy: 0.5200\n",
      "Epoch 28/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0733 - accuracy: 0.5883 - val_loss: 0.0760 - val_accuracy: 0.5200\n",
      "Epoch 29/240\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0721 - accuracy: 0.5883 - val_loss: 0.0751 - val_accuracy: 0.5200\n",
      "Epoch 30/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0710 - accuracy: 0.5900 - val_loss: 0.0742 - val_accuracy: 0.5300\n",
      "Epoch 31/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0698 - accuracy: 0.5917 - val_loss: 0.0733 - val_accuracy: 0.5300\n",
      "Epoch 32/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0686 - accuracy: 0.5933 - val_loss: 0.0725 - val_accuracy: 0.5300\n",
      "Epoch 33/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0674 - accuracy: 0.5950 - val_loss: 0.0716 - val_accuracy: 0.5300\n",
      "Epoch 34/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0663 - accuracy: 0.6017 - val_loss: 0.0707 - val_accuracy: 0.5300\n",
      "Epoch 35/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0651 - accuracy: 0.6050 - val_loss: 0.0698 - val_accuracy: 0.5300\n",
      "Epoch 36/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0640 - accuracy: 0.6100 - val_loss: 0.0690 - val_accuracy: 0.5400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0629 - accuracy: 0.6100 - val_loss: 0.0682 - val_accuracy: 0.5400\n",
      "Epoch 38/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0618 - accuracy: 0.6150 - val_loss: 0.0673 - val_accuracy: 0.5600\n",
      "Epoch 39/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0607 - accuracy: 0.6200 - val_loss: 0.0665 - val_accuracy: 0.5600\n",
      "Epoch 40/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0597 - accuracy: 0.6200 - val_loss: 0.0658 - val_accuracy: 0.5600\n",
      "Epoch 41/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0586 - accuracy: 0.6250 - val_loss: 0.0650 - val_accuracy: 0.5600\n",
      "Epoch 42/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0576 - accuracy: 0.6300 - val_loss: 0.0642 - val_accuracy: 0.5700\n",
      "Epoch 43/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0567 - accuracy: 0.6350 - val_loss: 0.0635 - val_accuracy: 0.5800\n",
      "Epoch 44/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0557 - accuracy: 0.6383 - val_loss: 0.0627 - val_accuracy: 0.5900\n",
      "Epoch 45/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0548 - accuracy: 0.6433 - val_loss: 0.0620 - val_accuracy: 0.5800\n",
      "Epoch 46/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0539 - accuracy: 0.6483 - val_loss: 0.0613 - val_accuracy: 0.6000\n",
      "Epoch 47/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0530 - accuracy: 0.6517 - val_loss: 0.0607 - val_accuracy: 0.6200\n",
      "Epoch 48/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0521 - accuracy: 0.6550 - val_loss: 0.0600 - val_accuracy: 0.6200\n",
      "Epoch 49/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0513 - accuracy: 0.6583 - val_loss: 0.0594 - val_accuracy: 0.6200\n",
      "Epoch 50/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0505 - accuracy: 0.6667 - val_loss: 0.0588 - val_accuracy: 0.6200\n",
      "Epoch 51/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0497 - accuracy: 0.6717 - val_loss: 0.0582 - val_accuracy: 0.6200\n",
      "Epoch 52/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0489 - accuracy: 0.6750 - val_loss: 0.0576 - val_accuracy: 0.6200\n",
      "Epoch 53/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0481 - accuracy: 0.6783 - val_loss: 0.0571 - val_accuracy: 0.6200\n",
      "Epoch 54/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0473 - accuracy: 0.6800 - val_loss: 0.0566 - val_accuracy: 0.6200\n",
      "Epoch 55/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0466 - accuracy: 0.6850 - val_loss: 0.0560 - val_accuracy: 0.6300\n",
      "Epoch 56/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0458 - accuracy: 0.6850 - val_loss: 0.0556 - val_accuracy: 0.6200\n",
      "Epoch 57/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0451 - accuracy: 0.6900 - val_loss: 0.0551 - val_accuracy: 0.6100\n",
      "Epoch 58/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0444 - accuracy: 0.6917 - val_loss: 0.0546 - val_accuracy: 0.6400\n",
      "Epoch 59/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0436 - accuracy: 0.7000 - val_loss: 0.0541 - val_accuracy: 0.6400\n",
      "Epoch 60/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0429 - accuracy: 0.7050 - val_loss: 0.0537 - val_accuracy: 0.6400\n",
      "Epoch 61/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0422 - accuracy: 0.7117 - val_loss: 0.0532 - val_accuracy: 0.6600\n",
      "Epoch 62/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0415 - accuracy: 0.7167 - val_loss: 0.0528 - val_accuracy: 0.6600\n",
      "Epoch 63/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0408 - accuracy: 0.7383 - val_loss: 0.0524 - val_accuracy: 0.6600\n",
      "Epoch 64/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0401 - accuracy: 0.7517 - val_loss: 0.0520 - val_accuracy: 0.6600\n",
      "Epoch 65/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0394 - accuracy: 0.7533 - val_loss: 0.0516 - val_accuracy: 0.6700\n",
      "Epoch 66/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0387 - accuracy: 0.7633 - val_loss: 0.0512 - val_accuracy: 0.6700\n",
      "Epoch 67/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0381 - accuracy: 0.7683 - val_loss: 0.0508 - val_accuracy: 0.6800\n",
      "Epoch 68/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0374 - accuracy: 0.7717 - val_loss: 0.0504 - val_accuracy: 0.6700\n",
      "Epoch 69/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0368 - accuracy: 0.7867 - val_loss: 0.0500 - val_accuracy: 0.6800\n",
      "Epoch 70/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0361 - accuracy: 0.7950 - val_loss: 0.0495 - val_accuracy: 0.6800\n",
      "Epoch 71/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0355 - accuracy: 0.8017 - val_loss: 0.0491 - val_accuracy: 0.6800\n",
      "Epoch 72/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0349 - accuracy: 0.8117 - val_loss: 0.0487 - val_accuracy: 0.6800\n",
      "Epoch 73/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0342 - accuracy: 0.8150 - val_loss: 0.0483 - val_accuracy: 0.6800\n",
      "Epoch 74/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0336 - accuracy: 0.8250 - val_loss: 0.0479 - val_accuracy: 0.6800\n",
      "Epoch 75/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0331 - accuracy: 0.8283 - val_loss: 0.0475 - val_accuracy: 0.6800\n",
      "Epoch 76/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0325 - accuracy: 0.8300 - val_loss: 0.0470 - val_accuracy: 0.6800\n",
      "Epoch 77/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0319 - accuracy: 0.8333 - val_loss: 0.0466 - val_accuracy: 0.6800\n",
      "Epoch 78/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0314 - accuracy: 0.8400 - val_loss: 0.0463 - val_accuracy: 0.6900\n",
      "Epoch 79/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0308 - accuracy: 0.8433 - val_loss: 0.0459 - val_accuracy: 0.6900\n",
      "Epoch 80/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0303 - accuracy: 0.8450 - val_loss: 0.0455 - val_accuracy: 0.6900\n",
      "Epoch 81/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0298 - accuracy: 0.8517 - val_loss: 0.0451 - val_accuracy: 0.7000\n",
      "Epoch 82/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0293 - accuracy: 0.8533 - val_loss: 0.0447 - val_accuracy: 0.6900\n",
      "Epoch 83/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0289 - accuracy: 0.8533 - val_loss: 0.0444 - val_accuracy: 0.6900\n",
      "Epoch 84/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0283 - accuracy: 0.8617 - val_loss: 0.0440 - val_accuracy: 0.7000\n",
      "Epoch 85/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0279 - accuracy: 0.8617 - val_loss: 0.0437 - val_accuracy: 0.6900\n",
      "Epoch 86/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0274 - accuracy: 0.8633 - val_loss: 0.0434 - val_accuracy: 0.7000\n",
      "Epoch 87/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0270 - accuracy: 0.8683 - val_loss: 0.0430 - val_accuracy: 0.7200\n",
      "Epoch 88/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0266 - accuracy: 0.8650 - val_loss: 0.0426 - val_accuracy: 0.7200\n",
      "Epoch 89/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0262 - accuracy: 0.8700 - val_loss: 0.0423 - val_accuracy: 0.7200\n",
      "Epoch 90/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0258 - accuracy: 0.8700 - val_loss: 0.0420 - val_accuracy: 0.7200\n",
      "Epoch 91/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0254 - accuracy: 0.8733 - val_loss: 0.0417 - val_accuracy: 0.7200\n",
      "Epoch 92/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0250 - accuracy: 0.8717 - val_loss: 0.0413 - val_accuracy: 0.7200\n",
      "Epoch 93/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0246 - accuracy: 0.8750 - val_loss: 0.0410 - val_accuracy: 0.7200\n",
      "Epoch 94/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0243 - accuracy: 0.8783 - val_loss: 0.0408 - val_accuracy: 0.7200\n",
      "Epoch 95/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0239 - accuracy: 0.8833 - val_loss: 0.0405 - val_accuracy: 0.7200\n",
      "Epoch 96/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0236 - accuracy: 0.8833 - val_loss: 0.0403 - val_accuracy: 0.7200\n",
      "Epoch 97/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0232 - accuracy: 0.8833 - val_loss: 0.0400 - val_accuracy: 0.7300\n",
      "Epoch 98/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0229 - accuracy: 0.8833 - val_loss: 0.0397 - val_accuracy: 0.7300\n",
      "Epoch 99/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0226 - accuracy: 0.8850 - val_loss: 0.0394 - val_accuracy: 0.7300\n",
      "Epoch 100/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0223 - accuracy: 0.8867 - val_loss: 0.0391 - val_accuracy: 0.7300\n",
      "Epoch 101/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0220 - accuracy: 0.8883 - val_loss: 0.0388 - val_accuracy: 0.7300\n",
      "Epoch 102/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0217 - accuracy: 0.8867 - val_loss: 0.0386 - val_accuracy: 0.7400\n",
      "Epoch 103/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0214 - accuracy: 0.8900 - val_loss: 0.0384 - val_accuracy: 0.7400\n",
      "Epoch 104/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0212 - accuracy: 0.8917 - val_loss: 0.0381 - val_accuracy: 0.7400\n",
      "Epoch 105/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0209 - accuracy: 0.8933 - val_loss: 0.0378 - val_accuracy: 0.7400\n",
      "Epoch 106/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0206 - accuracy: 0.8933 - val_loss: 0.0376 - val_accuracy: 0.7500\n",
      "Epoch 107/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0203 - accuracy: 0.8967 - val_loss: 0.0374 - val_accuracy: 0.7500\n",
      "Epoch 108/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0201 - accuracy: 0.8983 - val_loss: 0.0371 - val_accuracy: 0.7500\n",
      "Epoch 109/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0198 - accuracy: 0.9000 - val_loss: 0.0369 - val_accuracy: 0.7500\n",
      "Epoch 110/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0196 - accuracy: 0.8983 - val_loss: 0.0366 - val_accuracy: 0.7500\n",
      "Epoch 111/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0194 - accuracy: 0.9000 - val_loss: 0.0364 - val_accuracy: 0.7500\n",
      "Epoch 112/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0191 - accuracy: 0.9017 - val_loss: 0.0362 - val_accuracy: 0.7500\n",
      "Epoch 113/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0189 - accuracy: 0.9033 - val_loss: 0.0360 - val_accuracy: 0.7500\n",
      "Epoch 114/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0186 - accuracy: 0.9067 - val_loss: 0.0357 - val_accuracy: 0.7500\n",
      "Epoch 115/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0185 - accuracy: 0.9050 - val_loss: 0.0355 - val_accuracy: 0.7500\n",
      "Epoch 116/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0182 - accuracy: 0.9083 - val_loss: 0.0354 - val_accuracy: 0.7500\n",
      "Epoch 117/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0180 - accuracy: 0.9083 - val_loss: 0.0352 - val_accuracy: 0.7500\n",
      "Epoch 118/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0178 - accuracy: 0.9100 - val_loss: 0.0350 - val_accuracy: 0.7500\n",
      "Epoch 119/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0176 - accuracy: 0.9083 - val_loss: 0.0348 - val_accuracy: 0.7500\n",
      "Epoch 120/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0174 - accuracy: 0.9150 - val_loss: 0.0345 - val_accuracy: 0.7500\n",
      "Epoch 121/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0172 - accuracy: 0.9167 - val_loss: 0.0343 - val_accuracy: 0.7500\n",
      "Epoch 122/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0170 - accuracy: 0.9150 - val_loss: 0.0341 - val_accuracy: 0.7500\n",
      "Epoch 123/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0168 - accuracy: 0.9167 - val_loss: 0.0339 - val_accuracy: 0.7500\n",
      "Epoch 124/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0166 - accuracy: 0.9200 - val_loss: 0.0338 - val_accuracy: 0.7500\n",
      "Epoch 125/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0165 - accuracy: 0.9217 - val_loss: 0.0336 - val_accuracy: 0.7500\n",
      "Epoch 126/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0163 - accuracy: 0.9267 - val_loss: 0.0335 - val_accuracy: 0.7500\n",
      "Epoch 127/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0161 - accuracy: 0.9217 - val_loss: 0.0333 - val_accuracy: 0.7500\n",
      "Epoch 128/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0159 - accuracy: 0.9233 - val_loss: 0.0332 - val_accuracy: 0.7500\n",
      "Epoch 129/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0158 - accuracy: 0.9267 - val_loss: 0.0330 - val_accuracy: 0.7500\n",
      "Epoch 130/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0156 - accuracy: 0.9250 - val_loss: 0.0328 - val_accuracy: 0.7400\n",
      "Epoch 131/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0154 - accuracy: 0.9267 - val_loss: 0.0326 - val_accuracy: 0.7400\n",
      "Epoch 132/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0153 - accuracy: 0.9283 - val_loss: 0.0325 - val_accuracy: 0.7400\n",
      "Epoch 133/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0151 - accuracy: 0.9300 - val_loss: 0.0324 - val_accuracy: 0.7400\n",
      "Epoch 134/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0150 - accuracy: 0.9333 - val_loss: 0.0322 - val_accuracy: 0.7400\n",
      "Epoch 135/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0148 - accuracy: 0.9317 - val_loss: 0.0320 - val_accuracy: 0.7500\n",
      "Epoch 136/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0147 - accuracy: 0.9317 - val_loss: 0.0319 - val_accuracy: 0.7600\n",
      "Epoch 137/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0145 - accuracy: 0.9333 - val_loss: 0.0317 - val_accuracy: 0.7600\n",
      "Epoch 138/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0144 - accuracy: 0.9350 - val_loss: 0.0315 - val_accuracy: 0.7600\n",
      "Epoch 139/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0142 - accuracy: 0.9367 - val_loss: 0.0315 - val_accuracy: 0.7600\n",
      "Epoch 140/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0141 - accuracy: 0.9367 - val_loss: 0.0314 - val_accuracy: 0.7600\n",
      "Epoch 141/240\n",
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0139 - accuracy: 0.9383 - val_loss: 0.0313 - val_accuracy: 0.7600\n",
      "Epoch 142/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0138 - accuracy: 0.9383 - val_loss: 0.0312 - val_accuracy: 0.7600\n",
      "Epoch 143/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0137 - accuracy: 0.9367 - val_loss: 0.0311 - val_accuracy: 0.7600\n",
      "Epoch 144/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0135 - accuracy: 0.9367 - val_loss: 0.0309 - val_accuracy: 0.7600\n",
      "Epoch 145/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0134 - accuracy: 0.9417 - val_loss: 0.0308 - val_accuracy: 0.7600\n",
      "Epoch 146/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0133 - accuracy: 0.9383 - val_loss: 0.0307 - val_accuracy: 0.7600\n",
      "Epoch 147/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0132 - accuracy: 0.9417 - val_loss: 0.0306 - val_accuracy: 0.7600\n",
      "Epoch 148/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0131 - accuracy: 0.9433 - val_loss: 0.0304 - val_accuracy: 0.7800\n",
      "Epoch 149/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0129 - accuracy: 0.9433 - val_loss: 0.0304 - val_accuracy: 0.7800\n",
      "Epoch 150/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0128 - accuracy: 0.9417 - val_loss: 0.0302 - val_accuracy: 0.7800\n",
      "Epoch 151/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0127 - accuracy: 0.9417 - val_loss: 0.0301 - val_accuracy: 0.7800\n",
      "Epoch 152/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0126 - accuracy: 0.9450 - val_loss: 0.0300 - val_accuracy: 0.7800\n",
      "Epoch 153/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0125 - accuracy: 0.9450 - val_loss: 0.0299 - val_accuracy: 0.7800\n",
      "Epoch 154/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0124 - accuracy: 0.9450 - val_loss: 0.0298 - val_accuracy: 0.7800\n",
      "Epoch 155/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0122 - accuracy: 0.9433 - val_loss: 0.0297 - val_accuracy: 0.7800\n",
      "Epoch 156/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0121 - accuracy: 0.9467 - val_loss: 0.0296 - val_accuracy: 0.7800\n",
      "Epoch 157/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0120 - accuracy: 0.9467 - val_loss: 0.0295 - val_accuracy: 0.7800\n",
      "Epoch 158/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0119 - accuracy: 0.9483 - val_loss: 0.0293 - val_accuracy: 0.7800\n",
      "Epoch 159/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0118 - accuracy: 0.9467 - val_loss: 0.0292 - val_accuracy: 0.7900\n",
      "Epoch 160/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0117 - accuracy: 0.9483 - val_loss: 0.0292 - val_accuracy: 0.7900\n",
      "Epoch 161/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0116 - accuracy: 0.9483 - val_loss: 0.0292 - val_accuracy: 0.7900\n",
      "Epoch 162/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0115 - accuracy: 0.9483 - val_loss: 0.0291 - val_accuracy: 0.7900\n",
      "Epoch 163/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0114 - accuracy: 0.9500 - val_loss: 0.0289 - val_accuracy: 0.7900\n",
      "Epoch 164/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0113 - accuracy: 0.9483 - val_loss: 0.0290 - val_accuracy: 0.7900\n",
      "Epoch 165/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0112 - accuracy: 0.9533 - val_loss: 0.0289 - val_accuracy: 0.7900\n",
      "Epoch 166/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0111 - accuracy: 0.9533 - val_loss: 0.0288 - val_accuracy: 0.7900\n",
      "Epoch 167/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0110 - accuracy: 0.9533 - val_loss: 0.0286 - val_accuracy: 0.7900\n",
      "Epoch 168/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0109 - accuracy: 0.9533 - val_loss: 0.0285 - val_accuracy: 0.7900\n",
      "Epoch 169/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0108 - accuracy: 0.9533 - val_loss: 0.0285 - val_accuracy: 0.7900\n",
      "Epoch 170/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0107 - accuracy: 0.9533 - val_loss: 0.0285 - val_accuracy: 0.7900\n",
      "Epoch 171/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0106 - accuracy: 0.9533 - val_loss: 0.0284 - val_accuracy: 0.7900\n",
      "Epoch 172/240\n",
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0105 - accuracy: 0.9533 - val_loss: 0.0283 - val_accuracy: 0.7900\n",
      "Epoch 173/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0105 - accuracy: 0.9533 - val_loss: 0.0282 - val_accuracy: 0.7900\n",
      "Epoch 174/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0104 - accuracy: 0.9533 - val_loss: 0.0282 - val_accuracy: 0.7900\n",
      "Epoch 175/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0103 - accuracy: 0.9533 - val_loss: 0.0281 - val_accuracy: 0.7900\n",
      "Epoch 176/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0102 - accuracy: 0.9533 - val_loss: 0.0280 - val_accuracy: 0.7900\n",
      "Epoch 177/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0101 - accuracy: 0.9550 - val_loss: 0.0280 - val_accuracy: 0.7900\n",
      "Epoch 178/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0100 - accuracy: 0.9533 - val_loss: 0.0279 - val_accuracy: 0.7900\n",
      "Epoch 179/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0099 - accuracy: 0.9550 - val_loss: 0.0278 - val_accuracy: 0.7900\n",
      "Epoch 180/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0099 - accuracy: 0.9533 - val_loss: 0.0277 - val_accuracy: 0.7900\n",
      "Epoch 181/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0098 - accuracy: 0.9550 - val_loss: 0.0277 - val_accuracy: 0.7900\n",
      "Epoch 182/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0097 - accuracy: 0.9567 - val_loss: 0.0277 - val_accuracy: 0.7900\n",
      "Epoch 183/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0096 - accuracy: 0.9583 - val_loss: 0.0276 - val_accuracy: 0.7900\n",
      "Epoch 184/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0095 - accuracy: 0.9600 - val_loss: 0.0275 - val_accuracy: 0.7900\n",
      "Epoch 185/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0095 - accuracy: 0.9617 - val_loss: 0.0275 - val_accuracy: 0.7900\n",
      "Epoch 186/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0094 - accuracy: 0.9600 - val_loss: 0.0275 - val_accuracy: 0.7900\n",
      "Epoch 187/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0093 - accuracy: 0.9633 - val_loss: 0.0275 - val_accuracy: 0.7900\n",
      "Epoch 188/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0092 - accuracy: 0.9617 - val_loss: 0.0274 - val_accuracy: 0.7900\n",
      "Epoch 189/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0092 - accuracy: 0.9617 - val_loss: 0.0274 - val_accuracy: 0.7900\n",
      "Epoch 190/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0091 - accuracy: 0.9617 - val_loss: 0.0273 - val_accuracy: 0.7900\n",
      "Epoch 191/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0090 - accuracy: 0.9617 - val_loss: 0.0272 - val_accuracy: 0.7900\n",
      "Epoch 192/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0090 - accuracy: 0.9633 - val_loss: 0.0272 - val_accuracy: 0.7900\n",
      "Epoch 193/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0089 - accuracy: 0.9633 - val_loss: 0.0272 - val_accuracy: 0.7900\n",
      "Epoch 194/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0088 - accuracy: 0.9650 - val_loss: 0.0271 - val_accuracy: 0.7900\n",
      "Epoch 195/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0088 - accuracy: 0.9650 - val_loss: 0.0270 - val_accuracy: 0.7900\n",
      "Epoch 196/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0087 - accuracy: 0.9650 - val_loss: 0.0270 - val_accuracy: 0.7900\n",
      "Epoch 197/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0086 - accuracy: 0.9650 - val_loss: 0.0270 - val_accuracy: 0.7900\n",
      "Epoch 198/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0086 - accuracy: 0.9650 - val_loss: 0.0269 - val_accuracy: 0.7900\n",
      "Epoch 199/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0085 - accuracy: 0.9650 - val_loss: 0.0269 - val_accuracy: 0.7900\n",
      "Epoch 200/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0084 - accuracy: 0.9650 - val_loss: 0.0268 - val_accuracy: 0.7900\n",
      "Epoch 201/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0084 - accuracy: 0.9650 - val_loss: 0.0268 - val_accuracy: 0.7900\n",
      "Epoch 202/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0083 - accuracy: 0.9650 - val_loss: 0.0268 - val_accuracy: 0.7900\n",
      "Epoch 203/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0083 - accuracy: 0.9650 - val_loss: 0.0267 - val_accuracy: 0.7900\n",
      "Epoch 204/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0082 - accuracy: 0.9650 - val_loss: 0.0266 - val_accuracy: 0.7900\n",
      "Epoch 205/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0081 - accuracy: 0.9650 - val_loss: 0.0267 - val_accuracy: 0.7900\n",
      "Epoch 206/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0081 - accuracy: 0.9650 - val_loss: 0.0266 - val_accuracy: 0.7900\n",
      "Epoch 207/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0080 - accuracy: 0.9650 - val_loss: 0.0266 - val_accuracy: 0.7900\n",
      "Epoch 208/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0080 - accuracy: 0.9650 - val_loss: 0.0265 - val_accuracy: 0.7900\n",
      "Epoch 209/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0079 - accuracy: 0.9650 - val_loss: 0.0265 - val_accuracy: 0.7900\n",
      "Epoch 210/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0078 - accuracy: 0.9650 - val_loss: 0.0265 - val_accuracy: 0.7900\n",
      "Epoch 211/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0078 - accuracy: 0.9650 - val_loss: 0.0264 - val_accuracy: 0.7900\n",
      "Epoch 212/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0077 - accuracy: 0.9650 - val_loss: 0.0264 - val_accuracy: 0.7900\n",
      "Epoch 213/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0077 - accuracy: 0.9650 - val_loss: 0.0264 - val_accuracy: 0.7900\n",
      "Epoch 214/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0076 - accuracy: 0.9650 - val_loss: 0.0264 - val_accuracy: 0.7900\n",
      "Epoch 215/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0076 - accuracy: 0.9650 - val_loss: 0.0264 - val_accuracy: 0.7900\n",
      "Epoch 216/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0075 - accuracy: 0.9650 - val_loss: 0.0263 - val_accuracy: 0.7900\n",
      "Epoch 217/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0075 - accuracy: 0.9650 - val_loss: 0.0263 - val_accuracy: 0.7900\n",
      "Epoch 218/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0074 - accuracy: 0.9683 - val_loss: 0.0262 - val_accuracy: 0.7900\n",
      "Epoch 219/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0074 - accuracy: 0.9667 - val_loss: 0.0262 - val_accuracy: 0.7900\n",
      "Epoch 220/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0073 - accuracy: 0.9683 - val_loss: 0.0262 - val_accuracy: 0.7900\n",
      "Epoch 221/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0073 - accuracy: 0.9683 - val_loss: 0.0261 - val_accuracy: 0.7900\n",
      "Epoch 222/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0072 - accuracy: 0.9683 - val_loss: 0.0261 - val_accuracy: 0.7900\n",
      "Epoch 223/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0072 - accuracy: 0.9683 - val_loss: 0.0261 - val_accuracy: 0.8000\n",
      "Epoch 224/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0071 - accuracy: 0.9683 - val_loss: 0.0260 - val_accuracy: 0.8000\n",
      "Epoch 225/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0071 - accuracy: 0.9683 - val_loss: 0.0260 - val_accuracy: 0.8000\n",
      "Epoch 226/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0070 - accuracy: 0.9683 - val_loss: 0.0260 - val_accuracy: 0.8000\n",
      "Epoch 227/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0070 - accuracy: 0.9683 - val_loss: 0.0260 - val_accuracy: 0.8000\n",
      "Epoch 228/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0069 - accuracy: 0.9683 - val_loss: 0.0259 - val_accuracy: 0.8000\n",
      "Epoch 229/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0069 - accuracy: 0.9683 - val_loss: 0.0260 - val_accuracy: 0.8000\n",
      "Epoch 230/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0068 - accuracy: 0.9683 - val_loss: 0.0259 - val_accuracy: 0.8000\n",
      "Epoch 231/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0068 - accuracy: 0.9700 - val_loss: 0.0259 - val_accuracy: 0.8000\n",
      "Epoch 232/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0068 - accuracy: 0.9717 - val_loss: 0.0259 - val_accuracy: 0.8000\n",
      "Epoch 233/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0067 - accuracy: 0.9717 - val_loss: 0.0259 - val_accuracy: 0.8000\n",
      "Epoch 234/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0067 - accuracy: 0.9700 - val_loss: 0.0259 - val_accuracy: 0.8000\n",
      "Epoch 235/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0066 - accuracy: 0.9700 - val_loss: 0.0258 - val_accuracy: 0.8000\n",
      "Epoch 236/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0066 - accuracy: 0.9717 - val_loss: 0.0258 - val_accuracy: 0.8000\n",
      "Epoch 237/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0065 - accuracy: 0.9717 - val_loss: 0.0258 - val_accuracy: 0.8000\n",
      "Epoch 238/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0065 - accuracy: 0.9700 - val_loss: 0.0258 - val_accuracy: 0.8000\n",
      "Epoch 239/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0064 - accuracy: 0.9717 - val_loss: 0.0258 - val_accuracy: 0.8000\n",
      "Epoch 240/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0064 - accuracy: 0.9717 - val_loss: 0.0257 - val_accuracy: 0.8100\n",
      "Training date and time : \n",
      "2020-04-09 21:02:11\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/240\n",
      "600/600 [==============================] - 0s 646us/sample - loss: 0.0903 - accuracy: 0.1117 - val_loss: 0.0896 - val_accuracy: 0.1500\n",
      "Epoch 2/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0899 - accuracy: 0.1300 - val_loss: 0.0893 - val_accuracy: 0.1700\n",
      "Epoch 3/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0896 - accuracy: 0.1500 - val_loss: 0.0890 - val_accuracy: 0.1800\n",
      "Epoch 4/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0893 - accuracy: 0.1733 - val_loss: 0.0888 - val_accuracy: 0.2200\n",
      "Epoch 5/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0890 - accuracy: 0.2017 - val_loss: 0.0885 - val_accuracy: 0.2700\n",
      "Epoch 6/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0886 - accuracy: 0.2400 - val_loss: 0.0883 - val_accuracy: 0.3000\n",
      "Epoch 7/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0883 - accuracy: 0.2717 - val_loss: 0.0880 - val_accuracy: 0.3000\n",
      "Epoch 8/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0880 - accuracy: 0.2950 - val_loss: 0.0878 - val_accuracy: 0.3200\n",
      "Epoch 9/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0876 - accuracy: 0.3217 - val_loss: 0.0875 - val_accuracy: 0.3400\n",
      "Epoch 10/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0873 - accuracy: 0.3567 - val_loss: 0.0872 - val_accuracy: 0.3400\n",
      "Epoch 11/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0869 - accuracy: 0.3667 - val_loss: 0.0870 - val_accuracy: 0.3800\n",
      "Epoch 12/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0866 - accuracy: 0.3850 - val_loss: 0.0867 - val_accuracy: 0.3800\n",
      "Epoch 13/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0862 - accuracy: 0.4117 - val_loss: 0.0864 - val_accuracy: 0.4100\n",
      "Epoch 14/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0858 - accuracy: 0.4450 - val_loss: 0.0861 - val_accuracy: 0.4300\n",
      "Epoch 15/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0854 - accuracy: 0.4750 - val_loss: 0.0857 - val_accuracy: 0.4500\n",
      "Epoch 16/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0849 - accuracy: 0.4917 - val_loss: 0.0854 - val_accuracy: 0.4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0845 - accuracy: 0.5017 - val_loss: 0.0850 - val_accuracy: 0.4500\n",
      "Epoch 18/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0840 - accuracy: 0.5100 - val_loss: 0.0846 - val_accuracy: 0.4500\n",
      "Epoch 19/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0835 - accuracy: 0.5150 - val_loss: 0.0842 - val_accuracy: 0.4700\n",
      "Epoch 20/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0829 - accuracy: 0.5283 - val_loss: 0.0838 - val_accuracy: 0.4700\n",
      "Epoch 21/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0823 - accuracy: 0.5350 - val_loss: 0.0833 - val_accuracy: 0.4700\n",
      "Epoch 22/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0817 - accuracy: 0.5450 - val_loss: 0.0828 - val_accuracy: 0.4700\n",
      "Epoch 23/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0811 - accuracy: 0.5500 - val_loss: 0.0823 - val_accuracy: 0.4800\n",
      "Epoch 24/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0804 - accuracy: 0.5583 - val_loss: 0.0817 - val_accuracy: 0.4800\n",
      "Epoch 25/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0796 - accuracy: 0.5633 - val_loss: 0.0811 - val_accuracy: 0.4900\n",
      "Epoch 26/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0788 - accuracy: 0.5683 - val_loss: 0.0805 - val_accuracy: 0.5000\n",
      "Epoch 27/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0780 - accuracy: 0.5733 - val_loss: 0.0798 - val_accuracy: 0.4900\n",
      "Epoch 28/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0771 - accuracy: 0.5750 - val_loss: 0.0791 - val_accuracy: 0.4900\n",
      "Epoch 29/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0762 - accuracy: 0.5767 - val_loss: 0.0784 - val_accuracy: 0.4900\n",
      "Epoch 30/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0753 - accuracy: 0.5733 - val_loss: 0.0777 - val_accuracy: 0.4900\n",
      "Epoch 31/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0743 - accuracy: 0.5800 - val_loss: 0.0769 - val_accuracy: 0.4900\n",
      "Epoch 32/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0733 - accuracy: 0.5850 - val_loss: 0.0761 - val_accuracy: 0.5000\n",
      "Epoch 33/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0722 - accuracy: 0.5900 - val_loss: 0.0753 - val_accuracy: 0.4900\n",
      "Epoch 34/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0712 - accuracy: 0.5900 - val_loss: 0.0745 - val_accuracy: 0.4900\n",
      "Epoch 35/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0701 - accuracy: 0.5900 - val_loss: 0.0737 - val_accuracy: 0.5100\n",
      "Epoch 36/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0690 - accuracy: 0.5950 - val_loss: 0.0729 - val_accuracy: 0.5200\n",
      "Epoch 37/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0680 - accuracy: 0.5933 - val_loss: 0.0721 - val_accuracy: 0.5200\n",
      "Epoch 38/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0669 - accuracy: 0.5933 - val_loss: 0.0713 - val_accuracy: 0.5200\n",
      "Epoch 39/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0658 - accuracy: 0.6033 - val_loss: 0.0705 - val_accuracy: 0.5300\n",
      "Epoch 40/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0647 - accuracy: 0.6050 - val_loss: 0.0697 - val_accuracy: 0.5300\n",
      "Epoch 41/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0637 - accuracy: 0.6033 - val_loss: 0.0689 - val_accuracy: 0.5400\n",
      "Epoch 42/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0627 - accuracy: 0.6133 - val_loss: 0.0681 - val_accuracy: 0.5300\n",
      "Epoch 43/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0617 - accuracy: 0.6167 - val_loss: 0.0674 - val_accuracy: 0.5700\n",
      "Epoch 44/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0606 - accuracy: 0.6217 - val_loss: 0.0666 - val_accuracy: 0.5700\n",
      "Epoch 45/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0597 - accuracy: 0.6233 - val_loss: 0.0658 - val_accuracy: 0.5800\n",
      "Epoch 46/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0587 - accuracy: 0.6233 - val_loss: 0.0651 - val_accuracy: 0.5800\n",
      "Epoch 47/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0578 - accuracy: 0.6317 - val_loss: 0.0644 - val_accuracy: 0.5900\n",
      "Epoch 48/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0569 - accuracy: 0.6333 - val_loss: 0.0636 - val_accuracy: 0.6000\n",
      "Epoch 49/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0560 - accuracy: 0.6417 - val_loss: 0.0629 - val_accuracy: 0.6000\n",
      "Epoch 50/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0551 - accuracy: 0.6417 - val_loss: 0.0622 - val_accuracy: 0.6000\n",
      "Epoch 51/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0542 - accuracy: 0.6433 - val_loss: 0.0616 - val_accuracy: 0.6200\n",
      "Epoch 52/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0534 - accuracy: 0.6500 - val_loss: 0.0609 - val_accuracy: 0.6200\n",
      "Epoch 53/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0526 - accuracy: 0.6550 - val_loss: 0.0603 - val_accuracy: 0.6300\n",
      "Epoch 54/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0517 - accuracy: 0.6567 - val_loss: 0.0597 - val_accuracy: 0.6300\n",
      "Epoch 55/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0509 - accuracy: 0.6567 - val_loss: 0.0590 - val_accuracy: 0.6300\n",
      "Epoch 56/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0501 - accuracy: 0.6650 - val_loss: 0.0585 - val_accuracy: 0.6300\n",
      "Epoch 57/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0494 - accuracy: 0.6717 - val_loss: 0.0579 - val_accuracy: 0.6300\n",
      "Epoch 58/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0486 - accuracy: 0.6700 - val_loss: 0.0574 - val_accuracy: 0.6300\n",
      "Epoch 59/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0479 - accuracy: 0.6750 - val_loss: 0.0568 - val_accuracy: 0.6300\n",
      "Epoch 60/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0471 - accuracy: 0.6800 - val_loss: 0.0563 - val_accuracy: 0.6300\n",
      "Epoch 61/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0464 - accuracy: 0.6817 - val_loss: 0.0558 - val_accuracy: 0.6300\n",
      "Epoch 62/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0456 - accuracy: 0.6867 - val_loss: 0.0554 - val_accuracy: 0.6300\n",
      "Epoch 63/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0449 - accuracy: 0.6917 - val_loss: 0.0549 - val_accuracy: 0.6400\n",
      "Epoch 64/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0442 - accuracy: 0.6933 - val_loss: 0.0545 - val_accuracy: 0.6400\n",
      "Epoch 65/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0435 - accuracy: 0.7100 - val_loss: 0.0540 - val_accuracy: 0.6400\n",
      "Epoch 66/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0428 - accuracy: 0.7167 - val_loss: 0.0536 - val_accuracy: 0.6500\n",
      "Epoch 67/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0421 - accuracy: 0.7317 - val_loss: 0.0532 - val_accuracy: 0.6500\n",
      "Epoch 68/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0414 - accuracy: 0.7417 - val_loss: 0.0528 - val_accuracy: 0.6700\n",
      "Epoch 69/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0407 - accuracy: 0.7500 - val_loss: 0.0524 - val_accuracy: 0.6700\n",
      "Epoch 70/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0401 - accuracy: 0.7633 - val_loss: 0.0519 - val_accuracy: 0.6800\n",
      "Epoch 71/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0394 - accuracy: 0.7650 - val_loss: 0.0515 - val_accuracy: 0.6800\n",
      "Epoch 72/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0388 - accuracy: 0.7650 - val_loss: 0.0511 - val_accuracy: 0.6700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0381 - accuracy: 0.7750 - val_loss: 0.0507 - val_accuracy: 0.6700\n",
      "Epoch 74/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0375 - accuracy: 0.7783 - val_loss: 0.0504 - val_accuracy: 0.6800\n",
      "Epoch 75/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0369 - accuracy: 0.7817 - val_loss: 0.0499 - val_accuracy: 0.6800\n",
      "Epoch 76/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0362 - accuracy: 0.7933 - val_loss: 0.0495 - val_accuracy: 0.6800\n",
      "Epoch 77/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0356 - accuracy: 0.7967 - val_loss: 0.0491 - val_accuracy: 0.6800\n",
      "Epoch 78/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0350 - accuracy: 0.7967 - val_loss: 0.0488 - val_accuracy: 0.6800\n",
      "Epoch 79/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0345 - accuracy: 0.8017 - val_loss: 0.0484 - val_accuracy: 0.6800\n",
      "Epoch 80/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0339 - accuracy: 0.8067 - val_loss: 0.0480 - val_accuracy: 0.6800\n",
      "Epoch 81/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0333 - accuracy: 0.8133 - val_loss: 0.0476 - val_accuracy: 0.6900\n",
      "Epoch 82/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0328 - accuracy: 0.8200 - val_loss: 0.0472 - val_accuracy: 0.6900\n",
      "Epoch 83/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0323 - accuracy: 0.8250 - val_loss: 0.0468 - val_accuracy: 0.6900\n",
      "Epoch 84/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0317 - accuracy: 0.8317 - val_loss: 0.0465 - val_accuracy: 0.6900\n",
      "Epoch 85/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0312 - accuracy: 0.8317 - val_loss: 0.0461 - val_accuracy: 0.6900\n",
      "Epoch 86/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0307 - accuracy: 0.8367 - val_loss: 0.0457 - val_accuracy: 0.6900\n",
      "Epoch 87/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0302 - accuracy: 0.8400 - val_loss: 0.0453 - val_accuracy: 0.6900\n",
      "Epoch 88/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0298 - accuracy: 0.8450 - val_loss: 0.0449 - val_accuracy: 0.6900\n",
      "Epoch 89/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0293 - accuracy: 0.8567 - val_loss: 0.0446 - val_accuracy: 0.6900\n",
      "Epoch 90/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0288 - accuracy: 0.8600 - val_loss: 0.0442 - val_accuracy: 0.6900\n",
      "Epoch 91/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0284 - accuracy: 0.8633 - val_loss: 0.0439 - val_accuracy: 0.6900\n",
      "Epoch 92/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0280 - accuracy: 0.8667 - val_loss: 0.0436 - val_accuracy: 0.6900\n",
      "Epoch 93/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0275 - accuracy: 0.8683 - val_loss: 0.0432 - val_accuracy: 0.6900\n",
      "Epoch 94/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0271 - accuracy: 0.8700 - val_loss: 0.0429 - val_accuracy: 0.6900\n",
      "Epoch 95/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0267 - accuracy: 0.8733 - val_loss: 0.0426 - val_accuracy: 0.7000\n",
      "Epoch 96/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0263 - accuracy: 0.8750 - val_loss: 0.0424 - val_accuracy: 0.7000\n",
      "Epoch 97/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0259 - accuracy: 0.8733 - val_loss: 0.0420 - val_accuracy: 0.7000\n",
      "Epoch 98/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0256 - accuracy: 0.8783 - val_loss: 0.0417 - val_accuracy: 0.7000\n",
      "Epoch 99/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0252 - accuracy: 0.8767 - val_loss: 0.0414 - val_accuracy: 0.7100\n",
      "Epoch 100/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0248 - accuracy: 0.8833 - val_loss: 0.0411 - val_accuracy: 0.7200\n",
      "Epoch 101/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0245 - accuracy: 0.8800 - val_loss: 0.0408 - val_accuracy: 0.7200\n",
      "Epoch 102/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0242 - accuracy: 0.8833 - val_loss: 0.0406 - val_accuracy: 0.7200\n",
      "Epoch 103/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0239 - accuracy: 0.8833 - val_loss: 0.0403 - val_accuracy: 0.7200\n",
      "Epoch 104/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0235 - accuracy: 0.8833 - val_loss: 0.0400 - val_accuracy: 0.7300\n",
      "Epoch 105/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0232 - accuracy: 0.8833 - val_loss: 0.0397 - val_accuracy: 0.7300\n",
      "Epoch 106/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0229 - accuracy: 0.8850 - val_loss: 0.0395 - val_accuracy: 0.7300\n",
      "Epoch 107/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0226 - accuracy: 0.8833 - val_loss: 0.0393 - val_accuracy: 0.7300\n",
      "Epoch 108/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0223 - accuracy: 0.8917 - val_loss: 0.0390 - val_accuracy: 0.7400\n",
      "Epoch 109/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0220 - accuracy: 0.8883 - val_loss: 0.0388 - val_accuracy: 0.7400\n",
      "Epoch 110/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0218 - accuracy: 0.8917 - val_loss: 0.0385 - val_accuracy: 0.7400\n",
      "Epoch 111/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0215 - accuracy: 0.8950 - val_loss: 0.0382 - val_accuracy: 0.7400\n",
      "Epoch 112/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0212 - accuracy: 0.8933 - val_loss: 0.0380 - val_accuracy: 0.7400\n",
      "Epoch 113/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0210 - accuracy: 0.8933 - val_loss: 0.0378 - val_accuracy: 0.7400\n",
      "Epoch 114/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0207 - accuracy: 0.8950 - val_loss: 0.0375 - val_accuracy: 0.7500\n",
      "Epoch 115/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0205 - accuracy: 0.8950 - val_loss: 0.0373 - val_accuracy: 0.7500\n",
      "Epoch 116/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0202 - accuracy: 0.8967 - val_loss: 0.0371 - val_accuracy: 0.7500\n",
      "Epoch 117/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0200 - accuracy: 0.8967 - val_loss: 0.0369 - val_accuracy: 0.7500\n",
      "Epoch 118/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0197 - accuracy: 0.9000 - val_loss: 0.0367 - val_accuracy: 0.7500\n",
      "Epoch 119/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0195 - accuracy: 0.8967 - val_loss: 0.0365 - val_accuracy: 0.7500\n",
      "Epoch 120/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0193 - accuracy: 0.8983 - val_loss: 0.0362 - val_accuracy: 0.7500\n",
      "Epoch 121/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0191 - accuracy: 0.9000 - val_loss: 0.0360 - val_accuracy: 0.7500\n",
      "Epoch 122/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0188 - accuracy: 0.9000 - val_loss: 0.0358 - val_accuracy: 0.7500\n",
      "Epoch 123/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0187 - accuracy: 0.9033 - val_loss: 0.0356 - val_accuracy: 0.7500\n",
      "Epoch 124/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0184 - accuracy: 0.9067 - val_loss: 0.0355 - val_accuracy: 0.7500\n",
      "Epoch 125/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0182 - accuracy: 0.9050 - val_loss: 0.0353 - val_accuracy: 0.7500\n",
      "Epoch 126/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0180 - accuracy: 0.9133 - val_loss: 0.0351 - val_accuracy: 0.7500\n",
      "Epoch 127/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0178 - accuracy: 0.9100 - val_loss: 0.0349 - val_accuracy: 0.7500\n",
      "Epoch 128/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0176 - accuracy: 0.9117 - val_loss: 0.0348 - val_accuracy: 0.7500\n",
      "Epoch 129/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0174 - accuracy: 0.9117 - val_loss: 0.0345 - val_accuracy: 0.7500\n",
      "Epoch 130/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0173 - accuracy: 0.9150 - val_loss: 0.0344 - val_accuracy: 0.7500\n",
      "Epoch 131/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0171 - accuracy: 0.9150 - val_loss: 0.0342 - val_accuracy: 0.7500\n",
      "Epoch 132/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0169 - accuracy: 0.9167 - val_loss: 0.0340 - val_accuracy: 0.7500\n",
      "Epoch 133/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0167 - accuracy: 0.9183 - val_loss: 0.0338 - val_accuracy: 0.7400\n",
      "Epoch 134/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0165 - accuracy: 0.9233 - val_loss: 0.0337 - val_accuracy: 0.7400\n",
      "Epoch 135/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0164 - accuracy: 0.9167 - val_loss: 0.0335 - val_accuracy: 0.7400\n",
      "Epoch 136/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0162 - accuracy: 0.9217 - val_loss: 0.0333 - val_accuracy: 0.7400\n",
      "Epoch 137/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0160 - accuracy: 0.9250 - val_loss: 0.0331 - val_accuracy: 0.7400\n",
      "Epoch 138/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0159 - accuracy: 0.9233 - val_loss: 0.0330 - val_accuracy: 0.7400\n",
      "Epoch 139/240\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0157 - accuracy: 0.9300 - val_loss: 0.0328 - val_accuracy: 0.7400\n",
      "Epoch 140/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0156 - accuracy: 0.9267 - val_loss: 0.0327 - val_accuracy: 0.7500\n",
      "Epoch 141/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0154 - accuracy: 0.9283 - val_loss: 0.0327 - val_accuracy: 0.7500\n",
      "Epoch 142/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0153 - accuracy: 0.9283 - val_loss: 0.0326 - val_accuracy: 0.7500\n",
      "Epoch 143/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0151 - accuracy: 0.9300 - val_loss: 0.0324 - val_accuracy: 0.7500\n",
      "Epoch 144/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0149 - accuracy: 0.9283 - val_loss: 0.0322 - val_accuracy: 0.7500\n",
      "Epoch 145/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0148 - accuracy: 0.9350 - val_loss: 0.0321 - val_accuracy: 0.7500\n",
      "Epoch 146/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0147 - accuracy: 0.9333 - val_loss: 0.0320 - val_accuracy: 0.7600\n",
      "Epoch 147/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0146 - accuracy: 0.9333 - val_loss: 0.0318 - val_accuracy: 0.7600\n",
      "Epoch 148/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0144 - accuracy: 0.9367 - val_loss: 0.0317 - val_accuracy: 0.7600\n",
      "Epoch 149/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0143 - accuracy: 0.9367 - val_loss: 0.0316 - val_accuracy: 0.7600\n",
      "Epoch 150/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0141 - accuracy: 0.9400 - val_loss: 0.0314 - val_accuracy: 0.7600\n",
      "Epoch 151/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0140 - accuracy: 0.9383 - val_loss: 0.0313 - val_accuracy: 0.7700\n",
      "Epoch 152/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0139 - accuracy: 0.9400 - val_loss: 0.0311 - val_accuracy: 0.7700\n",
      "Epoch 153/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0137 - accuracy: 0.9400 - val_loss: 0.0311 - val_accuracy: 0.7600\n",
      "Epoch 154/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0136 - accuracy: 0.9367 - val_loss: 0.0309 - val_accuracy: 0.7700\n",
      "Epoch 155/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0135 - accuracy: 0.9400 - val_loss: 0.0308 - val_accuracy: 0.7700\n",
      "Epoch 156/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0134 - accuracy: 0.9417 - val_loss: 0.0307 - val_accuracy: 0.7700\n",
      "Epoch 157/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0132 - accuracy: 0.9417 - val_loss: 0.0306 - val_accuracy: 0.7700\n",
      "Epoch 158/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0131 - accuracy: 0.9417 - val_loss: 0.0304 - val_accuracy: 0.7700\n",
      "Epoch 159/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0130 - accuracy: 0.9400 - val_loss: 0.0303 - val_accuracy: 0.7700\n",
      "Epoch 160/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0129 - accuracy: 0.9433 - val_loss: 0.0303 - val_accuracy: 0.7700\n",
      "Epoch 161/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0128 - accuracy: 0.9450 - val_loss: 0.0302 - val_accuracy: 0.7700\n",
      "Epoch 162/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0127 - accuracy: 0.9450 - val_loss: 0.0301 - val_accuracy: 0.7700\n",
      "Epoch 163/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0125 - accuracy: 0.9433 - val_loss: 0.0300 - val_accuracy: 0.7800\n",
      "Epoch 164/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0124 - accuracy: 0.9433 - val_loss: 0.0300 - val_accuracy: 0.7800\n",
      "Epoch 165/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0123 - accuracy: 0.9433 - val_loss: 0.0299 - val_accuracy: 0.7800\n",
      "Epoch 166/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0122 - accuracy: 0.9450 - val_loss: 0.0298 - val_accuracy: 0.7800\n",
      "Epoch 167/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0121 - accuracy: 0.9450 - val_loss: 0.0296 - val_accuracy: 0.7800\n",
      "Epoch 168/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0120 - accuracy: 0.9467 - val_loss: 0.0295 - val_accuracy: 0.7900\n",
      "Epoch 169/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0119 - accuracy: 0.9467 - val_loss: 0.0295 - val_accuracy: 0.7900\n",
      "Epoch 170/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0118 - accuracy: 0.9467 - val_loss: 0.0294 - val_accuracy: 0.7900\n",
      "Epoch 171/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0117 - accuracy: 0.9500 - val_loss: 0.0293 - val_accuracy: 0.7900\n",
      "Epoch 172/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0116 - accuracy: 0.9517 - val_loss: 0.0292 - val_accuracy: 0.7900\n",
      "Epoch 173/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0115 - accuracy: 0.9517 - val_loss: 0.0291 - val_accuracy: 0.7900\n",
      "Epoch 174/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0114 - accuracy: 0.9517 - val_loss: 0.0291 - val_accuracy: 0.7900\n",
      "Epoch 175/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0113 - accuracy: 0.9517 - val_loss: 0.0290 - val_accuracy: 0.7900\n",
      "Epoch 176/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0112 - accuracy: 0.9517 - val_loss: 0.0289 - val_accuracy: 0.7900\n",
      "Epoch 177/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0111 - accuracy: 0.9533 - val_loss: 0.0289 - val_accuracy: 0.7900\n",
      "Epoch 178/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0110 - accuracy: 0.9517 - val_loss: 0.0288 - val_accuracy: 0.7900\n",
      "Epoch 179/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0109 - accuracy: 0.9533 - val_loss: 0.0287 - val_accuracy: 0.7900\n",
      "Epoch 180/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0108 - accuracy: 0.9517 - val_loss: 0.0286 - val_accuracy: 0.7900\n",
      "Epoch 181/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0108 - accuracy: 0.9533 - val_loss: 0.0285 - val_accuracy: 0.7900\n",
      "Epoch 182/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0107 - accuracy: 0.9533 - val_loss: 0.0285 - val_accuracy: 0.7900\n",
      "Epoch 183/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0106 - accuracy: 0.9517 - val_loss: 0.0284 - val_accuracy: 0.7900\n",
      "Epoch 184/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0105 - accuracy: 0.9533 - val_loss: 0.0284 - val_accuracy: 0.7900\n",
      "Epoch 185/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0104 - accuracy: 0.9533 - val_loss: 0.0283 - val_accuracy: 0.7900\n",
      "Epoch 186/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0103 - accuracy: 0.9533 - val_loss: 0.0284 - val_accuracy: 0.7900\n",
      "Epoch 187/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0103 - accuracy: 0.9533 - val_loss: 0.0283 - val_accuracy: 0.7900\n",
      "Epoch 188/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0102 - accuracy: 0.9533 - val_loss: 0.0282 - val_accuracy: 0.7900\n",
      "Epoch 189/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0101 - accuracy: 0.9533 - val_loss: 0.0282 - val_accuracy: 0.7900\n",
      "Epoch 190/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0100 - accuracy: 0.9533 - val_loss: 0.0281 - val_accuracy: 0.7900\n",
      "Epoch 191/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0099 - accuracy: 0.9533 - val_loss: 0.0280 - val_accuracy: 0.7900\n",
      "Epoch 192/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0099 - accuracy: 0.9533 - val_loss: 0.0280 - val_accuracy: 0.7900\n",
      "Epoch 193/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0098 - accuracy: 0.9550 - val_loss: 0.0280 - val_accuracy: 0.7900\n",
      "Epoch 194/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0097 - accuracy: 0.9583 - val_loss: 0.0279 - val_accuracy: 0.7900\n",
      "Epoch 195/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0096 - accuracy: 0.9583 - val_loss: 0.0278 - val_accuracy: 0.7900\n",
      "Epoch 196/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0095 - accuracy: 0.9583 - val_loss: 0.0277 - val_accuracy: 0.7900\n",
      "Epoch 197/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0095 - accuracy: 0.9617 - val_loss: 0.0278 - val_accuracy: 0.7900\n",
      "Epoch 198/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0094 - accuracy: 0.9617 - val_loss: 0.0277 - val_accuracy: 0.7900\n",
      "Epoch 199/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0093 - accuracy: 0.9617 - val_loss: 0.0276 - val_accuracy: 0.7900\n",
      "Epoch 200/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0093 - accuracy: 0.9633 - val_loss: 0.0275 - val_accuracy: 0.7900\n",
      "Epoch 201/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0092 - accuracy: 0.9617 - val_loss: 0.0275 - val_accuracy: 0.7900\n",
      "Epoch 202/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0091 - accuracy: 0.9617 - val_loss: 0.0275 - val_accuracy: 0.7900\n",
      "Epoch 203/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0091 - accuracy: 0.9650 - val_loss: 0.0274 - val_accuracy: 0.7900\n",
      "Epoch 204/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0090 - accuracy: 0.9633 - val_loss: 0.0273 - val_accuracy: 0.7900\n",
      "Epoch 205/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0089 - accuracy: 0.9633 - val_loss: 0.0274 - val_accuracy: 0.7900\n",
      "Epoch 206/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0089 - accuracy: 0.9633 - val_loss: 0.0273 - val_accuracy: 0.7900\n",
      "Epoch 207/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0088 - accuracy: 0.9633 - val_loss: 0.0273 - val_accuracy: 0.7900\n",
      "Epoch 208/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0087 - accuracy: 0.9633 - val_loss: 0.0272 - val_accuracy: 0.7900\n",
      "Epoch 209/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0087 - accuracy: 0.9650 - val_loss: 0.0272 - val_accuracy: 0.7900\n",
      "Epoch 210/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0086 - accuracy: 0.9650 - val_loss: 0.0272 - val_accuracy: 0.7900\n",
      "Epoch 211/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0085 - accuracy: 0.9650 - val_loss: 0.0271 - val_accuracy: 0.7900\n",
      "Epoch 212/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0085 - accuracy: 0.9650 - val_loss: 0.0271 - val_accuracy: 0.7900\n",
      "Epoch 213/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0084 - accuracy: 0.9650 - val_loss: 0.0270 - val_accuracy: 0.7900\n",
      "Epoch 214/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0084 - accuracy: 0.9650 - val_loss: 0.0270 - val_accuracy: 0.7900\n",
      "Epoch 215/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0083 - accuracy: 0.9650 - val_loss: 0.0270 - val_accuracy: 0.7900\n",
      "Epoch 216/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0082 - accuracy: 0.9650 - val_loss: 0.0270 - val_accuracy: 0.7900\n",
      "Epoch 217/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0082 - accuracy: 0.9650 - val_loss: 0.0270 - val_accuracy: 0.7900\n",
      "Epoch 218/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0081 - accuracy: 0.9650 - val_loss: 0.0269 - val_accuracy: 0.7900\n",
      "Epoch 219/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0081 - accuracy: 0.9650 - val_loss: 0.0268 - val_accuracy: 0.7900\n",
      "Epoch 220/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0080 - accuracy: 0.9650 - val_loss: 0.0269 - val_accuracy: 0.7900\n",
      "Epoch 221/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0080 - accuracy: 0.9667 - val_loss: 0.0268 - val_accuracy: 0.7900\n",
      "Epoch 222/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0079 - accuracy: 0.9667 - val_loss: 0.0267 - val_accuracy: 0.7900\n",
      "Epoch 223/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0078 - accuracy: 0.9667 - val_loss: 0.0267 - val_accuracy: 0.7900\n",
      "Epoch 224/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0078 - accuracy: 0.9667 - val_loss: 0.0266 - val_accuracy: 0.7900\n",
      "Epoch 225/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0078 - accuracy: 0.9667 - val_loss: 0.0266 - val_accuracy: 0.7900\n",
      "Epoch 226/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0077 - accuracy: 0.9667 - val_loss: 0.0266 - val_accuracy: 0.7900\n",
      "Epoch 227/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0076 - accuracy: 0.9667 - val_loss: 0.0266 - val_accuracy: 0.7900\n",
      "Epoch 228/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0076 - accuracy: 0.9667 - val_loss: 0.0265 - val_accuracy: 0.7900\n",
      "Epoch 229/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0075 - accuracy: 0.9667 - val_loss: 0.0266 - val_accuracy: 0.7900\n",
      "Epoch 230/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0075 - accuracy: 0.9667 - val_loss: 0.0265 - val_accuracy: 0.7900\n",
      "Epoch 231/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0074 - accuracy: 0.9667 - val_loss: 0.0265 - val_accuracy: 0.7900\n",
      "Epoch 232/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0074 - accuracy: 0.9683 - val_loss: 0.0265 - val_accuracy: 0.7900\n",
      "Epoch 233/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0073 - accuracy: 0.9667 - val_loss: 0.0265 - val_accuracy: 0.7900\n",
      "Epoch 234/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0073 - accuracy: 0.9683 - val_loss: 0.0265 - val_accuracy: 0.7900\n",
      "Epoch 235/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0072 - accuracy: 0.9700 - val_loss: 0.0264 - val_accuracy: 0.7900\n",
      "Epoch 236/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0072 - accuracy: 0.9683 - val_loss: 0.0264 - val_accuracy: 0.7900\n",
      "Epoch 237/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0071 - accuracy: 0.9683 - val_loss: 0.0264 - val_accuracy: 0.7900\n",
      "Epoch 238/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0071 - accuracy: 0.9700 - val_loss: 0.0263 - val_accuracy: 0.7900\n",
      "Epoch 239/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0070 - accuracy: 0.9683 - val_loss: 0.0263 - val_accuracy: 0.7900\n",
      "Epoch 240/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0070 - accuracy: 0.9683 - val_loss: 0.0263 - val_accuracy: 0.7900\n",
      "Training date and time : \n",
      "2020-04-09 21:02:27\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/240\n",
      "600/600 [==============================] - 0s 657us/sample - loss: 0.0902 - accuracy: 0.1117 - val_loss: 0.0895 - val_accuracy: 0.1600\n",
      "Epoch 2/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0899 - accuracy: 0.1300 - val_loss: 0.0893 - val_accuracy: 0.1600\n",
      "Epoch 3/240\n",
      "600/600 [==============================] - 0s 116us/sample - loss: 0.0896 - accuracy: 0.1483 - val_loss: 0.0891 - val_accuracy: 0.1800\n",
      "Epoch 4/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0894 - accuracy: 0.1717 - val_loss: 0.0889 - val_accuracy: 0.2000\n",
      "Epoch 5/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0891 - accuracy: 0.1983 - val_loss: 0.0887 - val_accuracy: 0.2300\n",
      "Epoch 6/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0888 - accuracy: 0.2183 - val_loss: 0.0885 - val_accuracy: 0.2500\n",
      "Epoch 7/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0886 - accuracy: 0.2517 - val_loss: 0.0883 - val_accuracy: 0.3100\n",
      "Epoch 8/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0883 - accuracy: 0.2783 - val_loss: 0.0881 - val_accuracy: 0.3200\n",
      "Epoch 9/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0880 - accuracy: 0.3033 - val_loss: 0.0879 - val_accuracy: 0.3200\n",
      "Epoch 10/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0878 - accuracy: 0.3300 - val_loss: 0.0877 - val_accuracy: 0.3700\n",
      "Epoch 11/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0875 - accuracy: 0.3517 - val_loss: 0.0875 - val_accuracy: 0.3800\n",
      "Epoch 12/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0872 - accuracy: 0.3750 - val_loss: 0.0872 - val_accuracy: 0.4000\n",
      "Epoch 13/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0869 - accuracy: 0.3983 - val_loss: 0.0870 - val_accuracy: 0.4200\n",
      "Epoch 14/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0866 - accuracy: 0.4200 - val_loss: 0.0868 - val_accuracy: 0.4200\n",
      "Epoch 15/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0862 - accuracy: 0.4417 - val_loss: 0.0865 - val_accuracy: 0.4300\n",
      "Epoch 16/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0859 - accuracy: 0.4650 - val_loss: 0.0862 - val_accuracy: 0.4300\n",
      "Epoch 17/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0856 - accuracy: 0.4850 - val_loss: 0.0859 - val_accuracy: 0.4600\n",
      "Epoch 18/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0852 - accuracy: 0.5050 - val_loss: 0.0856 - val_accuracy: 0.4600\n",
      "Epoch 19/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0848 - accuracy: 0.5117 - val_loss: 0.0853 - val_accuracy: 0.4700\n",
      "Epoch 20/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0844 - accuracy: 0.5183 - val_loss: 0.0850 - val_accuracy: 0.4800\n",
      "Epoch 21/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0840 - accuracy: 0.5300 - val_loss: 0.0847 - val_accuracy: 0.4800\n",
      "Epoch 22/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0835 - accuracy: 0.5367 - val_loss: 0.0843 - val_accuracy: 0.4800\n",
      "Epoch 23/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0830 - accuracy: 0.5417 - val_loss: 0.0839 - val_accuracy: 0.4700\n",
      "Epoch 24/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0825 - accuracy: 0.5483 - val_loss: 0.0835 - val_accuracy: 0.4700\n",
      "Epoch 25/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0819 - accuracy: 0.5550 - val_loss: 0.0830 - val_accuracy: 0.4700\n",
      "Epoch 26/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0814 - accuracy: 0.5617 - val_loss: 0.0826 - val_accuracy: 0.4800\n",
      "Epoch 27/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0808 - accuracy: 0.5633 - val_loss: 0.0821 - val_accuracy: 0.4800\n",
      "Epoch 28/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0801 - accuracy: 0.5650 - val_loss: 0.0815 - val_accuracy: 0.4800\n",
      "Epoch 29/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0794 - accuracy: 0.5617 - val_loss: 0.0810 - val_accuracy: 0.4800\n",
      "Epoch 30/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0787 - accuracy: 0.5633 - val_loss: 0.0804 - val_accuracy: 0.4800\n",
      "Epoch 31/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0779 - accuracy: 0.5717 - val_loss: 0.0798 - val_accuracy: 0.4700\n",
      "Epoch 32/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0772 - accuracy: 0.5717 - val_loss: 0.0792 - val_accuracy: 0.4700\n",
      "Epoch 33/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0763 - accuracy: 0.5783 - val_loss: 0.0786 - val_accuracy: 0.4600\n",
      "Epoch 34/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0755 - accuracy: 0.5733 - val_loss: 0.0779 - val_accuracy: 0.4600\n",
      "Epoch 35/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0746 - accuracy: 0.5783 - val_loss: 0.0772 - val_accuracy: 0.4600\n",
      "Epoch 36/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0736 - accuracy: 0.5800 - val_loss: 0.0765 - val_accuracy: 0.4600\n",
      "Epoch 37/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0727 - accuracy: 0.5767 - val_loss: 0.0758 - val_accuracy: 0.4600\n",
      "Epoch 38/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0718 - accuracy: 0.5833 - val_loss: 0.0751 - val_accuracy: 0.4600\n",
      "Epoch 39/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0708 - accuracy: 0.5867 - val_loss: 0.0743 - val_accuracy: 0.4800\n",
      "Epoch 40/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0698 - accuracy: 0.5883 - val_loss: 0.0736 - val_accuracy: 0.4900\n",
      "Epoch 41/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0688 - accuracy: 0.5883 - val_loss: 0.0728 - val_accuracy: 0.5100\n",
      "Epoch 42/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0678 - accuracy: 0.5917 - val_loss: 0.0721 - val_accuracy: 0.5200\n",
      "Epoch 43/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0668 - accuracy: 0.5950 - val_loss: 0.0713 - val_accuracy: 0.5200\n",
      "Epoch 44/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0658 - accuracy: 0.6017 - val_loss: 0.0706 - val_accuracy: 0.5300\n",
      "Epoch 45/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0649 - accuracy: 0.6050 - val_loss: 0.0698 - val_accuracy: 0.5300\n",
      "Epoch 46/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0639 - accuracy: 0.6067 - val_loss: 0.0691 - val_accuracy: 0.5300\n",
      "Epoch 47/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0629 - accuracy: 0.6117 - val_loss: 0.0683 - val_accuracy: 0.5400\n",
      "Epoch 48/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0620 - accuracy: 0.6183 - val_loss: 0.0676 - val_accuracy: 0.5700\n",
      "Epoch 49/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0611 - accuracy: 0.6200 - val_loss: 0.0669 - val_accuracy: 0.5800\n",
      "Epoch 50/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0601 - accuracy: 0.6200 - val_loss: 0.0661 - val_accuracy: 0.5800\n",
      "Epoch 51/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0592 - accuracy: 0.6233 - val_loss: 0.0654 - val_accuracy: 0.5800\n",
      "Epoch 52/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0583 - accuracy: 0.6233 - val_loss: 0.0647 - val_accuracy: 0.5800\n",
      "Epoch 53/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0574 - accuracy: 0.6317 - val_loss: 0.0640 - val_accuracy: 0.5900\n",
      "Epoch 54/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0566 - accuracy: 0.6400 - val_loss: 0.0633 - val_accuracy: 0.5900\n",
      "Epoch 55/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0557 - accuracy: 0.6400 - val_loss: 0.0627 - val_accuracy: 0.5900\n",
      "Epoch 56/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0549 - accuracy: 0.6467 - val_loss: 0.0620 - val_accuracy: 0.6200\n",
      "Epoch 57/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0541 - accuracy: 0.6483 - val_loss: 0.0614 - val_accuracy: 0.6200\n",
      "Epoch 58/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0532 - accuracy: 0.6500 - val_loss: 0.0607 - val_accuracy: 0.6200\n",
      "Epoch 59/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0524 - accuracy: 0.6517 - val_loss: 0.0601 - val_accuracy: 0.6300\n",
      "Epoch 60/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0517 - accuracy: 0.6550 - val_loss: 0.0595 - val_accuracy: 0.6300\n",
      "Epoch 61/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0509 - accuracy: 0.6567 - val_loss: 0.0590 - val_accuracy: 0.6300\n",
      "Epoch 62/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0502 - accuracy: 0.6600 - val_loss: 0.0584 - val_accuracy: 0.6300\n",
      "Epoch 63/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0494 - accuracy: 0.6633 - val_loss: 0.0579 - val_accuracy: 0.6300\n",
      "Epoch 64/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0487 - accuracy: 0.6700 - val_loss: 0.0574 - val_accuracy: 0.6300\n",
      "Epoch 65/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0480 - accuracy: 0.6750 - val_loss: 0.0569 - val_accuracy: 0.6300\n",
      "Epoch 66/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0472 - accuracy: 0.6750 - val_loss: 0.0564 - val_accuracy: 0.6400\n",
      "Epoch 67/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0465 - accuracy: 0.6833 - val_loss: 0.0559 - val_accuracy: 0.6400\n",
      "Epoch 68/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0458 - accuracy: 0.6850 - val_loss: 0.0554 - val_accuracy: 0.6400\n",
      "Epoch 69/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0451 - accuracy: 0.6933 - val_loss: 0.0550 - val_accuracy: 0.6400\n",
      "Epoch 70/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0444 - accuracy: 0.7167 - val_loss: 0.0545 - val_accuracy: 0.6400\n",
      "Epoch 71/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0437 - accuracy: 0.7233 - val_loss: 0.0541 - val_accuracy: 0.6600\n",
      "Epoch 72/240\n",
      "600/600 [==============================] - 0s 122us/sample - loss: 0.0430 - accuracy: 0.7367 - val_loss: 0.0537 - val_accuracy: 0.6600\n",
      "Epoch 73/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0423 - accuracy: 0.7467 - val_loss: 0.0533 - val_accuracy: 0.6700\n",
      "Epoch 74/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0416 - accuracy: 0.7550 - val_loss: 0.0529 - val_accuracy: 0.6700\n",
      "Epoch 75/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0410 - accuracy: 0.7583 - val_loss: 0.0525 - val_accuracy: 0.6800\n",
      "Epoch 76/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0403 - accuracy: 0.7617 - val_loss: 0.0520 - val_accuracy: 0.6800\n",
      "Epoch 77/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0396 - accuracy: 0.7717 - val_loss: 0.0517 - val_accuracy: 0.6800\n",
      "Epoch 78/240\n",
      "600/600 [==============================] - 0s 121us/sample - loss: 0.0390 - accuracy: 0.7717 - val_loss: 0.0513 - val_accuracy: 0.6800\n",
      "Epoch 79/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0384 - accuracy: 0.7800 - val_loss: 0.0509 - val_accuracy: 0.6700\n",
      "Epoch 80/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0378 - accuracy: 0.7817 - val_loss: 0.0505 - val_accuracy: 0.6800\n",
      "Epoch 81/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0372 - accuracy: 0.7867 - val_loss: 0.0501 - val_accuracy: 0.6800\n",
      "Epoch 82/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0366 - accuracy: 0.7917 - val_loss: 0.0497 - val_accuracy: 0.6800\n",
      "Epoch 83/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0360 - accuracy: 0.7933 - val_loss: 0.0494 - val_accuracy: 0.6900\n",
      "Epoch 84/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0354 - accuracy: 0.7933 - val_loss: 0.0490 - val_accuracy: 0.6900\n",
      "Epoch 85/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0349 - accuracy: 0.7933 - val_loss: 0.0486 - val_accuracy: 0.6900\n",
      "Epoch 86/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0344 - accuracy: 0.7967 - val_loss: 0.0483 - val_accuracy: 0.6900\n",
      "Epoch 87/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0338 - accuracy: 0.8000 - val_loss: 0.0479 - val_accuracy: 0.6900\n",
      "Epoch 88/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0333 - accuracy: 0.8017 - val_loss: 0.0475 - val_accuracy: 0.6900\n",
      "Epoch 89/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0328 - accuracy: 0.8067 - val_loss: 0.0471 - val_accuracy: 0.6900\n",
      "Epoch 90/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0323 - accuracy: 0.8133 - val_loss: 0.0467 - val_accuracy: 0.6900\n",
      "Epoch 91/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0318 - accuracy: 0.8217 - val_loss: 0.0464 - val_accuracy: 0.6900\n",
      "Epoch 92/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0314 - accuracy: 0.8267 - val_loss: 0.0460 - val_accuracy: 0.6900\n",
      "Epoch 93/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0309 - accuracy: 0.8317 - val_loss: 0.0456 - val_accuracy: 0.6900\n",
      "Epoch 94/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0305 - accuracy: 0.8383 - val_loss: 0.0453 - val_accuracy: 0.6900\n",
      "Epoch 95/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0300 - accuracy: 0.8433 - val_loss: 0.0450 - val_accuracy: 0.6900\n",
      "Epoch 96/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0296 - accuracy: 0.8450 - val_loss: 0.0447 - val_accuracy: 0.6900\n",
      "Epoch 97/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0291 - accuracy: 0.8533 - val_loss: 0.0444 - val_accuracy: 0.6900\n",
      "Epoch 98/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0287 - accuracy: 0.8633 - val_loss: 0.0440 - val_accuracy: 0.6900\n",
      "Epoch 99/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0283 - accuracy: 0.8650 - val_loss: 0.0437 - val_accuracy: 0.6900\n",
      "Epoch 100/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0279 - accuracy: 0.8733 - val_loss: 0.0433 - val_accuracy: 0.6900\n",
      "Epoch 101/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0275 - accuracy: 0.8750 - val_loss: 0.0430 - val_accuracy: 0.6900\n",
      "Epoch 102/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0271 - accuracy: 0.8783 - val_loss: 0.0428 - val_accuracy: 0.6900\n",
      "Epoch 103/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0268 - accuracy: 0.8783 - val_loss: 0.0425 - val_accuracy: 0.6900\n",
      "Epoch 104/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0264 - accuracy: 0.8783 - val_loss: 0.0421 - val_accuracy: 0.6900\n",
      "Epoch 105/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0260 - accuracy: 0.8800 - val_loss: 0.0418 - val_accuracy: 0.7000\n",
      "Epoch 106/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0257 - accuracy: 0.8817 - val_loss: 0.0416 - val_accuracy: 0.7000\n",
      "Epoch 107/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0254 - accuracy: 0.8800 - val_loss: 0.0414 - val_accuracy: 0.7000\n",
      "Epoch 108/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0250 - accuracy: 0.8817 - val_loss: 0.0410 - val_accuracy: 0.7100\n",
      "Epoch 109/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0247 - accuracy: 0.8783 - val_loss: 0.0408 - val_accuracy: 0.7100\n",
      "Epoch 110/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0244 - accuracy: 0.8800 - val_loss: 0.0404 - val_accuracy: 0.7100\n",
      "Epoch 111/240\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0240 - accuracy: 0.8800 - val_loss: 0.0402 - val_accuracy: 0.7300\n",
      "Epoch 112/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0237 - accuracy: 0.8833 - val_loss: 0.0399 - val_accuracy: 0.7300\n",
      "Epoch 113/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0234 - accuracy: 0.8817 - val_loss: 0.0397 - val_accuracy: 0.7300\n",
      "Epoch 114/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0231 - accuracy: 0.8850 - val_loss: 0.0394 - val_accuracy: 0.7300\n",
      "Epoch 115/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0229 - accuracy: 0.8850 - val_loss: 0.0392 - val_accuracy: 0.7300\n",
      "Epoch 116/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0226 - accuracy: 0.8883 - val_loss: 0.0390 - val_accuracy: 0.7300\n",
      "Epoch 117/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0223 - accuracy: 0.8883 - val_loss: 0.0388 - val_accuracy: 0.7300\n",
      "Epoch 118/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0220 - accuracy: 0.8917 - val_loss: 0.0385 - val_accuracy: 0.7300\n",
      "Epoch 119/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0218 - accuracy: 0.8917 - val_loss: 0.0383 - val_accuracy: 0.7300\n",
      "Epoch 120/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0215 - accuracy: 0.8917 - val_loss: 0.0380 - val_accuracy: 0.7400\n",
      "Epoch 121/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0213 - accuracy: 0.8917 - val_loss: 0.0378 - val_accuracy: 0.7300\n",
      "Epoch 122/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0210 - accuracy: 0.8950 - val_loss: 0.0376 - val_accuracy: 0.7400\n",
      "Epoch 123/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0208 - accuracy: 0.8917 - val_loss: 0.0373 - val_accuracy: 0.7400\n",
      "Epoch 124/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0205 - accuracy: 0.8967 - val_loss: 0.0372 - val_accuracy: 0.7400\n",
      "Epoch 125/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0203 - accuracy: 0.8933 - val_loss: 0.0370 - val_accuracy: 0.7400\n",
      "Epoch 126/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0201 - accuracy: 0.8950 - val_loss: 0.0368 - val_accuracy: 0.7500\n",
      "Epoch 127/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0199 - accuracy: 0.8933 - val_loss: 0.0366 - val_accuracy: 0.7600\n",
      "Epoch 128/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0196 - accuracy: 0.8967 - val_loss: 0.0364 - val_accuracy: 0.7600\n",
      "Epoch 129/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0194 - accuracy: 0.8983 - val_loss: 0.0361 - val_accuracy: 0.7500\n",
      "Epoch 130/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0192 - accuracy: 0.9000 - val_loss: 0.0360 - val_accuracy: 0.7600\n",
      "Epoch 131/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0190 - accuracy: 0.8983 - val_loss: 0.0357 - val_accuracy: 0.7500\n",
      "Epoch 132/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0188 - accuracy: 0.9033 - val_loss: 0.0356 - val_accuracy: 0.7500\n",
      "Epoch 133/240\n",
      "600/600 [==============================] - 0s 114us/sample - loss: 0.0186 - accuracy: 0.9033 - val_loss: 0.0354 - val_accuracy: 0.7500\n",
      "Epoch 134/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0184 - accuracy: 0.9083 - val_loss: 0.0352 - val_accuracy: 0.7500\n",
      "Epoch 135/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0182 - accuracy: 0.9050 - val_loss: 0.0350 - val_accuracy: 0.7400\n",
      "Epoch 136/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0180 - accuracy: 0.9050 - val_loss: 0.0348 - val_accuracy: 0.7500\n",
      "Epoch 137/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0178 - accuracy: 0.9117 - val_loss: 0.0346 - val_accuracy: 0.7500\n",
      "Epoch 138/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0176 - accuracy: 0.9133 - val_loss: 0.0344 - val_accuracy: 0.7400\n",
      "Epoch 139/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0174 - accuracy: 0.9133 - val_loss: 0.0343 - val_accuracy: 0.7500\n",
      "Epoch 140/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0173 - accuracy: 0.9150 - val_loss: 0.0342 - val_accuracy: 0.7500\n",
      "Epoch 141/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0171 - accuracy: 0.9150 - val_loss: 0.0341 - val_accuracy: 0.7500\n",
      "Epoch 142/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0169 - accuracy: 0.9217 - val_loss: 0.0339 - val_accuracy: 0.7500\n",
      "Epoch 143/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0168 - accuracy: 0.9183 - val_loss: 0.0338 - val_accuracy: 0.7600\n",
      "Epoch 144/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0165 - accuracy: 0.9200 - val_loss: 0.0336 - val_accuracy: 0.7600\n",
      "Epoch 145/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0164 - accuracy: 0.9233 - val_loss: 0.0334 - val_accuracy: 0.7600\n",
      "Epoch 146/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0162 - accuracy: 0.9217 - val_loss: 0.0333 - val_accuracy: 0.7700\n",
      "Epoch 147/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0161 - accuracy: 0.9217 - val_loss: 0.0331 - val_accuracy: 0.7700\n",
      "Epoch 148/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0159 - accuracy: 0.9267 - val_loss: 0.0329 - val_accuracy: 0.7600\n",
      "Epoch 149/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0158 - accuracy: 0.9250 - val_loss: 0.0328 - val_accuracy: 0.7600\n",
      "Epoch 150/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0156 - accuracy: 0.9300 - val_loss: 0.0327 - val_accuracy: 0.7600\n",
      "Epoch 151/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0155 - accuracy: 0.9233 - val_loss: 0.0325 - val_accuracy: 0.7600\n",
      "Epoch 152/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0153 - accuracy: 0.9300 - val_loss: 0.0323 - val_accuracy: 0.7700\n",
      "Epoch 153/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0152 - accuracy: 0.9317 - val_loss: 0.0323 - val_accuracy: 0.7600\n",
      "Epoch 154/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0150 - accuracy: 0.9317 - val_loss: 0.0321 - val_accuracy: 0.7600\n",
      "Epoch 155/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0149 - accuracy: 0.9350 - val_loss: 0.0319 - val_accuracy: 0.7600\n",
      "Epoch 156/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0148 - accuracy: 0.9350 - val_loss: 0.0318 - val_accuracy: 0.7500\n",
      "Epoch 157/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0146 - accuracy: 0.9317 - val_loss: 0.0317 - val_accuracy: 0.7700\n",
      "Epoch 158/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0145 - accuracy: 0.9350 - val_loss: 0.0315 - val_accuracy: 0.7600\n",
      "Epoch 159/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0144 - accuracy: 0.9333 - val_loss: 0.0314 - val_accuracy: 0.7600\n",
      "Epoch 160/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0142 - accuracy: 0.9367 - val_loss: 0.0313 - val_accuracy: 0.7700\n",
      "Epoch 161/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0141 - accuracy: 0.9383 - val_loss: 0.0312 - val_accuracy: 0.7700\n",
      "Epoch 162/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0139 - accuracy: 0.9367 - val_loss: 0.0311 - val_accuracy: 0.7700\n",
      "Epoch 163/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0138 - accuracy: 0.9383 - val_loss: 0.0310 - val_accuracy: 0.7600\n",
      "Epoch 164/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0137 - accuracy: 0.9383 - val_loss: 0.0309 - val_accuracy: 0.7600\n",
      "Epoch 165/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0136 - accuracy: 0.9383 - val_loss: 0.0308 - val_accuracy: 0.7600\n",
      "Epoch 166/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0135 - accuracy: 0.9383 - val_loss: 0.0307 - val_accuracy: 0.7700\n",
      "Epoch 167/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0133 - accuracy: 0.9383 - val_loss: 0.0305 - val_accuracy: 0.7700\n",
      "Epoch 168/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0132 - accuracy: 0.9417 - val_loss: 0.0304 - val_accuracy: 0.7700\n",
      "Epoch 169/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0131 - accuracy: 0.9383 - val_loss: 0.0304 - val_accuracy: 0.7700\n",
      "Epoch 170/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0130 - accuracy: 0.9400 - val_loss: 0.0303 - val_accuracy: 0.7800\n",
      "Epoch 171/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0129 - accuracy: 0.9417 - val_loss: 0.0302 - val_accuracy: 0.7700\n",
      "Epoch 172/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0128 - accuracy: 0.9400 - val_loss: 0.0301 - val_accuracy: 0.7700\n",
      "Epoch 173/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0127 - accuracy: 0.9433 - val_loss: 0.0300 - val_accuracy: 0.7700\n",
      "Epoch 174/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0126 - accuracy: 0.9433 - val_loss: 0.0299 - val_accuracy: 0.7800\n",
      "Epoch 175/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0125 - accuracy: 0.9433 - val_loss: 0.0298 - val_accuracy: 0.7700\n",
      "Epoch 176/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0123 - accuracy: 0.9450 - val_loss: 0.0297 - val_accuracy: 0.7800\n",
      "Epoch 177/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0122 - accuracy: 0.9450 - val_loss: 0.0297 - val_accuracy: 0.7900\n",
      "Epoch 178/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0121 - accuracy: 0.9433 - val_loss: 0.0295 - val_accuracy: 0.7900\n",
      "Epoch 179/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0120 - accuracy: 0.9433 - val_loss: 0.0295 - val_accuracy: 0.7900\n",
      "Epoch 180/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0119 - accuracy: 0.9467 - val_loss: 0.0293 - val_accuracy: 0.7900\n",
      "Epoch 181/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0118 - accuracy: 0.9517 - val_loss: 0.0292 - val_accuracy: 0.7900\n",
      "Epoch 182/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0117 - accuracy: 0.9483 - val_loss: 0.0292 - val_accuracy: 0.7900\n",
      "Epoch 183/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0116 - accuracy: 0.9483 - val_loss: 0.0291 - val_accuracy: 0.7900\n",
      "Epoch 184/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0115 - accuracy: 0.9517 - val_loss: 0.0290 - val_accuracy: 0.7900\n",
      "Epoch 185/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0114 - accuracy: 0.9517 - val_loss: 0.0290 - val_accuracy: 0.8000\n",
      "Epoch 186/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0113 - accuracy: 0.9500 - val_loss: 0.0290 - val_accuracy: 0.8000\n",
      "Epoch 187/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0113 - accuracy: 0.9517 - val_loss: 0.0289 - val_accuracy: 0.7900\n",
      "Epoch 188/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0112 - accuracy: 0.9517 - val_loss: 0.0288 - val_accuracy: 0.7900\n",
      "Epoch 189/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0111 - accuracy: 0.9517 - val_loss: 0.0288 - val_accuracy: 0.7900\n",
      "Epoch 190/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0110 - accuracy: 0.9517 - val_loss: 0.0287 - val_accuracy: 0.7900\n",
      "Epoch 191/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0109 - accuracy: 0.9517 - val_loss: 0.0286 - val_accuracy: 0.7900\n",
      "Epoch 192/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0108 - accuracy: 0.9517 - val_loss: 0.0285 - val_accuracy: 0.8000\n",
      "Epoch 193/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0107 - accuracy: 0.9500 - val_loss: 0.0285 - val_accuracy: 0.8000\n",
      "Epoch 194/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0106 - accuracy: 0.9517 - val_loss: 0.0284 - val_accuracy: 0.8000\n",
      "Epoch 195/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0105 - accuracy: 0.9533 - val_loss: 0.0283 - val_accuracy: 0.8000\n",
      "Epoch 196/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0105 - accuracy: 0.9550 - val_loss: 0.0283 - val_accuracy: 0.8000\n",
      "Epoch 197/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0104 - accuracy: 0.9533 - val_loss: 0.0283 - val_accuracy: 0.7900\n",
      "Epoch 198/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0103 - accuracy: 0.9533 - val_loss: 0.0282 - val_accuracy: 0.7900\n",
      "Epoch 199/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0102 - accuracy: 0.9533 - val_loss: 0.0281 - val_accuracy: 0.7900\n",
      "Epoch 200/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0102 - accuracy: 0.9533 - val_loss: 0.0280 - val_accuracy: 0.7900\n",
      "Epoch 201/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0101 - accuracy: 0.9567 - val_loss: 0.0280 - val_accuracy: 0.7900\n",
      "Epoch 202/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0100 - accuracy: 0.9583 - val_loss: 0.0279 - val_accuracy: 0.7900\n",
      "Epoch 203/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0099 - accuracy: 0.9567 - val_loss: 0.0279 - val_accuracy: 0.7900\n",
      "Epoch 204/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0098 - accuracy: 0.9583 - val_loss: 0.0278 - val_accuracy: 0.7900\n",
      "Epoch 205/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0098 - accuracy: 0.9600 - val_loss: 0.0278 - val_accuracy: 0.7900\n",
      "Epoch 206/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0097 - accuracy: 0.9583 - val_loss: 0.0277 - val_accuracy: 0.7900\n",
      "Epoch 207/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0096 - accuracy: 0.9600 - val_loss: 0.0277 - val_accuracy: 0.7900\n",
      "Epoch 208/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0096 - accuracy: 0.9600 - val_loss: 0.0276 - val_accuracy: 0.7900\n",
      "Epoch 209/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0095 - accuracy: 0.9600 - val_loss: 0.0275 - val_accuracy: 0.7900\n",
      "Epoch 210/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0094 - accuracy: 0.9600 - val_loss: 0.0275 - val_accuracy: 0.7900\n",
      "Epoch 211/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0094 - accuracy: 0.9600 - val_loss: 0.0275 - val_accuracy: 0.7900\n",
      "Epoch 212/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0093 - accuracy: 0.9600 - val_loss: 0.0274 - val_accuracy: 0.7900\n",
      "Epoch 213/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0092 - accuracy: 0.9617 - val_loss: 0.0274 - val_accuracy: 0.7900\n",
      "Epoch 214/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0091 - accuracy: 0.9600 - val_loss: 0.0274 - val_accuracy: 0.7900\n",
      "Epoch 215/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0091 - accuracy: 0.9600 - val_loss: 0.0274 - val_accuracy: 0.7900\n",
      "Epoch 216/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0090 - accuracy: 0.9633 - val_loss: 0.0273 - val_accuracy: 0.7900\n",
      "Epoch 217/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0089 - accuracy: 0.9617 - val_loss: 0.0273 - val_accuracy: 0.7900\n",
      "Epoch 218/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0089 - accuracy: 0.9633 - val_loss: 0.0272 - val_accuracy: 0.7900\n",
      "Epoch 219/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0088 - accuracy: 0.9633 - val_loss: 0.0272 - val_accuracy: 0.7900\n",
      "Epoch 220/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0088 - accuracy: 0.9633 - val_loss: 0.0272 - val_accuracy: 0.7900\n",
      "Epoch 221/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0087 - accuracy: 0.9633 - val_loss: 0.0271 - val_accuracy: 0.7900\n",
      "Epoch 222/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0087 - accuracy: 0.9633 - val_loss: 0.0271 - val_accuracy: 0.7900\n",
      "Epoch 223/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0086 - accuracy: 0.9633 - val_loss: 0.0271 - val_accuracy: 0.7900\n",
      "Epoch 224/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0085 - accuracy: 0.9633 - val_loss: 0.0270 - val_accuracy: 0.7900\n",
      "Epoch 225/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0085 - accuracy: 0.9650 - val_loss: 0.0269 - val_accuracy: 0.7900\n",
      "Epoch 226/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0084 - accuracy: 0.9650 - val_loss: 0.0269 - val_accuracy: 0.7900\n",
      "Epoch 227/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0084 - accuracy: 0.9650 - val_loss: 0.0269 - val_accuracy: 0.7900\n",
      "Epoch 228/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0083 - accuracy: 0.9667 - val_loss: 0.0268 - val_accuracy: 0.7900\n",
      "Epoch 229/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0082 - accuracy: 0.9650 - val_loss: 0.0269 - val_accuracy: 0.7900\n",
      "Epoch 230/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0082 - accuracy: 0.9667 - val_loss: 0.0268 - val_accuracy: 0.7900\n",
      "Epoch 231/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0081 - accuracy: 0.9667 - val_loss: 0.0268 - val_accuracy: 0.7900\n",
      "Epoch 232/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0081 - accuracy: 0.9650 - val_loss: 0.0268 - val_accuracy: 0.7900\n",
      "Epoch 233/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0080 - accuracy: 0.9667 - val_loss: 0.0268 - val_accuracy: 0.7900\n",
      "Epoch 234/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0080 - accuracy: 0.9667 - val_loss: 0.0268 - val_accuracy: 0.7900\n",
      "Epoch 235/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0079 - accuracy: 0.9667 - val_loss: 0.0267 - val_accuracy: 0.7900\n",
      "Epoch 236/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0079 - accuracy: 0.9667 - val_loss: 0.0267 - val_accuracy: 0.7900\n",
      "Epoch 237/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0078 - accuracy: 0.9650 - val_loss: 0.0266 - val_accuracy: 0.7900\n",
      "Epoch 238/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0078 - accuracy: 0.9667 - val_loss: 0.0266 - val_accuracy: 0.7900\n",
      "Epoch 239/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0077 - accuracy: 0.9683 - val_loss: 0.0266 - val_accuracy: 0.7900\n",
      "Epoch 240/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0077 - accuracy: 0.9667 - val_loss: 0.0266 - val_accuracy: 0.7900\n",
      "Training date and time : \n",
      "2020-04-09 21:02:42\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/240\n",
      "600/600 [==============================] - 0s 650us/sample - loss: 0.0901 - accuracy: 0.1167 - val_loss: 0.0896 - val_accuracy: 0.1600\n",
      "Epoch 2/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0899 - accuracy: 0.1267 - val_loss: 0.0894 - val_accuracy: 0.1700\n",
      "Epoch 3/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0896 - accuracy: 0.1467 - val_loss: 0.0892 - val_accuracy: 0.1900\n",
      "Epoch 4/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0894 - accuracy: 0.1567 - val_loss: 0.0891 - val_accuracy: 0.2000\n",
      "Epoch 5/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0892 - accuracy: 0.1767 - val_loss: 0.0889 - val_accuracy: 0.2100\n",
      "Epoch 6/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0890 - accuracy: 0.2050 - val_loss: 0.0887 - val_accuracy: 0.2300\n",
      "Epoch 7/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0888 - accuracy: 0.2250 - val_loss: 0.0886 - val_accuracy: 0.2400\n",
      "Epoch 8/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0886 - accuracy: 0.2517 - val_loss: 0.0884 - val_accuracy: 0.2900\n",
      "Epoch 9/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0883 - accuracy: 0.2850 - val_loss: 0.0882 - val_accuracy: 0.3100\n",
      "Epoch 10/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0881 - accuracy: 0.3083 - val_loss: 0.0880 - val_accuracy: 0.3400\n",
      "Epoch 11/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0879 - accuracy: 0.3333 - val_loss: 0.0879 - val_accuracy: 0.3700\n",
      "Epoch 12/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0877 - accuracy: 0.3483 - val_loss: 0.0877 - val_accuracy: 0.4000\n",
      "Epoch 13/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0874 - accuracy: 0.3733 - val_loss: 0.0875 - val_accuracy: 0.4200\n",
      "Epoch 14/240\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0872 - accuracy: 0.4033 - val_loss: 0.0873 - val_accuracy: 0.4200\n",
      "Epoch 15/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0869 - accuracy: 0.4183 - val_loss: 0.0871 - val_accuracy: 0.4400\n",
      "Epoch 16/240\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0866 - accuracy: 0.4367 - val_loss: 0.0869 - val_accuracy: 0.4300\n",
      "Epoch 17/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0864 - accuracy: 0.4633 - val_loss: 0.0866 - val_accuracy: 0.4300\n",
      "Epoch 18/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0861 - accuracy: 0.4733 - val_loss: 0.0864 - val_accuracy: 0.4300\n",
      "Epoch 19/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0858 - accuracy: 0.4867 - val_loss: 0.0862 - val_accuracy: 0.4300\n",
      "Epoch 20/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0854 - accuracy: 0.4950 - val_loss: 0.0859 - val_accuracy: 0.4500\n",
      "Epoch 21/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0851 - accuracy: 0.5167 - val_loss: 0.0856 - val_accuracy: 0.4700\n",
      "Epoch 22/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0848 - accuracy: 0.5283 - val_loss: 0.0854 - val_accuracy: 0.4700\n",
      "Epoch 23/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0844 - accuracy: 0.5333 - val_loss: 0.0851 - val_accuracy: 0.4700\n",
      "Epoch 24/240\n",
      "600/600 [==============================] - 0s 85us/sample - loss: 0.0840 - accuracy: 0.5417 - val_loss: 0.0847 - val_accuracy: 0.4700\n",
      "Epoch 25/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0836 - accuracy: 0.5467 - val_loss: 0.0844 - val_accuracy: 0.4700\n",
      "Epoch 26/240\n",
      "600/600 [==============================] - 0s 83us/sample - loss: 0.0832 - accuracy: 0.5517 - val_loss: 0.0841 - val_accuracy: 0.4700\n",
      "Epoch 27/240\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0827 - accuracy: 0.5517 - val_loss: 0.0837 - val_accuracy: 0.4700\n",
      "Epoch 28/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0823 - accuracy: 0.5567 - val_loss: 0.0833 - val_accuracy: 0.4700\n",
      "Epoch 29/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0817 - accuracy: 0.5600 - val_loss: 0.0829 - val_accuracy: 0.4700\n",
      "Epoch 30/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0812 - accuracy: 0.5617 - val_loss: 0.0824 - val_accuracy: 0.4700\n",
      "Epoch 31/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0806 - accuracy: 0.5650 - val_loss: 0.0820 - val_accuracy: 0.4800\n",
      "Epoch 32/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0800 - accuracy: 0.5683 - val_loss: 0.0815 - val_accuracy: 0.4700\n",
      "Epoch 33/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0794 - accuracy: 0.5683 - val_loss: 0.0810 - val_accuracy: 0.4700\n",
      "Epoch 34/240\n",
      "600/600 [==============================] - 0s 85us/sample - loss: 0.0788 - accuracy: 0.5633 - val_loss: 0.0805 - val_accuracy: 0.4700\n",
      "Epoch 35/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0781 - accuracy: 0.5633 - val_loss: 0.0799 - val_accuracy: 0.4600\n",
      "Epoch 36/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0773 - accuracy: 0.5633 - val_loss: 0.0793 - val_accuracy: 0.4600\n",
      "Epoch 37/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0766 - accuracy: 0.5617 - val_loss: 0.0787 - val_accuracy: 0.4600\n",
      "Epoch 38/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0758 - accuracy: 0.5617 - val_loss: 0.0781 - val_accuracy: 0.4600\n",
      "Epoch 39/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0750 - accuracy: 0.5617 - val_loss: 0.0775 - val_accuracy: 0.4600\n",
      "Epoch 40/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0742 - accuracy: 0.5617 - val_loss: 0.0769 - val_accuracy: 0.4600\n",
      "Epoch 41/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0733 - accuracy: 0.5667 - val_loss: 0.0762 - val_accuracy: 0.4600\n",
      "Epoch 42/240\n",
      "600/600 [==============================] - 0s 85us/sample - loss: 0.0725 - accuracy: 0.5717 - val_loss: 0.0755 - val_accuracy: 0.4600\n",
      "Epoch 43/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0716 - accuracy: 0.5750 - val_loss: 0.0749 - val_accuracy: 0.4700\n",
      "Epoch 44/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0707 - accuracy: 0.5750 - val_loss: 0.0742 - val_accuracy: 0.4900\n",
      "Epoch 45/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0698 - accuracy: 0.5783 - val_loss: 0.0735 - val_accuracy: 0.5000\n",
      "Epoch 46/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0689 - accuracy: 0.5783 - val_loss: 0.0728 - val_accuracy: 0.5000\n",
      "Epoch 47/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0679 - accuracy: 0.5883 - val_loss: 0.0721 - val_accuracy: 0.5100\n",
      "Epoch 48/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0670 - accuracy: 0.5900 - val_loss: 0.0714 - val_accuracy: 0.5100\n",
      "Epoch 49/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0661 - accuracy: 0.5933 - val_loss: 0.0707 - val_accuracy: 0.5300\n",
      "Epoch 50/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0652 - accuracy: 0.6050 - val_loss: 0.0700 - val_accuracy: 0.5300\n",
      "Epoch 51/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0643 - accuracy: 0.6083 - val_loss: 0.0693 - val_accuracy: 0.5400\n",
      "Epoch 52/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0634 - accuracy: 0.6117 - val_loss: 0.0686 - val_accuracy: 0.5400\n",
      "Epoch 53/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0625 - accuracy: 0.6183 - val_loss: 0.0679 - val_accuracy: 0.5600\n",
      "Epoch 54/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0616 - accuracy: 0.6200 - val_loss: 0.0672 - val_accuracy: 0.5700\n",
      "Epoch 55/240\n",
      "600/600 [==============================] - 0s 83us/sample - loss: 0.0607 - accuracy: 0.6200 - val_loss: 0.0665 - val_accuracy: 0.5800\n",
      "Epoch 56/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0598 - accuracy: 0.6217 - val_loss: 0.0658 - val_accuracy: 0.5800\n",
      "Epoch 57/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0590 - accuracy: 0.6250 - val_loss: 0.0652 - val_accuracy: 0.5800\n",
      "Epoch 58/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0581 - accuracy: 0.6233 - val_loss: 0.0645 - val_accuracy: 0.5800\n",
      "Epoch 59/240\n",
      "600/600 [==============================] - 0s 83us/sample - loss: 0.0573 - accuracy: 0.6333 - val_loss: 0.0639 - val_accuracy: 0.5800\n",
      "Epoch 60/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0565 - accuracy: 0.6350 - val_loss: 0.0632 - val_accuracy: 0.6000\n",
      "Epoch 61/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0557 - accuracy: 0.6417 - val_loss: 0.0626 - val_accuracy: 0.6100\n",
      "Epoch 62/240\n",
      "600/600 [==============================] - 0s 85us/sample - loss: 0.0549 - accuracy: 0.6450 - val_loss: 0.0620 - val_accuracy: 0.6100\n",
      "Epoch 63/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0541 - accuracy: 0.6483 - val_loss: 0.0614 - val_accuracy: 0.6100\n",
      "Epoch 64/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0533 - accuracy: 0.6483 - val_loss: 0.0608 - val_accuracy: 0.6100\n",
      "Epoch 65/240\n",
      "600/600 [==============================] - 0s 84us/sample - loss: 0.0526 - accuracy: 0.6467 - val_loss: 0.0602 - val_accuracy: 0.6200\n",
      "Epoch 66/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0518 - accuracy: 0.6483 - val_loss: 0.0596 - val_accuracy: 0.6300\n",
      "Epoch 67/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0511 - accuracy: 0.6517 - val_loss: 0.0591 - val_accuracy: 0.6300\n",
      "Epoch 68/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0503 - accuracy: 0.6533 - val_loss: 0.0585 - val_accuracy: 0.6400\n",
      "Epoch 69/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0496 - accuracy: 0.6567 - val_loss: 0.0580 - val_accuracy: 0.6400\n",
      "Epoch 70/240\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0489 - accuracy: 0.6633 - val_loss: 0.0575 - val_accuracy: 0.6400\n",
      "Epoch 71/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0482 - accuracy: 0.6683 - val_loss: 0.0570 - val_accuracy: 0.6400\n",
      "Epoch 72/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0475 - accuracy: 0.6683 - val_loss: 0.0565 - val_accuracy: 0.6400\n",
      "Epoch 73/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0468 - accuracy: 0.6833 - val_loss: 0.0561 - val_accuracy: 0.6500\n",
      "Epoch 74/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0461 - accuracy: 0.6967 - val_loss: 0.0556 - val_accuracy: 0.6500\n",
      "Epoch 75/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0454 - accuracy: 0.7133 - val_loss: 0.0552 - val_accuracy: 0.6600\n",
      "Epoch 76/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0447 - accuracy: 0.7300 - val_loss: 0.0547 - val_accuracy: 0.6700\n",
      "Epoch 77/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0440 - accuracy: 0.7333 - val_loss: 0.0543 - val_accuracy: 0.6700\n",
      "Epoch 78/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0433 - accuracy: 0.7417 - val_loss: 0.0539 - val_accuracy: 0.6700\n",
      "Epoch 79/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0426 - accuracy: 0.7483 - val_loss: 0.0535 - val_accuracy: 0.6700\n",
      "Epoch 80/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0420 - accuracy: 0.7567 - val_loss: 0.0531 - val_accuracy: 0.6700\n",
      "Epoch 81/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0413 - accuracy: 0.7583 - val_loss: 0.0527 - val_accuracy: 0.6700\n",
      "Epoch 82/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0407 - accuracy: 0.7633 - val_loss: 0.0523 - val_accuracy: 0.6700\n",
      "Epoch 83/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0401 - accuracy: 0.7700 - val_loss: 0.0519 - val_accuracy: 0.6700\n",
      "Epoch 84/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0394 - accuracy: 0.7750 - val_loss: 0.0516 - val_accuracy: 0.6700\n",
      "Epoch 85/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0388 - accuracy: 0.7817 - val_loss: 0.0512 - val_accuracy: 0.6900\n",
      "Epoch 86/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0382 - accuracy: 0.7867 - val_loss: 0.0508 - val_accuracy: 0.6800\n",
      "Epoch 87/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0376 - accuracy: 0.7917 - val_loss: 0.0504 - val_accuracy: 0.6800\n",
      "Epoch 88/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0371 - accuracy: 0.7900 - val_loss: 0.0500 - val_accuracy: 0.6800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/240\n",
      "600/600 [==============================] - 0s 85us/sample - loss: 0.0365 - accuracy: 0.7917 - val_loss: 0.0496 - val_accuracy: 0.6800\n",
      "Epoch 90/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0360 - accuracy: 0.7950 - val_loss: 0.0493 - val_accuracy: 0.6900\n",
      "Epoch 91/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0354 - accuracy: 0.7967 - val_loss: 0.0490 - val_accuracy: 0.6900\n",
      "Epoch 92/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0349 - accuracy: 0.7967 - val_loss: 0.0486 - val_accuracy: 0.6900\n",
      "Epoch 93/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0344 - accuracy: 0.7983 - val_loss: 0.0482 - val_accuracy: 0.6900\n",
      "Epoch 94/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0340 - accuracy: 0.8033 - val_loss: 0.0479 - val_accuracy: 0.6900\n",
      "Epoch 95/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0335 - accuracy: 0.8050 - val_loss: 0.0475 - val_accuracy: 0.6900\n",
      "Epoch 96/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0330 - accuracy: 0.8083 - val_loss: 0.0472 - val_accuracy: 0.6900\n",
      "Epoch 97/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0325 - accuracy: 0.8100 - val_loss: 0.0469 - val_accuracy: 0.6900\n",
      "Epoch 98/240\n",
      "600/600 [==============================] - 0s 82us/sample - loss: 0.0321 - accuracy: 0.8150 - val_loss: 0.0465 - val_accuracy: 0.6900\n",
      "Epoch 99/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0316 - accuracy: 0.8217 - val_loss: 0.0462 - val_accuracy: 0.6900\n",
      "Epoch 100/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0312 - accuracy: 0.8300 - val_loss: 0.0458 - val_accuracy: 0.6900\n",
      "Epoch 101/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0308 - accuracy: 0.8317 - val_loss: 0.0455 - val_accuracy: 0.6900\n",
      "Epoch 102/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0304 - accuracy: 0.8317 - val_loss: 0.0452 - val_accuracy: 0.6900\n",
      "Epoch 103/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0300 - accuracy: 0.8417 - val_loss: 0.0449 - val_accuracy: 0.6900\n",
      "Epoch 104/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0296 - accuracy: 0.8450 - val_loss: 0.0446 - val_accuracy: 0.6900\n",
      "Epoch 105/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0291 - accuracy: 0.8500 - val_loss: 0.0442 - val_accuracy: 0.6900\n",
      "Epoch 106/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0288 - accuracy: 0.8567 - val_loss: 0.0440 - val_accuracy: 0.6900\n",
      "Epoch 107/240\n",
      "600/600 [==============================] - 0s 84us/sample - loss: 0.0284 - accuracy: 0.8567 - val_loss: 0.0437 - val_accuracy: 0.6900\n",
      "Epoch 108/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0280 - accuracy: 0.8583 - val_loss: 0.0433 - val_accuracy: 0.6900\n",
      "Epoch 109/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0276 - accuracy: 0.8633 - val_loss: 0.0431 - val_accuracy: 0.6900\n",
      "Epoch 110/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0273 - accuracy: 0.8667 - val_loss: 0.0427 - val_accuracy: 0.6900\n",
      "Epoch 111/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0269 - accuracy: 0.8683 - val_loss: 0.0424 - val_accuracy: 0.6900\n",
      "Epoch 112/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0266 - accuracy: 0.8733 - val_loss: 0.0421 - val_accuracy: 0.6900\n",
      "Epoch 113/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0262 - accuracy: 0.8783 - val_loss: 0.0419 - val_accuracy: 0.6900\n",
      "Epoch 114/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0259 - accuracy: 0.8750 - val_loss: 0.0416 - val_accuracy: 0.6900\n",
      "Epoch 115/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0256 - accuracy: 0.8800 - val_loss: 0.0413 - val_accuracy: 0.6900\n",
      "Epoch 116/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0252 - accuracy: 0.8833 - val_loss: 0.0411 - val_accuracy: 0.7100\n",
      "Epoch 117/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0249 - accuracy: 0.8817 - val_loss: 0.0409 - val_accuracy: 0.7100\n",
      "Epoch 118/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0246 - accuracy: 0.8833 - val_loss: 0.0406 - val_accuracy: 0.7100\n",
      "Epoch 119/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0243 - accuracy: 0.8817 - val_loss: 0.0403 - val_accuracy: 0.7200\n",
      "Epoch 120/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0241 - accuracy: 0.8833 - val_loss: 0.0401 - val_accuracy: 0.7200\n",
      "Epoch 121/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0238 - accuracy: 0.8817 - val_loss: 0.0398 - val_accuracy: 0.7200\n",
      "Epoch 122/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0235 - accuracy: 0.8817 - val_loss: 0.0396 - val_accuracy: 0.7200\n",
      "Epoch 123/240\n",
      "600/600 [==============================] - 0s 85us/sample - loss: 0.0232 - accuracy: 0.8800 - val_loss: 0.0393 - val_accuracy: 0.7100\n",
      "Epoch 124/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0229 - accuracy: 0.8833 - val_loss: 0.0392 - val_accuracy: 0.7100\n",
      "Epoch 125/240\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0227 - accuracy: 0.8833 - val_loss: 0.0389 - val_accuracy: 0.7100\n",
      "Epoch 126/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0224 - accuracy: 0.8817 - val_loss: 0.0387 - val_accuracy: 0.7200\n",
      "Epoch 127/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0221 - accuracy: 0.8833 - val_loss: 0.0385 - val_accuracy: 0.7300\n",
      "Epoch 128/240\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0219 - accuracy: 0.8833 - val_loss: 0.0383 - val_accuracy: 0.7300\n",
      "Epoch 129/240\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0216 - accuracy: 0.8867 - val_loss: 0.0380 - val_accuracy: 0.7500\n",
      "Epoch 130/240\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0214 - accuracy: 0.8817 - val_loss: 0.0378 - val_accuracy: 0.7400\n",
      "Epoch 131/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0212 - accuracy: 0.8883 - val_loss: 0.0376 - val_accuracy: 0.7400\n",
      "Epoch 132/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0209 - accuracy: 0.8867 - val_loss: 0.0374 - val_accuracy: 0.7400\n",
      "Epoch 133/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0207 - accuracy: 0.8900 - val_loss: 0.0372 - val_accuracy: 0.7400\n",
      "Epoch 134/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0205 - accuracy: 0.8917 - val_loss: 0.0370 - val_accuracy: 0.7500\n",
      "Epoch 135/240\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0203 - accuracy: 0.8900 - val_loss: 0.0368 - val_accuracy: 0.7500\n",
      "Epoch 136/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0200 - accuracy: 0.8950 - val_loss: 0.0366 - val_accuracy: 0.7500\n",
      "Epoch 137/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0198 - accuracy: 0.8967 - val_loss: 0.0364 - val_accuracy: 0.7500\n",
      "Epoch 138/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0196 - accuracy: 0.8983 - val_loss: 0.0362 - val_accuracy: 0.7500\n",
      "Epoch 139/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0194 - accuracy: 0.9000 - val_loss: 0.0360 - val_accuracy: 0.7500\n",
      "Epoch 140/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0192 - accuracy: 0.8967 - val_loss: 0.0359 - val_accuracy: 0.7500\n",
      "Epoch 141/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0190 - accuracy: 0.8967 - val_loss: 0.0357 - val_accuracy: 0.7500\n",
      "Epoch 142/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0188 - accuracy: 0.9050 - val_loss: 0.0356 - val_accuracy: 0.7500\n",
      "Epoch 143/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0186 - accuracy: 0.9017 - val_loss: 0.0354 - val_accuracy: 0.7500\n",
      "Epoch 144/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 85us/sample - loss: 0.0184 - accuracy: 0.9050 - val_loss: 0.0352 - val_accuracy: 0.7500\n",
      "Epoch 145/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0182 - accuracy: 0.9050 - val_loss: 0.0350 - val_accuracy: 0.7500\n",
      "Epoch 146/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0180 - accuracy: 0.9100 - val_loss: 0.0349 - val_accuracy: 0.7500\n",
      "Epoch 147/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0179 - accuracy: 0.9067 - val_loss: 0.0347 - val_accuracy: 0.7500\n",
      "Epoch 148/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0177 - accuracy: 0.9133 - val_loss: 0.0345 - val_accuracy: 0.7500\n",
      "Epoch 149/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0175 - accuracy: 0.9100 - val_loss: 0.0344 - val_accuracy: 0.7600\n",
      "Epoch 150/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0174 - accuracy: 0.9117 - val_loss: 0.0342 - val_accuracy: 0.7600\n",
      "Epoch 151/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0172 - accuracy: 0.9117 - val_loss: 0.0340 - val_accuracy: 0.7500\n",
      "Epoch 152/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0170 - accuracy: 0.9183 - val_loss: 0.0339 - val_accuracy: 0.7600\n",
      "Epoch 153/240\n",
      "600/600 [==============================] - 0s 86us/sample - loss: 0.0169 - accuracy: 0.9150 - val_loss: 0.0337 - val_accuracy: 0.7500\n",
      "Epoch 154/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0167 - accuracy: 0.9150 - val_loss: 0.0336 - val_accuracy: 0.7500\n",
      "Epoch 155/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0165 - accuracy: 0.9183 - val_loss: 0.0334 - val_accuracy: 0.7500\n",
      "Epoch 156/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0164 - accuracy: 0.9200 - val_loss: 0.0332 - val_accuracy: 0.7600\n",
      "Epoch 157/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0162 - accuracy: 0.9233 - val_loss: 0.0331 - val_accuracy: 0.7700\n",
      "Epoch 158/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0160 - accuracy: 0.9233 - val_loss: 0.0329 - val_accuracy: 0.7700\n",
      "Epoch 159/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0159 - accuracy: 0.9217 - val_loss: 0.0328 - val_accuracy: 0.7600\n",
      "Epoch 160/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0158 - accuracy: 0.9250 - val_loss: 0.0327 - val_accuracy: 0.7700\n",
      "Epoch 161/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0156 - accuracy: 0.9267 - val_loss: 0.0326 - val_accuracy: 0.7700\n",
      "Epoch 162/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0155 - accuracy: 0.9250 - val_loss: 0.0325 - val_accuracy: 0.7700\n",
      "Epoch 163/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0153 - accuracy: 0.9250 - val_loss: 0.0323 - val_accuracy: 0.7700\n",
      "Epoch 164/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0152 - accuracy: 0.9317 - val_loss: 0.0322 - val_accuracy: 0.7700\n",
      "Epoch 165/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0150 - accuracy: 0.9283 - val_loss: 0.0321 - val_accuracy: 0.7700\n",
      "Epoch 166/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0149 - accuracy: 0.9300 - val_loss: 0.0320 - val_accuracy: 0.7800\n",
      "Epoch 167/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0148 - accuracy: 0.9283 - val_loss: 0.0318 - val_accuracy: 0.7800\n",
      "Epoch 168/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0146 - accuracy: 0.9350 - val_loss: 0.0317 - val_accuracy: 0.7800\n",
      "Epoch 169/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0145 - accuracy: 0.9350 - val_loss: 0.0316 - val_accuracy: 0.7800\n",
      "Epoch 170/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0144 - accuracy: 0.9350 - val_loss: 0.0315 - val_accuracy: 0.7800\n",
      "Epoch 171/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0143 - accuracy: 0.9383 - val_loss: 0.0314 - val_accuracy: 0.7800\n",
      "Epoch 172/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0141 - accuracy: 0.9350 - val_loss: 0.0313 - val_accuracy: 0.7800\n",
      "Epoch 173/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0140 - accuracy: 0.9367 - val_loss: 0.0311 - val_accuracy: 0.7800\n",
      "Epoch 174/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0139 - accuracy: 0.9350 - val_loss: 0.0310 - val_accuracy: 0.7800\n",
      "Epoch 175/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0138 - accuracy: 0.9367 - val_loss: 0.0309 - val_accuracy: 0.7800\n",
      "Epoch 176/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0136 - accuracy: 0.9383 - val_loss: 0.0308 - val_accuracy: 0.7800\n",
      "Epoch 177/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0135 - accuracy: 0.9350 - val_loss: 0.0308 - val_accuracy: 0.7700\n",
      "Epoch 178/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0134 - accuracy: 0.9383 - val_loss: 0.0306 - val_accuracy: 0.7800\n",
      "Epoch 179/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0133 - accuracy: 0.9383 - val_loss: 0.0305 - val_accuracy: 0.7800\n",
      "Epoch 180/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0132 - accuracy: 0.9367 - val_loss: 0.0304 - val_accuracy: 0.7800\n",
      "Epoch 181/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0131 - accuracy: 0.9383 - val_loss: 0.0303 - val_accuracy: 0.7800\n",
      "Epoch 182/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0130 - accuracy: 0.9400 - val_loss: 0.0302 - val_accuracy: 0.7800\n",
      "Epoch 183/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0129 - accuracy: 0.9417 - val_loss: 0.0301 - val_accuracy: 0.7800\n",
      "Epoch 184/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0127 - accuracy: 0.9400 - val_loss: 0.0300 - val_accuracy: 0.7800\n",
      "Epoch 185/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0126 - accuracy: 0.9417 - val_loss: 0.0300 - val_accuracy: 0.7800\n",
      "Epoch 186/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0125 - accuracy: 0.9417 - val_loss: 0.0300 - val_accuracy: 0.7800\n",
      "Epoch 187/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0124 - accuracy: 0.9417 - val_loss: 0.0299 - val_accuracy: 0.7800\n",
      "Epoch 188/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0123 - accuracy: 0.9433 - val_loss: 0.0298 - val_accuracy: 0.7800\n",
      "Epoch 189/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0122 - accuracy: 0.9450 - val_loss: 0.0297 - val_accuracy: 0.7900\n",
      "Epoch 190/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0121 - accuracy: 0.9467 - val_loss: 0.0296 - val_accuracy: 0.7900\n",
      "Epoch 191/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0120 - accuracy: 0.9450 - val_loss: 0.0295 - val_accuracy: 0.7900\n",
      "Epoch 192/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0119 - accuracy: 0.9467 - val_loss: 0.0294 - val_accuracy: 0.7900\n",
      "Epoch 193/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0118 - accuracy: 0.9450 - val_loss: 0.0294 - val_accuracy: 0.7900\n",
      "Epoch 194/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0117 - accuracy: 0.9467 - val_loss: 0.0293 - val_accuracy: 0.7900\n",
      "Epoch 195/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0116 - accuracy: 0.9483 - val_loss: 0.0292 - val_accuracy: 0.7900\n",
      "Epoch 196/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0115 - accuracy: 0.9467 - val_loss: 0.0291 - val_accuracy: 0.7900\n",
      "Epoch 197/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0115 - accuracy: 0.9467 - val_loss: 0.0291 - val_accuracy: 0.7900\n",
      "Epoch 198/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0114 - accuracy: 0.9467 - val_loss: 0.0290 - val_accuracy: 0.7900\n",
      "Epoch 199/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0113 - accuracy: 0.9483 - val_loss: 0.0289 - val_accuracy: 0.7900\n",
      "Epoch 200/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0112 - accuracy: 0.9500 - val_loss: 0.0288 - val_accuracy: 0.7900\n",
      "Epoch 201/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0111 - accuracy: 0.9500 - val_loss: 0.0288 - val_accuracy: 0.7900\n",
      "Epoch 202/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0110 - accuracy: 0.9483 - val_loss: 0.0287 - val_accuracy: 0.8000\n",
      "Epoch 203/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0109 - accuracy: 0.9500 - val_loss: 0.0287 - val_accuracy: 0.8000\n",
      "Epoch 204/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0108 - accuracy: 0.9500 - val_loss: 0.0285 - val_accuracy: 0.8000\n",
      "Epoch 205/240\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0108 - accuracy: 0.9567 - val_loss: 0.0286 - val_accuracy: 0.8000\n",
      "Epoch 206/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0107 - accuracy: 0.9533 - val_loss: 0.0285 - val_accuracy: 0.8000\n",
      "Epoch 207/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0106 - accuracy: 0.9533 - val_loss: 0.0284 - val_accuracy: 0.8000\n",
      "Epoch 208/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0105 - accuracy: 0.9533 - val_loss: 0.0283 - val_accuracy: 0.8000\n",
      "Epoch 209/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0104 - accuracy: 0.9567 - val_loss: 0.0283 - val_accuracy: 0.8000\n",
      "Epoch 210/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0103 - accuracy: 0.9567 - val_loss: 0.0283 - val_accuracy: 0.8000\n",
      "Epoch 211/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0103 - accuracy: 0.9567 - val_loss: 0.0282 - val_accuracy: 0.8000\n",
      "Epoch 212/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0102 - accuracy: 0.9567 - val_loss: 0.0281 - val_accuracy: 0.8000\n",
      "Epoch 213/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0101 - accuracy: 0.9583 - val_loss: 0.0281 - val_accuracy: 0.8000\n",
      "Epoch 214/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0101 - accuracy: 0.9583 - val_loss: 0.0281 - val_accuracy: 0.8000\n",
      "Epoch 215/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0100 - accuracy: 0.9583 - val_loss: 0.0280 - val_accuracy: 0.8000\n",
      "Epoch 216/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0099 - accuracy: 0.9583 - val_loss: 0.0280 - val_accuracy: 0.8000\n",
      "Epoch 217/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0098 - accuracy: 0.9583 - val_loss: 0.0279 - val_accuracy: 0.8000\n",
      "Epoch 218/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0098 - accuracy: 0.9583 - val_loss: 0.0279 - val_accuracy: 0.8000\n",
      "Epoch 219/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0097 - accuracy: 0.9583 - val_loss: 0.0278 - val_accuracy: 0.8000\n",
      "Epoch 220/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0096 - accuracy: 0.9583 - val_loss: 0.0278 - val_accuracy: 0.8000\n",
      "Epoch 221/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0096 - accuracy: 0.9600 - val_loss: 0.0277 - val_accuracy: 0.8000\n",
      "Epoch 222/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0095 - accuracy: 0.9583 - val_loss: 0.0277 - val_accuracy: 0.8000\n",
      "Epoch 223/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0094 - accuracy: 0.9600 - val_loss: 0.0277 - val_accuracy: 0.8000\n",
      "Epoch 224/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0094 - accuracy: 0.9600 - val_loss: 0.0275 - val_accuracy: 0.8000\n",
      "Epoch 225/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0093 - accuracy: 0.9600 - val_loss: 0.0275 - val_accuracy: 0.8000\n",
      "Epoch 226/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0092 - accuracy: 0.9600 - val_loss: 0.0275 - val_accuracy: 0.8000\n",
      "Epoch 227/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0092 - accuracy: 0.9600 - val_loss: 0.0275 - val_accuracy: 0.8000\n",
      "Epoch 228/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0091 - accuracy: 0.9600 - val_loss: 0.0274 - val_accuracy: 0.8000\n",
      "Epoch 229/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0090 - accuracy: 0.9600 - val_loss: 0.0274 - val_accuracy: 0.8000\n",
      "Epoch 230/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0090 - accuracy: 0.9600 - val_loss: 0.0273 - val_accuracy: 0.8000\n",
      "Epoch 231/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0089 - accuracy: 0.9600 - val_loss: 0.0273 - val_accuracy: 0.8000\n",
      "Epoch 232/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0088 - accuracy: 0.9600 - val_loss: 0.0274 - val_accuracy: 0.8000\n",
      "Epoch 233/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0088 - accuracy: 0.9633 - val_loss: 0.0273 - val_accuracy: 0.8000\n",
      "Epoch 234/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0087 - accuracy: 0.9600 - val_loss: 0.0273 - val_accuracy: 0.8000\n",
      "Epoch 235/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0087 - accuracy: 0.9650 - val_loss: 0.0272 - val_accuracy: 0.8000\n",
      "Epoch 236/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0086 - accuracy: 0.9650 - val_loss: 0.0272 - val_accuracy: 0.8000\n",
      "Epoch 237/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0085 - accuracy: 0.9650 - val_loss: 0.0271 - val_accuracy: 0.8000\n",
      "Epoch 238/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0085 - accuracy: 0.9650 - val_loss: 0.0271 - val_accuracy: 0.8000\n",
      "Epoch 239/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0084 - accuracy: 0.9650 - val_loss: 0.0271 - val_accuracy: 0.8000\n",
      "Epoch 240/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0084 - accuracy: 0.9650 - val_loss: 0.0271 - val_accuracy: 0.8000\n",
      "Training date and time : \n",
      "2020-04-09 21:02:57\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/240\n",
      "600/600 [==============================] - 0s 664us/sample - loss: 0.0900 - accuracy: 0.1200 - val_loss: 0.0896 - val_accuracy: 0.1600\n",
      "Epoch 2/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0898 - accuracy: 0.1283 - val_loss: 0.0894 - val_accuracy: 0.1700\n",
      "Epoch 3/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0896 - accuracy: 0.1367 - val_loss: 0.0893 - val_accuracy: 0.1900\n",
      "Epoch 4/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0895 - accuracy: 0.1517 - val_loss: 0.0892 - val_accuracy: 0.1900\n",
      "Epoch 5/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0893 - accuracy: 0.1767 - val_loss: 0.0890 - val_accuracy: 0.2000\n",
      "Epoch 6/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0891 - accuracy: 0.1900 - val_loss: 0.0889 - val_accuracy: 0.2100\n",
      "Epoch 7/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0889 - accuracy: 0.2067 - val_loss: 0.0888 - val_accuracy: 0.2400\n",
      "Epoch 8/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0888 - accuracy: 0.2417 - val_loss: 0.0886 - val_accuracy: 0.2600\n",
      "Epoch 9/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0886 - accuracy: 0.2733 - val_loss: 0.0885 - val_accuracy: 0.2700\n",
      "Epoch 10/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0884 - accuracy: 0.2933 - val_loss: 0.0883 - val_accuracy: 0.2900\n",
      "Epoch 11/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0882 - accuracy: 0.3133 - val_loss: 0.0882 - val_accuracy: 0.3100\n",
      "Epoch 12/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0880 - accuracy: 0.3317 - val_loss: 0.0880 - val_accuracy: 0.3300\n",
      "Epoch 13/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0878 - accuracy: 0.3500 - val_loss: 0.0879 - val_accuracy: 0.3700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0876 - accuracy: 0.3700 - val_loss: 0.0877 - val_accuracy: 0.4000\n",
      "Epoch 15/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0874 - accuracy: 0.3967 - val_loss: 0.0875 - val_accuracy: 0.4100\n",
      "Epoch 16/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0872 - accuracy: 0.4167 - val_loss: 0.0873 - val_accuracy: 0.4100\n",
      "Epoch 17/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0869 - accuracy: 0.4333 - val_loss: 0.0872 - val_accuracy: 0.4200\n",
      "Epoch 18/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0867 - accuracy: 0.4517 - val_loss: 0.0870 - val_accuracy: 0.4200\n",
      "Epoch 19/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0865 - accuracy: 0.4700 - val_loss: 0.0868 - val_accuracy: 0.4200\n",
      "Epoch 20/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0862 - accuracy: 0.4783 - val_loss: 0.0866 - val_accuracy: 0.4300\n",
      "Epoch 21/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0860 - accuracy: 0.4867 - val_loss: 0.0864 - val_accuracy: 0.4500\n",
      "Epoch 22/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0857 - accuracy: 0.5000 - val_loss: 0.0862 - val_accuracy: 0.4500\n",
      "Epoch 23/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0854 - accuracy: 0.5100 - val_loss: 0.0859 - val_accuracy: 0.4500\n",
      "Epoch 24/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0851 - accuracy: 0.5183 - val_loss: 0.0857 - val_accuracy: 0.4600\n",
      "Epoch 25/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0848 - accuracy: 0.5333 - val_loss: 0.0854 - val_accuracy: 0.4600\n",
      "Epoch 26/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0845 - accuracy: 0.5417 - val_loss: 0.0852 - val_accuracy: 0.4600\n",
      "Epoch 27/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0841 - accuracy: 0.5483 - val_loss: 0.0849 - val_accuracy: 0.4600\n",
      "Epoch 28/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0838 - accuracy: 0.5550 - val_loss: 0.0846 - val_accuracy: 0.4700\n",
      "Epoch 29/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0834 - accuracy: 0.5600 - val_loss: 0.0843 - val_accuracy: 0.4700\n",
      "Epoch 30/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0830 - accuracy: 0.5633 - val_loss: 0.0839 - val_accuracy: 0.4700\n",
      "Epoch 31/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0826 - accuracy: 0.5617 - val_loss: 0.0836 - val_accuracy: 0.4700\n",
      "Epoch 32/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0821 - accuracy: 0.5617 - val_loss: 0.0832 - val_accuracy: 0.4800\n",
      "Epoch 33/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0817 - accuracy: 0.5600 - val_loss: 0.0828 - val_accuracy: 0.4700\n",
      "Epoch 34/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0812 - accuracy: 0.5567 - val_loss: 0.0824 - val_accuracy: 0.4700\n",
      "Epoch 35/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0806 - accuracy: 0.5567 - val_loss: 0.0820 - val_accuracy: 0.4600\n",
      "Epoch 36/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0801 - accuracy: 0.5583 - val_loss: 0.0816 - val_accuracy: 0.4600\n",
      "Epoch 37/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0795 - accuracy: 0.5583 - val_loss: 0.0811 - val_accuracy: 0.4600\n",
      "Epoch 38/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0789 - accuracy: 0.5600 - val_loss: 0.0806 - val_accuracy: 0.4600\n",
      "Epoch 39/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0783 - accuracy: 0.5617 - val_loss: 0.0801 - val_accuracy: 0.4500\n",
      "Epoch 40/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0776 - accuracy: 0.5583 - val_loss: 0.0796 - val_accuracy: 0.4500\n",
      "Epoch 41/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0769 - accuracy: 0.5600 - val_loss: 0.0790 - val_accuracy: 0.4500\n",
      "Epoch 42/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0762 - accuracy: 0.5617 - val_loss: 0.0785 - val_accuracy: 0.4500\n",
      "Epoch 43/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0755 - accuracy: 0.5617 - val_loss: 0.0779 - val_accuracy: 0.4500\n",
      "Epoch 44/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0748 - accuracy: 0.5617 - val_loss: 0.0773 - val_accuracy: 0.4500\n",
      "Epoch 45/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0740 - accuracy: 0.5650 - val_loss: 0.0767 - val_accuracy: 0.4600\n",
      "Epoch 46/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0732 - accuracy: 0.5683 - val_loss: 0.0761 - val_accuracy: 0.4600\n",
      "Epoch 47/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0724 - accuracy: 0.5683 - val_loss: 0.0755 - val_accuracy: 0.4700\n",
      "Epoch 48/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0716 - accuracy: 0.5700 - val_loss: 0.0749 - val_accuracy: 0.4700\n",
      "Epoch 49/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0708 - accuracy: 0.5767 - val_loss: 0.0743 - val_accuracy: 0.4900\n",
      "Epoch 50/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0699 - accuracy: 0.5733 - val_loss: 0.0736 - val_accuracy: 0.4900\n",
      "Epoch 51/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0691 - accuracy: 0.5767 - val_loss: 0.0730 - val_accuracy: 0.5000\n",
      "Epoch 52/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0682 - accuracy: 0.5800 - val_loss: 0.0723 - val_accuracy: 0.5000\n",
      "Epoch 53/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0674 - accuracy: 0.5833 - val_loss: 0.0716 - val_accuracy: 0.5000\n",
      "Epoch 54/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0665 - accuracy: 0.5883 - val_loss: 0.0710 - val_accuracy: 0.5200\n",
      "Epoch 55/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0656 - accuracy: 0.5917 - val_loss: 0.0703 - val_accuracy: 0.5300\n",
      "Epoch 56/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0648 - accuracy: 0.6033 - val_loss: 0.0696 - val_accuracy: 0.5400\n",
      "Epoch 57/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0639 - accuracy: 0.6067 - val_loss: 0.0690 - val_accuracy: 0.5400\n",
      "Epoch 58/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0630 - accuracy: 0.6067 - val_loss: 0.0683 - val_accuracy: 0.5500\n",
      "Epoch 59/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0622 - accuracy: 0.6117 - val_loss: 0.0677 - val_accuracy: 0.5600\n",
      "Epoch 60/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0613 - accuracy: 0.6150 - val_loss: 0.0670 - val_accuracy: 0.5700\n",
      "Epoch 61/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0605 - accuracy: 0.6233 - val_loss: 0.0663 - val_accuracy: 0.5800\n",
      "Epoch 62/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0597 - accuracy: 0.6267 - val_loss: 0.0657 - val_accuracy: 0.5800\n",
      "Epoch 63/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0588 - accuracy: 0.6317 - val_loss: 0.0651 - val_accuracy: 0.5800\n",
      "Epoch 64/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0580 - accuracy: 0.6350 - val_loss: 0.0644 - val_accuracy: 0.5900\n",
      "Epoch 65/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0572 - accuracy: 0.6400 - val_loss: 0.0638 - val_accuracy: 0.6000\n",
      "Epoch 66/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0564 - accuracy: 0.6450 - val_loss: 0.0632 - val_accuracy: 0.6100\n",
      "Epoch 67/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0556 - accuracy: 0.6467 - val_loss: 0.0625 - val_accuracy: 0.6100\n",
      "Epoch 68/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0549 - accuracy: 0.6483 - val_loss: 0.0619 - val_accuracy: 0.6200\n",
      "Epoch 69/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0541 - accuracy: 0.6467 - val_loss: 0.0613 - val_accuracy: 0.6300\n",
      "Epoch 70/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0533 - accuracy: 0.6483 - val_loss: 0.0607 - val_accuracy: 0.6300\n",
      "Epoch 71/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0526 - accuracy: 0.6500 - val_loss: 0.0602 - val_accuracy: 0.6300\n",
      "Epoch 72/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0518 - accuracy: 0.6500 - val_loss: 0.0596 - val_accuracy: 0.6300\n",
      "Epoch 73/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0511 - accuracy: 0.6533 - val_loss: 0.0590 - val_accuracy: 0.6300\n",
      "Epoch 74/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0504 - accuracy: 0.6567 - val_loss: 0.0585 - val_accuracy: 0.6300\n",
      "Epoch 75/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0497 - accuracy: 0.6600 - val_loss: 0.0580 - val_accuracy: 0.6400\n",
      "Epoch 76/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0490 - accuracy: 0.6583 - val_loss: 0.0575 - val_accuracy: 0.6500\n",
      "Epoch 77/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0483 - accuracy: 0.6650 - val_loss: 0.0570 - val_accuracy: 0.6500\n",
      "Epoch 78/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0476 - accuracy: 0.6867 - val_loss: 0.0565 - val_accuracy: 0.6600\n",
      "Epoch 79/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0469 - accuracy: 0.7017 - val_loss: 0.0561 - val_accuracy: 0.6600\n",
      "Epoch 80/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0462 - accuracy: 0.7150 - val_loss: 0.0556 - val_accuracy: 0.6600\n",
      "Epoch 81/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0455 - accuracy: 0.7200 - val_loss: 0.0551 - val_accuracy: 0.6700\n",
      "Epoch 82/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0448 - accuracy: 0.7250 - val_loss: 0.0547 - val_accuracy: 0.6700\n",
      "Epoch 83/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0442 - accuracy: 0.7350 - val_loss: 0.0543 - val_accuracy: 0.6700\n",
      "Epoch 84/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0435 - accuracy: 0.7433 - val_loss: 0.0539 - val_accuracy: 0.6700\n",
      "Epoch 85/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0429 - accuracy: 0.7467 - val_loss: 0.0535 - val_accuracy: 0.6700\n",
      "Epoch 86/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0422 - accuracy: 0.7533 - val_loss: 0.0531 - val_accuracy: 0.6700\n",
      "Epoch 87/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0416 - accuracy: 0.7600 - val_loss: 0.0527 - val_accuracy: 0.6700\n",
      "Epoch 88/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0410 - accuracy: 0.7683 - val_loss: 0.0523 - val_accuracy: 0.6700\n",
      "Epoch 89/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0404 - accuracy: 0.7700 - val_loss: 0.0519 - val_accuracy: 0.6800\n",
      "Epoch 90/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0397 - accuracy: 0.7700 - val_loss: 0.0515 - val_accuracy: 0.6800\n",
      "Epoch 91/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0392 - accuracy: 0.7850 - val_loss: 0.0512 - val_accuracy: 0.6900\n",
      "Epoch 92/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0386 - accuracy: 0.7900 - val_loss: 0.0508 - val_accuracy: 0.6900\n",
      "Epoch 93/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0380 - accuracy: 0.7900 - val_loss: 0.0504 - val_accuracy: 0.6900\n",
      "Epoch 94/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0375 - accuracy: 0.7933 - val_loss: 0.0501 - val_accuracy: 0.6900\n",
      "Epoch 95/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0369 - accuracy: 0.7967 - val_loss: 0.0497 - val_accuracy: 0.7000\n",
      "Epoch 96/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0364 - accuracy: 0.8000 - val_loss: 0.0494 - val_accuracy: 0.6900\n",
      "Epoch 97/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0359 - accuracy: 0.7983 - val_loss: 0.0491 - val_accuracy: 0.6900\n",
      "Epoch 98/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0354 - accuracy: 0.8033 - val_loss: 0.0487 - val_accuracy: 0.6900\n",
      "Epoch 99/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0349 - accuracy: 0.8050 - val_loss: 0.0483 - val_accuracy: 0.6900\n",
      "Epoch 100/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0344 - accuracy: 0.8017 - val_loss: 0.0480 - val_accuracy: 0.7000\n",
      "Epoch 101/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0339 - accuracy: 0.8017 - val_loss: 0.0476 - val_accuracy: 0.6900\n",
      "Epoch 102/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0335 - accuracy: 0.8033 - val_loss: 0.0474 - val_accuracy: 0.6900\n",
      "Epoch 103/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0330 - accuracy: 0.8083 - val_loss: 0.0471 - val_accuracy: 0.6900\n",
      "Epoch 104/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0326 - accuracy: 0.8117 - val_loss: 0.0467 - val_accuracy: 0.6900\n",
      "Epoch 105/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0322 - accuracy: 0.8133 - val_loss: 0.0464 - val_accuracy: 0.6900\n",
      "Epoch 106/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0318 - accuracy: 0.8217 - val_loss: 0.0461 - val_accuracy: 0.6900\n",
      "Epoch 107/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0314 - accuracy: 0.8250 - val_loss: 0.0458 - val_accuracy: 0.6900\n",
      "Epoch 108/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0309 - accuracy: 0.8267 - val_loss: 0.0454 - val_accuracy: 0.6900\n",
      "Epoch 109/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0305 - accuracy: 0.8350 - val_loss: 0.0452 - val_accuracy: 0.6900\n",
      "Epoch 110/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0301 - accuracy: 0.8367 - val_loss: 0.0448 - val_accuracy: 0.6900\n",
      "Epoch 111/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0298 - accuracy: 0.8333 - val_loss: 0.0445 - val_accuracy: 0.6900\n",
      "Epoch 112/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0294 - accuracy: 0.8433 - val_loss: 0.0441 - val_accuracy: 0.6900\n",
      "Epoch 113/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0290 - accuracy: 0.8417 - val_loss: 0.0439 - val_accuracy: 0.6900\n",
      "Epoch 114/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0286 - accuracy: 0.8500 - val_loss: 0.0436 - val_accuracy: 0.6900\n",
      "Epoch 115/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0283 - accuracy: 0.8517 - val_loss: 0.0433 - val_accuracy: 0.6900\n",
      "Epoch 116/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0279 - accuracy: 0.8567 - val_loss: 0.0430 - val_accuracy: 0.6900\n",
      "Epoch 117/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0276 - accuracy: 0.8533 - val_loss: 0.0428 - val_accuracy: 0.7000\n",
      "Epoch 118/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0273 - accuracy: 0.8583 - val_loss: 0.0425 - val_accuracy: 0.7000\n",
      "Epoch 119/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0269 - accuracy: 0.8617 - val_loss: 0.0422 - val_accuracy: 0.7000\n",
      "Epoch 120/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0266 - accuracy: 0.8667 - val_loss: 0.0419 - val_accuracy: 0.7000\n",
      "Epoch 121/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0263 - accuracy: 0.8700 - val_loss: 0.0416 - val_accuracy: 0.7000\n",
      "Epoch 122/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0260 - accuracy: 0.8717 - val_loss: 0.0414 - val_accuracy: 0.7100\n",
      "Epoch 123/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0257 - accuracy: 0.8750 - val_loss: 0.0411 - val_accuracy: 0.7100\n",
      "Epoch 124/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0253 - accuracy: 0.8767 - val_loss: 0.0409 - val_accuracy: 0.7100\n",
      "Epoch 125/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0251 - accuracy: 0.8783 - val_loss: 0.0407 - val_accuracy: 0.7100\n",
      "Epoch 126/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0248 - accuracy: 0.8767 - val_loss: 0.0404 - val_accuracy: 0.7100\n",
      "Epoch 127/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0245 - accuracy: 0.8800 - val_loss: 0.0402 - val_accuracy: 0.7100\n",
      "Epoch 128/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0242 - accuracy: 0.8800 - val_loss: 0.0400 - val_accuracy: 0.7200\n",
      "Epoch 129/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0239 - accuracy: 0.8800 - val_loss: 0.0397 - val_accuracy: 0.7200\n",
      "Epoch 130/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0236 - accuracy: 0.8783 - val_loss: 0.0395 - val_accuracy: 0.7200\n",
      "Epoch 131/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0234 - accuracy: 0.8783 - val_loss: 0.0392 - val_accuracy: 0.7200\n",
      "Epoch 132/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0231 - accuracy: 0.8800 - val_loss: 0.0390 - val_accuracy: 0.7200\n",
      "Epoch 133/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0229 - accuracy: 0.8817 - val_loss: 0.0388 - val_accuracy: 0.7300\n",
      "Epoch 134/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0226 - accuracy: 0.8800 - val_loss: 0.0386 - val_accuracy: 0.7400\n",
      "Epoch 135/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0224 - accuracy: 0.8833 - val_loss: 0.0384 - val_accuracy: 0.7300\n",
      "Epoch 136/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0221 - accuracy: 0.8833 - val_loss: 0.0382 - val_accuracy: 0.7300\n",
      "Epoch 137/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0219 - accuracy: 0.8867 - val_loss: 0.0379 - val_accuracy: 0.7300\n",
      "Epoch 138/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0217 - accuracy: 0.8817 - val_loss: 0.0378 - val_accuracy: 0.7300\n",
      "Epoch 139/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0214 - accuracy: 0.8883 - val_loss: 0.0376 - val_accuracy: 0.7300\n",
      "Epoch 140/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0212 - accuracy: 0.8867 - val_loss: 0.0374 - val_accuracy: 0.7300\n",
      "Epoch 141/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0209 - accuracy: 0.8900 - val_loss: 0.0373 - val_accuracy: 0.7300\n",
      "Epoch 142/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0208 - accuracy: 0.8900 - val_loss: 0.0371 - val_accuracy: 0.7300\n",
      "Epoch 143/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0205 - accuracy: 0.8900 - val_loss: 0.0369 - val_accuracy: 0.7400\n",
      "Epoch 144/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0203 - accuracy: 0.8950 - val_loss: 0.0368 - val_accuracy: 0.7400\n",
      "Epoch 145/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0201 - accuracy: 0.8967 - val_loss: 0.0366 - val_accuracy: 0.7400\n",
      "Epoch 146/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0199 - accuracy: 0.8967 - val_loss: 0.0364 - val_accuracy: 0.7400\n",
      "Epoch 147/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0197 - accuracy: 0.8967 - val_loss: 0.0362 - val_accuracy: 0.7400\n",
      "Epoch 148/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0195 - accuracy: 0.9033 - val_loss: 0.0360 - val_accuracy: 0.7400\n",
      "Epoch 149/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0193 - accuracy: 0.9050 - val_loss: 0.0358 - val_accuracy: 0.7400\n",
      "Epoch 150/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0191 - accuracy: 0.9033 - val_loss: 0.0356 - val_accuracy: 0.7600\n",
      "Epoch 151/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0189 - accuracy: 0.9067 - val_loss: 0.0355 - val_accuracy: 0.7500\n",
      "Epoch 152/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0187 - accuracy: 0.9083 - val_loss: 0.0353 - val_accuracy: 0.7500\n",
      "Epoch 153/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0186 - accuracy: 0.9067 - val_loss: 0.0352 - val_accuracy: 0.7500\n",
      "Epoch 154/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0184 - accuracy: 0.9050 - val_loss: 0.0350 - val_accuracy: 0.7500\n",
      "Epoch 155/240\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0182 - accuracy: 0.9083 - val_loss: 0.0348 - val_accuracy: 0.7500\n",
      "Epoch 156/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0180 - accuracy: 0.9117 - val_loss: 0.0347 - val_accuracy: 0.7500\n",
      "Epoch 157/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0179 - accuracy: 0.9150 - val_loss: 0.0345 - val_accuracy: 0.7500\n",
      "Epoch 158/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0177 - accuracy: 0.9117 - val_loss: 0.0343 - val_accuracy: 0.7500\n",
      "Epoch 159/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0175 - accuracy: 0.9117 - val_loss: 0.0342 - val_accuracy: 0.7500\n",
      "Epoch 160/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0174 - accuracy: 0.9150 - val_loss: 0.0341 - val_accuracy: 0.7500\n",
      "Epoch 161/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0172 - accuracy: 0.9167 - val_loss: 0.0340 - val_accuracy: 0.7600\n",
      "Epoch 162/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0170 - accuracy: 0.9200 - val_loss: 0.0338 - val_accuracy: 0.7600\n",
      "Epoch 163/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0169 - accuracy: 0.9183 - val_loss: 0.0337 - val_accuracy: 0.7600\n",
      "Epoch 164/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0167 - accuracy: 0.9183 - val_loss: 0.0336 - val_accuracy: 0.7700\n",
      "Epoch 165/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0166 - accuracy: 0.9200 - val_loss: 0.0335 - val_accuracy: 0.7700\n",
      "Epoch 166/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0164 - accuracy: 0.9217 - val_loss: 0.0333 - val_accuracy: 0.7700\n",
      "Epoch 167/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0163 - accuracy: 0.9233 - val_loss: 0.0331 - val_accuracy: 0.7700\n",
      "Epoch 168/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0161 - accuracy: 0.9267 - val_loss: 0.0330 - val_accuracy: 0.7700\n",
      "Epoch 169/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0160 - accuracy: 0.9267 - val_loss: 0.0330 - val_accuracy: 0.7700\n",
      "Epoch 170/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0158 - accuracy: 0.9267 - val_loss: 0.0328 - val_accuracy: 0.7700\n",
      "Epoch 171/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0157 - accuracy: 0.9300 - val_loss: 0.0327 - val_accuracy: 0.7700\n",
      "Epoch 172/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0156 - accuracy: 0.9267 - val_loss: 0.0326 - val_accuracy: 0.7700\n",
      "Epoch 173/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0154 - accuracy: 0.9283 - val_loss: 0.0324 - val_accuracy: 0.7700\n",
      "Epoch 174/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0153 - accuracy: 0.9250 - val_loss: 0.0323 - val_accuracy: 0.7700\n",
      "Epoch 175/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0152 - accuracy: 0.9300 - val_loss: 0.0322 - val_accuracy: 0.7800\n",
      "Epoch 176/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0150 - accuracy: 0.9283 - val_loss: 0.0321 - val_accuracy: 0.7800\n",
      "Epoch 177/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0149 - accuracy: 0.9300 - val_loss: 0.0320 - val_accuracy: 0.7800\n",
      "Epoch 178/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0148 - accuracy: 0.9350 - val_loss: 0.0318 - val_accuracy: 0.7800\n",
      "Epoch 179/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0146 - accuracy: 0.9333 - val_loss: 0.0318 - val_accuracy: 0.7800\n",
      "Epoch 180/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0145 - accuracy: 0.9317 - val_loss: 0.0316 - val_accuracy: 0.7800\n",
      "Epoch 181/240\n",
      "600/600 [==============================] - 0s 113us/sample - loss: 0.0144 - accuracy: 0.9300 - val_loss: 0.0315 - val_accuracy: 0.7800\n",
      "Epoch 182/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0143 - accuracy: 0.9300 - val_loss: 0.0315 - val_accuracy: 0.7800\n",
      "Epoch 183/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0142 - accuracy: 0.9333 - val_loss: 0.0314 - val_accuracy: 0.7800\n",
      "Epoch 184/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0140 - accuracy: 0.9317 - val_loss: 0.0313 - val_accuracy: 0.7800\n",
      "Epoch 185/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0139 - accuracy: 0.9333 - val_loss: 0.0312 - val_accuracy: 0.7800\n",
      "Epoch 186/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0138 - accuracy: 0.9350 - val_loss: 0.0312 - val_accuracy: 0.7800\n",
      "Epoch 187/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0137 - accuracy: 0.9350 - val_loss: 0.0311 - val_accuracy: 0.7800\n",
      "Epoch 188/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0136 - accuracy: 0.9350 - val_loss: 0.0310 - val_accuracy: 0.7800\n",
      "Epoch 189/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0135 - accuracy: 0.9383 - val_loss: 0.0309 - val_accuracy: 0.7800\n",
      "Epoch 190/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0134 - accuracy: 0.9383 - val_loss: 0.0308 - val_accuracy: 0.7800\n",
      "Epoch 191/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0133 - accuracy: 0.9383 - val_loss: 0.0306 - val_accuracy: 0.7800\n",
      "Epoch 192/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0131 - accuracy: 0.9400 - val_loss: 0.0306 - val_accuracy: 0.7800\n",
      "Epoch 193/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0130 - accuracy: 0.9383 - val_loss: 0.0305 - val_accuracy: 0.7800\n",
      "Epoch 194/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0129 - accuracy: 0.9383 - val_loss: 0.0304 - val_accuracy: 0.7800\n",
      "Epoch 195/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0128 - accuracy: 0.9417 - val_loss: 0.0303 - val_accuracy: 0.7800\n",
      "Epoch 196/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0127 - accuracy: 0.9433 - val_loss: 0.0302 - val_accuracy: 0.7800\n",
      "Epoch 197/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0126 - accuracy: 0.9417 - val_loss: 0.0302 - val_accuracy: 0.7900\n",
      "Epoch 198/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0125 - accuracy: 0.9433 - val_loss: 0.0301 - val_accuracy: 0.7900\n",
      "Epoch 199/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0124 - accuracy: 0.9450 - val_loss: 0.0300 - val_accuracy: 0.7900\n",
      "Epoch 200/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0123 - accuracy: 0.9450 - val_loss: 0.0299 - val_accuracy: 0.8000\n",
      "Epoch 201/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0122 - accuracy: 0.9433 - val_loss: 0.0299 - val_accuracy: 0.7900\n",
      "Epoch 202/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0121 - accuracy: 0.9450 - val_loss: 0.0298 - val_accuracy: 0.7900\n",
      "Epoch 203/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0121 - accuracy: 0.9433 - val_loss: 0.0297 - val_accuracy: 0.7900\n",
      "Epoch 204/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0119 - accuracy: 0.9467 - val_loss: 0.0296 - val_accuracy: 0.8000\n",
      "Epoch 205/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0118 - accuracy: 0.9467 - val_loss: 0.0296 - val_accuracy: 0.7900\n",
      "Epoch 206/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0118 - accuracy: 0.9467 - val_loss: 0.0295 - val_accuracy: 0.8000\n",
      "Epoch 207/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0117 - accuracy: 0.9467 - val_loss: 0.0294 - val_accuracy: 0.8000\n",
      "Epoch 208/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0116 - accuracy: 0.9483 - val_loss: 0.0294 - val_accuracy: 0.8000\n",
      "Epoch 209/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0115 - accuracy: 0.9483 - val_loss: 0.0293 - val_accuracy: 0.7900\n",
      "Epoch 210/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0114 - accuracy: 0.9483 - val_loss: 0.0293 - val_accuracy: 0.7900\n",
      "Epoch 211/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0113 - accuracy: 0.9483 - val_loss: 0.0292 - val_accuracy: 0.7900\n",
      "Epoch 212/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0112 - accuracy: 0.9500 - val_loss: 0.0291 - val_accuracy: 0.7900\n",
      "Epoch 213/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0111 - accuracy: 0.9533 - val_loss: 0.0291 - val_accuracy: 0.7900\n",
      "Epoch 214/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0111 - accuracy: 0.9500 - val_loss: 0.0291 - val_accuracy: 0.7900\n",
      "Epoch 215/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0110 - accuracy: 0.9517 - val_loss: 0.0290 - val_accuracy: 0.7900\n",
      "Epoch 216/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0109 - accuracy: 0.9533 - val_loss: 0.0289 - val_accuracy: 0.7900\n",
      "Epoch 217/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0108 - accuracy: 0.9517 - val_loss: 0.0289 - val_accuracy: 0.7900\n",
      "Epoch 218/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0107 - accuracy: 0.9550 - val_loss: 0.0289 - val_accuracy: 0.7900\n",
      "Epoch 219/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0107 - accuracy: 0.9550 - val_loss: 0.0288 - val_accuracy: 0.7900\n",
      "Epoch 220/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0106 - accuracy: 0.9550 - val_loss: 0.0288 - val_accuracy: 0.7900\n",
      "Epoch 221/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0105 - accuracy: 0.9583 - val_loss: 0.0287 - val_accuracy: 0.7900\n",
      "Epoch 222/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0104 - accuracy: 0.9550 - val_loss: 0.0286 - val_accuracy: 0.7900\n",
      "Epoch 223/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0103 - accuracy: 0.9583 - val_loss: 0.0286 - val_accuracy: 0.7900\n",
      "Epoch 224/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0103 - accuracy: 0.9567 - val_loss: 0.0284 - val_accuracy: 0.8000\n",
      "Epoch 225/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0102 - accuracy: 0.9583 - val_loss: 0.0284 - val_accuracy: 0.8000\n",
      "Epoch 226/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0101 - accuracy: 0.9583 - val_loss: 0.0284 - val_accuracy: 0.8000\n",
      "Epoch 227/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0101 - accuracy: 0.9583 - val_loss: 0.0284 - val_accuracy: 0.8000\n",
      "Epoch 228/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0100 - accuracy: 0.9583 - val_loss: 0.0283 - val_accuracy: 0.8000\n",
      "Epoch 229/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0099 - accuracy: 0.9583 - val_loss: 0.0283 - val_accuracy: 0.8000\n",
      "Epoch 230/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0098 - accuracy: 0.9583 - val_loss: 0.0282 - val_accuracy: 0.8000\n",
      "Epoch 231/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0098 - accuracy: 0.9583 - val_loss: 0.0282 - val_accuracy: 0.8000\n",
      "Epoch 232/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0097 - accuracy: 0.9583 - val_loss: 0.0282 - val_accuracy: 0.8000\n",
      "Epoch 233/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0096 - accuracy: 0.9583 - val_loss: 0.0281 - val_accuracy: 0.8000\n",
      "Epoch 234/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0096 - accuracy: 0.9583 - val_loss: 0.0281 - val_accuracy: 0.8000\n",
      "Epoch 235/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0095 - accuracy: 0.9583 - val_loss: 0.0280 - val_accuracy: 0.8000\n",
      "Epoch 236/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0094 - accuracy: 0.9583 - val_loss: 0.0280 - val_accuracy: 0.8000\n",
      "Epoch 237/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0094 - accuracy: 0.9583 - val_loss: 0.0280 - val_accuracy: 0.8000\n",
      "Epoch 238/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0093 - accuracy: 0.9583 - val_loss: 0.0279 - val_accuracy: 0.8000\n",
      "Epoch 239/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0092 - accuracy: 0.9583 - val_loss: 0.0279 - val_accuracy: 0.8000\n",
      "Epoch 240/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0092 - accuracy: 0.9600 - val_loss: 0.0279 - val_accuracy: 0.8000\n",
      "Training date and time : \n",
      "2020-04-09 21:03:13\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/240\n",
      "600/600 [==============================] - 0s 656us/sample - loss: 0.0899 - accuracy: 0.1233 - val_loss: 0.0896 - val_accuracy: 0.1600\n",
      "Epoch 2/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0898 - accuracy: 0.1317 - val_loss: 0.0895 - val_accuracy: 0.1800\n",
      "Epoch 3/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0896 - accuracy: 0.1433 - val_loss: 0.0894 - val_accuracy: 0.1900\n",
      "Epoch 4/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0895 - accuracy: 0.1500 - val_loss: 0.0893 - val_accuracy: 0.2200\n",
      "Epoch 5/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0893 - accuracy: 0.1717 - val_loss: 0.0891 - val_accuracy: 0.2200\n",
      "Epoch 6/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0892 - accuracy: 0.1850 - val_loss: 0.0890 - val_accuracy: 0.2300\n",
      "Epoch 7/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0890 - accuracy: 0.2100 - val_loss: 0.0889 - val_accuracy: 0.2300\n",
      "Epoch 8/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0889 - accuracy: 0.2400 - val_loss: 0.0888 - val_accuracy: 0.2600\n",
      "Epoch 9/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0887 - accuracy: 0.2567 - val_loss: 0.0887 - val_accuracy: 0.2700\n",
      "Epoch 10/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0886 - accuracy: 0.2683 - val_loss: 0.0885 - val_accuracy: 0.3000\n",
      "Epoch 11/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0884 - accuracy: 0.2950 - val_loss: 0.0884 - val_accuracy: 0.3000\n",
      "Epoch 12/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0882 - accuracy: 0.3133 - val_loss: 0.0883 - val_accuracy: 0.3100\n",
      "Epoch 13/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0881 - accuracy: 0.3417 - val_loss: 0.0881 - val_accuracy: 0.3200\n",
      "Epoch 14/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0879 - accuracy: 0.3583 - val_loss: 0.0880 - val_accuracy: 0.3400\n",
      "Epoch 15/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0877 - accuracy: 0.3783 - val_loss: 0.0879 - val_accuracy: 0.3500\n",
      "Epoch 16/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0876 - accuracy: 0.3917 - val_loss: 0.0877 - val_accuracy: 0.3600\n",
      "Epoch 17/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0874 - accuracy: 0.4167 - val_loss: 0.0876 - val_accuracy: 0.3800\n",
      "Epoch 18/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0872 - accuracy: 0.4300 - val_loss: 0.0874 - val_accuracy: 0.4000\n",
      "Epoch 19/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0870 - accuracy: 0.4467 - val_loss: 0.0872 - val_accuracy: 0.4000\n",
      "Epoch 20/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0868 - accuracy: 0.4550 - val_loss: 0.0871 - val_accuracy: 0.4000\n",
      "Epoch 21/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0866 - accuracy: 0.4617 - val_loss: 0.0869 - val_accuracy: 0.4200\n",
      "Epoch 22/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0864 - accuracy: 0.4767 - val_loss: 0.0867 - val_accuracy: 0.4200\n",
      "Epoch 23/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0861 - accuracy: 0.4850 - val_loss: 0.0865 - val_accuracy: 0.4400\n",
      "Epoch 24/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0859 - accuracy: 0.4967 - val_loss: 0.0864 - val_accuracy: 0.4400\n",
      "Epoch 25/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0856 - accuracy: 0.5083 - val_loss: 0.0861 - val_accuracy: 0.4500\n",
      "Epoch 26/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0854 - accuracy: 0.5183 - val_loss: 0.0859 - val_accuracy: 0.4500\n",
      "Epoch 27/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0851 - accuracy: 0.5200 - val_loss: 0.0857 - val_accuracy: 0.4500\n",
      "Epoch 28/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0848 - accuracy: 0.5283 - val_loss: 0.0855 - val_accuracy: 0.4600\n",
      "Epoch 29/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0845 - accuracy: 0.5350 - val_loss: 0.0852 - val_accuracy: 0.4700\n",
      "Epoch 30/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0842 - accuracy: 0.5383 - val_loss: 0.0850 - val_accuracy: 0.4700\n",
      "Epoch 31/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0839 - accuracy: 0.5417 - val_loss: 0.0847 - val_accuracy: 0.4700\n",
      "Epoch 32/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0836 - accuracy: 0.5467 - val_loss: 0.0844 - val_accuracy: 0.4600\n",
      "Epoch 33/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0832 - accuracy: 0.5483 - val_loss: 0.0841 - val_accuracy: 0.4600\n",
      "Epoch 34/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0828 - accuracy: 0.5483 - val_loss: 0.0838 - val_accuracy: 0.4600\n",
      "Epoch 35/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0824 - accuracy: 0.5500 - val_loss: 0.0835 - val_accuracy: 0.4700\n",
      "Epoch 36/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0820 - accuracy: 0.5517 - val_loss: 0.0831 - val_accuracy: 0.4700\n",
      "Epoch 37/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0815 - accuracy: 0.5500 - val_loss: 0.0827 - val_accuracy: 0.4700\n",
      "Epoch 38/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0811 - accuracy: 0.5500 - val_loss: 0.0824 - val_accuracy: 0.4700\n",
      "Epoch 39/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0806 - accuracy: 0.5517 - val_loss: 0.0820 - val_accuracy: 0.4700\n",
      "Epoch 40/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0801 - accuracy: 0.5483 - val_loss: 0.0815 - val_accuracy: 0.4600\n",
      "Epoch 41/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0795 - accuracy: 0.5417 - val_loss: 0.0811 - val_accuracy: 0.4500\n",
      "Epoch 42/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0790 - accuracy: 0.5417 - val_loss: 0.0806 - val_accuracy: 0.4500\n",
      "Epoch 43/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0784 - accuracy: 0.5417 - val_loss: 0.0802 - val_accuracy: 0.4500\n",
      "Epoch 44/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0778 - accuracy: 0.5383 - val_loss: 0.0797 - val_accuracy: 0.4500\n",
      "Epoch 45/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0772 - accuracy: 0.5450 - val_loss: 0.0792 - val_accuracy: 0.4500\n",
      "Epoch 46/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0765 - accuracy: 0.5400 - val_loss: 0.0787 - val_accuracy: 0.4500\n",
      "Epoch 47/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0758 - accuracy: 0.5417 - val_loss: 0.0781 - val_accuracy: 0.4500\n",
      "Epoch 48/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0751 - accuracy: 0.5450 - val_loss: 0.0776 - val_accuracy: 0.4600\n",
      "Epoch 49/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0744 - accuracy: 0.5467 - val_loss: 0.0770 - val_accuracy: 0.4600\n",
      "Epoch 50/240\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0737 - accuracy: 0.5483 - val_loss: 0.0765 - val_accuracy: 0.4600\n",
      "Epoch 51/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0729 - accuracy: 0.5500 - val_loss: 0.0759 - val_accuracy: 0.4600\n",
      "Epoch 52/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0722 - accuracy: 0.5533 - val_loss: 0.0753 - val_accuracy: 0.4700\n",
      "Epoch 53/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0714 - accuracy: 0.5600 - val_loss: 0.0747 - val_accuracy: 0.4700\n",
      "Epoch 54/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0706 - accuracy: 0.5617 - val_loss: 0.0741 - val_accuracy: 0.4800\n",
      "Epoch 55/240\n",
      "600/600 [==============================] - 0s 118us/sample - loss: 0.0698 - accuracy: 0.5617 - val_loss: 0.0735 - val_accuracy: 0.4800\n",
      "Epoch 56/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0690 - accuracy: 0.5700 - val_loss: 0.0729 - val_accuracy: 0.4800\n",
      "Epoch 57/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0682 - accuracy: 0.5767 - val_loss: 0.0722 - val_accuracy: 0.4800\n",
      "Epoch 58/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0674 - accuracy: 0.5800 - val_loss: 0.0716 - val_accuracy: 0.5000\n",
      "Epoch 59/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0665 - accuracy: 0.5867 - val_loss: 0.0710 - val_accuracy: 0.5200\n",
      "Epoch 60/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0657 - accuracy: 0.5900 - val_loss: 0.0703 - val_accuracy: 0.5200\n",
      "Epoch 61/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0649 - accuracy: 0.5900 - val_loss: 0.0697 - val_accuracy: 0.5300\n",
      "Epoch 62/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0641 - accuracy: 0.5917 - val_loss: 0.0691 - val_accuracy: 0.5400\n",
      "Epoch 63/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0632 - accuracy: 0.5983 - val_loss: 0.0685 - val_accuracy: 0.5400\n",
      "Epoch 64/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0624 - accuracy: 0.6067 - val_loss: 0.0678 - val_accuracy: 0.5600\n",
      "Epoch 65/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0616 - accuracy: 0.6150 - val_loss: 0.0672 - val_accuracy: 0.5700\n",
      "Epoch 66/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0608 - accuracy: 0.6217 - val_loss: 0.0666 - val_accuracy: 0.5800\n",
      "Epoch 67/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0600 - accuracy: 0.6317 - val_loss: 0.0659 - val_accuracy: 0.5900\n",
      "Epoch 68/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0592 - accuracy: 0.6383 - val_loss: 0.0653 - val_accuracy: 0.5900\n",
      "Epoch 69/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0584 - accuracy: 0.6367 - val_loss: 0.0647 - val_accuracy: 0.6100\n",
      "Epoch 70/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0576 - accuracy: 0.6417 - val_loss: 0.0641 - val_accuracy: 0.6200\n",
      "Epoch 71/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0568 - accuracy: 0.6467 - val_loss: 0.0634 - val_accuracy: 0.6200\n",
      "Epoch 72/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0560 - accuracy: 0.6450 - val_loss: 0.0628 - val_accuracy: 0.6300\n",
      "Epoch 73/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0553 - accuracy: 0.6450 - val_loss: 0.0622 - val_accuracy: 0.6300\n",
      "Epoch 74/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0545 - accuracy: 0.6500 - val_loss: 0.0616 - val_accuracy: 0.6300\n",
      "Epoch 75/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0537 - accuracy: 0.6500 - val_loss: 0.0610 - val_accuracy: 0.6300\n",
      "Epoch 76/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0530 - accuracy: 0.6517 - val_loss: 0.0604 - val_accuracy: 0.6300\n",
      "Epoch 77/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0523 - accuracy: 0.6500 - val_loss: 0.0599 - val_accuracy: 0.6400\n",
      "Epoch 78/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0515 - accuracy: 0.6517 - val_loss: 0.0593 - val_accuracy: 0.6400\n",
      "Epoch 79/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0508 - accuracy: 0.6583 - val_loss: 0.0588 - val_accuracy: 0.6400\n",
      "Epoch 80/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0501 - accuracy: 0.6617 - val_loss: 0.0582 - val_accuracy: 0.6500\n",
      "Epoch 81/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0494 - accuracy: 0.6717 - val_loss: 0.0577 - val_accuracy: 0.6500\n",
      "Epoch 82/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0487 - accuracy: 0.6800 - val_loss: 0.0572 - val_accuracy: 0.6500\n",
      "Epoch 83/240\n",
      "600/600 [==============================] - 0s 114us/sample - loss: 0.0480 - accuracy: 0.6867 - val_loss: 0.0567 - val_accuracy: 0.6500\n",
      "Epoch 84/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0473 - accuracy: 0.7033 - val_loss: 0.0563 - val_accuracy: 0.6500\n",
      "Epoch 85/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0466 - accuracy: 0.7050 - val_loss: 0.0558 - val_accuracy: 0.6600\n",
      "Epoch 86/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0460 - accuracy: 0.7150 - val_loss: 0.0553 - val_accuracy: 0.6600\n",
      "Epoch 87/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0453 - accuracy: 0.7233 - val_loss: 0.0549 - val_accuracy: 0.6600\n",
      "Epoch 88/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0447 - accuracy: 0.7317 - val_loss: 0.0545 - val_accuracy: 0.6700\n",
      "Epoch 89/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0441 - accuracy: 0.7367 - val_loss: 0.0541 - val_accuracy: 0.6700\n",
      "Epoch 90/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0434 - accuracy: 0.7367 - val_loss: 0.0536 - val_accuracy: 0.6700\n",
      "Epoch 91/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0428 - accuracy: 0.7467 - val_loss: 0.0533 - val_accuracy: 0.6700\n",
      "Epoch 92/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0422 - accuracy: 0.7533 - val_loss: 0.0529 - val_accuracy: 0.6700\n",
      "Epoch 93/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0416 - accuracy: 0.7650 - val_loss: 0.0525 - val_accuracy: 0.6700\n",
      "Epoch 94/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0410 - accuracy: 0.7700 - val_loss: 0.0521 - val_accuracy: 0.6900\n",
      "Epoch 95/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0404 - accuracy: 0.7750 - val_loss: 0.0517 - val_accuracy: 0.6900\n",
      "Epoch 96/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0398 - accuracy: 0.7767 - val_loss: 0.0514 - val_accuracy: 0.6900\n",
      "Epoch 97/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0392 - accuracy: 0.7817 - val_loss: 0.0510 - val_accuracy: 0.6900\n",
      "Epoch 98/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0387 - accuracy: 0.7817 - val_loss: 0.0507 - val_accuracy: 0.6900\n",
      "Epoch 99/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0381 - accuracy: 0.7867 - val_loss: 0.0503 - val_accuracy: 0.6900\n",
      "Epoch 100/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0376 - accuracy: 0.7900 - val_loss: 0.0499 - val_accuracy: 0.6900\n",
      "Epoch 101/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0371 - accuracy: 0.7900 - val_loss: 0.0496 - val_accuracy: 0.6900\n",
      "Epoch 102/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0366 - accuracy: 0.7917 - val_loss: 0.0493 - val_accuracy: 0.6900\n",
      "Epoch 103/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0361 - accuracy: 0.7933 - val_loss: 0.0490 - val_accuracy: 0.7000\n",
      "Epoch 104/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0356 - accuracy: 0.7983 - val_loss: 0.0487 - val_accuracy: 0.7000\n",
      "Epoch 105/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0351 - accuracy: 0.7983 - val_loss: 0.0483 - val_accuracy: 0.7000\n",
      "Epoch 106/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0347 - accuracy: 0.8017 - val_loss: 0.0481 - val_accuracy: 0.6900\n",
      "Epoch 107/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0342 - accuracy: 0.8017 - val_loss: 0.0478 - val_accuracy: 0.6900\n",
      "Epoch 108/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0338 - accuracy: 0.8050 - val_loss: 0.0474 - val_accuracy: 0.6900\n",
      "Epoch 109/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0333 - accuracy: 0.8067 - val_loss: 0.0471 - val_accuracy: 0.6900\n",
      "Epoch 110/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0329 - accuracy: 0.8117 - val_loss: 0.0467 - val_accuracy: 0.7000\n",
      "Epoch 111/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0325 - accuracy: 0.8117 - val_loss: 0.0464 - val_accuracy: 0.6900\n",
      "Epoch 112/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0321 - accuracy: 0.8133 - val_loss: 0.0461 - val_accuracy: 0.6900\n",
      "Epoch 113/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0317 - accuracy: 0.8217 - val_loss: 0.0459 - val_accuracy: 0.6900\n",
      "Epoch 114/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0313 - accuracy: 0.8267 - val_loss: 0.0455 - val_accuracy: 0.6900\n",
      "Epoch 115/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0309 - accuracy: 0.8267 - val_loss: 0.0452 - val_accuracy: 0.6900\n",
      "Epoch 116/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0305 - accuracy: 0.8267 - val_loss: 0.0450 - val_accuracy: 0.6900\n",
      "Epoch 117/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0302 - accuracy: 0.8317 - val_loss: 0.0447 - val_accuracy: 0.6900\n",
      "Epoch 118/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0298 - accuracy: 0.8400 - val_loss: 0.0444 - val_accuracy: 0.7000\n",
      "Epoch 119/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0294 - accuracy: 0.8367 - val_loss: 0.0441 - val_accuracy: 0.7000\n",
      "Epoch 120/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0291 - accuracy: 0.8450 - val_loss: 0.0438 - val_accuracy: 0.7000\n",
      "Epoch 121/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0287 - accuracy: 0.8450 - val_loss: 0.0435 - val_accuracy: 0.7000\n",
      "Epoch 122/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0284 - accuracy: 0.8500 - val_loss: 0.0432 - val_accuracy: 0.7000\n",
      "Epoch 123/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0281 - accuracy: 0.8533 - val_loss: 0.0429 - val_accuracy: 0.7100\n",
      "Epoch 124/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0277 - accuracy: 0.8583 - val_loss: 0.0427 - val_accuracy: 0.7000\n",
      "Epoch 125/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0274 - accuracy: 0.8550 - val_loss: 0.0425 - val_accuracy: 0.7000\n",
      "Epoch 126/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0271 - accuracy: 0.8600 - val_loss: 0.0422 - val_accuracy: 0.7000\n",
      "Epoch 127/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0268 - accuracy: 0.8633 - val_loss: 0.0420 - val_accuracy: 0.7000\n",
      "Epoch 128/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0265 - accuracy: 0.8650 - val_loss: 0.0417 - val_accuracy: 0.7100\n",
      "Epoch 129/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0262 - accuracy: 0.8683 - val_loss: 0.0414 - val_accuracy: 0.7100\n",
      "Epoch 130/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0259 - accuracy: 0.8717 - val_loss: 0.0412 - val_accuracy: 0.7100\n",
      "Epoch 131/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0256 - accuracy: 0.8733 - val_loss: 0.0409 - val_accuracy: 0.7200\n",
      "Epoch 132/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0253 - accuracy: 0.8733 - val_loss: 0.0407 - val_accuracy: 0.7300\n",
      "Epoch 133/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0251 - accuracy: 0.8733 - val_loss: 0.0405 - val_accuracy: 0.7300\n",
      "Epoch 134/240\n",
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0248 - accuracy: 0.8750 - val_loss: 0.0403 - val_accuracy: 0.7300\n",
      "Epoch 135/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0245 - accuracy: 0.8767 - val_loss: 0.0401 - val_accuracy: 0.7300\n",
      "Epoch 136/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0242 - accuracy: 0.8783 - val_loss: 0.0399 - val_accuracy: 0.7200\n",
      "Epoch 137/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0240 - accuracy: 0.8767 - val_loss: 0.0396 - val_accuracy: 0.7300\n",
      "Epoch 138/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0237 - accuracy: 0.8767 - val_loss: 0.0394 - val_accuracy: 0.7300\n",
      "Epoch 139/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0235 - accuracy: 0.8767 - val_loss: 0.0392 - val_accuracy: 0.7300\n",
      "Epoch 140/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0232 - accuracy: 0.8767 - val_loss: 0.0390 - val_accuracy: 0.7200\n",
      "Epoch 141/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0230 - accuracy: 0.8767 - val_loss: 0.0388 - val_accuracy: 0.7300\n",
      "Epoch 142/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0227 - accuracy: 0.8783 - val_loss: 0.0387 - val_accuracy: 0.7200\n",
      "Epoch 143/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0225 - accuracy: 0.8783 - val_loss: 0.0385 - val_accuracy: 0.7400\n",
      "Epoch 144/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0223 - accuracy: 0.8833 - val_loss: 0.0383 - val_accuracy: 0.7400\n",
      "Epoch 145/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0220 - accuracy: 0.8817 - val_loss: 0.0381 - val_accuracy: 0.7400\n",
      "Epoch 146/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0218 - accuracy: 0.8867 - val_loss: 0.0379 - val_accuracy: 0.7400\n",
      "Epoch 147/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0216 - accuracy: 0.8883 - val_loss: 0.0377 - val_accuracy: 0.7400\n",
      "Epoch 148/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0214 - accuracy: 0.8883 - val_loss: 0.0375 - val_accuracy: 0.7400\n",
      "Epoch 149/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0212 - accuracy: 0.8917 - val_loss: 0.0373 - val_accuracy: 0.7400\n",
      "Epoch 150/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0210 - accuracy: 0.8933 - val_loss: 0.0371 - val_accuracy: 0.7500\n",
      "Epoch 151/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0207 - accuracy: 0.8933 - val_loss: 0.0369 - val_accuracy: 0.7500\n",
      "Epoch 152/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0205 - accuracy: 0.8933 - val_loss: 0.0368 - val_accuracy: 0.7500\n",
      "Epoch 153/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0203 - accuracy: 0.8933 - val_loss: 0.0367 - val_accuracy: 0.7600\n",
      "Epoch 154/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0201 - accuracy: 0.8933 - val_loss: 0.0365 - val_accuracy: 0.7500\n",
      "Epoch 155/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0199 - accuracy: 0.9017 - val_loss: 0.0363 - val_accuracy: 0.7600\n",
      "Epoch 156/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0198 - accuracy: 0.8983 - val_loss: 0.0361 - val_accuracy: 0.7500\n",
      "Epoch 157/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0196 - accuracy: 0.9000 - val_loss: 0.0360 - val_accuracy: 0.7500\n",
      "Epoch 158/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0194 - accuracy: 0.9000 - val_loss: 0.0357 - val_accuracy: 0.7600\n",
      "Epoch 159/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0192 - accuracy: 0.9017 - val_loss: 0.0356 - val_accuracy: 0.7500\n",
      "Epoch 160/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0190 - accuracy: 0.9050 - val_loss: 0.0355 - val_accuracy: 0.7500\n",
      "Epoch 161/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0188 - accuracy: 0.9017 - val_loss: 0.0354 - val_accuracy: 0.7500\n",
      "Epoch 162/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0186 - accuracy: 0.9067 - val_loss: 0.0352 - val_accuracy: 0.7500\n",
      "Epoch 163/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0185 - accuracy: 0.9067 - val_loss: 0.0350 - val_accuracy: 0.7500\n",
      "Epoch 164/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0183 - accuracy: 0.9083 - val_loss: 0.0350 - val_accuracy: 0.7600\n",
      "Epoch 165/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0181 - accuracy: 0.9117 - val_loss: 0.0348 - val_accuracy: 0.7500\n",
      "Epoch 166/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0180 - accuracy: 0.9133 - val_loss: 0.0346 - val_accuracy: 0.7600\n",
      "Epoch 167/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0178 - accuracy: 0.9150 - val_loss: 0.0345 - val_accuracy: 0.7600\n",
      "Epoch 168/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0176 - accuracy: 0.9150 - val_loss: 0.0344 - val_accuracy: 0.7700\n",
      "Epoch 169/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0175 - accuracy: 0.9167 - val_loss: 0.0343 - val_accuracy: 0.7700\n",
      "Epoch 170/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0173 - accuracy: 0.9150 - val_loss: 0.0342 - val_accuracy: 0.7700\n",
      "Epoch 171/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0172 - accuracy: 0.9150 - val_loss: 0.0340 - val_accuracy: 0.7700\n",
      "Epoch 172/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0170 - accuracy: 0.9183 - val_loss: 0.0339 - val_accuracy: 0.7700\n",
      "Epoch 173/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0169 - accuracy: 0.9183 - val_loss: 0.0337 - val_accuracy: 0.7700\n",
      "Epoch 174/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0168 - accuracy: 0.9200 - val_loss: 0.0336 - val_accuracy: 0.7700\n",
      "Epoch 175/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0166 - accuracy: 0.9150 - val_loss: 0.0335 - val_accuracy: 0.7700\n",
      "Epoch 176/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0164 - accuracy: 0.9200 - val_loss: 0.0334 - val_accuracy: 0.7700\n",
      "Epoch 177/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0163 - accuracy: 0.9217 - val_loss: 0.0333 - val_accuracy: 0.7700\n",
      "Epoch 178/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0162 - accuracy: 0.9200 - val_loss: 0.0331 - val_accuracy: 0.7700\n",
      "Epoch 179/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0160 - accuracy: 0.9233 - val_loss: 0.0330 - val_accuracy: 0.7700\n",
      "Epoch 180/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0159 - accuracy: 0.9233 - val_loss: 0.0328 - val_accuracy: 0.7700\n",
      "Epoch 181/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0158 - accuracy: 0.9233 - val_loss: 0.0327 - val_accuracy: 0.7700\n",
      "Epoch 182/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0156 - accuracy: 0.9250 - val_loss: 0.0327 - val_accuracy: 0.7800\n",
      "Epoch 183/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0155 - accuracy: 0.9267 - val_loss: 0.0325 - val_accuracy: 0.7800\n",
      "Epoch 184/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0154 - accuracy: 0.9250 - val_loss: 0.0324 - val_accuracy: 0.7800\n",
      "Epoch 185/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0152 - accuracy: 0.9250 - val_loss: 0.0324 - val_accuracy: 0.7800\n",
      "Epoch 186/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0151 - accuracy: 0.9267 - val_loss: 0.0324 - val_accuracy: 0.7800\n",
      "Epoch 187/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0150 - accuracy: 0.9300 - val_loss: 0.0322 - val_accuracy: 0.7800\n",
      "Epoch 188/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0149 - accuracy: 0.9300 - val_loss: 0.0322 - val_accuracy: 0.7800\n",
      "Epoch 189/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0148 - accuracy: 0.9300 - val_loss: 0.0321 - val_accuracy: 0.7800\n",
      "Epoch 190/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0146 - accuracy: 0.9350 - val_loss: 0.0320 - val_accuracy: 0.7800\n",
      "Epoch 191/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0145 - accuracy: 0.9300 - val_loss: 0.0318 - val_accuracy: 0.7800\n",
      "Epoch 192/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0144 - accuracy: 0.9333 - val_loss: 0.0317 - val_accuracy: 0.7800\n",
      "Epoch 193/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0143 - accuracy: 0.9350 - val_loss: 0.0317 - val_accuracy: 0.7800\n",
      "Epoch 194/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0142 - accuracy: 0.9300 - val_loss: 0.0315 - val_accuracy: 0.7800\n",
      "Epoch 195/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0140 - accuracy: 0.9350 - val_loss: 0.0314 - val_accuracy: 0.7800\n",
      "Epoch 196/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0139 - accuracy: 0.9333 - val_loss: 0.0313 - val_accuracy: 0.7800\n",
      "Epoch 197/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0138 - accuracy: 0.9350 - val_loss: 0.0313 - val_accuracy: 0.7800\n",
      "Epoch 198/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0137 - accuracy: 0.9367 - val_loss: 0.0312 - val_accuracy: 0.7800\n",
      "Epoch 199/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0136 - accuracy: 0.9350 - val_loss: 0.0311 - val_accuracy: 0.7800\n",
      "Epoch 200/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0135 - accuracy: 0.9350 - val_loss: 0.0310 - val_accuracy: 0.7800\n",
      "Epoch 201/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0134 - accuracy: 0.9367 - val_loss: 0.0309 - val_accuracy: 0.7800\n",
      "Epoch 202/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0133 - accuracy: 0.9383 - val_loss: 0.0308 - val_accuracy: 0.7800\n",
      "Epoch 203/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0132 - accuracy: 0.9383 - val_loss: 0.0307 - val_accuracy: 0.7800\n",
      "Epoch 204/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0131 - accuracy: 0.9400 - val_loss: 0.0306 - val_accuracy: 0.7900\n",
      "Epoch 205/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0130 - accuracy: 0.9400 - val_loss: 0.0306 - val_accuracy: 0.7900\n",
      "Epoch 206/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0129 - accuracy: 0.9383 - val_loss: 0.0305 - val_accuracy: 0.7900\n",
      "Epoch 207/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0128 - accuracy: 0.9433 - val_loss: 0.0304 - val_accuracy: 0.7900\n",
      "Epoch 208/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0127 - accuracy: 0.9417 - val_loss: 0.0304 - val_accuracy: 0.7900\n",
      "Epoch 209/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0126 - accuracy: 0.9433 - val_loss: 0.0302 - val_accuracy: 0.7900\n",
      "Epoch 210/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0125 - accuracy: 0.9450 - val_loss: 0.0302 - val_accuracy: 0.7900\n",
      "Epoch 211/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0124 - accuracy: 0.9433 - val_loss: 0.0301 - val_accuracy: 0.7900\n",
      "Epoch 212/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0123 - accuracy: 0.9467 - val_loss: 0.0301 - val_accuracy: 0.7900\n",
      "Epoch 213/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0122 - accuracy: 0.9450 - val_loss: 0.0300 - val_accuracy: 0.7900\n",
      "Epoch 214/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0121 - accuracy: 0.9467 - val_loss: 0.0300 - val_accuracy: 0.7900\n",
      "Epoch 215/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0120 - accuracy: 0.9483 - val_loss: 0.0300 - val_accuracy: 0.7900\n",
      "Epoch 216/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0119 - accuracy: 0.9500 - val_loss: 0.0299 - val_accuracy: 0.7900\n",
      "Epoch 217/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0118 - accuracy: 0.9467 - val_loss: 0.0298 - val_accuracy: 0.7900\n",
      "Epoch 218/240\n",
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0118 - accuracy: 0.9483 - val_loss: 0.0298 - val_accuracy: 0.7900\n",
      "Epoch 219/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0117 - accuracy: 0.9500 - val_loss: 0.0297 - val_accuracy: 0.7900\n",
      "Epoch 220/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0116 - accuracy: 0.9500 - val_loss: 0.0297 - val_accuracy: 0.7900\n",
      "Epoch 221/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0115 - accuracy: 0.9500 - val_loss: 0.0296 - val_accuracy: 0.8000\n",
      "Epoch 222/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0114 - accuracy: 0.9500 - val_loss: 0.0295 - val_accuracy: 0.7900\n",
      "Epoch 223/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0113 - accuracy: 0.9500 - val_loss: 0.0295 - val_accuracy: 0.7900\n",
      "Epoch 224/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0113 - accuracy: 0.9500 - val_loss: 0.0293 - val_accuracy: 0.8000\n",
      "Epoch 225/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0112 - accuracy: 0.9500 - val_loss: 0.0293 - val_accuracy: 0.8000\n",
      "Epoch 226/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0111 - accuracy: 0.9533 - val_loss: 0.0293 - val_accuracy: 0.8000\n",
      "Epoch 227/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0110 - accuracy: 0.9500 - val_loss: 0.0292 - val_accuracy: 0.8000\n",
      "Epoch 228/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0109 - accuracy: 0.9517 - val_loss: 0.0292 - val_accuracy: 0.8000\n",
      "Epoch 229/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0108 - accuracy: 0.9517 - val_loss: 0.0292 - val_accuracy: 0.8000\n",
      "Epoch 230/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0108 - accuracy: 0.9533 - val_loss: 0.0290 - val_accuracy: 0.8000\n",
      "Epoch 231/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0107 - accuracy: 0.9533 - val_loss: 0.0290 - val_accuracy: 0.8000\n",
      "Epoch 232/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0106 - accuracy: 0.9550 - val_loss: 0.0291 - val_accuracy: 0.8000\n",
      "Epoch 233/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0105 - accuracy: 0.9533 - val_loss: 0.0290 - val_accuracy: 0.8000\n",
      "Epoch 234/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0105 - accuracy: 0.9567 - val_loss: 0.0289 - val_accuracy: 0.8000\n",
      "Epoch 235/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0104 - accuracy: 0.9567 - val_loss: 0.0289 - val_accuracy: 0.8000\n",
      "Epoch 236/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0103 - accuracy: 0.9567 - val_loss: 0.0288 - val_accuracy: 0.8000\n",
      "Epoch 237/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0102 - accuracy: 0.9567 - val_loss: 0.0288 - val_accuracy: 0.8000\n",
      "Epoch 238/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0102 - accuracy: 0.9567 - val_loss: 0.0288 - val_accuracy: 0.8000\n",
      "Epoch 239/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0101 - accuracy: 0.9567 - val_loss: 0.0287 - val_accuracy: 0.8000\n",
      "Epoch 240/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0100 - accuracy: 0.9567 - val_loss: 0.0287 - val_accuracy: 0.8000\n",
      "Training date and time : \n",
      "2020-04-09 21:03:29\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/240\n",
      "600/600 [==============================] - 0s 661us/sample - loss: 0.0899 - accuracy: 0.1300 - val_loss: 0.0896 - val_accuracy: 0.1900\n",
      "Epoch 2/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0898 - accuracy: 0.1383 - val_loss: 0.0895 - val_accuracy: 0.2000\n",
      "Epoch 3/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0896 - accuracy: 0.1433 - val_loss: 0.0894 - val_accuracy: 0.2100\n",
      "Epoch 4/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0895 - accuracy: 0.1533 - val_loss: 0.0893 - val_accuracy: 0.2200\n",
      "Epoch 5/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0894 - accuracy: 0.1683 - val_loss: 0.0892 - val_accuracy: 0.2200\n",
      "Epoch 6/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0892 - accuracy: 0.1817 - val_loss: 0.0891 - val_accuracy: 0.2400\n",
      "Epoch 7/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0891 - accuracy: 0.1983 - val_loss: 0.0890 - val_accuracy: 0.2500\n",
      "Epoch 8/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0890 - accuracy: 0.2250 - val_loss: 0.0889 - val_accuracy: 0.2500\n",
      "Epoch 9/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0888 - accuracy: 0.2483 - val_loss: 0.0888 - val_accuracy: 0.2700\n",
      "Epoch 10/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0887 - accuracy: 0.2650 - val_loss: 0.0887 - val_accuracy: 0.3000\n",
      "Epoch 11/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0886 - accuracy: 0.2850 - val_loss: 0.0886 - val_accuracy: 0.3000\n",
      "Epoch 12/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0884 - accuracy: 0.3067 - val_loss: 0.0885 - val_accuracy: 0.3000\n",
      "Epoch 13/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0883 - accuracy: 0.3217 - val_loss: 0.0884 - val_accuracy: 0.3100\n",
      "Epoch 14/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0881 - accuracy: 0.3333 - val_loss: 0.0882 - val_accuracy: 0.3200\n",
      "Epoch 15/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0880 - accuracy: 0.3550 - val_loss: 0.0881 - val_accuracy: 0.3200\n",
      "Epoch 16/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0878 - accuracy: 0.3750 - val_loss: 0.0880 - val_accuracy: 0.3300\n",
      "Epoch 17/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0877 - accuracy: 0.3900 - val_loss: 0.0879 - val_accuracy: 0.3300\n",
      "Epoch 18/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0875 - accuracy: 0.4067 - val_loss: 0.0877 - val_accuracy: 0.3500\n",
      "Epoch 19/240\n",
      "600/600 [==============================] - 0s 114us/sample - loss: 0.0874 - accuracy: 0.4150 - val_loss: 0.0876 - val_accuracy: 0.3600\n",
      "Epoch 20/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0872 - accuracy: 0.4317 - val_loss: 0.0875 - val_accuracy: 0.3800\n",
      "Epoch 21/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0870 - accuracy: 0.4483 - val_loss: 0.0873 - val_accuracy: 0.3900\n",
      "Epoch 22/240\n",
      "600/600 [==============================] - 0s 120us/sample - loss: 0.0868 - accuracy: 0.4550 - val_loss: 0.0872 - val_accuracy: 0.4000\n",
      "Epoch 23/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0866 - accuracy: 0.4600 - val_loss: 0.0870 - val_accuracy: 0.4100\n",
      "Epoch 24/240\n",
      "600/600 [==============================] - 0s 125us/sample - loss: 0.0864 - accuracy: 0.4717 - val_loss: 0.0868 - val_accuracy: 0.4100\n",
      "Epoch 25/240\n",
      "600/600 [==============================] - 0s 199us/sample - loss: 0.0862 - accuracy: 0.4783 - val_loss: 0.0867 - val_accuracy: 0.4100\n",
      "Epoch 26/240\n",
      "600/600 [==============================] - 0s 214us/sample - loss: 0.0860 - accuracy: 0.4917 - val_loss: 0.0865 - val_accuracy: 0.4100\n",
      "Epoch 27/240\n",
      "600/600 [==============================] - 0s 195us/sample - loss: 0.0858 - accuracy: 0.4967 - val_loss: 0.0863 - val_accuracy: 0.4300\n",
      "Epoch 28/240\n",
      "600/600 [==============================] - 0s 194us/sample - loss: 0.0856 - accuracy: 0.5017 - val_loss: 0.0861 - val_accuracy: 0.4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/240\n",
      "600/600 [==============================] - 0s 143us/sample - loss: 0.0853 - accuracy: 0.5067 - val_loss: 0.0859 - val_accuracy: 0.4500\n",
      "Epoch 30/240\n",
      "600/600 [==============================] - 0s 156us/sample - loss: 0.0851 - accuracy: 0.5050 - val_loss: 0.0857 - val_accuracy: 0.4500\n",
      "Epoch 31/240\n",
      "600/600 [==============================] - 0s 160us/sample - loss: 0.0848 - accuracy: 0.5100 - val_loss: 0.0855 - val_accuracy: 0.4500\n",
      "Epoch 32/240\n",
      "600/600 [==============================] - 0s 214us/sample - loss: 0.0845 - accuracy: 0.5167 - val_loss: 0.0852 - val_accuracy: 0.4600\n",
      "Epoch 33/240\n",
      "600/600 [==============================] - 0s 246us/sample - loss: 0.0842 - accuracy: 0.5233 - val_loss: 0.0850 - val_accuracy: 0.4600\n",
      "Epoch 34/240\n",
      "600/600 [==============================] - 0s 195us/sample - loss: 0.0839 - accuracy: 0.5233 - val_loss: 0.0847 - val_accuracy: 0.4700\n",
      "Epoch 35/240\n",
      "600/600 [==============================] - 0s 192us/sample - loss: 0.0836 - accuracy: 0.5250 - val_loss: 0.0845 - val_accuracy: 0.4700\n",
      "Epoch 36/240\n",
      "600/600 [==============================] - 0s 183us/sample - loss: 0.0833 - accuracy: 0.5267 - val_loss: 0.0842 - val_accuracy: 0.4700\n",
      "Epoch 37/240\n",
      "600/600 [==============================] - 0s 223us/sample - loss: 0.0829 - accuracy: 0.5267 - val_loss: 0.0839 - val_accuracy: 0.4700\n",
      "Epoch 38/240\n",
      "600/600 [==============================] - 0s 276us/sample - loss: 0.0825 - accuracy: 0.5200 - val_loss: 0.0836 - val_accuracy: 0.4700\n",
      "Epoch 39/240\n",
      "600/600 [==============================] - 0s 168us/sample - loss: 0.0821 - accuracy: 0.5150 - val_loss: 0.0833 - val_accuracy: 0.4700\n",
      "Epoch 40/240\n",
      "600/600 [==============================] - 0s 183us/sample - loss: 0.0817 - accuracy: 0.5133 - val_loss: 0.0829 - val_accuracy: 0.4600\n",
      "Epoch 41/240\n",
      "600/600 [==============================] - 0s 208us/sample - loss: 0.0813 - accuracy: 0.5100 - val_loss: 0.0826 - val_accuracy: 0.4600\n",
      "Epoch 42/240\n",
      "600/600 [==============================] - 0s 199us/sample - loss: 0.0808 - accuracy: 0.5133 - val_loss: 0.0822 - val_accuracy: 0.4500\n",
      "Epoch 43/240\n",
      "600/600 [==============================] - 0s 153us/sample - loss: 0.0804 - accuracy: 0.5133 - val_loss: 0.0818 - val_accuracy: 0.4400\n",
      "Epoch 44/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0799 - accuracy: 0.5117 - val_loss: 0.0814 - val_accuracy: 0.4400\n",
      "Epoch 45/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0793 - accuracy: 0.5167 - val_loss: 0.0810 - val_accuracy: 0.4400\n",
      "Epoch 46/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0788 - accuracy: 0.5133 - val_loss: 0.0805 - val_accuracy: 0.4400\n",
      "Epoch 47/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0782 - accuracy: 0.5117 - val_loss: 0.0801 - val_accuracy: 0.4400\n",
      "Epoch 48/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0776 - accuracy: 0.5150 - val_loss: 0.0796 - val_accuracy: 0.4400\n",
      "Epoch 49/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0770 - accuracy: 0.5200 - val_loss: 0.0791 - val_accuracy: 0.4400\n",
      "Epoch 50/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0764 - accuracy: 0.5217 - val_loss: 0.0786 - val_accuracy: 0.4400\n",
      "Epoch 51/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0758 - accuracy: 0.5250 - val_loss: 0.0781 - val_accuracy: 0.4400\n",
      "Epoch 52/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0751 - accuracy: 0.5233 - val_loss: 0.0776 - val_accuracy: 0.4500\n",
      "Epoch 53/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0744 - accuracy: 0.5250 - val_loss: 0.0771 - val_accuracy: 0.4600\n",
      "Epoch 54/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0737 - accuracy: 0.5333 - val_loss: 0.0765 - val_accuracy: 0.4600\n",
      "Epoch 55/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0730 - accuracy: 0.5317 - val_loss: 0.0760 - val_accuracy: 0.4700\n",
      "Epoch 56/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0723 - accuracy: 0.5367 - val_loss: 0.0754 - val_accuracy: 0.4700\n",
      "Epoch 57/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0716 - accuracy: 0.5433 - val_loss: 0.0748 - val_accuracy: 0.4800\n",
      "Epoch 58/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0708 - accuracy: 0.5500 - val_loss: 0.0742 - val_accuracy: 0.4800\n",
      "Epoch 59/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0701 - accuracy: 0.5533 - val_loss: 0.0737 - val_accuracy: 0.4900\n",
      "Epoch 60/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0693 - accuracy: 0.5567 - val_loss: 0.0731 - val_accuracy: 0.5000\n",
      "Epoch 61/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0686 - accuracy: 0.5600 - val_loss: 0.0725 - val_accuracy: 0.5000\n",
      "Epoch 62/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0678 - accuracy: 0.5617 - val_loss: 0.0719 - val_accuracy: 0.5000\n",
      "Epoch 63/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0670 - accuracy: 0.5717 - val_loss: 0.0713 - val_accuracy: 0.5100\n",
      "Epoch 64/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0662 - accuracy: 0.5750 - val_loss: 0.0707 - val_accuracy: 0.5100\n",
      "Epoch 65/240\n",
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0654 - accuracy: 0.5833 - val_loss: 0.0701 - val_accuracy: 0.5300\n",
      "Epoch 66/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0646 - accuracy: 0.5900 - val_loss: 0.0695 - val_accuracy: 0.5500\n",
      "Epoch 67/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0639 - accuracy: 0.5983 - val_loss: 0.0689 - val_accuracy: 0.5600\n",
      "Epoch 68/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0631 - accuracy: 0.6017 - val_loss: 0.0683 - val_accuracy: 0.5700\n",
      "Epoch 69/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0623 - accuracy: 0.6100 - val_loss: 0.0677 - val_accuracy: 0.5700\n",
      "Epoch 70/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0615 - accuracy: 0.6200 - val_loss: 0.0671 - val_accuracy: 0.5800\n",
      "Epoch 71/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0607 - accuracy: 0.6267 - val_loss: 0.0665 - val_accuracy: 0.5900\n",
      "Epoch 72/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0600 - accuracy: 0.6300 - val_loss: 0.0659 - val_accuracy: 0.6000\n",
      "Epoch 73/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0592 - accuracy: 0.6350 - val_loss: 0.0652 - val_accuracy: 0.6100\n",
      "Epoch 74/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0584 - accuracy: 0.6383 - val_loss: 0.0646 - val_accuracy: 0.6100\n",
      "Epoch 75/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0576 - accuracy: 0.6400 - val_loss: 0.0640 - val_accuracy: 0.6200\n",
      "Epoch 76/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0568 - accuracy: 0.6450 - val_loss: 0.0634 - val_accuracy: 0.6300\n",
      "Epoch 77/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0561 - accuracy: 0.6467 - val_loss: 0.0628 - val_accuracy: 0.6300\n",
      "Epoch 78/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0553 - accuracy: 0.6500 - val_loss: 0.0622 - val_accuracy: 0.6400\n",
      "Epoch 79/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0546 - accuracy: 0.6533 - val_loss: 0.0617 - val_accuracy: 0.6400\n",
      "Epoch 80/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0538 - accuracy: 0.6517 - val_loss: 0.0611 - val_accuracy: 0.6400\n",
      "Epoch 81/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0531 - accuracy: 0.6583 - val_loss: 0.0605 - val_accuracy: 0.6400\n",
      "Epoch 82/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0523 - accuracy: 0.6567 - val_loss: 0.0599 - val_accuracy: 0.6400\n",
      "Epoch 83/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0516 - accuracy: 0.6567 - val_loss: 0.0594 - val_accuracy: 0.6400\n",
      "Epoch 84/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0509 - accuracy: 0.6650 - val_loss: 0.0589 - val_accuracy: 0.6400\n",
      "Epoch 85/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0502 - accuracy: 0.6717 - val_loss: 0.0584 - val_accuracy: 0.6500\n",
      "Epoch 86/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0495 - accuracy: 0.6767 - val_loss: 0.0578 - val_accuracy: 0.6500\n",
      "Epoch 87/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0488 - accuracy: 0.6883 - val_loss: 0.0573 - val_accuracy: 0.6500\n",
      "Epoch 88/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0481 - accuracy: 0.6967 - val_loss: 0.0569 - val_accuracy: 0.6500\n",
      "Epoch 89/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0475 - accuracy: 0.7033 - val_loss: 0.0564 - val_accuracy: 0.6500\n",
      "Epoch 90/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0468 - accuracy: 0.7133 - val_loss: 0.0559 - val_accuracy: 0.6500\n",
      "Epoch 91/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0462 - accuracy: 0.7183 - val_loss: 0.0555 - val_accuracy: 0.6500\n",
      "Epoch 92/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0455 - accuracy: 0.7233 - val_loss: 0.0551 - val_accuracy: 0.6500\n",
      "Epoch 93/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0449 - accuracy: 0.7317 - val_loss: 0.0547 - val_accuracy: 0.6500\n",
      "Epoch 94/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0443 - accuracy: 0.7333 - val_loss: 0.0542 - val_accuracy: 0.6500\n",
      "Epoch 95/240\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0436 - accuracy: 0.7450 - val_loss: 0.0539 - val_accuracy: 0.6600\n",
      "Epoch 96/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0430 - accuracy: 0.7483 - val_loss: 0.0535 - val_accuracy: 0.6800\n",
      "Epoch 97/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0424 - accuracy: 0.7517 - val_loss: 0.0531 - val_accuracy: 0.6900\n",
      "Epoch 98/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0418 - accuracy: 0.7600 - val_loss: 0.0527 - val_accuracy: 0.6900\n",
      "Epoch 99/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0412 - accuracy: 0.7667 - val_loss: 0.0523 - val_accuracy: 0.6900\n",
      "Epoch 100/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0406 - accuracy: 0.7717 - val_loss: 0.0519 - val_accuracy: 0.6900\n",
      "Epoch 101/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0401 - accuracy: 0.7717 - val_loss: 0.0516 - val_accuracy: 0.6900\n",
      "Epoch 102/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0395 - accuracy: 0.7767 - val_loss: 0.0513 - val_accuracy: 0.6900\n",
      "Epoch 103/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0390 - accuracy: 0.7783 - val_loss: 0.0509 - val_accuracy: 0.6900\n",
      "Epoch 104/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0384 - accuracy: 0.7800 - val_loss: 0.0506 - val_accuracy: 0.6900\n",
      "Epoch 105/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0379 - accuracy: 0.7850 - val_loss: 0.0502 - val_accuracy: 0.6900\n",
      "Epoch 106/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0374 - accuracy: 0.7833 - val_loss: 0.0500 - val_accuracy: 0.6900\n",
      "Epoch 107/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0369 - accuracy: 0.7883 - val_loss: 0.0496 - val_accuracy: 0.6900\n",
      "Epoch 108/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0364 - accuracy: 0.7917 - val_loss: 0.0493 - val_accuracy: 0.6900\n",
      "Epoch 109/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0359 - accuracy: 0.7950 - val_loss: 0.0490 - val_accuracy: 0.6900\n",
      "Epoch 110/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0355 - accuracy: 0.7983 - val_loss: 0.0486 - val_accuracy: 0.7000\n",
      "Epoch 111/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0350 - accuracy: 0.8017 - val_loss: 0.0483 - val_accuracy: 0.7000\n",
      "Epoch 112/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0346 - accuracy: 0.8017 - val_loss: 0.0480 - val_accuracy: 0.7000\n",
      "Epoch 113/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0341 - accuracy: 0.8017 - val_loss: 0.0477 - val_accuracy: 0.7000\n",
      "Epoch 114/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0337 - accuracy: 0.8000 - val_loss: 0.0474 - val_accuracy: 0.7000\n",
      "Epoch 115/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0333 - accuracy: 0.8017 - val_loss: 0.0471 - val_accuracy: 0.7000\n",
      "Epoch 116/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0329 - accuracy: 0.8067 - val_loss: 0.0468 - val_accuracy: 0.7000\n",
      "Epoch 117/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0325 - accuracy: 0.8067 - val_loss: 0.0466 - val_accuracy: 0.6900\n",
      "Epoch 118/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0321 - accuracy: 0.8100 - val_loss: 0.0463 - val_accuracy: 0.6900\n",
      "Epoch 119/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0317 - accuracy: 0.8100 - val_loss: 0.0460 - val_accuracy: 0.6900\n",
      "Epoch 120/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0314 - accuracy: 0.8167 - val_loss: 0.0456 - val_accuracy: 0.7000\n",
      "Epoch 121/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0310 - accuracy: 0.8200 - val_loss: 0.0453 - val_accuracy: 0.7000\n",
      "Epoch 122/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0306 - accuracy: 0.8233 - val_loss: 0.0451 - val_accuracy: 0.7000\n",
      "Epoch 123/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0303 - accuracy: 0.8233 - val_loss: 0.0448 - val_accuracy: 0.7000\n",
      "Epoch 124/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0299 - accuracy: 0.8317 - val_loss: 0.0445 - val_accuracy: 0.7000\n",
      "Epoch 125/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0296 - accuracy: 0.8367 - val_loss: 0.0443 - val_accuracy: 0.7100\n",
      "Epoch 126/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0292 - accuracy: 0.8383 - val_loss: 0.0440 - val_accuracy: 0.7100\n",
      "Epoch 127/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0289 - accuracy: 0.8433 - val_loss: 0.0437 - val_accuracy: 0.7100\n",
      "Epoch 128/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0286 - accuracy: 0.8417 - val_loss: 0.0434 - val_accuracy: 0.7100\n",
      "Epoch 129/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0282 - accuracy: 0.8433 - val_loss: 0.0431 - val_accuracy: 0.7100\n",
      "Epoch 130/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0279 - accuracy: 0.8533 - val_loss: 0.0428 - val_accuracy: 0.7100\n",
      "Epoch 131/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0276 - accuracy: 0.8500 - val_loss: 0.0426 - val_accuracy: 0.7200\n",
      "Epoch 132/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0273 - accuracy: 0.8533 - val_loss: 0.0423 - val_accuracy: 0.7200\n",
      "Epoch 133/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0270 - accuracy: 0.8550 - val_loss: 0.0421 - val_accuracy: 0.7300\n",
      "Epoch 134/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0267 - accuracy: 0.8617 - val_loss: 0.0418 - val_accuracy: 0.7300\n",
      "Epoch 135/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0265 - accuracy: 0.8650 - val_loss: 0.0416 - val_accuracy: 0.7300\n",
      "Epoch 136/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0261 - accuracy: 0.8650 - val_loss: 0.0414 - val_accuracy: 0.7300\n",
      "Epoch 137/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0259 - accuracy: 0.8667 - val_loss: 0.0411 - val_accuracy: 0.7300\n",
      "Epoch 138/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0256 - accuracy: 0.8667 - val_loss: 0.0408 - val_accuracy: 0.7300\n",
      "Epoch 139/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0253 - accuracy: 0.8700 - val_loss: 0.0406 - val_accuracy: 0.7300\n",
      "Epoch 140/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0251 - accuracy: 0.8733 - val_loss: 0.0404 - val_accuracy: 0.7300\n",
      "Epoch 141/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0248 - accuracy: 0.8717 - val_loss: 0.0402 - val_accuracy: 0.7300\n",
      "Epoch 142/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0246 - accuracy: 0.8700 - val_loss: 0.0401 - val_accuracy: 0.7300\n",
      "Epoch 143/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0243 - accuracy: 0.8717 - val_loss: 0.0398 - val_accuracy: 0.7300\n",
      "Epoch 144/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0240 - accuracy: 0.8717 - val_loss: 0.0396 - val_accuracy: 0.7300\n",
      "Epoch 145/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0238 - accuracy: 0.8767 - val_loss: 0.0394 - val_accuracy: 0.7300\n",
      "Epoch 146/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0236 - accuracy: 0.8767 - val_loss: 0.0393 - val_accuracy: 0.7300\n",
      "Epoch 147/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0233 - accuracy: 0.8767 - val_loss: 0.0390 - val_accuracy: 0.7300\n",
      "Epoch 148/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0231 - accuracy: 0.8767 - val_loss: 0.0388 - val_accuracy: 0.7500\n",
      "Epoch 149/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0229 - accuracy: 0.8817 - val_loss: 0.0386 - val_accuracy: 0.7500\n",
      "Epoch 150/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0227 - accuracy: 0.8833 - val_loss: 0.0384 - val_accuracy: 0.7500\n",
      "Epoch 151/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0224 - accuracy: 0.8850 - val_loss: 0.0382 - val_accuracy: 0.7500\n",
      "Epoch 152/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0222 - accuracy: 0.8783 - val_loss: 0.0380 - val_accuracy: 0.7500\n",
      "Epoch 153/240\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0220 - accuracy: 0.8817 - val_loss: 0.0379 - val_accuracy: 0.7500\n",
      "Epoch 154/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0218 - accuracy: 0.8850 - val_loss: 0.0376 - val_accuracy: 0.7500\n",
      "Epoch 155/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0216 - accuracy: 0.8900 - val_loss: 0.0374 - val_accuracy: 0.7500\n",
      "Epoch 156/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0214 - accuracy: 0.8883 - val_loss: 0.0373 - val_accuracy: 0.7500\n",
      "Epoch 157/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0212 - accuracy: 0.8917 - val_loss: 0.0371 - val_accuracy: 0.7500\n",
      "Epoch 158/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0209 - accuracy: 0.8917 - val_loss: 0.0369 - val_accuracy: 0.7600\n",
      "Epoch 159/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0208 - accuracy: 0.8917 - val_loss: 0.0367 - val_accuracy: 0.7600\n",
      "Epoch 160/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0206 - accuracy: 0.8933 - val_loss: 0.0366 - val_accuracy: 0.7600\n",
      "Epoch 161/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0204 - accuracy: 0.8950 - val_loss: 0.0364 - val_accuracy: 0.7600\n",
      "Epoch 162/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0202 - accuracy: 0.8950 - val_loss: 0.0363 - val_accuracy: 0.7600\n",
      "Epoch 163/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0200 - accuracy: 0.8950 - val_loss: 0.0361 - val_accuracy: 0.7600\n",
      "Epoch 164/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0198 - accuracy: 0.8967 - val_loss: 0.0360 - val_accuracy: 0.7600\n",
      "Epoch 165/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0196 - accuracy: 0.8967 - val_loss: 0.0358 - val_accuracy: 0.7600\n",
      "Epoch 166/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0194 - accuracy: 0.8983 - val_loss: 0.0356 - val_accuracy: 0.7600\n",
      "Epoch 167/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0193 - accuracy: 0.9000 - val_loss: 0.0355 - val_accuracy: 0.7600\n",
      "Epoch 168/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0191 - accuracy: 0.9000 - val_loss: 0.0353 - val_accuracy: 0.7600\n",
      "Epoch 169/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0189 - accuracy: 0.9000 - val_loss: 0.0353 - val_accuracy: 0.7600\n",
      "Epoch 170/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0188 - accuracy: 0.9050 - val_loss: 0.0351 - val_accuracy: 0.7800\n",
      "Epoch 171/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0186 - accuracy: 0.9033 - val_loss: 0.0349 - val_accuracy: 0.7700\n",
      "Epoch 172/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0184 - accuracy: 0.9117 - val_loss: 0.0348 - val_accuracy: 0.7800\n",
      "Epoch 173/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0183 - accuracy: 0.9083 - val_loss: 0.0347 - val_accuracy: 0.7700\n",
      "Epoch 174/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0181 - accuracy: 0.9100 - val_loss: 0.0345 - val_accuracy: 0.7800\n",
      "Epoch 175/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0180 - accuracy: 0.9083 - val_loss: 0.0344 - val_accuracy: 0.7800\n",
      "Epoch 176/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0178 - accuracy: 0.9100 - val_loss: 0.0342 - val_accuracy: 0.7800\n",
      "Epoch 177/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0176 - accuracy: 0.9117 - val_loss: 0.0342 - val_accuracy: 0.7800\n",
      "Epoch 178/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0175 - accuracy: 0.9100 - val_loss: 0.0339 - val_accuracy: 0.7800\n",
      "Epoch 179/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0173 - accuracy: 0.9150 - val_loss: 0.0339 - val_accuracy: 0.7800\n",
      "Epoch 180/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0172 - accuracy: 0.9183 - val_loss: 0.0337 - val_accuracy: 0.7800\n",
      "Epoch 181/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0171 - accuracy: 0.9167 - val_loss: 0.0336 - val_accuracy: 0.7800\n",
      "Epoch 182/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0169 - accuracy: 0.9117 - val_loss: 0.0335 - val_accuracy: 0.7800\n",
      "Epoch 183/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0168 - accuracy: 0.9167 - val_loss: 0.0334 - val_accuracy: 0.7800\n",
      "Epoch 184/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0166 - accuracy: 0.9200 - val_loss: 0.0332 - val_accuracy: 0.7800\n",
      "Epoch 185/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0165 - accuracy: 0.9150 - val_loss: 0.0332 - val_accuracy: 0.7800\n",
      "Epoch 186/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0163 - accuracy: 0.9200 - val_loss: 0.0331 - val_accuracy: 0.7800\n",
      "Epoch 187/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0162 - accuracy: 0.9183 - val_loss: 0.0330 - val_accuracy: 0.7900\n",
      "Epoch 188/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0161 - accuracy: 0.9233 - val_loss: 0.0329 - val_accuracy: 0.7900\n",
      "Epoch 189/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0159 - accuracy: 0.9217 - val_loss: 0.0328 - val_accuracy: 0.7900\n",
      "Epoch 190/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0158 - accuracy: 0.9250 - val_loss: 0.0327 - val_accuracy: 0.7900\n",
      "Epoch 191/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0157 - accuracy: 0.9217 - val_loss: 0.0325 - val_accuracy: 0.7900\n",
      "Epoch 192/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0156 - accuracy: 0.9267 - val_loss: 0.0324 - val_accuracy: 0.7900\n",
      "Epoch 193/240\n",
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0154 - accuracy: 0.9283 - val_loss: 0.0324 - val_accuracy: 0.7900\n",
      "Epoch 194/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0153 - accuracy: 0.9250 - val_loss: 0.0322 - val_accuracy: 0.7900\n",
      "Epoch 195/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0152 - accuracy: 0.9317 - val_loss: 0.0321 - val_accuracy: 0.7900\n",
      "Epoch 196/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0150 - accuracy: 0.9283 - val_loss: 0.0320 - val_accuracy: 0.7900\n",
      "Epoch 197/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0149 - accuracy: 0.9300 - val_loss: 0.0320 - val_accuracy: 0.7900\n",
      "Epoch 198/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0148 - accuracy: 0.9333 - val_loss: 0.0318 - val_accuracy: 0.7900\n",
      "Epoch 199/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0147 - accuracy: 0.9317 - val_loss: 0.0317 - val_accuracy: 0.7900\n",
      "Epoch 200/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0146 - accuracy: 0.9317 - val_loss: 0.0316 - val_accuracy: 0.7800\n",
      "Epoch 201/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0145 - accuracy: 0.9350 - val_loss: 0.0315 - val_accuracy: 0.7900\n",
      "Epoch 202/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0143 - accuracy: 0.9367 - val_loss: 0.0315 - val_accuracy: 0.7900\n",
      "Epoch 203/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0143 - accuracy: 0.9333 - val_loss: 0.0313 - val_accuracy: 0.7800\n",
      "Epoch 204/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0141 - accuracy: 0.9350 - val_loss: 0.0312 - val_accuracy: 0.7900\n",
      "Epoch 205/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0140 - accuracy: 0.9350 - val_loss: 0.0312 - val_accuracy: 0.7900\n",
      "Epoch 206/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0139 - accuracy: 0.9383 - val_loss: 0.0311 - val_accuracy: 0.7900\n",
      "Epoch 207/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0138 - accuracy: 0.9350 - val_loss: 0.0310 - val_accuracy: 0.7900\n",
      "Epoch 208/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0137 - accuracy: 0.9383 - val_loss: 0.0309 - val_accuracy: 0.7900\n",
      "Epoch 209/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0136 - accuracy: 0.9350 - val_loss: 0.0308 - val_accuracy: 0.7900\n",
      "Epoch 210/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0135 - accuracy: 0.9383 - val_loss: 0.0308 - val_accuracy: 0.7900\n",
      "Epoch 211/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0134 - accuracy: 0.9367 - val_loss: 0.0307 - val_accuracy: 0.7900\n",
      "Epoch 212/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0133 - accuracy: 0.9400 - val_loss: 0.0306 - val_accuracy: 0.7900\n",
      "Epoch 213/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0132 - accuracy: 0.9400 - val_loss: 0.0306 - val_accuracy: 0.7900\n",
      "Epoch 214/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0131 - accuracy: 0.9383 - val_loss: 0.0306 - val_accuracy: 0.7900\n",
      "Epoch 215/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0130 - accuracy: 0.9417 - val_loss: 0.0305 - val_accuracy: 0.7900\n",
      "Epoch 216/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0129 - accuracy: 0.9417 - val_loss: 0.0304 - val_accuracy: 0.7900\n",
      "Epoch 217/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0128 - accuracy: 0.9433 - val_loss: 0.0304 - val_accuracy: 0.7900\n",
      "Epoch 218/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0127 - accuracy: 0.9417 - val_loss: 0.0303 - val_accuracy: 0.7900\n",
      "Epoch 219/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0126 - accuracy: 0.9433 - val_loss: 0.0302 - val_accuracy: 0.8000\n",
      "Epoch 220/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0125 - accuracy: 0.9467 - val_loss: 0.0302 - val_accuracy: 0.7900\n",
      "Epoch 221/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0124 - accuracy: 0.9417 - val_loss: 0.0301 - val_accuracy: 0.8000\n",
      "Epoch 222/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0123 - accuracy: 0.9433 - val_loss: 0.0300 - val_accuracy: 0.8000\n",
      "Epoch 223/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0122 - accuracy: 0.9467 - val_loss: 0.0300 - val_accuracy: 0.7900\n",
      "Epoch 224/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0121 - accuracy: 0.9450 - val_loss: 0.0298 - val_accuracy: 0.8000\n",
      "Epoch 225/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0121 - accuracy: 0.9450 - val_loss: 0.0297 - val_accuracy: 0.8000\n",
      "Epoch 226/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0119 - accuracy: 0.9500 - val_loss: 0.0297 - val_accuracy: 0.8000\n",
      "Epoch 227/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0119 - accuracy: 0.9500 - val_loss: 0.0297 - val_accuracy: 0.8000\n",
      "Epoch 228/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0118 - accuracy: 0.9483 - val_loss: 0.0296 - val_accuracy: 0.8000\n",
      "Epoch 229/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0117 - accuracy: 0.9500 - val_loss: 0.0296 - val_accuracy: 0.8000\n",
      "Epoch 230/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0116 - accuracy: 0.9500 - val_loss: 0.0295 - val_accuracy: 0.8000\n",
      "Epoch 231/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0115 - accuracy: 0.9517 - val_loss: 0.0295 - val_accuracy: 0.8000\n",
      "Epoch 232/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0114 - accuracy: 0.9533 - val_loss: 0.0295 - val_accuracy: 0.8000\n",
      "Epoch 233/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0114 - accuracy: 0.9533 - val_loss: 0.0294 - val_accuracy: 0.8000\n",
      "Epoch 234/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0113 - accuracy: 0.9533 - val_loss: 0.0294 - val_accuracy: 0.8000\n",
      "Epoch 235/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0112 - accuracy: 0.9533 - val_loss: 0.0293 - val_accuracy: 0.8000\n",
      "Epoch 236/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0111 - accuracy: 0.9533 - val_loss: 0.0293 - val_accuracy: 0.8000\n",
      "Epoch 237/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0110 - accuracy: 0.9533 - val_loss: 0.0292 - val_accuracy: 0.8000\n",
      "Epoch 238/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0109 - accuracy: 0.9533 - val_loss: 0.0292 - val_accuracy: 0.8000\n",
      "Epoch 239/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0109 - accuracy: 0.9533 - val_loss: 0.0291 - val_accuracy: 0.8000\n",
      "Epoch 240/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0108 - accuracy: 0.9550 - val_loss: 0.0291 - val_accuracy: 0.8000\n",
      "Training date and time : \n",
      "2020-04-09 21:03:46\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/240\n",
      "600/600 [==============================] - 0s 659us/sample - loss: 0.0899 - accuracy: 0.1367 - val_loss: 0.0897 - val_accuracy: 0.1700\n",
      "Epoch 2/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0897 - accuracy: 0.1433 - val_loss: 0.0896 - val_accuracy: 0.1800\n",
      "Epoch 3/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0896 - accuracy: 0.1500 - val_loss: 0.0895 - val_accuracy: 0.1800\n",
      "Epoch 4/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0895 - accuracy: 0.1617 - val_loss: 0.0894 - val_accuracy: 0.1900\n",
      "Epoch 5/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0894 - accuracy: 0.1700 - val_loss: 0.0893 - val_accuracy: 0.2000\n",
      "Epoch 6/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0893 - accuracy: 0.1817 - val_loss: 0.0892 - val_accuracy: 0.2300\n",
      "Epoch 7/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0892 - accuracy: 0.1950 - val_loss: 0.0891 - val_accuracy: 0.2400\n",
      "Epoch 8/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0890 - accuracy: 0.2183 - val_loss: 0.0890 - val_accuracy: 0.2600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0889 - accuracy: 0.2300 - val_loss: 0.0889 - val_accuracy: 0.2600\n",
      "Epoch 10/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0888 - accuracy: 0.2533 - val_loss: 0.0888 - val_accuracy: 0.2700\n",
      "Epoch 11/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0887 - accuracy: 0.2683 - val_loss: 0.0887 - val_accuracy: 0.2900\n",
      "Epoch 12/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0886 - accuracy: 0.2800 - val_loss: 0.0886 - val_accuracy: 0.3000\n",
      "Epoch 13/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0884 - accuracy: 0.3017 - val_loss: 0.0885 - val_accuracy: 0.3100\n",
      "Epoch 14/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0883 - accuracy: 0.3117 - val_loss: 0.0884 - val_accuracy: 0.3100\n",
      "Epoch 15/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0882 - accuracy: 0.3317 - val_loss: 0.0883 - val_accuracy: 0.3200\n",
      "Epoch 16/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0880 - accuracy: 0.3467 - val_loss: 0.0882 - val_accuracy: 0.3200\n",
      "Epoch 17/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0879 - accuracy: 0.3667 - val_loss: 0.0881 - val_accuracy: 0.3200\n",
      "Epoch 18/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0878 - accuracy: 0.3783 - val_loss: 0.0880 - val_accuracy: 0.3300\n",
      "Epoch 19/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0876 - accuracy: 0.3850 - val_loss: 0.0879 - val_accuracy: 0.3400\n",
      "Epoch 20/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0875 - accuracy: 0.3950 - val_loss: 0.0877 - val_accuracy: 0.3400\n",
      "Epoch 21/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0873 - accuracy: 0.4050 - val_loss: 0.0876 - val_accuracy: 0.3700\n",
      "Epoch 22/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0872 - accuracy: 0.4133 - val_loss: 0.0875 - val_accuracy: 0.3600\n",
      "Epoch 23/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0870 - accuracy: 0.4350 - val_loss: 0.0874 - val_accuracy: 0.3700\n",
      "Epoch 24/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0868 - accuracy: 0.4400 - val_loss: 0.0872 - val_accuracy: 0.3700\n",
      "Epoch 25/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0866 - accuracy: 0.4500 - val_loss: 0.0871 - val_accuracy: 0.3800\n",
      "Epoch 26/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0865 - accuracy: 0.4650 - val_loss: 0.0869 - val_accuracy: 0.3900\n",
      "Epoch 27/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0863 - accuracy: 0.4667 - val_loss: 0.0868 - val_accuracy: 0.3900\n",
      "Epoch 28/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0861 - accuracy: 0.4717 - val_loss: 0.0866 - val_accuracy: 0.4000\n",
      "Epoch 29/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0859 - accuracy: 0.4833 - val_loss: 0.0864 - val_accuracy: 0.4000\n",
      "Epoch 30/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0856 - accuracy: 0.4867 - val_loss: 0.0862 - val_accuracy: 0.4100\n",
      "Epoch 31/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0854 - accuracy: 0.4917 - val_loss: 0.0861 - val_accuracy: 0.4400\n",
      "Epoch 32/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0852 - accuracy: 0.4983 - val_loss: 0.0859 - val_accuracy: 0.4400\n",
      "Epoch 33/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0849 - accuracy: 0.4983 - val_loss: 0.0857 - val_accuracy: 0.4400\n",
      "Epoch 34/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0847 - accuracy: 0.4983 - val_loss: 0.0854 - val_accuracy: 0.4500\n",
      "Epoch 35/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0844 - accuracy: 0.5017 - val_loss: 0.0852 - val_accuracy: 0.4700\n",
      "Epoch 36/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0841 - accuracy: 0.5017 - val_loss: 0.0850 - val_accuracy: 0.4700\n",
      "Epoch 37/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0838 - accuracy: 0.5017 - val_loss: 0.0847 - val_accuracy: 0.4700\n",
      "Epoch 38/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0835 - accuracy: 0.5033 - val_loss: 0.0845 - val_accuracy: 0.4600\n",
      "Epoch 39/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0832 - accuracy: 0.5083 - val_loss: 0.0842 - val_accuracy: 0.4500\n",
      "Epoch 40/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0828 - accuracy: 0.4983 - val_loss: 0.0839 - val_accuracy: 0.4400\n",
      "Epoch 41/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0825 - accuracy: 0.4950 - val_loss: 0.0836 - val_accuracy: 0.4300\n",
      "Epoch 42/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0821 - accuracy: 0.4967 - val_loss: 0.0833 - val_accuracy: 0.4300\n",
      "Epoch 43/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0817 - accuracy: 0.4950 - val_loss: 0.0829 - val_accuracy: 0.4300\n",
      "Epoch 44/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0812 - accuracy: 0.4933 - val_loss: 0.0826 - val_accuracy: 0.4300\n",
      "Epoch 45/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0808 - accuracy: 0.4950 - val_loss: 0.0822 - val_accuracy: 0.4300\n",
      "Epoch 46/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0803 - accuracy: 0.4933 - val_loss: 0.0818 - val_accuracy: 0.4300\n",
      "Epoch 47/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0798 - accuracy: 0.4917 - val_loss: 0.0814 - val_accuracy: 0.4400\n",
      "Epoch 48/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0793 - accuracy: 0.4933 - val_loss: 0.0810 - val_accuracy: 0.4400\n",
      "Epoch 49/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0788 - accuracy: 0.4967 - val_loss: 0.0806 - val_accuracy: 0.4400\n",
      "Epoch 50/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0783 - accuracy: 0.4950 - val_loss: 0.0801 - val_accuracy: 0.4500\n",
      "Epoch 51/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0777 - accuracy: 0.5050 - val_loss: 0.0797 - val_accuracy: 0.4500\n",
      "Epoch 52/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0771 - accuracy: 0.4983 - val_loss: 0.0792 - val_accuracy: 0.4500\n",
      "Epoch 53/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0765 - accuracy: 0.5050 - val_loss: 0.0788 - val_accuracy: 0.4600\n",
      "Epoch 54/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0759 - accuracy: 0.5050 - val_loss: 0.0783 - val_accuracy: 0.4700\n",
      "Epoch 55/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0753 - accuracy: 0.5083 - val_loss: 0.0778 - val_accuracy: 0.4700\n",
      "Epoch 56/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0747 - accuracy: 0.5133 - val_loss: 0.0773 - val_accuracy: 0.4800\n",
      "Epoch 57/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0740 - accuracy: 0.5183 - val_loss: 0.0768 - val_accuracy: 0.4800\n",
      "Epoch 58/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0734 - accuracy: 0.5250 - val_loss: 0.0763 - val_accuracy: 0.4900\n",
      "Epoch 59/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0727 - accuracy: 0.5333 - val_loss: 0.0757 - val_accuracy: 0.5000\n",
      "Epoch 60/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0720 - accuracy: 0.5367 - val_loss: 0.0752 - val_accuracy: 0.5000\n",
      "Epoch 61/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0713 - accuracy: 0.5400 - val_loss: 0.0747 - val_accuracy: 0.5000\n",
      "Epoch 62/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0706 - accuracy: 0.5500 - val_loss: 0.0741 - val_accuracy: 0.5000\n",
      "Epoch 63/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0699 - accuracy: 0.5517 - val_loss: 0.0736 - val_accuracy: 0.5000\n",
      "Epoch 64/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0692 - accuracy: 0.5550 - val_loss: 0.0730 - val_accuracy: 0.5000\n",
      "Epoch 65/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0684 - accuracy: 0.5633 - val_loss: 0.0724 - val_accuracy: 0.5000\n",
      "Epoch 66/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0677 - accuracy: 0.5667 - val_loss: 0.0719 - val_accuracy: 0.5000\n",
      "Epoch 67/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0670 - accuracy: 0.5733 - val_loss: 0.0713 - val_accuracy: 0.5200\n",
      "Epoch 68/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0662 - accuracy: 0.5817 - val_loss: 0.0707 - val_accuracy: 0.5400\n",
      "Epoch 69/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0655 - accuracy: 0.5850 - val_loss: 0.0701 - val_accuracy: 0.5600\n",
      "Epoch 70/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0647 - accuracy: 0.5917 - val_loss: 0.0696 - val_accuracy: 0.5700\n",
      "Epoch 71/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0639 - accuracy: 0.5917 - val_loss: 0.0690 - val_accuracy: 0.5700\n",
      "Epoch 72/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0632 - accuracy: 0.5983 - val_loss: 0.0684 - val_accuracy: 0.5800\n",
      "Epoch 73/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0624 - accuracy: 0.6033 - val_loss: 0.0678 - val_accuracy: 0.5900\n",
      "Epoch 74/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0617 - accuracy: 0.6150 - val_loss: 0.0672 - val_accuracy: 0.5900\n",
      "Epoch 75/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0609 - accuracy: 0.6167 - val_loss: 0.0666 - val_accuracy: 0.6000\n",
      "Epoch 76/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0601 - accuracy: 0.6283 - val_loss: 0.0660 - val_accuracy: 0.6100\n",
      "Epoch 77/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0593 - accuracy: 0.6300 - val_loss: 0.0654 - val_accuracy: 0.6200\n",
      "Epoch 78/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0586 - accuracy: 0.6333 - val_loss: 0.0649 - val_accuracy: 0.6200\n",
      "Epoch 79/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0578 - accuracy: 0.6383 - val_loss: 0.0643 - val_accuracy: 0.6300\n",
      "Epoch 80/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0570 - accuracy: 0.6400 - val_loss: 0.0637 - val_accuracy: 0.6300\n",
      "Epoch 81/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0563 - accuracy: 0.6417 - val_loss: 0.0631 - val_accuracy: 0.6400\n",
      "Epoch 82/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0555 - accuracy: 0.6483 - val_loss: 0.0625 - val_accuracy: 0.6400\n",
      "Epoch 83/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0547 - accuracy: 0.6533 - val_loss: 0.0619 - val_accuracy: 0.6400\n",
      "Epoch 84/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0540 - accuracy: 0.6533 - val_loss: 0.0614 - val_accuracy: 0.6400\n",
      "Epoch 85/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0532 - accuracy: 0.6600 - val_loss: 0.0608 - val_accuracy: 0.6400\n",
      "Epoch 86/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0525 - accuracy: 0.6667 - val_loss: 0.0602 - val_accuracy: 0.6400\n",
      "Epoch 87/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0517 - accuracy: 0.6700 - val_loss: 0.0597 - val_accuracy: 0.6400\n",
      "Epoch 88/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0510 - accuracy: 0.6833 - val_loss: 0.0591 - val_accuracy: 0.6400\n",
      "Epoch 89/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0503 - accuracy: 0.6883 - val_loss: 0.0586 - val_accuracy: 0.6500\n",
      "Epoch 90/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0496 - accuracy: 0.6917 - val_loss: 0.0581 - val_accuracy: 0.6500\n",
      "Epoch 91/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0489 - accuracy: 0.7000 - val_loss: 0.0576 - val_accuracy: 0.6500\n",
      "Epoch 92/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0482 - accuracy: 0.7083 - val_loss: 0.0571 - val_accuracy: 0.6500\n",
      "Epoch 93/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0475 - accuracy: 0.7183 - val_loss: 0.0567 - val_accuracy: 0.6500\n",
      "Epoch 94/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0469 - accuracy: 0.7200 - val_loss: 0.0562 - val_accuracy: 0.6500\n",
      "Epoch 95/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0462 - accuracy: 0.7200 - val_loss: 0.0558 - val_accuracy: 0.6500\n",
      "Epoch 96/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0456 - accuracy: 0.7217 - val_loss: 0.0554 - val_accuracy: 0.6600\n",
      "Epoch 97/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0449 - accuracy: 0.7333 - val_loss: 0.0549 - val_accuracy: 0.6600\n",
      "Epoch 98/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0443 - accuracy: 0.7433 - val_loss: 0.0545 - val_accuracy: 0.6700\n",
      "Epoch 99/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0437 - accuracy: 0.7483 - val_loss: 0.0541 - val_accuracy: 0.6800\n",
      "Epoch 100/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0431 - accuracy: 0.7533 - val_loss: 0.0537 - val_accuracy: 0.6800\n",
      "Epoch 101/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0425 - accuracy: 0.7567 - val_loss: 0.0533 - val_accuracy: 0.6800\n",
      "Epoch 102/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0419 - accuracy: 0.7617 - val_loss: 0.0530 - val_accuracy: 0.6800\n",
      "Epoch 103/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0413 - accuracy: 0.7683 - val_loss: 0.0526 - val_accuracy: 0.6800\n",
      "Epoch 104/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0407 - accuracy: 0.7733 - val_loss: 0.0522 - val_accuracy: 0.6800\n",
      "Epoch 105/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0402 - accuracy: 0.7800 - val_loss: 0.0519 - val_accuracy: 0.6800\n",
      "Epoch 106/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0396 - accuracy: 0.7800 - val_loss: 0.0516 - val_accuracy: 0.6800\n",
      "Epoch 107/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0391 - accuracy: 0.7817 - val_loss: 0.0512 - val_accuracy: 0.6800\n",
      "Epoch 108/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0386 - accuracy: 0.7833 - val_loss: 0.0509 - val_accuracy: 0.6800\n",
      "Epoch 109/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0380 - accuracy: 0.7850 - val_loss: 0.0505 - val_accuracy: 0.6800\n",
      "Epoch 110/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0375 - accuracy: 0.7833 - val_loss: 0.0502 - val_accuracy: 0.6800\n",
      "Epoch 111/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0370 - accuracy: 0.7900 - val_loss: 0.0498 - val_accuracy: 0.6800\n",
      "Epoch 112/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0366 - accuracy: 0.7883 - val_loss: 0.0495 - val_accuracy: 0.6800\n",
      "Epoch 113/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0361 - accuracy: 0.7917 - val_loss: 0.0492 - val_accuracy: 0.6800\n",
      "Epoch 114/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0356 - accuracy: 0.7950 - val_loss: 0.0489 - val_accuracy: 0.6800\n",
      "Epoch 115/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0352 - accuracy: 0.7967 - val_loss: 0.0486 - val_accuracy: 0.6900\n",
      "Epoch 116/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0347 - accuracy: 0.7983 - val_loss: 0.0483 - val_accuracy: 0.6900\n",
      "Epoch 117/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0343 - accuracy: 0.7983 - val_loss: 0.0480 - val_accuracy: 0.6900\n",
      "Epoch 118/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0339 - accuracy: 0.7983 - val_loss: 0.0477 - val_accuracy: 0.6900\n",
      "Epoch 119/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0335 - accuracy: 0.7983 - val_loss: 0.0474 - val_accuracy: 0.6900\n",
      "Epoch 120/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0331 - accuracy: 0.8017 - val_loss: 0.0471 - val_accuracy: 0.6900\n",
      "Epoch 121/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0327 - accuracy: 0.8017 - val_loss: 0.0468 - val_accuracy: 0.6900\n",
      "Epoch 122/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0323 - accuracy: 0.8050 - val_loss: 0.0465 - val_accuracy: 0.6900\n",
      "Epoch 123/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0320 - accuracy: 0.8067 - val_loss: 0.0462 - val_accuracy: 0.6900\n",
      "Epoch 124/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0316 - accuracy: 0.8067 - val_loss: 0.0460 - val_accuracy: 0.6900\n",
      "Epoch 125/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0312 - accuracy: 0.8083 - val_loss: 0.0457 - val_accuracy: 0.6900\n",
      "Epoch 126/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0309 - accuracy: 0.8117 - val_loss: 0.0454 - val_accuracy: 0.6900\n",
      "Epoch 127/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0305 - accuracy: 0.8200 - val_loss: 0.0451 - val_accuracy: 0.6900\n",
      "Epoch 128/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0302 - accuracy: 0.8250 - val_loss: 0.0448 - val_accuracy: 0.6900\n",
      "Epoch 129/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0298 - accuracy: 0.8317 - val_loss: 0.0445 - val_accuracy: 0.6900\n",
      "Epoch 130/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0295 - accuracy: 0.8300 - val_loss: 0.0442 - val_accuracy: 0.7000\n",
      "Epoch 131/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0292 - accuracy: 0.8333 - val_loss: 0.0439 - val_accuracy: 0.7000\n",
      "Epoch 132/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0289 - accuracy: 0.8383 - val_loss: 0.0436 - val_accuracy: 0.7000\n",
      "Epoch 133/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0285 - accuracy: 0.8433 - val_loss: 0.0434 - val_accuracy: 0.7000\n",
      "Epoch 134/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0282 - accuracy: 0.8450 - val_loss: 0.0431 - val_accuracy: 0.7000\n",
      "Epoch 135/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0279 - accuracy: 0.8450 - val_loss: 0.0429 - val_accuracy: 0.7100\n",
      "Epoch 136/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0276 - accuracy: 0.8533 - val_loss: 0.0426 - val_accuracy: 0.7100\n",
      "Epoch 137/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0273 - accuracy: 0.8567 - val_loss: 0.0423 - val_accuracy: 0.7100\n",
      "Epoch 138/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0271 - accuracy: 0.8533 - val_loss: 0.0420 - val_accuracy: 0.7200\n",
      "Epoch 139/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0267 - accuracy: 0.8617 - val_loss: 0.0418 - val_accuracy: 0.7100\n",
      "Epoch 140/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0265 - accuracy: 0.8633 - val_loss: 0.0416 - val_accuracy: 0.7200\n",
      "Epoch 141/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0262 - accuracy: 0.8683 - val_loss: 0.0414 - val_accuracy: 0.7200\n",
      "Epoch 142/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0259 - accuracy: 0.8700 - val_loss: 0.0412 - val_accuracy: 0.7200\n",
      "Epoch 143/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0257 - accuracy: 0.8683 - val_loss: 0.0409 - val_accuracy: 0.7100\n",
      "Epoch 144/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0254 - accuracy: 0.8700 - val_loss: 0.0407 - val_accuracy: 0.7200\n",
      "Epoch 145/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0251 - accuracy: 0.8717 - val_loss: 0.0405 - val_accuracy: 0.7300\n",
      "Epoch 146/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0249 - accuracy: 0.8733 - val_loss: 0.0403 - val_accuracy: 0.7300\n",
      "Epoch 147/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0246 - accuracy: 0.8717 - val_loss: 0.0400 - val_accuracy: 0.7200\n",
      "Epoch 148/240\n",
      "600/600 [==============================] - 0s 168us/sample - loss: 0.0244 - accuracy: 0.8700 - val_loss: 0.0398 - val_accuracy: 0.7300\n",
      "Epoch 149/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0241 - accuracy: 0.8717 - val_loss: 0.0396 - val_accuracy: 0.7400\n",
      "Epoch 150/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0239 - accuracy: 0.8733 - val_loss: 0.0393 - val_accuracy: 0.7400\n",
      "Epoch 151/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0236 - accuracy: 0.8717 - val_loss: 0.0391 - val_accuracy: 0.7400\n",
      "Epoch 152/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0234 - accuracy: 0.8767 - val_loss: 0.0389 - val_accuracy: 0.7400\n",
      "Epoch 153/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0232 - accuracy: 0.8750 - val_loss: 0.0388 - val_accuracy: 0.7400\n",
      "Epoch 154/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0230 - accuracy: 0.8733 - val_loss: 0.0385 - val_accuracy: 0.7400\n",
      "Epoch 155/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0228 - accuracy: 0.8767 - val_loss: 0.0383 - val_accuracy: 0.7400\n",
      "Epoch 156/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0225 - accuracy: 0.8800 - val_loss: 0.0381 - val_accuracy: 0.7400\n",
      "Epoch 157/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0223 - accuracy: 0.8817 - val_loss: 0.0379 - val_accuracy: 0.7400\n",
      "Epoch 158/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0221 - accuracy: 0.8833 - val_loss: 0.0377 - val_accuracy: 0.7500\n",
      "Epoch 159/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0219 - accuracy: 0.8850 - val_loss: 0.0375 - val_accuracy: 0.7500\n",
      "Epoch 160/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0217 - accuracy: 0.8850 - val_loss: 0.0374 - val_accuracy: 0.7500\n",
      "Epoch 161/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0215 - accuracy: 0.8883 - val_loss: 0.0372 - val_accuracy: 0.7500\n",
      "Epoch 162/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0213 - accuracy: 0.8867 - val_loss: 0.0370 - val_accuracy: 0.7500\n",
      "Epoch 163/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0211 - accuracy: 0.8883 - val_loss: 0.0368 - val_accuracy: 0.7500\n",
      "Epoch 164/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0209 - accuracy: 0.8883 - val_loss: 0.0367 - val_accuracy: 0.7500\n",
      "Epoch 165/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0207 - accuracy: 0.8933 - val_loss: 0.0365 - val_accuracy: 0.7500\n",
      "Epoch 166/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0205 - accuracy: 0.8933 - val_loss: 0.0363 - val_accuracy: 0.7500\n",
      "Epoch 167/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0203 - accuracy: 0.8950 - val_loss: 0.0361 - val_accuracy: 0.7600\n",
      "Epoch 168/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0201 - accuracy: 0.8983 - val_loss: 0.0360 - val_accuracy: 0.7700\n",
      "Epoch 169/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0199 - accuracy: 0.8967 - val_loss: 0.0359 - val_accuracy: 0.7700\n",
      "Epoch 170/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0198 - accuracy: 0.9017 - val_loss: 0.0357 - val_accuracy: 0.7700\n",
      "Epoch 171/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0196 - accuracy: 0.9017 - val_loss: 0.0355 - val_accuracy: 0.7700\n",
      "Epoch 172/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0194 - accuracy: 0.9017 - val_loss: 0.0354 - val_accuracy: 0.7700\n",
      "Epoch 173/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0193 - accuracy: 0.9067 - val_loss: 0.0353 - val_accuracy: 0.7700\n",
      "Epoch 174/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0191 - accuracy: 0.9000 - val_loss: 0.0351 - val_accuracy: 0.7700\n",
      "Epoch 175/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0190 - accuracy: 0.9050 - val_loss: 0.0349 - val_accuracy: 0.7800\n",
      "Epoch 176/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0187 - accuracy: 0.9050 - val_loss: 0.0348 - val_accuracy: 0.7800\n",
      "Epoch 177/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0186 - accuracy: 0.9083 - val_loss: 0.0347 - val_accuracy: 0.7700\n",
      "Epoch 178/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0184 - accuracy: 0.9083 - val_loss: 0.0345 - val_accuracy: 0.7800\n",
      "Epoch 179/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0183 - accuracy: 0.9100 - val_loss: 0.0344 - val_accuracy: 0.7800\n",
      "Epoch 180/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0181 - accuracy: 0.9117 - val_loss: 0.0342 - val_accuracy: 0.7800\n",
      "Epoch 181/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0180 - accuracy: 0.9083 - val_loss: 0.0341 - val_accuracy: 0.7800\n",
      "Epoch 182/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0178 - accuracy: 0.9083 - val_loss: 0.0340 - val_accuracy: 0.7800\n",
      "Epoch 183/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0177 - accuracy: 0.9100 - val_loss: 0.0338 - val_accuracy: 0.7800\n",
      "Epoch 184/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0175 - accuracy: 0.9150 - val_loss: 0.0337 - val_accuracy: 0.7800\n",
      "Epoch 185/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0174 - accuracy: 0.9133 - val_loss: 0.0336 - val_accuracy: 0.7800\n",
      "Epoch 186/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0172 - accuracy: 0.9167 - val_loss: 0.0336 - val_accuracy: 0.7800\n",
      "Epoch 187/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0171 - accuracy: 0.9150 - val_loss: 0.0334 - val_accuracy: 0.7800\n",
      "Epoch 188/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0169 - accuracy: 0.9183 - val_loss: 0.0333 - val_accuracy: 0.7800\n",
      "Epoch 189/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0168 - accuracy: 0.9167 - val_loss: 0.0332 - val_accuracy: 0.7900\n",
      "Epoch 190/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0166 - accuracy: 0.9183 - val_loss: 0.0331 - val_accuracy: 0.7900\n",
      "Epoch 191/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0165 - accuracy: 0.9167 - val_loss: 0.0329 - val_accuracy: 0.7900\n",
      "Epoch 192/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0164 - accuracy: 0.9200 - val_loss: 0.0327 - val_accuracy: 0.7900\n",
      "Epoch 193/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0162 - accuracy: 0.9200 - val_loss: 0.0327 - val_accuracy: 0.7900\n",
      "Epoch 194/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0161 - accuracy: 0.9200 - val_loss: 0.0325 - val_accuracy: 0.7900\n",
      "Epoch 195/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0159 - accuracy: 0.9217 - val_loss: 0.0324 - val_accuracy: 0.7900\n",
      "Epoch 196/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0158 - accuracy: 0.9217 - val_loss: 0.0323 - val_accuracy: 0.7900\n",
      "Epoch 197/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0157 - accuracy: 0.9233 - val_loss: 0.0323 - val_accuracy: 0.7900\n",
      "Epoch 198/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0156 - accuracy: 0.9233 - val_loss: 0.0321 - val_accuracy: 0.7900\n",
      "Epoch 199/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0155 - accuracy: 0.9233 - val_loss: 0.0320 - val_accuracy: 0.7900\n",
      "Epoch 200/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0153 - accuracy: 0.9233 - val_loss: 0.0319 - val_accuracy: 0.8000\n",
      "Epoch 201/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0152 - accuracy: 0.9233 - val_loss: 0.0318 - val_accuracy: 0.7900\n",
      "Epoch 202/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0151 - accuracy: 0.9250 - val_loss: 0.0317 - val_accuracy: 0.7900\n",
      "Epoch 203/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0150 - accuracy: 0.9267 - val_loss: 0.0316 - val_accuracy: 0.7900\n",
      "Epoch 204/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0148 - accuracy: 0.9300 - val_loss: 0.0314 - val_accuracy: 0.8000\n",
      "Epoch 205/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0147 - accuracy: 0.9283 - val_loss: 0.0314 - val_accuracy: 0.8000\n",
      "Epoch 206/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0146 - accuracy: 0.9317 - val_loss: 0.0313 - val_accuracy: 0.8000\n",
      "Epoch 207/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0145 - accuracy: 0.9300 - val_loss: 0.0312 - val_accuracy: 0.8000\n",
      "Epoch 208/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0144 - accuracy: 0.9317 - val_loss: 0.0311 - val_accuracy: 0.8000\n",
      "Epoch 209/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0143 - accuracy: 0.9317 - val_loss: 0.0310 - val_accuracy: 0.8100\n",
      "Epoch 210/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0142 - accuracy: 0.9317 - val_loss: 0.0310 - val_accuracy: 0.8000\n",
      "Epoch 211/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0141 - accuracy: 0.9317 - val_loss: 0.0309 - val_accuracy: 0.8100\n",
      "Epoch 212/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0139 - accuracy: 0.9350 - val_loss: 0.0308 - val_accuracy: 0.8000\n",
      "Epoch 213/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0138 - accuracy: 0.9350 - val_loss: 0.0307 - val_accuracy: 0.8100\n",
      "Epoch 214/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0137 - accuracy: 0.9367 - val_loss: 0.0307 - val_accuracy: 0.8100\n",
      "Epoch 215/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0136 - accuracy: 0.9350 - val_loss: 0.0307 - val_accuracy: 0.8000\n",
      "Epoch 216/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0135 - accuracy: 0.9367 - val_loss: 0.0305 - val_accuracy: 0.8100\n",
      "Epoch 217/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0134 - accuracy: 0.9383 - val_loss: 0.0305 - val_accuracy: 0.8000\n",
      "Epoch 218/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0133 - accuracy: 0.9367 - val_loss: 0.0304 - val_accuracy: 0.8100\n",
      "Epoch 219/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0132 - accuracy: 0.9400 - val_loss: 0.0303 - val_accuracy: 0.8100\n",
      "Epoch 220/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0131 - accuracy: 0.9400 - val_loss: 0.0303 - val_accuracy: 0.8000\n",
      "Epoch 221/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0130 - accuracy: 0.9383 - val_loss: 0.0302 - val_accuracy: 0.8100\n",
      "Epoch 222/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0129 - accuracy: 0.9400 - val_loss: 0.0301 - val_accuracy: 0.8100\n",
      "Epoch 223/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0128 - accuracy: 0.9400 - val_loss: 0.0301 - val_accuracy: 0.8000\n",
      "Epoch 224/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0128 - accuracy: 0.9400 - val_loss: 0.0299 - val_accuracy: 0.8000\n",
      "Epoch 225/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0127 - accuracy: 0.9383 - val_loss: 0.0298 - val_accuracy: 0.8100\n",
      "Epoch 226/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0125 - accuracy: 0.9467 - val_loss: 0.0298 - val_accuracy: 0.8000\n",
      "Epoch 227/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0125 - accuracy: 0.9433 - val_loss: 0.0298 - val_accuracy: 0.8000\n",
      "Epoch 228/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0124 - accuracy: 0.9433 - val_loss: 0.0297 - val_accuracy: 0.8200\n",
      "Epoch 229/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0123 - accuracy: 0.9467 - val_loss: 0.0297 - val_accuracy: 0.8000\n",
      "Epoch 230/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0122 - accuracy: 0.9433 - val_loss: 0.0296 - val_accuracy: 0.8000\n",
      "Epoch 231/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0121 - accuracy: 0.9500 - val_loss: 0.0295 - val_accuracy: 0.8000\n",
      "Epoch 232/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0120 - accuracy: 0.9517 - val_loss: 0.0296 - val_accuracy: 0.8000\n",
      "Epoch 233/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0119 - accuracy: 0.9467 - val_loss: 0.0295 - val_accuracy: 0.8000\n",
      "Epoch 234/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0119 - accuracy: 0.9500 - val_loss: 0.0295 - val_accuracy: 0.8000\n",
      "Epoch 235/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0117 - accuracy: 0.9500 - val_loss: 0.0294 - val_accuracy: 0.8000\n",
      "Epoch 236/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0117 - accuracy: 0.9517 - val_loss: 0.0293 - val_accuracy: 0.8000\n",
      "Epoch 237/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0116 - accuracy: 0.9500 - val_loss: 0.0293 - val_accuracy: 0.8000\n",
      "Epoch 238/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0115 - accuracy: 0.9517 - val_loss: 0.0293 - val_accuracy: 0.8000\n",
      "Epoch 239/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0114 - accuracy: 0.9500 - val_loss: 0.0292 - val_accuracy: 0.8000\n",
      "Epoch 240/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0113 - accuracy: 0.9500 - val_loss: 0.0291 - val_accuracy: 0.8000\n",
      "Training date and time : \n",
      "2020-04-09 21:04:01\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/240\n",
      "600/600 [==============================] - 1s 2ms/sample - loss: 0.0898 - accuracy: 0.1383 - val_loss: 0.0897 - val_accuracy: 0.1600\n",
      "Epoch 2/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0897 - accuracy: 0.1467 - val_loss: 0.0896 - val_accuracy: 0.1700\n",
      "Epoch 3/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0896 - accuracy: 0.1650 - val_loss: 0.0896 - val_accuracy: 0.1700\n",
      "Epoch 4/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0895 - accuracy: 0.1800 - val_loss: 0.0895 - val_accuracy: 0.1800\n",
      "Epoch 5/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0894 - accuracy: 0.1867 - val_loss: 0.0894 - val_accuracy: 0.2100\n",
      "Epoch 6/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0893 - accuracy: 0.1983 - val_loss: 0.0893 - val_accuracy: 0.2300\n",
      "Epoch 7/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0892 - accuracy: 0.2133 - val_loss: 0.0892 - val_accuracy: 0.2300\n",
      "Epoch 8/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0891 - accuracy: 0.2250 - val_loss: 0.0891 - val_accuracy: 0.2500\n",
      "Epoch 9/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0890 - accuracy: 0.2350 - val_loss: 0.0890 - val_accuracy: 0.2500\n",
      "Epoch 10/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0889 - accuracy: 0.2467 - val_loss: 0.0890 - val_accuracy: 0.2500\n",
      "Epoch 11/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0888 - accuracy: 0.2517 - val_loss: 0.0889 - val_accuracy: 0.2500\n",
      "Epoch 12/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0886 - accuracy: 0.2683 - val_loss: 0.0888 - val_accuracy: 0.2800\n",
      "Epoch 13/240\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0885 - accuracy: 0.2833 - val_loss: 0.0887 - val_accuracy: 0.2800\n",
      "Epoch 14/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0884 - accuracy: 0.2883 - val_loss: 0.0886 - val_accuracy: 0.2800\n",
      "Epoch 15/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0883 - accuracy: 0.3000 - val_loss: 0.0885 - val_accuracy: 0.2900\n",
      "Epoch 16/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0882 - accuracy: 0.3100 - val_loss: 0.0884 - val_accuracy: 0.3000\n",
      "Epoch 17/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0880 - accuracy: 0.3217 - val_loss: 0.0883 - val_accuracy: 0.3000\n",
      "Epoch 18/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0879 - accuracy: 0.3500 - val_loss: 0.0882 - val_accuracy: 0.3100\n",
      "Epoch 19/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0878 - accuracy: 0.3583 - val_loss: 0.0881 - val_accuracy: 0.3100\n",
      "Epoch 20/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0877 - accuracy: 0.3733 - val_loss: 0.0880 - val_accuracy: 0.3100\n",
      "Epoch 21/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0875 - accuracy: 0.3817 - val_loss: 0.0879 - val_accuracy: 0.3200\n",
      "Epoch 22/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0874 - accuracy: 0.3950 - val_loss: 0.0878 - val_accuracy: 0.3200\n",
      "Epoch 23/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0872 - accuracy: 0.4067 - val_loss: 0.0876 - val_accuracy: 0.3300\n",
      "Epoch 24/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0871 - accuracy: 0.4133 - val_loss: 0.0875 - val_accuracy: 0.3400\n",
      "Epoch 25/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0869 - accuracy: 0.4300 - val_loss: 0.0874 - val_accuracy: 0.3500\n",
      "Epoch 26/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0867 - accuracy: 0.4400 - val_loss: 0.0873 - val_accuracy: 0.3500\n",
      "Epoch 27/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0866 - accuracy: 0.4450 - val_loss: 0.0871 - val_accuracy: 0.3500\n",
      "Epoch 28/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0864 - accuracy: 0.4500 - val_loss: 0.0870 - val_accuracy: 0.3600\n",
      "Epoch 29/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0862 - accuracy: 0.4533 - val_loss: 0.0868 - val_accuracy: 0.3700\n",
      "Epoch 30/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0860 - accuracy: 0.4583 - val_loss: 0.0867 - val_accuracy: 0.3700\n",
      "Epoch 31/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0858 - accuracy: 0.4667 - val_loss: 0.0865 - val_accuracy: 0.3700\n",
      "Epoch 32/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0856 - accuracy: 0.4650 - val_loss: 0.0863 - val_accuracy: 0.3800\n",
      "Epoch 33/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0854 - accuracy: 0.4717 - val_loss: 0.0861 - val_accuracy: 0.3900\n",
      "Epoch 34/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0851 - accuracy: 0.4667 - val_loss: 0.0859 - val_accuracy: 0.4000\n",
      "Epoch 35/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0849 - accuracy: 0.4700 - val_loss: 0.0857 - val_accuracy: 0.4000\n",
      "Epoch 36/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0847 - accuracy: 0.4750 - val_loss: 0.0855 - val_accuracy: 0.3900\n",
      "Epoch 37/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0844 - accuracy: 0.4767 - val_loss: 0.0853 - val_accuracy: 0.3900\n",
      "Epoch 38/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0841 - accuracy: 0.4767 - val_loss: 0.0851 - val_accuracy: 0.3800\n",
      "Epoch 39/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0838 - accuracy: 0.4817 - val_loss: 0.0848 - val_accuracy: 0.3800\n",
      "Epoch 40/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0835 - accuracy: 0.4817 - val_loss: 0.0845 - val_accuracy: 0.4000\n",
      "Epoch 41/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0832 - accuracy: 0.4850 - val_loss: 0.0843 - val_accuracy: 0.4100\n",
      "Epoch 42/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0828 - accuracy: 0.4883 - val_loss: 0.0840 - val_accuracy: 0.4200\n",
      "Epoch 43/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0825 - accuracy: 0.4867 - val_loss: 0.0837 - val_accuracy: 0.4200\n",
      "Epoch 44/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0821 - accuracy: 0.4883 - val_loss: 0.0833 - val_accuracy: 0.4200\n",
      "Epoch 45/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0817 - accuracy: 0.4883 - val_loss: 0.0830 - val_accuracy: 0.4300\n",
      "Epoch 46/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0813 - accuracy: 0.4850 - val_loss: 0.0827 - val_accuracy: 0.4300\n",
      "Epoch 47/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0808 - accuracy: 0.4817 - val_loss: 0.0823 - val_accuracy: 0.4300\n",
      "Epoch 48/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0804 - accuracy: 0.4750 - val_loss: 0.0819 - val_accuracy: 0.4300\n",
      "Epoch 49/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0799 - accuracy: 0.4817 - val_loss: 0.0815 - val_accuracy: 0.4300\n",
      "Epoch 50/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0794 - accuracy: 0.4733 - val_loss: 0.0811 - val_accuracy: 0.4300\n",
      "Epoch 51/240\n",
      "600/600 [==============================] - 0s 115us/sample - loss: 0.0789 - accuracy: 0.4783 - val_loss: 0.0807 - val_accuracy: 0.4300\n",
      "Epoch 52/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0784 - accuracy: 0.4833 - val_loss: 0.0803 - val_accuracy: 0.4400\n",
      "Epoch 53/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0779 - accuracy: 0.4900 - val_loss: 0.0799 - val_accuracy: 0.4400\n",
      "Epoch 54/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0773 - accuracy: 0.4950 - val_loss: 0.0794 - val_accuracy: 0.4500\n",
      "Epoch 55/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0768 - accuracy: 0.4917 - val_loss: 0.0790 - val_accuracy: 0.4500\n",
      "Epoch 56/240\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0762 - accuracy: 0.4900 - val_loss: 0.0785 - val_accuracy: 0.4500\n",
      "Epoch 57/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0756 - accuracy: 0.4967 - val_loss: 0.0781 - val_accuracy: 0.4500\n",
      "Epoch 58/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0750 - accuracy: 0.5017 - val_loss: 0.0776 - val_accuracy: 0.4600\n",
      "Epoch 59/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0744 - accuracy: 0.5083 - val_loss: 0.0771 - val_accuracy: 0.4600\n",
      "Epoch 60/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0738 - accuracy: 0.5117 - val_loss: 0.0767 - val_accuracy: 0.4600\n",
      "Epoch 61/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0732 - accuracy: 0.5167 - val_loss: 0.0762 - val_accuracy: 0.4700\n",
      "Epoch 62/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0725 - accuracy: 0.5233 - val_loss: 0.0757 - val_accuracy: 0.4800\n",
      "Epoch 63/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0719 - accuracy: 0.5333 - val_loss: 0.0752 - val_accuracy: 0.4800\n",
      "Epoch 64/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0712 - accuracy: 0.5417 - val_loss: 0.0746 - val_accuracy: 0.4900\n",
      "Epoch 65/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0706 - accuracy: 0.5500 - val_loss: 0.0741 - val_accuracy: 0.5200\n",
      "Epoch 66/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0699 - accuracy: 0.5533 - val_loss: 0.0736 - val_accuracy: 0.5200\n",
      "Epoch 67/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0692 - accuracy: 0.5600 - val_loss: 0.0730 - val_accuracy: 0.5200\n",
      "Epoch 68/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0685 - accuracy: 0.5617 - val_loss: 0.0725 - val_accuracy: 0.5200\n",
      "Epoch 69/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0678 - accuracy: 0.5683 - val_loss: 0.0719 - val_accuracy: 0.5200\n",
      "Epoch 70/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0671 - accuracy: 0.5767 - val_loss: 0.0714 - val_accuracy: 0.5200\n",
      "Epoch 71/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0663 - accuracy: 0.5783 - val_loss: 0.0708 - val_accuracy: 0.5400\n",
      "Epoch 72/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0656 - accuracy: 0.5850 - val_loss: 0.0703 - val_accuracy: 0.5500\n",
      "Epoch 73/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0649 - accuracy: 0.5917 - val_loss: 0.0697 - val_accuracy: 0.5700\n",
      "Epoch 74/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0642 - accuracy: 0.5917 - val_loss: 0.0691 - val_accuracy: 0.6000\n",
      "Epoch 75/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0634 - accuracy: 0.5967 - val_loss: 0.0686 - val_accuracy: 0.6000\n",
      "Epoch 76/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0627 - accuracy: 0.6033 - val_loss: 0.0680 - val_accuracy: 0.6000\n",
      "Epoch 77/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0619 - accuracy: 0.6083 - val_loss: 0.0674 - val_accuracy: 0.6000\n",
      "Epoch 78/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0612 - accuracy: 0.6167 - val_loss: 0.0669 - val_accuracy: 0.6000\n",
      "Epoch 79/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0604 - accuracy: 0.6217 - val_loss: 0.0663 - val_accuracy: 0.6000\n",
      "Epoch 80/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0596 - accuracy: 0.6300 - val_loss: 0.0657 - val_accuracy: 0.6200\n",
      "Epoch 81/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0589 - accuracy: 0.6367 - val_loss: 0.0651 - val_accuracy: 0.6200\n",
      "Epoch 82/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0581 - accuracy: 0.6433 - val_loss: 0.0645 - val_accuracy: 0.6200\n",
      "Epoch 83/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0574 - accuracy: 0.6450 - val_loss: 0.0640 - val_accuracy: 0.6300\n",
      "Epoch 84/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0566 - accuracy: 0.6483 - val_loss: 0.0634 - val_accuracy: 0.6400\n",
      "Epoch 85/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0558 - accuracy: 0.6533 - val_loss: 0.0628 - val_accuracy: 0.6400\n",
      "Epoch 86/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0551 - accuracy: 0.6617 - val_loss: 0.0622 - val_accuracy: 0.6400\n",
      "Epoch 87/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0543 - accuracy: 0.6733 - val_loss: 0.0617 - val_accuracy: 0.6400\n",
      "Epoch 88/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0535 - accuracy: 0.6817 - val_loss: 0.0611 - val_accuracy: 0.6400\n",
      "Epoch 89/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0528 - accuracy: 0.6867 - val_loss: 0.0605 - val_accuracy: 0.6400\n",
      "Epoch 90/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0520 - accuracy: 0.6917 - val_loss: 0.0600 - val_accuracy: 0.6500\n",
      "Epoch 91/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0513 - accuracy: 0.6967 - val_loss: 0.0595 - val_accuracy: 0.6500\n",
      "Epoch 92/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0506 - accuracy: 0.6983 - val_loss: 0.0590 - val_accuracy: 0.6500\n",
      "Epoch 93/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0498 - accuracy: 0.7100 - val_loss: 0.0584 - val_accuracy: 0.6500\n",
      "Epoch 94/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0492 - accuracy: 0.7150 - val_loss: 0.0579 - val_accuracy: 0.6500\n",
      "Epoch 95/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0484 - accuracy: 0.7217 - val_loss: 0.0575 - val_accuracy: 0.6500\n",
      "Epoch 96/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0477 - accuracy: 0.7200 - val_loss: 0.0570 - val_accuracy: 0.6500\n",
      "Epoch 97/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0471 - accuracy: 0.7267 - val_loss: 0.0565 - val_accuracy: 0.6500\n",
      "Epoch 98/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0464 - accuracy: 0.7300 - val_loss: 0.0561 - val_accuracy: 0.6500\n",
      "Epoch 99/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0457 - accuracy: 0.7383 - val_loss: 0.0556 - val_accuracy: 0.6600\n",
      "Epoch 100/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0451 - accuracy: 0.7483 - val_loss: 0.0552 - val_accuracy: 0.6700\n",
      "Epoch 101/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0445 - accuracy: 0.7517 - val_loss: 0.0548 - val_accuracy: 0.6700\n",
      "Epoch 102/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0438 - accuracy: 0.7583 - val_loss: 0.0544 - val_accuracy: 0.6800\n",
      "Epoch 103/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0432 - accuracy: 0.7633 - val_loss: 0.0540 - val_accuracy: 0.6800\n",
      "Epoch 104/240\n",
      "600/600 [==============================] - 0s 117us/sample - loss: 0.0426 - accuracy: 0.7700 - val_loss: 0.0536 - val_accuracy: 0.6800\n",
      "Epoch 105/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0420 - accuracy: 0.7733 - val_loss: 0.0532 - val_accuracy: 0.6800\n",
      "Epoch 106/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0414 - accuracy: 0.7767 - val_loss: 0.0529 - val_accuracy: 0.6700\n",
      "Epoch 107/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0409 - accuracy: 0.7767 - val_loss: 0.0525 - val_accuracy: 0.6600\n",
      "Epoch 108/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0403 - accuracy: 0.7783 - val_loss: 0.0521 - val_accuracy: 0.6700\n",
      "Epoch 109/240\n",
      "600/600 [==============================] - 0s 120us/sample - loss: 0.0397 - accuracy: 0.7783 - val_loss: 0.0517 - val_accuracy: 0.6600\n",
      "Epoch 110/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0392 - accuracy: 0.7800 - val_loss: 0.0513 - val_accuracy: 0.6700\n",
      "Epoch 111/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0387 - accuracy: 0.7850 - val_loss: 0.0510 - val_accuracy: 0.6700\n",
      "Epoch 112/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0381 - accuracy: 0.7850 - val_loss: 0.0506 - val_accuracy: 0.6700\n",
      "Epoch 113/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0376 - accuracy: 0.7867 - val_loss: 0.0503 - val_accuracy: 0.6600\n",
      "Epoch 114/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0371 - accuracy: 0.7850 - val_loss: 0.0500 - val_accuracy: 0.6800\n",
      "Epoch 115/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0367 - accuracy: 0.7850 - val_loss: 0.0497 - val_accuracy: 0.6800\n",
      "Epoch 116/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0362 - accuracy: 0.7900 - val_loss: 0.0494 - val_accuracy: 0.6800\n",
      "Epoch 117/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0357 - accuracy: 0.7917 - val_loss: 0.0491 - val_accuracy: 0.6800\n",
      "Epoch 118/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0353 - accuracy: 0.7933 - val_loss: 0.0488 - val_accuracy: 0.6800\n",
      "Epoch 119/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0349 - accuracy: 0.7950 - val_loss: 0.0484 - val_accuracy: 0.6900\n",
      "Epoch 120/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0344 - accuracy: 0.7967 - val_loss: 0.0481 - val_accuracy: 0.6900\n",
      "Epoch 121/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0340 - accuracy: 0.8000 - val_loss: 0.0478 - val_accuracy: 0.6900\n",
      "Epoch 122/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0336 - accuracy: 0.7967 - val_loss: 0.0475 - val_accuracy: 0.6900\n",
      "Epoch 123/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0332 - accuracy: 0.8017 - val_loss: 0.0472 - val_accuracy: 0.6900\n",
      "Epoch 124/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0328 - accuracy: 0.7967 - val_loss: 0.0469 - val_accuracy: 0.6900\n",
      "Epoch 125/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0325 - accuracy: 0.8017 - val_loss: 0.0467 - val_accuracy: 0.6900\n",
      "Epoch 126/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0321 - accuracy: 0.8017 - val_loss: 0.0464 - val_accuracy: 0.6900\n",
      "Epoch 127/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0317 - accuracy: 0.8067 - val_loss: 0.0461 - val_accuracy: 0.6900\n",
      "Epoch 128/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0314 - accuracy: 0.8067 - val_loss: 0.0458 - val_accuracy: 0.6900\n",
      "Epoch 129/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0310 - accuracy: 0.8167 - val_loss: 0.0454 - val_accuracy: 0.7000\n",
      "Epoch 130/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0307 - accuracy: 0.8183 - val_loss: 0.0452 - val_accuracy: 0.6900\n",
      "Epoch 131/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0303 - accuracy: 0.8200 - val_loss: 0.0449 - val_accuracy: 0.6900\n",
      "Epoch 132/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0300 - accuracy: 0.8250 - val_loss: 0.0446 - val_accuracy: 0.6900\n",
      "Epoch 133/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0297 - accuracy: 0.8300 - val_loss: 0.0443 - val_accuracy: 0.7000\n",
      "Epoch 134/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0293 - accuracy: 0.8350 - val_loss: 0.0440 - val_accuracy: 0.7000\n",
      "Epoch 135/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0290 - accuracy: 0.8350 - val_loss: 0.0438 - val_accuracy: 0.7000\n",
      "Epoch 136/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0287 - accuracy: 0.8433 - val_loss: 0.0435 - val_accuracy: 0.6900\n",
      "Epoch 137/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0284 - accuracy: 0.8400 - val_loss: 0.0432 - val_accuracy: 0.7100\n",
      "Epoch 138/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0281 - accuracy: 0.8467 - val_loss: 0.0429 - val_accuracy: 0.7100\n",
      "Epoch 139/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0278 - accuracy: 0.8483 - val_loss: 0.0427 - val_accuracy: 0.7100\n",
      "Epoch 140/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0275 - accuracy: 0.8483 - val_loss: 0.0424 - val_accuracy: 0.7100\n",
      "Epoch 141/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0272 - accuracy: 0.8517 - val_loss: 0.0422 - val_accuracy: 0.7100\n",
      "Epoch 142/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0270 - accuracy: 0.8533 - val_loss: 0.0420 - val_accuracy: 0.7100\n",
      "Epoch 143/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0267 - accuracy: 0.8550 - val_loss: 0.0417 - val_accuracy: 0.7100\n",
      "Epoch 144/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0264 - accuracy: 0.8567 - val_loss: 0.0415 - val_accuracy: 0.7200\n",
      "Epoch 145/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0261 - accuracy: 0.8650 - val_loss: 0.0412 - val_accuracy: 0.7200\n",
      "Epoch 146/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0259 - accuracy: 0.8650 - val_loss: 0.0410 - val_accuracy: 0.7200\n",
      "Epoch 147/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0256 - accuracy: 0.8650 - val_loss: 0.0408 - val_accuracy: 0.7200\n",
      "Epoch 148/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0254 - accuracy: 0.8667 - val_loss: 0.0405 - val_accuracy: 0.7300\n",
      "Epoch 149/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0251 - accuracy: 0.8667 - val_loss: 0.0403 - val_accuracy: 0.7200\n",
      "Epoch 150/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0249 - accuracy: 0.8700 - val_loss: 0.0400 - val_accuracy: 0.7400\n",
      "Epoch 151/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0246 - accuracy: 0.8683 - val_loss: 0.0398 - val_accuracy: 0.7400\n",
      "Epoch 152/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0244 - accuracy: 0.8700 - val_loss: 0.0396 - val_accuracy: 0.7400\n",
      "Epoch 153/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0242 - accuracy: 0.8717 - val_loss: 0.0394 - val_accuracy: 0.7400\n",
      "Epoch 154/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0239 - accuracy: 0.8733 - val_loss: 0.0392 - val_accuracy: 0.7400\n",
      "Epoch 155/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0237 - accuracy: 0.8750 - val_loss: 0.0389 - val_accuracy: 0.7400\n",
      "Epoch 156/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0235 - accuracy: 0.8767 - val_loss: 0.0387 - val_accuracy: 0.7400\n",
      "Epoch 157/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0232 - accuracy: 0.8767 - val_loss: 0.0386 - val_accuracy: 0.7400\n",
      "Epoch 158/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0230 - accuracy: 0.8767 - val_loss: 0.0383 - val_accuracy: 0.7400\n",
      "Epoch 159/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0228 - accuracy: 0.8767 - val_loss: 0.0381 - val_accuracy: 0.7400\n",
      "Epoch 160/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0226 - accuracy: 0.8783 - val_loss: 0.0379 - val_accuracy: 0.7400\n",
      "Epoch 161/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0224 - accuracy: 0.8800 - val_loss: 0.0378 - val_accuracy: 0.7400\n",
      "Epoch 162/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0222 - accuracy: 0.8800 - val_loss: 0.0376 - val_accuracy: 0.7400\n",
      "Epoch 163/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0220 - accuracy: 0.8833 - val_loss: 0.0374 - val_accuracy: 0.7400\n",
      "Epoch 164/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0218 - accuracy: 0.8817 - val_loss: 0.0373 - val_accuracy: 0.7400\n",
      "Epoch 165/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0216 - accuracy: 0.8817 - val_loss: 0.0371 - val_accuracy: 0.7400\n",
      "Epoch 166/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0214 - accuracy: 0.8833 - val_loss: 0.0369 - val_accuracy: 0.7400\n",
      "Epoch 167/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0212 - accuracy: 0.8883 - val_loss: 0.0367 - val_accuracy: 0.7500\n",
      "Epoch 168/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0210 - accuracy: 0.8917 - val_loss: 0.0365 - val_accuracy: 0.7500\n",
      "Epoch 169/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0208 - accuracy: 0.8933 - val_loss: 0.0364 - val_accuracy: 0.7600\n",
      "Epoch 170/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0206 - accuracy: 0.8967 - val_loss: 0.0362 - val_accuracy: 0.7600\n",
      "Epoch 171/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0204 - accuracy: 0.8967 - val_loss: 0.0360 - val_accuracy: 0.7600\n",
      "Epoch 172/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0203 - accuracy: 0.8967 - val_loss: 0.0359 - val_accuracy: 0.7600\n",
      "Epoch 173/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0201 - accuracy: 0.8950 - val_loss: 0.0357 - val_accuracy: 0.7700\n",
      "Epoch 174/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0199 - accuracy: 0.8983 - val_loss: 0.0355 - val_accuracy: 0.7700\n",
      "Epoch 175/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0198 - accuracy: 0.8983 - val_loss: 0.0354 - val_accuracy: 0.7700\n",
      "Epoch 176/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0195 - accuracy: 0.8983 - val_loss: 0.0352 - val_accuracy: 0.7700\n",
      "Epoch 177/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0194 - accuracy: 0.9000 - val_loss: 0.0351 - val_accuracy: 0.7700\n",
      "Epoch 178/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0192 - accuracy: 0.9000 - val_loss: 0.0349 - val_accuracy: 0.7700\n",
      "Epoch 179/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0190 - accuracy: 0.9000 - val_loss: 0.0348 - val_accuracy: 0.7800\n",
      "Epoch 180/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0189 - accuracy: 0.9017 - val_loss: 0.0346 - val_accuracy: 0.7700\n",
      "Epoch 181/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0187 - accuracy: 0.9017 - val_loss: 0.0344 - val_accuracy: 0.7700\n",
      "Epoch 182/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0186 - accuracy: 0.8983 - val_loss: 0.0343 - val_accuracy: 0.7700\n",
      "Epoch 183/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0184 - accuracy: 0.9017 - val_loss: 0.0342 - val_accuracy: 0.7800\n",
      "Epoch 184/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0182 - accuracy: 0.9050 - val_loss: 0.0340 - val_accuracy: 0.7800\n",
      "Epoch 185/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0181 - accuracy: 0.9067 - val_loss: 0.0340 - val_accuracy: 0.7900\n",
      "Epoch 186/240\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0179 - accuracy: 0.9050 - val_loss: 0.0339 - val_accuracy: 0.7900\n",
      "Epoch 187/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0178 - accuracy: 0.9067 - val_loss: 0.0338 - val_accuracy: 0.7900\n",
      "Epoch 188/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0176 - accuracy: 0.9117 - val_loss: 0.0336 - val_accuracy: 0.7900\n",
      "Epoch 189/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0175 - accuracy: 0.9083 - val_loss: 0.0335 - val_accuracy: 0.8000\n",
      "Epoch 190/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0174 - accuracy: 0.9083 - val_loss: 0.0334 - val_accuracy: 0.7900\n",
      "Epoch 191/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0172 - accuracy: 0.9117 - val_loss: 0.0332 - val_accuracy: 0.7900\n",
      "Epoch 192/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0171 - accuracy: 0.9133 - val_loss: 0.0330 - val_accuracy: 0.7900\n",
      "Epoch 193/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0169 - accuracy: 0.9150 - val_loss: 0.0330 - val_accuracy: 0.7900\n",
      "Epoch 194/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0168 - accuracy: 0.9150 - val_loss: 0.0328 - val_accuracy: 0.7800\n",
      "Epoch 195/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0166 - accuracy: 0.9183 - val_loss: 0.0327 - val_accuracy: 0.7900\n",
      "Epoch 196/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0165 - accuracy: 0.9200 - val_loss: 0.0326 - val_accuracy: 0.8000\n",
      "Epoch 197/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0164 - accuracy: 0.9167 - val_loss: 0.0325 - val_accuracy: 0.8000\n",
      "Epoch 198/240\n",
      "600/600 [==============================] - 0s 115us/sample - loss: 0.0162 - accuracy: 0.9167 - val_loss: 0.0324 - val_accuracy: 0.8000\n",
      "Epoch 199/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0161 - accuracy: 0.9183 - val_loss: 0.0323 - val_accuracy: 0.8100\n",
      "Epoch 200/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0160 - accuracy: 0.9183 - val_loss: 0.0321 - val_accuracy: 0.8100\n",
      "Epoch 201/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0159 - accuracy: 0.9183 - val_loss: 0.0320 - val_accuracy: 0.8100\n",
      "Epoch 202/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0157 - accuracy: 0.9183 - val_loss: 0.0319 - val_accuracy: 0.7900\n",
      "Epoch 203/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0156 - accuracy: 0.9217 - val_loss: 0.0318 - val_accuracy: 0.8100\n",
      "Epoch 204/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0155 - accuracy: 0.9233 - val_loss: 0.0317 - val_accuracy: 0.8100\n",
      "Epoch 205/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0154 - accuracy: 0.9217 - val_loss: 0.0316 - val_accuracy: 0.8100\n",
      "Epoch 206/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0153 - accuracy: 0.9250 - val_loss: 0.0315 - val_accuracy: 0.8100\n",
      "Epoch 207/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0151 - accuracy: 0.9250 - val_loss: 0.0314 - val_accuracy: 0.8100\n",
      "Epoch 208/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0150 - accuracy: 0.9283 - val_loss: 0.0313 - val_accuracy: 0.8100\n",
      "Epoch 209/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0149 - accuracy: 0.9267 - val_loss: 0.0312 - val_accuracy: 0.8100\n",
      "Epoch 210/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0148 - accuracy: 0.9267 - val_loss: 0.0311 - val_accuracy: 0.8100\n",
      "Epoch 211/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0147 - accuracy: 0.9300 - val_loss: 0.0310 - val_accuracy: 0.8100\n",
      "Epoch 212/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0145 - accuracy: 0.9300 - val_loss: 0.0309 - val_accuracy: 0.8100\n",
      "Epoch 213/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0144 - accuracy: 0.9333 - val_loss: 0.0309 - val_accuracy: 0.8100\n",
      "Epoch 214/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0143 - accuracy: 0.9317 - val_loss: 0.0308 - val_accuracy: 0.8100\n",
      "Epoch 215/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0142 - accuracy: 0.9300 - val_loss: 0.0308 - val_accuracy: 0.8100\n",
      "Epoch 216/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0141 - accuracy: 0.9333 - val_loss: 0.0306 - val_accuracy: 0.8100\n",
      "Epoch 217/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0140 - accuracy: 0.9367 - val_loss: 0.0306 - val_accuracy: 0.8100\n",
      "Epoch 218/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0139 - accuracy: 0.9333 - val_loss: 0.0305 - val_accuracy: 0.8100\n",
      "Epoch 219/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0138 - accuracy: 0.9350 - val_loss: 0.0304 - val_accuracy: 0.8100\n",
      "Epoch 220/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0137 - accuracy: 0.9383 - val_loss: 0.0304 - val_accuracy: 0.8100\n",
      "Epoch 221/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0136 - accuracy: 0.9367 - val_loss: 0.0302 - val_accuracy: 0.8100\n",
      "Epoch 222/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0135 - accuracy: 0.9367 - val_loss: 0.0302 - val_accuracy: 0.8100\n",
      "Epoch 223/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0134 - accuracy: 0.9383 - val_loss: 0.0301 - val_accuracy: 0.8100\n",
      "Epoch 224/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0133 - accuracy: 0.9383 - val_loss: 0.0299 - val_accuracy: 0.8100\n",
      "Epoch 225/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0132 - accuracy: 0.9383 - val_loss: 0.0299 - val_accuracy: 0.8100\n",
      "Epoch 226/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0131 - accuracy: 0.9400 - val_loss: 0.0298 - val_accuracy: 0.8100\n",
      "Epoch 227/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0130 - accuracy: 0.9417 - val_loss: 0.0298 - val_accuracy: 0.8100\n",
      "Epoch 228/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0129 - accuracy: 0.9417 - val_loss: 0.0297 - val_accuracy: 0.8100\n",
      "Epoch 229/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0128 - accuracy: 0.9383 - val_loss: 0.0297 - val_accuracy: 0.8100\n",
      "Epoch 230/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0127 - accuracy: 0.9433 - val_loss: 0.0295 - val_accuracy: 0.8100\n",
      "Epoch 231/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0126 - accuracy: 0.9450 - val_loss: 0.0295 - val_accuracy: 0.8100\n",
      "Epoch 232/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0125 - accuracy: 0.9433 - val_loss: 0.0296 - val_accuracy: 0.8200\n",
      "Epoch 233/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0124 - accuracy: 0.9433 - val_loss: 0.0295 - val_accuracy: 0.8100\n",
      "Epoch 234/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0124 - accuracy: 0.9450 - val_loss: 0.0294 - val_accuracy: 0.8200\n",
      "Epoch 235/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0122 - accuracy: 0.9450 - val_loss: 0.0293 - val_accuracy: 0.8100\n",
      "Epoch 236/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0122 - accuracy: 0.9483 - val_loss: 0.0293 - val_accuracy: 0.8100\n",
      "Epoch 237/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0121 - accuracy: 0.9450 - val_loss: 0.0292 - val_accuracy: 0.8200\n",
      "Epoch 238/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0120 - accuracy: 0.9467 - val_loss: 0.0292 - val_accuracy: 0.8200\n",
      "Epoch 239/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0119 - accuracy: 0.9467 - val_loss: 0.0291 - val_accuracy: 0.8200\n",
      "Epoch 240/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0118 - accuracy: 0.9467 - val_loss: 0.0290 - val_accuracy: 0.8200\n",
      "Training date and time : \n",
      "2020-04-09 21:04:18\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/240\n",
      "600/600 [==============================] - 0s 708us/sample - loss: 0.0898 - accuracy: 0.1600 - val_loss: 0.0898 - val_accuracy: 0.1500\n",
      "Epoch 2/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0897 - accuracy: 0.1717 - val_loss: 0.0897 - val_accuracy: 0.1600\n",
      "Epoch 3/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0896 - accuracy: 0.1783 - val_loss: 0.0896 - val_accuracy: 0.1700\n",
      "Epoch 4/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0895 - accuracy: 0.1967 - val_loss: 0.0895 - val_accuracy: 0.1900\n",
      "Epoch 5/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0894 - accuracy: 0.2083 - val_loss: 0.0895 - val_accuracy: 0.2200\n",
      "Epoch 6/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0893 - accuracy: 0.2183 - val_loss: 0.0894 - val_accuracy: 0.2400\n",
      "Epoch 7/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0892 - accuracy: 0.2317 - val_loss: 0.0893 - val_accuracy: 0.2300\n",
      "Epoch 8/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0891 - accuracy: 0.2400 - val_loss: 0.0892 - val_accuracy: 0.2300\n",
      "Epoch 9/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0890 - accuracy: 0.2433 - val_loss: 0.0891 - val_accuracy: 0.2300\n",
      "Epoch 10/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0889 - accuracy: 0.2483 - val_loss: 0.0891 - val_accuracy: 0.2300\n",
      "Epoch 11/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0888 - accuracy: 0.2517 - val_loss: 0.0890 - val_accuracy: 0.2600\n",
      "Epoch 12/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0887 - accuracy: 0.2500 - val_loss: 0.0889 - val_accuracy: 0.2700\n",
      "Epoch 13/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0886 - accuracy: 0.2550 - val_loss: 0.0888 - val_accuracy: 0.2700\n",
      "Epoch 14/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0885 - accuracy: 0.2700 - val_loss: 0.0887 - val_accuracy: 0.2800\n",
      "Epoch 15/240\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0884 - accuracy: 0.2817 - val_loss: 0.0886 - val_accuracy: 0.2800\n",
      "Epoch 16/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0883 - accuracy: 0.2900 - val_loss: 0.0885 - val_accuracy: 0.2900\n",
      "Epoch 17/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0881 - accuracy: 0.3017 - val_loss: 0.0884 - val_accuracy: 0.3000\n",
      "Epoch 18/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0880 - accuracy: 0.3233 - val_loss: 0.0883 - val_accuracy: 0.3000\n",
      "Epoch 19/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0879 - accuracy: 0.3417 - val_loss: 0.0882 - val_accuracy: 0.3200\n",
      "Epoch 20/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0878 - accuracy: 0.3567 - val_loss: 0.0881 - val_accuracy: 0.3300\n",
      "Epoch 21/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0876 - accuracy: 0.3600 - val_loss: 0.0880 - val_accuracy: 0.3300\n",
      "Epoch 22/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0875 - accuracy: 0.3717 - val_loss: 0.0879 - val_accuracy: 0.3300\n",
      "Epoch 23/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0873 - accuracy: 0.3800 - val_loss: 0.0878 - val_accuracy: 0.3200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0872 - accuracy: 0.3900 - val_loss: 0.0877 - val_accuracy: 0.3300\n",
      "Epoch 25/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0870 - accuracy: 0.4033 - val_loss: 0.0876 - val_accuracy: 0.3400\n",
      "Epoch 26/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0869 - accuracy: 0.4117 - val_loss: 0.0874 - val_accuracy: 0.3500\n",
      "Epoch 27/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0867 - accuracy: 0.4150 - val_loss: 0.0873 - val_accuracy: 0.3500\n",
      "Epoch 28/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0866 - accuracy: 0.4267 - val_loss: 0.0872 - val_accuracy: 0.3500\n",
      "Epoch 29/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0864 - accuracy: 0.4300 - val_loss: 0.0870 - val_accuracy: 0.3500\n",
      "Epoch 30/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0862 - accuracy: 0.4383 - val_loss: 0.0869 - val_accuracy: 0.3400\n",
      "Epoch 31/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0860 - accuracy: 0.4450 - val_loss: 0.0867 - val_accuracy: 0.3500\n",
      "Epoch 32/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0858 - accuracy: 0.4483 - val_loss: 0.0865 - val_accuracy: 0.3500\n",
      "Epoch 33/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0856 - accuracy: 0.4567 - val_loss: 0.0863 - val_accuracy: 0.3700\n",
      "Epoch 34/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0854 - accuracy: 0.4583 - val_loss: 0.0862 - val_accuracy: 0.3700\n",
      "Epoch 35/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0851 - accuracy: 0.4617 - val_loss: 0.0860 - val_accuracy: 0.3700\n",
      "Epoch 36/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0849 - accuracy: 0.4650 - val_loss: 0.0858 - val_accuracy: 0.3800\n",
      "Epoch 37/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0846 - accuracy: 0.4583 - val_loss: 0.0855 - val_accuracy: 0.3800\n",
      "Epoch 38/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0844 - accuracy: 0.4650 - val_loss: 0.0853 - val_accuracy: 0.3700\n",
      "Epoch 39/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0841 - accuracy: 0.4667 - val_loss: 0.0851 - val_accuracy: 0.3700\n",
      "Epoch 40/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0838 - accuracy: 0.4617 - val_loss: 0.0848 - val_accuracy: 0.3700\n",
      "Epoch 41/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0835 - accuracy: 0.4617 - val_loss: 0.0845 - val_accuracy: 0.3700\n",
      "Epoch 42/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0831 - accuracy: 0.4633 - val_loss: 0.0843 - val_accuracy: 0.3700\n",
      "Epoch 43/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0828 - accuracy: 0.4583 - val_loss: 0.0840 - val_accuracy: 0.3700\n",
      "Epoch 44/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0824 - accuracy: 0.4600 - val_loss: 0.0837 - val_accuracy: 0.3700\n",
      "Epoch 45/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0820 - accuracy: 0.4617 - val_loss: 0.0833 - val_accuracy: 0.3700\n",
      "Epoch 46/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0816 - accuracy: 0.4533 - val_loss: 0.0830 - val_accuracy: 0.3700\n",
      "Epoch 47/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0812 - accuracy: 0.4517 - val_loss: 0.0827 - val_accuracy: 0.3700\n",
      "Epoch 48/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0808 - accuracy: 0.4467 - val_loss: 0.0823 - val_accuracy: 0.4000\n",
      "Epoch 49/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0803 - accuracy: 0.4533 - val_loss: 0.0819 - val_accuracy: 0.4100\n",
      "Epoch 50/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0799 - accuracy: 0.4483 - val_loss: 0.0816 - val_accuracy: 0.4200\n",
      "Epoch 51/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0794 - accuracy: 0.4533 - val_loss: 0.0812 - val_accuracy: 0.4200\n",
      "Epoch 52/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0789 - accuracy: 0.4567 - val_loss: 0.0808 - val_accuracy: 0.4200\n",
      "Epoch 53/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0784 - accuracy: 0.4633 - val_loss: 0.0804 - val_accuracy: 0.4200\n",
      "Epoch 54/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0779 - accuracy: 0.4717 - val_loss: 0.0800 - val_accuracy: 0.4200\n",
      "Epoch 55/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0774 - accuracy: 0.4717 - val_loss: 0.0796 - val_accuracy: 0.4400\n",
      "Epoch 56/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0769 - accuracy: 0.4717 - val_loss: 0.0792 - val_accuracy: 0.4500\n",
      "Epoch 57/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0763 - accuracy: 0.4800 - val_loss: 0.0787 - val_accuracy: 0.4500\n",
      "Epoch 58/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0758 - accuracy: 0.4817 - val_loss: 0.0783 - val_accuracy: 0.4500\n",
      "Epoch 59/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0752 - accuracy: 0.4867 - val_loss: 0.0778 - val_accuracy: 0.4500\n",
      "Epoch 60/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0747 - accuracy: 0.4933 - val_loss: 0.0774 - val_accuracy: 0.4600\n",
      "Epoch 61/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0741 - accuracy: 0.4967 - val_loss: 0.0769 - val_accuracy: 0.4700\n",
      "Epoch 62/240\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0735 - accuracy: 0.5017 - val_loss: 0.0765 - val_accuracy: 0.4700\n",
      "Epoch 63/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0729 - accuracy: 0.5100 - val_loss: 0.0760 - val_accuracy: 0.4900\n",
      "Epoch 64/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0723 - accuracy: 0.5217 - val_loss: 0.0755 - val_accuracy: 0.4900\n",
      "Epoch 65/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0717 - accuracy: 0.5283 - val_loss: 0.0750 - val_accuracy: 0.4900\n",
      "Epoch 66/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0710 - accuracy: 0.5333 - val_loss: 0.0745 - val_accuracy: 0.5000\n",
      "Epoch 67/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0704 - accuracy: 0.5400 - val_loss: 0.0740 - val_accuracy: 0.5000\n",
      "Epoch 68/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0697 - accuracy: 0.5483 - val_loss: 0.0735 - val_accuracy: 0.5000\n",
      "Epoch 69/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0691 - accuracy: 0.5533 - val_loss: 0.0730 - val_accuracy: 0.5100\n",
      "Epoch 70/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0684 - accuracy: 0.5583 - val_loss: 0.0725 - val_accuracy: 0.5300\n",
      "Epoch 71/240\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0677 - accuracy: 0.5633 - val_loss: 0.0719 - val_accuracy: 0.5300\n",
      "Epoch 72/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0671 - accuracy: 0.5750 - val_loss: 0.0714 - val_accuracy: 0.5300\n",
      "Epoch 73/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0664 - accuracy: 0.5817 - val_loss: 0.0709 - val_accuracy: 0.5400\n",
      "Epoch 74/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0657 - accuracy: 0.5867 - val_loss: 0.0703 - val_accuracy: 0.5400\n",
      "Epoch 75/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0650 - accuracy: 0.5917 - val_loss: 0.0698 - val_accuracy: 0.5600\n",
      "Epoch 76/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0642 - accuracy: 0.5933 - val_loss: 0.0692 - val_accuracy: 0.5700\n",
      "Epoch 77/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0635 - accuracy: 0.6050 - val_loss: 0.0687 - val_accuracy: 0.5800\n",
      "Epoch 78/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0628 - accuracy: 0.6067 - val_loss: 0.0681 - val_accuracy: 0.5900\n",
      "Epoch 79/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0621 - accuracy: 0.6117 - val_loss: 0.0676 - val_accuracy: 0.5900\n",
      "Epoch 80/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0613 - accuracy: 0.6183 - val_loss: 0.0670 - val_accuracy: 0.6000\n",
      "Epoch 81/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0606 - accuracy: 0.6267 - val_loss: 0.0665 - val_accuracy: 0.6100\n",
      "Epoch 82/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0598 - accuracy: 0.6333 - val_loss: 0.0659 - val_accuracy: 0.6100\n",
      "Epoch 83/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0591 - accuracy: 0.6433 - val_loss: 0.0653 - val_accuracy: 0.6200\n",
      "Epoch 84/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0583 - accuracy: 0.6600 - val_loss: 0.0648 - val_accuracy: 0.6200\n",
      "Epoch 85/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0575 - accuracy: 0.6617 - val_loss: 0.0642 - val_accuracy: 0.6200\n",
      "Epoch 86/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0568 - accuracy: 0.6650 - val_loss: 0.0636 - val_accuracy: 0.6400\n",
      "Epoch 87/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0560 - accuracy: 0.6783 - val_loss: 0.0631 - val_accuracy: 0.6400\n",
      "Epoch 88/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0553 - accuracy: 0.6883 - val_loss: 0.0625 - val_accuracy: 0.6400\n",
      "Epoch 89/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0545 - accuracy: 0.6883 - val_loss: 0.0619 - val_accuracy: 0.6400\n",
      "Epoch 90/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0537 - accuracy: 0.6967 - val_loss: 0.0613 - val_accuracy: 0.6400\n",
      "Epoch 91/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0530 - accuracy: 0.6983 - val_loss: 0.0608 - val_accuracy: 0.6500\n",
      "Epoch 92/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0522 - accuracy: 0.6967 - val_loss: 0.0603 - val_accuracy: 0.6500\n",
      "Epoch 93/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0514 - accuracy: 0.7067 - val_loss: 0.0597 - val_accuracy: 0.6500\n",
      "Epoch 94/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0507 - accuracy: 0.7083 - val_loss: 0.0592 - val_accuracy: 0.6500\n",
      "Epoch 95/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0500 - accuracy: 0.7167 - val_loss: 0.0587 - val_accuracy: 0.6500\n",
      "Epoch 96/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0492 - accuracy: 0.7183 - val_loss: 0.0582 - val_accuracy: 0.6500\n",
      "Epoch 97/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0485 - accuracy: 0.7233 - val_loss: 0.0577 - val_accuracy: 0.6600\n",
      "Epoch 98/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0478 - accuracy: 0.7233 - val_loss: 0.0572 - val_accuracy: 0.6600\n",
      "Epoch 99/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0471 - accuracy: 0.7300 - val_loss: 0.0567 - val_accuracy: 0.6600\n",
      "Epoch 100/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0464 - accuracy: 0.7417 - val_loss: 0.0563 - val_accuracy: 0.6600\n",
      "Epoch 101/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0458 - accuracy: 0.7433 - val_loss: 0.0558 - val_accuracy: 0.6700\n",
      "Epoch 102/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0451 - accuracy: 0.7533 - val_loss: 0.0554 - val_accuracy: 0.6700\n",
      "Epoch 103/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0445 - accuracy: 0.7650 - val_loss: 0.0550 - val_accuracy: 0.6700\n",
      "Epoch 104/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0438 - accuracy: 0.7650 - val_loss: 0.0545 - val_accuracy: 0.6800\n",
      "Epoch 105/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0432 - accuracy: 0.7700 - val_loss: 0.0541 - val_accuracy: 0.6800\n",
      "Epoch 106/240\n",
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0426 - accuracy: 0.7733 - val_loss: 0.0538 - val_accuracy: 0.6600\n",
      "Epoch 107/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0420 - accuracy: 0.7733 - val_loss: 0.0534 - val_accuracy: 0.6600\n",
      "Epoch 108/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0413 - accuracy: 0.7767 - val_loss: 0.0530 - val_accuracy: 0.6600\n",
      "Epoch 109/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0408 - accuracy: 0.7817 - val_loss: 0.0526 - val_accuracy: 0.6600\n",
      "Epoch 110/240\n",
      "600/600 [==============================] - 0s 113us/sample - loss: 0.0402 - accuracy: 0.7800 - val_loss: 0.0522 - val_accuracy: 0.6600\n",
      "Epoch 111/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0396 - accuracy: 0.7850 - val_loss: 0.0518 - val_accuracy: 0.6600\n",
      "Epoch 112/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0391 - accuracy: 0.7817 - val_loss: 0.0514 - val_accuracy: 0.6600\n",
      "Epoch 113/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0385 - accuracy: 0.7833 - val_loss: 0.0511 - val_accuracy: 0.6600\n",
      "Epoch 114/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0380 - accuracy: 0.7867 - val_loss: 0.0508 - val_accuracy: 0.6600\n",
      "Epoch 115/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0375 - accuracy: 0.7867 - val_loss: 0.0504 - val_accuracy: 0.6600\n",
      "Epoch 116/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0370 - accuracy: 0.7933 - val_loss: 0.0501 - val_accuracy: 0.6700\n",
      "Epoch 117/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0365 - accuracy: 0.7917 - val_loss: 0.0498 - val_accuracy: 0.6700\n",
      "Epoch 118/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0361 - accuracy: 0.7950 - val_loss: 0.0495 - val_accuracy: 0.6700\n",
      "Epoch 119/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0356 - accuracy: 0.7950 - val_loss: 0.0491 - val_accuracy: 0.6700\n",
      "Epoch 120/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0352 - accuracy: 0.7967 - val_loss: 0.0488 - val_accuracy: 0.6700\n",
      "Epoch 121/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0348 - accuracy: 0.7983 - val_loss: 0.0484 - val_accuracy: 0.6900\n",
      "Epoch 122/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0343 - accuracy: 0.7967 - val_loss: 0.0481 - val_accuracy: 0.6900\n",
      "Epoch 123/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0339 - accuracy: 0.7983 - val_loss: 0.0478 - val_accuracy: 0.6900\n",
      "Epoch 124/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0335 - accuracy: 0.8000 - val_loss: 0.0476 - val_accuracy: 0.6900\n",
      "Epoch 125/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0332 - accuracy: 0.8033 - val_loss: 0.0473 - val_accuracy: 0.6900\n",
      "Epoch 126/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0327 - accuracy: 0.8050 - val_loss: 0.0470 - val_accuracy: 0.6900\n",
      "Epoch 127/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0324 - accuracy: 0.8050 - val_loss: 0.0467 - val_accuracy: 0.6900\n",
      "Epoch 128/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0320 - accuracy: 0.8050 - val_loss: 0.0464 - val_accuracy: 0.6900\n",
      "Epoch 129/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0316 - accuracy: 0.8083 - val_loss: 0.0460 - val_accuracy: 0.7000\n",
      "Epoch 130/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0313 - accuracy: 0.8117 - val_loss: 0.0457 - val_accuracy: 0.6900\n",
      "Epoch 131/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0310 - accuracy: 0.8150 - val_loss: 0.0454 - val_accuracy: 0.7000\n",
      "Epoch 132/240\n",
      "600/600 [==============================] - 0s 116us/sample - loss: 0.0306 - accuracy: 0.8250 - val_loss: 0.0451 - val_accuracy: 0.7000\n",
      "Epoch 133/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0303 - accuracy: 0.8217 - val_loss: 0.0448 - val_accuracy: 0.7000\n",
      "Epoch 134/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0299 - accuracy: 0.8267 - val_loss: 0.0446 - val_accuracy: 0.7000\n",
      "Epoch 135/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0296 - accuracy: 0.8283 - val_loss: 0.0443 - val_accuracy: 0.7000\n",
      "Epoch 136/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0293 - accuracy: 0.8383 - val_loss: 0.0440 - val_accuracy: 0.7000\n",
      "Epoch 137/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0290 - accuracy: 0.8367 - val_loss: 0.0437 - val_accuracy: 0.7000\n",
      "Epoch 138/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0287 - accuracy: 0.8417 - val_loss: 0.0434 - val_accuracy: 0.7100\n",
      "Epoch 139/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0284 - accuracy: 0.8450 - val_loss: 0.0431 - val_accuracy: 0.7100\n",
      "Epoch 140/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0281 - accuracy: 0.8433 - val_loss: 0.0429 - val_accuracy: 0.7200\n",
      "Epoch 141/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0278 - accuracy: 0.8467 - val_loss: 0.0427 - val_accuracy: 0.7200\n",
      "Epoch 142/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0275 - accuracy: 0.8483 - val_loss: 0.0424 - val_accuracy: 0.7200\n",
      "Epoch 143/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0272 - accuracy: 0.8483 - val_loss: 0.0422 - val_accuracy: 0.7200\n",
      "Epoch 144/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0269 - accuracy: 0.8483 - val_loss: 0.0419 - val_accuracy: 0.7200\n",
      "Epoch 145/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0266 - accuracy: 0.8600 - val_loss: 0.0416 - val_accuracy: 0.7200\n",
      "Epoch 146/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0264 - accuracy: 0.8617 - val_loss: 0.0415 - val_accuracy: 0.7200\n",
      "Epoch 147/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0261 - accuracy: 0.8617 - val_loss: 0.0412 - val_accuracy: 0.7200\n",
      "Epoch 148/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0259 - accuracy: 0.8633 - val_loss: 0.0409 - val_accuracy: 0.7200\n",
      "Epoch 149/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0256 - accuracy: 0.8617 - val_loss: 0.0407 - val_accuracy: 0.7300\n",
      "Epoch 150/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0254 - accuracy: 0.8650 - val_loss: 0.0404 - val_accuracy: 0.7300\n",
      "Epoch 151/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0251 - accuracy: 0.8683 - val_loss: 0.0402 - val_accuracy: 0.7300\n",
      "Epoch 152/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0248 - accuracy: 0.8767 - val_loss: 0.0400 - val_accuracy: 0.7300\n",
      "Epoch 153/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0246 - accuracy: 0.8733 - val_loss: 0.0398 - val_accuracy: 0.7400\n",
      "Epoch 154/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0244 - accuracy: 0.8767 - val_loss: 0.0395 - val_accuracy: 0.7400\n",
      "Epoch 155/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0241 - accuracy: 0.8750 - val_loss: 0.0393 - val_accuracy: 0.7400\n",
      "Epoch 156/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0239 - accuracy: 0.8783 - val_loss: 0.0391 - val_accuracy: 0.7400\n",
      "Epoch 157/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0237 - accuracy: 0.8750 - val_loss: 0.0389 - val_accuracy: 0.7400\n",
      "Epoch 158/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0234 - accuracy: 0.8783 - val_loss: 0.0386 - val_accuracy: 0.7400\n",
      "Epoch 159/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0232 - accuracy: 0.8783 - val_loss: 0.0384 - val_accuracy: 0.7400\n",
      "Epoch 160/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0230 - accuracy: 0.8800 - val_loss: 0.0383 - val_accuracy: 0.7500\n",
      "Epoch 161/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0228 - accuracy: 0.8800 - val_loss: 0.0381 - val_accuracy: 0.7500\n",
      "Epoch 162/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0226 - accuracy: 0.8800 - val_loss: 0.0379 - val_accuracy: 0.7500\n",
      "Epoch 163/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0224 - accuracy: 0.8817 - val_loss: 0.0377 - val_accuracy: 0.7500\n",
      "Epoch 164/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0222 - accuracy: 0.8833 - val_loss: 0.0376 - val_accuracy: 0.7500\n",
      "Epoch 165/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0219 - accuracy: 0.8850 - val_loss: 0.0374 - val_accuracy: 0.7500\n",
      "Epoch 166/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0217 - accuracy: 0.8850 - val_loss: 0.0371 - val_accuracy: 0.7500\n",
      "Epoch 167/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0215 - accuracy: 0.8850 - val_loss: 0.0369 - val_accuracy: 0.7500\n",
      "Epoch 168/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0213 - accuracy: 0.8883 - val_loss: 0.0368 - val_accuracy: 0.7500\n",
      "Epoch 169/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0211 - accuracy: 0.8883 - val_loss: 0.0367 - val_accuracy: 0.7500\n",
      "Epoch 170/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0210 - accuracy: 0.8917 - val_loss: 0.0365 - val_accuracy: 0.7500\n",
      "Epoch 171/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0208 - accuracy: 0.8917 - val_loss: 0.0363 - val_accuracy: 0.7500\n",
      "Epoch 172/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0206 - accuracy: 0.8917 - val_loss: 0.0362 - val_accuracy: 0.7500\n",
      "Epoch 173/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0204 - accuracy: 0.8917 - val_loss: 0.0360 - val_accuracy: 0.7600\n",
      "Epoch 174/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0203 - accuracy: 0.8967 - val_loss: 0.0358 - val_accuracy: 0.7600\n",
      "Epoch 175/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0201 - accuracy: 0.8967 - val_loss: 0.0356 - val_accuracy: 0.7600\n",
      "Epoch 176/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0199 - accuracy: 0.8983 - val_loss: 0.0355 - val_accuracy: 0.7600\n",
      "Epoch 177/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0197 - accuracy: 0.8950 - val_loss: 0.0354 - val_accuracy: 0.7700\n",
      "Epoch 178/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0196 - accuracy: 0.8967 - val_loss: 0.0351 - val_accuracy: 0.7700\n",
      "Epoch 179/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0194 - accuracy: 0.9017 - val_loss: 0.0350 - val_accuracy: 0.7700\n",
      "Epoch 180/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0192 - accuracy: 0.8983 - val_loss: 0.0348 - val_accuracy: 0.7700\n",
      "Epoch 181/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0190 - accuracy: 0.9017 - val_loss: 0.0347 - val_accuracy: 0.7700\n",
      "Epoch 182/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0189 - accuracy: 0.8983 - val_loss: 0.0346 - val_accuracy: 0.7800\n",
      "Epoch 183/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0187 - accuracy: 0.9017 - val_loss: 0.0344 - val_accuracy: 0.7700\n",
      "Epoch 184/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0185 - accuracy: 0.9033 - val_loss: 0.0343 - val_accuracy: 0.7800\n",
      "Epoch 185/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0184 - accuracy: 0.9017 - val_loss: 0.0342 - val_accuracy: 0.7800\n",
      "Epoch 186/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0182 - accuracy: 0.9050 - val_loss: 0.0341 - val_accuracy: 0.7900\n",
      "Epoch 187/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0181 - accuracy: 0.9050 - val_loss: 0.0340 - val_accuracy: 0.7900\n",
      "Epoch 188/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0179 - accuracy: 0.9067 - val_loss: 0.0338 - val_accuracy: 0.7900\n",
      "Epoch 189/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0178 - accuracy: 0.9067 - val_loss: 0.0337 - val_accuracy: 0.7900\n",
      "Epoch 190/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0176 - accuracy: 0.9083 - val_loss: 0.0336 - val_accuracy: 0.7900\n",
      "Epoch 191/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0175 - accuracy: 0.9083 - val_loss: 0.0334 - val_accuracy: 0.8000\n",
      "Epoch 192/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0174 - accuracy: 0.9117 - val_loss: 0.0332 - val_accuracy: 0.7900\n",
      "Epoch 193/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0172 - accuracy: 0.9100 - val_loss: 0.0331 - val_accuracy: 0.7900\n",
      "Epoch 194/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0171 - accuracy: 0.9100 - val_loss: 0.0330 - val_accuracy: 0.7900\n",
      "Epoch 195/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0169 - accuracy: 0.9133 - val_loss: 0.0328 - val_accuracy: 0.8000\n",
      "Epoch 196/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0168 - accuracy: 0.9133 - val_loss: 0.0327 - val_accuracy: 0.8100\n",
      "Epoch 197/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0166 - accuracy: 0.9100 - val_loss: 0.0327 - val_accuracy: 0.8000\n",
      "Epoch 198/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0165 - accuracy: 0.9100 - val_loss: 0.0325 - val_accuracy: 0.8100\n",
      "Epoch 199/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0164 - accuracy: 0.9100 - val_loss: 0.0324 - val_accuracy: 0.8100\n",
      "Epoch 200/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0162 - accuracy: 0.9117 - val_loss: 0.0322 - val_accuracy: 0.8100\n",
      "Epoch 201/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0161 - accuracy: 0.9117 - val_loss: 0.0322 - val_accuracy: 0.8100\n",
      "Epoch 202/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0160 - accuracy: 0.9117 - val_loss: 0.0320 - val_accuracy: 0.8100\n",
      "Epoch 203/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0159 - accuracy: 0.9150 - val_loss: 0.0319 - val_accuracy: 0.8100\n",
      "Epoch 204/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0157 - accuracy: 0.9150 - val_loss: 0.0318 - val_accuracy: 0.8100\n",
      "Epoch 205/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0156 - accuracy: 0.9200 - val_loss: 0.0317 - val_accuracy: 0.8100\n",
      "Epoch 206/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0155 - accuracy: 0.9167 - val_loss: 0.0316 - val_accuracy: 0.8100\n",
      "Epoch 207/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0154 - accuracy: 0.9250 - val_loss: 0.0315 - val_accuracy: 0.8100\n",
      "Epoch 208/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0153 - accuracy: 0.9183 - val_loss: 0.0314 - val_accuracy: 0.8100\n",
      "Epoch 209/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0152 - accuracy: 0.9250 - val_loss: 0.0312 - val_accuracy: 0.8100\n",
      "Epoch 210/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0150 - accuracy: 0.9283 - val_loss: 0.0312 - val_accuracy: 0.8100\n",
      "Epoch 211/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0149 - accuracy: 0.9300 - val_loss: 0.0311 - val_accuracy: 0.8100\n",
      "Epoch 212/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0148 - accuracy: 0.9317 - val_loss: 0.0310 - val_accuracy: 0.8100\n",
      "Epoch 213/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0147 - accuracy: 0.9333 - val_loss: 0.0309 - val_accuracy: 0.8100\n",
      "Epoch 214/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0146 - accuracy: 0.9317 - val_loss: 0.0309 - val_accuracy: 0.8100\n",
      "Epoch 215/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0145 - accuracy: 0.9300 - val_loss: 0.0308 - val_accuracy: 0.8100\n",
      "Epoch 216/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0143 - accuracy: 0.9317 - val_loss: 0.0307 - val_accuracy: 0.8100\n",
      "Epoch 217/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0142 - accuracy: 0.9350 - val_loss: 0.0306 - val_accuracy: 0.8100\n",
      "Epoch 218/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0141 - accuracy: 0.9350 - val_loss: 0.0305 - val_accuracy: 0.8100\n",
      "Epoch 219/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0140 - accuracy: 0.9350 - val_loss: 0.0304 - val_accuracy: 0.8100\n",
      "Epoch 220/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0139 - accuracy: 0.9383 - val_loss: 0.0304 - val_accuracy: 0.8100\n",
      "Epoch 221/240\n",
      "600/600 [==============================] - 0s 115us/sample - loss: 0.0138 - accuracy: 0.9367 - val_loss: 0.0303 - val_accuracy: 0.8100\n",
      "Epoch 222/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0137 - accuracy: 0.9350 - val_loss: 0.0302 - val_accuracy: 0.8100\n",
      "Epoch 223/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0136 - accuracy: 0.9400 - val_loss: 0.0301 - val_accuracy: 0.8100\n",
      "Epoch 224/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0135 - accuracy: 0.9400 - val_loss: 0.0299 - val_accuracy: 0.8100\n",
      "Epoch 225/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0134 - accuracy: 0.9383 - val_loss: 0.0299 - val_accuracy: 0.8100\n",
      "Epoch 226/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0133 - accuracy: 0.9417 - val_loss: 0.0298 - val_accuracy: 0.8100\n",
      "Epoch 227/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0132 - accuracy: 0.9417 - val_loss: 0.0298 - val_accuracy: 0.8100\n",
      "Epoch 228/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0131 - accuracy: 0.9417 - val_loss: 0.0297 - val_accuracy: 0.8100\n",
      "Epoch 229/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0130 - accuracy: 0.9417 - val_loss: 0.0297 - val_accuracy: 0.8100\n",
      "Epoch 230/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0129 - accuracy: 0.9417 - val_loss: 0.0295 - val_accuracy: 0.8100\n",
      "Epoch 231/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0128 - accuracy: 0.9417 - val_loss: 0.0295 - val_accuracy: 0.8100\n",
      "Epoch 232/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0128 - accuracy: 0.9433 - val_loss: 0.0295 - val_accuracy: 0.8100\n",
      "Epoch 233/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0127 - accuracy: 0.9450 - val_loss: 0.0294 - val_accuracy: 0.8100\n",
      "Epoch 234/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0126 - accuracy: 0.9433 - val_loss: 0.0294 - val_accuracy: 0.8100\n",
      "Epoch 235/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0125 - accuracy: 0.9450 - val_loss: 0.0292 - val_accuracy: 0.8100\n",
      "Epoch 236/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0124 - accuracy: 0.9467 - val_loss: 0.0292 - val_accuracy: 0.8100\n",
      "Epoch 237/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0123 - accuracy: 0.9450 - val_loss: 0.0292 - val_accuracy: 0.8100\n",
      "Epoch 238/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0122 - accuracy: 0.9450 - val_loss: 0.0291 - val_accuracy: 0.8100\n",
      "Epoch 239/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0121 - accuracy: 0.9467 - val_loss: 0.0290 - val_accuracy: 0.8100\n",
      "Epoch 240/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0120 - accuracy: 0.9450 - val_loss: 0.0290 - val_accuracy: 0.8200\n",
      "Training date and time : \n",
      "2020-04-09 21:04:34\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/240\n",
      "600/600 [==============================] - 0s 674us/sample - loss: 0.0898 - accuracy: 0.1733 - val_loss: 0.0898 - val_accuracy: 0.1700\n",
      "Epoch 2/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0897 - accuracy: 0.1850 - val_loss: 0.0898 - val_accuracy: 0.1900\n",
      "Epoch 3/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0897 - accuracy: 0.2000 - val_loss: 0.0897 - val_accuracy: 0.2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0896 - accuracy: 0.2083 - val_loss: 0.0896 - val_accuracy: 0.2200\n",
      "Epoch 5/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0895 - accuracy: 0.2150 - val_loss: 0.0895 - val_accuracy: 0.2300\n",
      "Epoch 6/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0894 - accuracy: 0.2333 - val_loss: 0.0894 - val_accuracy: 0.2300\n",
      "Epoch 7/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0893 - accuracy: 0.2417 - val_loss: 0.0894 - val_accuracy: 0.2200\n",
      "Epoch 8/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0892 - accuracy: 0.2400 - val_loss: 0.0893 - val_accuracy: 0.2400\n",
      "Epoch 9/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0891 - accuracy: 0.2417 - val_loss: 0.0892 - val_accuracy: 0.2500\n",
      "Epoch 10/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0890 - accuracy: 0.2517 - val_loss: 0.0891 - val_accuracy: 0.2500\n",
      "Epoch 11/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0888 - accuracy: 0.2567 - val_loss: 0.0890 - val_accuracy: 0.2500\n",
      "Epoch 12/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0887 - accuracy: 0.2533 - val_loss: 0.0890 - val_accuracy: 0.2600\n",
      "Epoch 13/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0886 - accuracy: 0.2567 - val_loss: 0.0889 - val_accuracy: 0.2800\n",
      "Epoch 14/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0885 - accuracy: 0.2667 - val_loss: 0.0888 - val_accuracy: 0.2900\n",
      "Epoch 15/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0884 - accuracy: 0.2750 - val_loss: 0.0887 - val_accuracy: 0.2900\n",
      "Epoch 16/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0883 - accuracy: 0.2850 - val_loss: 0.0886 - val_accuracy: 0.2900\n",
      "Epoch 17/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0882 - accuracy: 0.3017 - val_loss: 0.0885 - val_accuracy: 0.3100\n",
      "Epoch 18/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0880 - accuracy: 0.3233 - val_loss: 0.0884 - val_accuracy: 0.3100\n",
      "Epoch 19/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0879 - accuracy: 0.3383 - val_loss: 0.0883 - val_accuracy: 0.3200\n",
      "Epoch 20/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0878 - accuracy: 0.3467 - val_loss: 0.0882 - val_accuracy: 0.3100\n",
      "Epoch 21/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0877 - accuracy: 0.3600 - val_loss: 0.0881 - val_accuracy: 0.3000\n",
      "Epoch 22/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0875 - accuracy: 0.3717 - val_loss: 0.0880 - val_accuracy: 0.3000\n",
      "Epoch 23/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0874 - accuracy: 0.3833 - val_loss: 0.0879 - val_accuracy: 0.3100\n",
      "Epoch 24/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0872 - accuracy: 0.3950 - val_loss: 0.0877 - val_accuracy: 0.3300\n",
      "Epoch 25/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0871 - accuracy: 0.4033 - val_loss: 0.0876 - val_accuracy: 0.3300\n",
      "Epoch 26/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0869 - accuracy: 0.4133 - val_loss: 0.0875 - val_accuracy: 0.3300\n",
      "Epoch 27/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0867 - accuracy: 0.4250 - val_loss: 0.0874 - val_accuracy: 0.3300\n",
      "Epoch 28/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0866 - accuracy: 0.4317 - val_loss: 0.0872 - val_accuracy: 0.3500\n",
      "Epoch 29/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0864 - accuracy: 0.4350 - val_loss: 0.0871 - val_accuracy: 0.3500\n",
      "Epoch 30/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0862 - accuracy: 0.4367 - val_loss: 0.0869 - val_accuracy: 0.3500\n",
      "Epoch 31/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0860 - accuracy: 0.4367 - val_loss: 0.0868 - val_accuracy: 0.3500\n",
      "Epoch 32/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0858 - accuracy: 0.4400 - val_loss: 0.0866 - val_accuracy: 0.3500\n",
      "Epoch 33/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0856 - accuracy: 0.4467 - val_loss: 0.0864 - val_accuracy: 0.3500\n",
      "Epoch 34/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0854 - accuracy: 0.4500 - val_loss: 0.0862 - val_accuracy: 0.3500\n",
      "Epoch 35/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0852 - accuracy: 0.4517 - val_loss: 0.0860 - val_accuracy: 0.3500\n",
      "Epoch 36/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0849 - accuracy: 0.4600 - val_loss: 0.0858 - val_accuracy: 0.3500\n",
      "Epoch 37/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0847 - accuracy: 0.4600 - val_loss: 0.0856 - val_accuracy: 0.3500\n",
      "Epoch 38/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0844 - accuracy: 0.4617 - val_loss: 0.0854 - val_accuracy: 0.3500\n",
      "Epoch 39/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0841 - accuracy: 0.4650 - val_loss: 0.0851 - val_accuracy: 0.3500\n",
      "Epoch 40/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0838 - accuracy: 0.4550 - val_loss: 0.0849 - val_accuracy: 0.3500\n",
      "Epoch 41/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0835 - accuracy: 0.4500 - val_loss: 0.0846 - val_accuracy: 0.3500\n",
      "Epoch 42/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0832 - accuracy: 0.4517 - val_loss: 0.0844 - val_accuracy: 0.3600\n",
      "Epoch 43/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0828 - accuracy: 0.4467 - val_loss: 0.0841 - val_accuracy: 0.3600\n",
      "Epoch 44/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0824 - accuracy: 0.4450 - val_loss: 0.0838 - val_accuracy: 0.3600\n",
      "Epoch 45/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0821 - accuracy: 0.4517 - val_loss: 0.0835 - val_accuracy: 0.3600\n",
      "Epoch 46/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0817 - accuracy: 0.4417 - val_loss: 0.0831 - val_accuracy: 0.3700\n",
      "Epoch 47/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0812 - accuracy: 0.4417 - val_loss: 0.0828 - val_accuracy: 0.3700\n",
      "Epoch 48/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0808 - accuracy: 0.4350 - val_loss: 0.0824 - val_accuracy: 0.3800\n",
      "Epoch 49/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0804 - accuracy: 0.4433 - val_loss: 0.0821 - val_accuracy: 0.3800\n",
      "Epoch 50/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0799 - accuracy: 0.4417 - val_loss: 0.0817 - val_accuracy: 0.3800\n",
      "Epoch 51/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0795 - accuracy: 0.4417 - val_loss: 0.0813 - val_accuracy: 0.3800\n",
      "Epoch 52/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0790 - accuracy: 0.4433 - val_loss: 0.0809 - val_accuracy: 0.3800\n",
      "Epoch 53/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0785 - accuracy: 0.4483 - val_loss: 0.0806 - val_accuracy: 0.4000\n",
      "Epoch 54/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0780 - accuracy: 0.4517 - val_loss: 0.0802 - val_accuracy: 0.4100\n",
      "Epoch 55/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0775 - accuracy: 0.4567 - val_loss: 0.0798 - val_accuracy: 0.4100\n",
      "Epoch 56/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0770 - accuracy: 0.4650 - val_loss: 0.0794 - val_accuracy: 0.4100\n",
      "Epoch 57/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0765 - accuracy: 0.4717 - val_loss: 0.0789 - val_accuracy: 0.4100\n",
      "Epoch 58/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0760 - accuracy: 0.4733 - val_loss: 0.0785 - val_accuracy: 0.4200\n",
      "Epoch 59/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0754 - accuracy: 0.4867 - val_loss: 0.0781 - val_accuracy: 0.4300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0749 - accuracy: 0.4867 - val_loss: 0.0777 - val_accuracy: 0.4600\n",
      "Epoch 61/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0743 - accuracy: 0.4933 - val_loss: 0.0772 - val_accuracy: 0.4700\n",
      "Epoch 62/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0737 - accuracy: 0.5067 - val_loss: 0.0768 - val_accuracy: 0.4700\n",
      "Epoch 63/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0732 - accuracy: 0.5117 - val_loss: 0.0763 - val_accuracy: 0.4800\n",
      "Epoch 64/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0726 - accuracy: 0.5200 - val_loss: 0.0759 - val_accuracy: 0.5000\n",
      "Epoch 65/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0720 - accuracy: 0.5267 - val_loss: 0.0754 - val_accuracy: 0.5000\n",
      "Epoch 66/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0714 - accuracy: 0.5350 - val_loss: 0.0749 - val_accuracy: 0.5000\n",
      "Epoch 67/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0708 - accuracy: 0.5450 - val_loss: 0.0744 - val_accuracy: 0.5000\n",
      "Epoch 68/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0701 - accuracy: 0.5483 - val_loss: 0.0739 - val_accuracy: 0.5100\n",
      "Epoch 69/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0695 - accuracy: 0.5500 - val_loss: 0.0734 - val_accuracy: 0.5100\n",
      "Epoch 70/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0688 - accuracy: 0.5583 - val_loss: 0.0729 - val_accuracy: 0.5100\n",
      "Epoch 71/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0682 - accuracy: 0.5683 - val_loss: 0.0724 - val_accuracy: 0.5200\n",
      "Epoch 72/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0675 - accuracy: 0.5700 - val_loss: 0.0719 - val_accuracy: 0.5400\n",
      "Epoch 73/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0668 - accuracy: 0.5817 - val_loss: 0.0714 - val_accuracy: 0.5400\n",
      "Epoch 74/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0661 - accuracy: 0.5900 - val_loss: 0.0708 - val_accuracy: 0.5400\n",
      "Epoch 75/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0654 - accuracy: 0.5967 - val_loss: 0.0703 - val_accuracy: 0.5600\n",
      "Epoch 76/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0647 - accuracy: 0.6183 - val_loss: 0.0698 - val_accuracy: 0.5700\n",
      "Epoch 77/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0640 - accuracy: 0.6117 - val_loss: 0.0692 - val_accuracy: 0.5900\n",
      "Epoch 78/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0633 - accuracy: 0.6250 - val_loss: 0.0687 - val_accuracy: 0.5900\n",
      "Epoch 79/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0626 - accuracy: 0.6350 - val_loss: 0.0681 - val_accuracy: 0.6000\n",
      "Epoch 80/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0618 - accuracy: 0.6417 - val_loss: 0.0676 - val_accuracy: 0.6000\n",
      "Epoch 81/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0611 - accuracy: 0.6467 - val_loss: 0.0670 - val_accuracy: 0.6000\n",
      "Epoch 82/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0603 - accuracy: 0.6600 - val_loss: 0.0665 - val_accuracy: 0.6000\n",
      "Epoch 83/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0596 - accuracy: 0.6600 - val_loss: 0.0659 - val_accuracy: 0.6100\n",
      "Epoch 84/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0588 - accuracy: 0.6750 - val_loss: 0.0653 - val_accuracy: 0.6200\n",
      "Epoch 85/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0580 - accuracy: 0.6750 - val_loss: 0.0648 - val_accuracy: 0.6300\n",
      "Epoch 86/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0572 - accuracy: 0.6800 - val_loss: 0.0642 - val_accuracy: 0.6400\n",
      "Epoch 87/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0564 - accuracy: 0.6883 - val_loss: 0.0636 - val_accuracy: 0.6400\n",
      "Epoch 88/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0557 - accuracy: 0.6900 - val_loss: 0.0630 - val_accuracy: 0.6500\n",
      "Epoch 89/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0549 - accuracy: 0.6933 - val_loss: 0.0625 - val_accuracy: 0.6600\n",
      "Epoch 90/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0541 - accuracy: 0.6967 - val_loss: 0.0619 - val_accuracy: 0.6600\n",
      "Epoch 91/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0533 - accuracy: 0.7100 - val_loss: 0.0613 - val_accuracy: 0.6500\n",
      "Epoch 92/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0525 - accuracy: 0.7067 - val_loss: 0.0608 - val_accuracy: 0.6500\n",
      "Epoch 93/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0517 - accuracy: 0.7183 - val_loss: 0.0602 - val_accuracy: 0.6600\n",
      "Epoch 94/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0510 - accuracy: 0.7183 - val_loss: 0.0597 - val_accuracy: 0.6600\n",
      "Epoch 95/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0502 - accuracy: 0.7217 - val_loss: 0.0591 - val_accuracy: 0.6600\n",
      "Epoch 96/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0494 - accuracy: 0.7233 - val_loss: 0.0586 - val_accuracy: 0.6600\n",
      "Epoch 97/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0487 - accuracy: 0.7367 - val_loss: 0.0581 - val_accuracy: 0.6700\n",
      "Epoch 98/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0479 - accuracy: 0.7400 - val_loss: 0.0576 - val_accuracy: 0.6700\n",
      "Epoch 99/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0472 - accuracy: 0.7517 - val_loss: 0.0571 - val_accuracy: 0.6700\n",
      "Epoch 100/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0465 - accuracy: 0.7583 - val_loss: 0.0566 - val_accuracy: 0.6700\n",
      "Epoch 101/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0458 - accuracy: 0.7533 - val_loss: 0.0561 - val_accuracy: 0.6700\n",
      "Epoch 102/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0451 - accuracy: 0.7583 - val_loss: 0.0557 - val_accuracy: 0.6700\n",
      "Epoch 103/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0444 - accuracy: 0.7633 - val_loss: 0.0553 - val_accuracy: 0.6600\n",
      "Epoch 104/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0437 - accuracy: 0.7633 - val_loss: 0.0548 - val_accuracy: 0.6700\n",
      "Epoch 105/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0431 - accuracy: 0.7767 - val_loss: 0.0544 - val_accuracy: 0.6700\n",
      "Epoch 106/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0424 - accuracy: 0.7817 - val_loss: 0.0540 - val_accuracy: 0.6700\n",
      "Epoch 107/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0418 - accuracy: 0.7817 - val_loss: 0.0536 - val_accuracy: 0.6600\n",
      "Epoch 108/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0412 - accuracy: 0.7867 - val_loss: 0.0532 - val_accuracy: 0.6700\n",
      "Epoch 109/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0406 - accuracy: 0.7883 - val_loss: 0.0528 - val_accuracy: 0.6600\n",
      "Epoch 110/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0400 - accuracy: 0.7883 - val_loss: 0.0523 - val_accuracy: 0.6800\n",
      "Epoch 111/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0394 - accuracy: 0.7850 - val_loss: 0.0520 - val_accuracy: 0.6700\n",
      "Epoch 112/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0389 - accuracy: 0.7883 - val_loss: 0.0516 - val_accuracy: 0.6700\n",
      "Epoch 113/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0383 - accuracy: 0.7900 - val_loss: 0.0512 - val_accuracy: 0.6700\n",
      "Epoch 114/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0378 - accuracy: 0.7933 - val_loss: 0.0509 - val_accuracy: 0.6800\n",
      "Epoch 115/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0373 - accuracy: 0.7917 - val_loss: 0.0505 - val_accuracy: 0.6700\n",
      "Epoch 116/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0368 - accuracy: 0.7967 - val_loss: 0.0502 - val_accuracy: 0.6700\n",
      "Epoch 117/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0363 - accuracy: 0.7983 - val_loss: 0.0499 - val_accuracy: 0.6700\n",
      "Epoch 118/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0359 - accuracy: 0.7967 - val_loss: 0.0495 - val_accuracy: 0.6700\n",
      "Epoch 119/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0354 - accuracy: 0.7967 - val_loss: 0.0492 - val_accuracy: 0.6700\n",
      "Epoch 120/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0350 - accuracy: 0.7983 - val_loss: 0.0488 - val_accuracy: 0.6700\n",
      "Epoch 121/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0345 - accuracy: 0.7983 - val_loss: 0.0485 - val_accuracy: 0.6900\n",
      "Epoch 122/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0341 - accuracy: 0.8017 - val_loss: 0.0482 - val_accuracy: 0.7000\n",
      "Epoch 123/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0337 - accuracy: 0.8000 - val_loss: 0.0478 - val_accuracy: 0.7000\n",
      "Epoch 124/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0333 - accuracy: 0.8050 - val_loss: 0.0476 - val_accuracy: 0.7000\n",
      "Epoch 125/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0330 - accuracy: 0.8083 - val_loss: 0.0473 - val_accuracy: 0.7000\n",
      "Epoch 126/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0325 - accuracy: 0.8083 - val_loss: 0.0470 - val_accuracy: 0.7000\n",
      "Epoch 127/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0322 - accuracy: 0.8067 - val_loss: 0.0467 - val_accuracy: 0.7000\n",
      "Epoch 128/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0318 - accuracy: 0.8083 - val_loss: 0.0464 - val_accuracy: 0.7000\n",
      "Epoch 129/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0315 - accuracy: 0.8083 - val_loss: 0.0460 - val_accuracy: 0.7100\n",
      "Epoch 130/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0311 - accuracy: 0.8133 - val_loss: 0.0457 - val_accuracy: 0.7100\n",
      "Epoch 131/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0308 - accuracy: 0.8150 - val_loss: 0.0454 - val_accuracy: 0.7100\n",
      "Epoch 132/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0304 - accuracy: 0.8217 - val_loss: 0.0451 - val_accuracy: 0.7100\n",
      "Epoch 133/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0301 - accuracy: 0.8250 - val_loss: 0.0448 - val_accuracy: 0.7100\n",
      "Epoch 134/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0298 - accuracy: 0.8233 - val_loss: 0.0445 - val_accuracy: 0.7100\n",
      "Epoch 135/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0295 - accuracy: 0.8283 - val_loss: 0.0443 - val_accuracy: 0.7100\n",
      "Epoch 136/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0291 - accuracy: 0.8417 - val_loss: 0.0440 - val_accuracy: 0.7100\n",
      "Epoch 137/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0288 - accuracy: 0.8400 - val_loss: 0.0436 - val_accuracy: 0.7100\n",
      "Epoch 138/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0285 - accuracy: 0.8417 - val_loss: 0.0433 - val_accuracy: 0.7200\n",
      "Epoch 139/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0282 - accuracy: 0.8450 - val_loss: 0.0431 - val_accuracy: 0.7200\n",
      "Epoch 140/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0279 - accuracy: 0.8450 - val_loss: 0.0428 - val_accuracy: 0.7200\n",
      "Epoch 141/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0276 - accuracy: 0.8467 - val_loss: 0.0426 - val_accuracy: 0.7200\n",
      "Epoch 142/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0273 - accuracy: 0.8483 - val_loss: 0.0424 - val_accuracy: 0.7200\n",
      "Epoch 143/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0271 - accuracy: 0.8483 - val_loss: 0.0421 - val_accuracy: 0.7200\n",
      "Epoch 144/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0268 - accuracy: 0.8517 - val_loss: 0.0418 - val_accuracy: 0.7200\n",
      "Epoch 145/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0265 - accuracy: 0.8550 - val_loss: 0.0415 - val_accuracy: 0.7200\n",
      "Epoch 146/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0262 - accuracy: 0.8583 - val_loss: 0.0413 - val_accuracy: 0.7200\n",
      "Epoch 147/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0260 - accuracy: 0.8633 - val_loss: 0.0411 - val_accuracy: 0.7200\n",
      "Epoch 148/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0257 - accuracy: 0.8600 - val_loss: 0.0408 - val_accuracy: 0.7200\n",
      "Epoch 149/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0255 - accuracy: 0.8650 - val_loss: 0.0405 - val_accuracy: 0.7200\n",
      "Epoch 150/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0252 - accuracy: 0.8717 - val_loss: 0.0403 - val_accuracy: 0.7200\n",
      "Epoch 151/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0249 - accuracy: 0.8750 - val_loss: 0.0400 - val_accuracy: 0.7200\n",
      "Epoch 152/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0247 - accuracy: 0.8783 - val_loss: 0.0398 - val_accuracy: 0.7400\n",
      "Epoch 153/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0245 - accuracy: 0.8783 - val_loss: 0.0396 - val_accuracy: 0.7400\n",
      "Epoch 154/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0243 - accuracy: 0.8767 - val_loss: 0.0394 - val_accuracy: 0.7400\n",
      "Epoch 155/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0240 - accuracy: 0.8783 - val_loss: 0.0391 - val_accuracy: 0.7300\n",
      "Epoch 156/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0238 - accuracy: 0.8783 - val_loss: 0.0389 - val_accuracy: 0.7400\n",
      "Epoch 157/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0236 - accuracy: 0.8833 - val_loss: 0.0387 - val_accuracy: 0.7400\n",
      "Epoch 158/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0233 - accuracy: 0.8817 - val_loss: 0.0384 - val_accuracy: 0.7400\n",
      "Epoch 159/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0231 - accuracy: 0.8850 - val_loss: 0.0382 - val_accuracy: 0.7400\n",
      "Epoch 160/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0229 - accuracy: 0.8883 - val_loss: 0.0381 - val_accuracy: 0.7500\n",
      "Epoch 161/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0227 - accuracy: 0.8883 - val_loss: 0.0379 - val_accuracy: 0.7500\n",
      "Epoch 162/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0225 - accuracy: 0.8900 - val_loss: 0.0377 - val_accuracy: 0.7500\n",
      "Epoch 163/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0223 - accuracy: 0.8900 - val_loss: 0.0374 - val_accuracy: 0.7500\n",
      "Epoch 164/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0221 - accuracy: 0.8900 - val_loss: 0.0373 - val_accuracy: 0.7500\n",
      "Epoch 165/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0218 - accuracy: 0.8917 - val_loss: 0.0371 - val_accuracy: 0.7500\n",
      "Epoch 166/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0216 - accuracy: 0.8917 - val_loss: 0.0369 - val_accuracy: 0.7500\n",
      "Epoch 167/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0214 - accuracy: 0.8917 - val_loss: 0.0367 - val_accuracy: 0.7500\n",
      "Epoch 168/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0212 - accuracy: 0.8917 - val_loss: 0.0365 - val_accuracy: 0.7500\n",
      "Epoch 169/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0210 - accuracy: 0.8917 - val_loss: 0.0364 - val_accuracy: 0.7500\n",
      "Epoch 170/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0209 - accuracy: 0.8917 - val_loss: 0.0362 - val_accuracy: 0.7500\n",
      "Epoch 171/240\n",
      "600/600 [==============================] - 0s 116us/sample - loss: 0.0207 - accuracy: 0.8950 - val_loss: 0.0360 - val_accuracy: 0.7500\n",
      "Epoch 172/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0205 - accuracy: 0.8917 - val_loss: 0.0358 - val_accuracy: 0.7500\n",
      "Epoch 173/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0203 - accuracy: 0.8950 - val_loss: 0.0357 - val_accuracy: 0.7800\n",
      "Epoch 174/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0202 - accuracy: 0.8950 - val_loss: 0.0355 - val_accuracy: 0.7700\n",
      "Epoch 175/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0200 - accuracy: 0.8950 - val_loss: 0.0353 - val_accuracy: 0.7700\n",
      "Epoch 176/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0198 - accuracy: 0.8967 - val_loss: 0.0351 - val_accuracy: 0.7800\n",
      "Epoch 177/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0196 - accuracy: 0.8950 - val_loss: 0.0351 - val_accuracy: 0.7800\n",
      "Epoch 178/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0195 - accuracy: 0.9000 - val_loss: 0.0348 - val_accuracy: 0.7900\n",
      "Epoch 179/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0193 - accuracy: 0.8983 - val_loss: 0.0347 - val_accuracy: 0.7900\n",
      "Epoch 180/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0191 - accuracy: 0.9017 - val_loss: 0.0345 - val_accuracy: 0.7900\n",
      "Epoch 181/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0190 - accuracy: 0.8983 - val_loss: 0.0343 - val_accuracy: 0.7900\n",
      "Epoch 182/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0188 - accuracy: 0.9033 - val_loss: 0.0342 - val_accuracy: 0.7900\n",
      "Epoch 183/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0186 - accuracy: 0.9033 - val_loss: 0.0341 - val_accuracy: 0.7900\n",
      "Epoch 184/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0185 - accuracy: 0.9017 - val_loss: 0.0339 - val_accuracy: 0.7900\n",
      "Epoch 185/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0183 - accuracy: 0.9000 - val_loss: 0.0338 - val_accuracy: 0.8100\n",
      "Epoch 186/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0182 - accuracy: 0.9033 - val_loss: 0.0337 - val_accuracy: 0.8100\n",
      "Epoch 187/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0180 - accuracy: 0.9033 - val_loss: 0.0336 - val_accuracy: 0.8100\n",
      "Epoch 188/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0178 - accuracy: 0.9067 - val_loss: 0.0334 - val_accuracy: 0.8100\n",
      "Epoch 189/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0177 - accuracy: 0.9067 - val_loss: 0.0333 - val_accuracy: 0.8100\n",
      "Epoch 190/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0176 - accuracy: 0.9083 - val_loss: 0.0332 - val_accuracy: 0.8100\n",
      "Epoch 191/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0174 - accuracy: 0.9083 - val_loss: 0.0330 - val_accuracy: 0.8100\n",
      "Epoch 192/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0173 - accuracy: 0.9100 - val_loss: 0.0328 - val_accuracy: 0.8100\n",
      "Epoch 193/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0171 - accuracy: 0.9083 - val_loss: 0.0327 - val_accuracy: 0.8100\n",
      "Epoch 194/240\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0170 - accuracy: 0.9117 - val_loss: 0.0326 - val_accuracy: 0.8100\n",
      "Epoch 195/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0168 - accuracy: 0.9083 - val_loss: 0.0324 - val_accuracy: 0.8100\n",
      "Epoch 196/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0167 - accuracy: 0.9083 - val_loss: 0.0323 - val_accuracy: 0.8100\n",
      "Epoch 197/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0166 - accuracy: 0.9100 - val_loss: 0.0323 - val_accuracy: 0.8100\n",
      "Epoch 198/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0164 - accuracy: 0.9100 - val_loss: 0.0321 - val_accuracy: 0.8100\n",
      "Epoch 199/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0163 - accuracy: 0.9117 - val_loss: 0.0320 - val_accuracy: 0.8100\n",
      "Epoch 200/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0162 - accuracy: 0.9117 - val_loss: 0.0318 - val_accuracy: 0.8100\n",
      "Epoch 201/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0160 - accuracy: 0.9117 - val_loss: 0.0318 - val_accuracy: 0.8100\n",
      "Epoch 202/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0159 - accuracy: 0.9117 - val_loss: 0.0316 - val_accuracy: 0.8100\n",
      "Epoch 203/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0158 - accuracy: 0.9117 - val_loss: 0.0315 - val_accuracy: 0.8100\n",
      "Epoch 204/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0157 - accuracy: 0.9133 - val_loss: 0.0313 - val_accuracy: 0.8100\n",
      "Epoch 205/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0155 - accuracy: 0.9150 - val_loss: 0.0313 - val_accuracy: 0.8100\n",
      "Epoch 206/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0154 - accuracy: 0.9167 - val_loss: 0.0312 - val_accuracy: 0.8100\n",
      "Epoch 207/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0153 - accuracy: 0.9167 - val_loss: 0.0310 - val_accuracy: 0.8100\n",
      "Epoch 208/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0152 - accuracy: 0.9167 - val_loss: 0.0310 - val_accuracy: 0.8100\n",
      "Epoch 209/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0151 - accuracy: 0.9200 - val_loss: 0.0308 - val_accuracy: 0.8100\n",
      "Epoch 210/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0149 - accuracy: 0.9233 - val_loss: 0.0308 - val_accuracy: 0.8100\n",
      "Epoch 211/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0148 - accuracy: 0.9233 - val_loss: 0.0307 - val_accuracy: 0.8100\n",
      "Epoch 212/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0147 - accuracy: 0.9250 - val_loss: 0.0306 - val_accuracy: 0.8100\n",
      "Epoch 213/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0146 - accuracy: 0.9283 - val_loss: 0.0305 - val_accuracy: 0.8100\n",
      "Epoch 214/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0145 - accuracy: 0.9250 - val_loss: 0.0305 - val_accuracy: 0.8100\n",
      "Epoch 215/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0144 - accuracy: 0.9317 - val_loss: 0.0304 - val_accuracy: 0.8100\n",
      "Epoch 216/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0143 - accuracy: 0.9300 - val_loss: 0.0303 - val_accuracy: 0.8100\n",
      "Epoch 217/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0142 - accuracy: 0.9333 - val_loss: 0.0302 - val_accuracy: 0.8100\n",
      "Epoch 218/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0141 - accuracy: 0.9317 - val_loss: 0.0301 - val_accuracy: 0.8100\n",
      "Epoch 219/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0140 - accuracy: 0.9383 - val_loss: 0.0300 - val_accuracy: 0.8100\n",
      "Epoch 220/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0138 - accuracy: 0.9367 - val_loss: 0.0300 - val_accuracy: 0.8100\n",
      "Epoch 221/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0137 - accuracy: 0.9350 - val_loss: 0.0299 - val_accuracy: 0.8100\n",
      "Epoch 222/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0137 - accuracy: 0.9350 - val_loss: 0.0298 - val_accuracy: 0.8100\n",
      "Epoch 223/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0135 - accuracy: 0.9383 - val_loss: 0.0297 - val_accuracy: 0.8100\n",
      "Epoch 224/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0135 - accuracy: 0.9417 - val_loss: 0.0295 - val_accuracy: 0.8100\n",
      "Epoch 225/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0134 - accuracy: 0.9383 - val_loss: 0.0295 - val_accuracy: 0.8100\n",
      "Epoch 226/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0132 - accuracy: 0.9383 - val_loss: 0.0294 - val_accuracy: 0.8100\n",
      "Epoch 227/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0132 - accuracy: 0.9383 - val_loss: 0.0294 - val_accuracy: 0.8100\n",
      "Epoch 228/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0131 - accuracy: 0.9433 - val_loss: 0.0293 - val_accuracy: 0.8100\n",
      "Epoch 229/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0130 - accuracy: 0.9400 - val_loss: 0.0292 - val_accuracy: 0.8100\n",
      "Epoch 230/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0129 - accuracy: 0.9433 - val_loss: 0.0291 - val_accuracy: 0.8100\n",
      "Epoch 231/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0128 - accuracy: 0.9433 - val_loss: 0.0291 - val_accuracy: 0.8100\n",
      "Epoch 232/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0127 - accuracy: 0.9433 - val_loss: 0.0291 - val_accuracy: 0.8100\n",
      "Epoch 233/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0126 - accuracy: 0.9450 - val_loss: 0.0290 - val_accuracy: 0.8100\n",
      "Epoch 234/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0125 - accuracy: 0.9433 - val_loss: 0.0289 - val_accuracy: 0.8100\n",
      "Epoch 235/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0124 - accuracy: 0.9450 - val_loss: 0.0288 - val_accuracy: 0.8100\n",
      "Epoch 236/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0123 - accuracy: 0.9483 - val_loss: 0.0288 - val_accuracy: 0.8100\n",
      "Epoch 237/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0122 - accuracy: 0.9467 - val_loss: 0.0287 - val_accuracy: 0.8100\n",
      "Epoch 238/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0122 - accuracy: 0.9467 - val_loss: 0.0287 - val_accuracy: 0.8100\n",
      "Epoch 239/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0121 - accuracy: 0.9467 - val_loss: 0.0286 - val_accuracy: 0.8100\n",
      "Epoch 240/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0120 - accuracy: 0.9467 - val_loss: 0.0286 - val_accuracy: 0.8100\n",
      "Training date and time : \n",
      "2020-04-09 21:04:50\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/240\n",
      "600/600 [==============================] - 0s 669us/sample - loss: 0.0899 - accuracy: 0.1767 - val_loss: 0.0899 - val_accuracy: 0.2200\n",
      "Epoch 2/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0898 - accuracy: 0.1967 - val_loss: 0.0898 - val_accuracy: 0.2300\n",
      "Epoch 3/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0897 - accuracy: 0.2067 - val_loss: 0.0897 - val_accuracy: 0.2400\n",
      "Epoch 4/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0896 - accuracy: 0.2117 - val_loss: 0.0896 - val_accuracy: 0.2500\n",
      "Epoch 5/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0894 - accuracy: 0.2283 - val_loss: 0.0896 - val_accuracy: 0.2500\n",
      "Epoch 6/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0893 - accuracy: 0.2383 - val_loss: 0.0895 - val_accuracy: 0.2500\n",
      "Epoch 7/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0892 - accuracy: 0.2483 - val_loss: 0.0894 - val_accuracy: 0.2400\n",
      "Epoch 8/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0891 - accuracy: 0.2500 - val_loss: 0.0893 - val_accuracy: 0.2400\n",
      "Epoch 9/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0890 - accuracy: 0.2583 - val_loss: 0.0892 - val_accuracy: 0.2400\n",
      "Epoch 10/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0889 - accuracy: 0.2683 - val_loss: 0.0891 - val_accuracy: 0.2500\n",
      "Epoch 11/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0888 - accuracy: 0.2717 - val_loss: 0.0891 - val_accuracy: 0.2400\n",
      "Epoch 12/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0887 - accuracy: 0.2750 - val_loss: 0.0890 - val_accuracy: 0.2500\n",
      "Epoch 13/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0886 - accuracy: 0.2767 - val_loss: 0.0889 - val_accuracy: 0.2500\n",
      "Epoch 14/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0885 - accuracy: 0.2850 - val_loss: 0.0888 - val_accuracy: 0.2600\n",
      "Epoch 15/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0884 - accuracy: 0.2917 - val_loss: 0.0887 - val_accuracy: 0.2800\n",
      "Epoch 16/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0882 - accuracy: 0.3067 - val_loss: 0.0886 - val_accuracy: 0.3000\n",
      "Epoch 17/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0881 - accuracy: 0.3200 - val_loss: 0.0885 - val_accuracy: 0.3100\n",
      "Epoch 18/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0880 - accuracy: 0.3350 - val_loss: 0.0884 - val_accuracy: 0.3200\n",
      "Epoch 19/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0878 - accuracy: 0.3500 - val_loss: 0.0883 - val_accuracy: 0.3200\n",
      "Epoch 20/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0877 - accuracy: 0.3617 - val_loss: 0.0882 - val_accuracy: 0.3200\n",
      "Epoch 21/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0876 - accuracy: 0.3683 - val_loss: 0.0881 - val_accuracy: 0.3200\n",
      "Epoch 22/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0874 - accuracy: 0.3833 - val_loss: 0.0879 - val_accuracy: 0.3400\n",
      "Epoch 23/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0873 - accuracy: 0.3900 - val_loss: 0.0878 - val_accuracy: 0.3300\n",
      "Epoch 24/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0871 - accuracy: 0.4017 - val_loss: 0.0877 - val_accuracy: 0.3400\n",
      "Epoch 25/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0870 - accuracy: 0.4150 - val_loss: 0.0876 - val_accuracy: 0.3600\n",
      "Epoch 26/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0868 - accuracy: 0.4217 - val_loss: 0.0874 - val_accuracy: 0.3500\n",
      "Epoch 27/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0866 - accuracy: 0.4333 - val_loss: 0.0873 - val_accuracy: 0.3600\n",
      "Epoch 28/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0865 - accuracy: 0.4367 - val_loss: 0.0871 - val_accuracy: 0.3700\n",
      "Epoch 29/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0863 - accuracy: 0.4367 - val_loss: 0.0870 - val_accuracy: 0.3600\n",
      "Epoch 30/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0861 - accuracy: 0.4367 - val_loss: 0.0868 - val_accuracy: 0.3600\n",
      "Epoch 31/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0859 - accuracy: 0.4467 - val_loss: 0.0867 - val_accuracy: 0.3600\n",
      "Epoch 32/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0857 - accuracy: 0.4450 - val_loss: 0.0865 - val_accuracy: 0.3600\n",
      "Epoch 33/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0854 - accuracy: 0.4433 - val_loss: 0.0863 - val_accuracy: 0.3600\n",
      "Epoch 34/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0852 - accuracy: 0.4483 - val_loss: 0.0861 - val_accuracy: 0.3600\n",
      "Epoch 35/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0849 - accuracy: 0.4500 - val_loss: 0.0859 - val_accuracy: 0.3600\n",
      "Epoch 36/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0847 - accuracy: 0.4533 - val_loss: 0.0857 - val_accuracy: 0.3600\n",
      "Epoch 37/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0844 - accuracy: 0.4500 - val_loss: 0.0854 - val_accuracy: 0.3400\n",
      "Epoch 38/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0841 - accuracy: 0.4517 - val_loss: 0.0852 - val_accuracy: 0.3400\n",
      "Epoch 39/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0838 - accuracy: 0.4550 - val_loss: 0.0850 - val_accuracy: 0.3400\n",
      "Epoch 40/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0835 - accuracy: 0.4467 - val_loss: 0.0847 - val_accuracy: 0.3400\n",
      "Epoch 41/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0832 - accuracy: 0.4483 - val_loss: 0.0844 - val_accuracy: 0.3400\n",
      "Epoch 42/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0828 - accuracy: 0.4500 - val_loss: 0.0841 - val_accuracy: 0.3300\n",
      "Epoch 43/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0825 - accuracy: 0.4450 - val_loss: 0.0838 - val_accuracy: 0.3300\n",
      "Epoch 44/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0821 - accuracy: 0.4517 - val_loss: 0.0835 - val_accuracy: 0.3300\n",
      "Epoch 45/240\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0817 - accuracy: 0.4567 - val_loss: 0.0832 - val_accuracy: 0.3300\n",
      "Epoch 46/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0813 - accuracy: 0.4483 - val_loss: 0.0828 - val_accuracy: 0.3300\n",
      "Epoch 47/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0808 - accuracy: 0.4500 - val_loss: 0.0825 - val_accuracy: 0.3300\n",
      "Epoch 48/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0804 - accuracy: 0.4483 - val_loss: 0.0821 - val_accuracy: 0.3400\n",
      "Epoch 49/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0799 - accuracy: 0.4550 - val_loss: 0.0817 - val_accuracy: 0.3400\n",
      "Epoch 50/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0795 - accuracy: 0.4533 - val_loss: 0.0814 - val_accuracy: 0.3500\n",
      "Epoch 51/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0790 - accuracy: 0.4650 - val_loss: 0.0810 - val_accuracy: 0.3500\n",
      "Epoch 52/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0785 - accuracy: 0.4650 - val_loss: 0.0806 - val_accuracy: 0.3600\n",
      "Epoch 53/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0780 - accuracy: 0.4733 - val_loss: 0.0802 - val_accuracy: 0.3600\n",
      "Epoch 54/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0775 - accuracy: 0.4833 - val_loss: 0.0798 - val_accuracy: 0.3800\n",
      "Epoch 55/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0770 - accuracy: 0.4850 - val_loss: 0.0794 - val_accuracy: 0.3900\n",
      "Epoch 56/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0765 - accuracy: 0.4883 - val_loss: 0.0790 - val_accuracy: 0.4300\n",
      "Epoch 57/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0759 - accuracy: 0.4917 - val_loss: 0.0786 - val_accuracy: 0.4400\n",
      "Epoch 58/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0754 - accuracy: 0.5000 - val_loss: 0.0782 - val_accuracy: 0.4400\n",
      "Epoch 59/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0748 - accuracy: 0.5117 - val_loss: 0.0777 - val_accuracy: 0.4500\n",
      "Epoch 60/240\n",
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0743 - accuracy: 0.5167 - val_loss: 0.0773 - val_accuracy: 0.4600\n",
      "Epoch 61/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0737 - accuracy: 0.5217 - val_loss: 0.0768 - val_accuracy: 0.4600\n",
      "Epoch 62/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0731 - accuracy: 0.5317 - val_loss: 0.0764 - val_accuracy: 0.4700\n",
      "Epoch 63/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0725 - accuracy: 0.5400 - val_loss: 0.0759 - val_accuracy: 0.4900\n",
      "Epoch 64/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0719 - accuracy: 0.5433 - val_loss: 0.0755 - val_accuracy: 0.4900\n",
      "Epoch 65/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0713 - accuracy: 0.5567 - val_loss: 0.0750 - val_accuracy: 0.4900\n",
      "Epoch 66/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0707 - accuracy: 0.5583 - val_loss: 0.0745 - val_accuracy: 0.4900\n",
      "Epoch 67/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0701 - accuracy: 0.5633 - val_loss: 0.0741 - val_accuracy: 0.5100\n",
      "Epoch 68/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0694 - accuracy: 0.5700 - val_loss: 0.0736 - val_accuracy: 0.5200\n",
      "Epoch 69/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0688 - accuracy: 0.5767 - val_loss: 0.0731 - val_accuracy: 0.5200\n",
      "Epoch 70/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0681 - accuracy: 0.5867 - val_loss: 0.0725 - val_accuracy: 0.5200\n",
      "Epoch 71/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0674 - accuracy: 0.5917 - val_loss: 0.0720 - val_accuracy: 0.5400\n",
      "Epoch 72/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0667 - accuracy: 0.6017 - val_loss: 0.0715 - val_accuracy: 0.5400\n",
      "Epoch 73/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0660 - accuracy: 0.6117 - val_loss: 0.0710 - val_accuracy: 0.5500\n",
      "Epoch 74/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0653 - accuracy: 0.6217 - val_loss: 0.0705 - val_accuracy: 0.5700\n",
      "Epoch 75/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0646 - accuracy: 0.6267 - val_loss: 0.0699 - val_accuracy: 0.5700\n",
      "Epoch 76/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0639 - accuracy: 0.6383 - val_loss: 0.0694 - val_accuracy: 0.5900\n",
      "Epoch 77/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0632 - accuracy: 0.6433 - val_loss: 0.0688 - val_accuracy: 0.6000\n",
      "Epoch 78/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0624 - accuracy: 0.6550 - val_loss: 0.0683 - val_accuracy: 0.6000\n",
      "Epoch 79/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0617 - accuracy: 0.6617 - val_loss: 0.0677 - val_accuracy: 0.6000\n",
      "Epoch 80/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0609 - accuracy: 0.6683 - val_loss: 0.0672 - val_accuracy: 0.6000\n",
      "Epoch 81/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0602 - accuracy: 0.6717 - val_loss: 0.0666 - val_accuracy: 0.6100\n",
      "Epoch 82/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0594 - accuracy: 0.6817 - val_loss: 0.0661 - val_accuracy: 0.6100\n",
      "Epoch 83/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0587 - accuracy: 0.6833 - val_loss: 0.0655 - val_accuracy: 0.6200\n",
      "Epoch 84/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0579 - accuracy: 0.6983 - val_loss: 0.0649 - val_accuracy: 0.6400\n",
      "Epoch 85/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0571 - accuracy: 0.6967 - val_loss: 0.0643 - val_accuracy: 0.6500\n",
      "Epoch 86/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0563 - accuracy: 0.7017 - val_loss: 0.0637 - val_accuracy: 0.6600\n",
      "Epoch 87/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0555 - accuracy: 0.7100 - val_loss: 0.0632 - val_accuracy: 0.6600\n",
      "Epoch 88/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0547 - accuracy: 0.7083 - val_loss: 0.0626 - val_accuracy: 0.6700\n",
      "Epoch 89/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0539 - accuracy: 0.7217 - val_loss: 0.0620 - val_accuracy: 0.6700\n",
      "Epoch 90/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0531 - accuracy: 0.7217 - val_loss: 0.0614 - val_accuracy: 0.6700\n",
      "Epoch 91/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0523 - accuracy: 0.7300 - val_loss: 0.0609 - val_accuracy: 0.6700\n",
      "Epoch 92/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0515 - accuracy: 0.7300 - val_loss: 0.0603 - val_accuracy: 0.6700\n",
      "Epoch 93/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0507 - accuracy: 0.7433 - val_loss: 0.0598 - val_accuracy: 0.6600\n",
      "Epoch 94/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0499 - accuracy: 0.7417 - val_loss: 0.0593 - val_accuracy: 0.6700\n",
      "Epoch 95/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0491 - accuracy: 0.7467 - val_loss: 0.0587 - val_accuracy: 0.6700\n",
      "Epoch 96/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0484 - accuracy: 0.7467 - val_loss: 0.0582 - val_accuracy: 0.6700\n",
      "Epoch 97/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0476 - accuracy: 0.7517 - val_loss: 0.0577 - val_accuracy: 0.6700\n",
      "Epoch 98/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0468 - accuracy: 0.7533 - val_loss: 0.0572 - val_accuracy: 0.6700\n",
      "Epoch 99/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0461 - accuracy: 0.7667 - val_loss: 0.0567 - val_accuracy: 0.6700\n",
      "Epoch 100/240\n",
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0454 - accuracy: 0.7717 - val_loss: 0.0562 - val_accuracy: 0.6700\n",
      "Epoch 101/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0447 - accuracy: 0.7717 - val_loss: 0.0557 - val_accuracy: 0.6600\n",
      "Epoch 102/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0440 - accuracy: 0.7733 - val_loss: 0.0553 - val_accuracy: 0.6600\n",
      "Epoch 103/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0433 - accuracy: 0.7750 - val_loss: 0.0548 - val_accuracy: 0.6700\n",
      "Epoch 104/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0426 - accuracy: 0.7767 - val_loss: 0.0544 - val_accuracy: 0.6700\n",
      "Epoch 105/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0419 - accuracy: 0.7850 - val_loss: 0.0539 - val_accuracy: 0.6700\n",
      "Epoch 106/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0413 - accuracy: 0.7800 - val_loss: 0.0535 - val_accuracy: 0.6600\n",
      "Epoch 107/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0407 - accuracy: 0.7850 - val_loss: 0.0531 - val_accuracy: 0.6700\n",
      "Epoch 108/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0401 - accuracy: 0.7867 - val_loss: 0.0527 - val_accuracy: 0.6700\n",
      "Epoch 109/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0395 - accuracy: 0.7917 - val_loss: 0.0523 - val_accuracy: 0.6700\n",
      "Epoch 110/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0389 - accuracy: 0.7950 - val_loss: 0.0519 - val_accuracy: 0.6700\n",
      "Epoch 111/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0384 - accuracy: 0.7950 - val_loss: 0.0515 - val_accuracy: 0.6700\n",
      "Epoch 112/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0379 - accuracy: 0.7933 - val_loss: 0.0511 - val_accuracy: 0.6700\n",
      "Epoch 113/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0373 - accuracy: 0.7950 - val_loss: 0.0507 - val_accuracy: 0.6700\n",
      "Epoch 114/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0368 - accuracy: 0.7967 - val_loss: 0.0503 - val_accuracy: 0.6700\n",
      "Epoch 115/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0363 - accuracy: 0.7983 - val_loss: 0.0500 - val_accuracy: 0.6700\n",
      "Epoch 116/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0358 - accuracy: 0.7983 - val_loss: 0.0497 - val_accuracy: 0.6700\n",
      "Epoch 117/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0354 - accuracy: 0.7983 - val_loss: 0.0493 - val_accuracy: 0.6600\n",
      "Epoch 118/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0350 - accuracy: 0.7983 - val_loss: 0.0490 - val_accuracy: 0.6600\n",
      "Epoch 119/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0345 - accuracy: 0.7983 - val_loss: 0.0486 - val_accuracy: 0.6600\n",
      "Epoch 120/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0341 - accuracy: 0.8000 - val_loss: 0.0483 - val_accuracy: 0.6700\n",
      "Epoch 121/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0337 - accuracy: 0.8033 - val_loss: 0.0479 - val_accuracy: 0.6700\n",
      "Epoch 122/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0333 - accuracy: 0.8067 - val_loss: 0.0476 - val_accuracy: 0.6900\n",
      "Epoch 123/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0329 - accuracy: 0.8067 - val_loss: 0.0473 - val_accuracy: 0.6900\n",
      "Epoch 124/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0325 - accuracy: 0.8083 - val_loss: 0.0470 - val_accuracy: 0.6900\n",
      "Epoch 125/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0321 - accuracy: 0.8100 - val_loss: 0.0467 - val_accuracy: 0.6900\n",
      "Epoch 126/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0317 - accuracy: 0.8100 - val_loss: 0.0464 - val_accuracy: 0.7000\n",
      "Epoch 127/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0314 - accuracy: 0.8100 - val_loss: 0.0460 - val_accuracy: 0.7000\n",
      "Epoch 128/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0310 - accuracy: 0.8133 - val_loss: 0.0457 - val_accuracy: 0.7000\n",
      "Epoch 129/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0307 - accuracy: 0.8133 - val_loss: 0.0454 - val_accuracy: 0.7000\n",
      "Epoch 130/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0303 - accuracy: 0.8167 - val_loss: 0.0451 - val_accuracy: 0.7000\n",
      "Epoch 131/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0300 - accuracy: 0.8167 - val_loss: 0.0447 - val_accuracy: 0.7000\n",
      "Epoch 132/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0297 - accuracy: 0.8233 - val_loss: 0.0444 - val_accuracy: 0.7100\n",
      "Epoch 133/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0294 - accuracy: 0.8267 - val_loss: 0.0441 - val_accuracy: 0.7100\n",
      "Epoch 134/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0290 - accuracy: 0.8317 - val_loss: 0.0438 - val_accuracy: 0.7200\n",
      "Epoch 135/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0287 - accuracy: 0.8333 - val_loss: 0.0435 - val_accuracy: 0.7200\n",
      "Epoch 136/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0284 - accuracy: 0.8417 - val_loss: 0.0432 - val_accuracy: 0.7200\n",
      "Epoch 137/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0281 - accuracy: 0.8417 - val_loss: 0.0429 - val_accuracy: 0.7200\n",
      "Epoch 138/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0278 - accuracy: 0.8417 - val_loss: 0.0426 - val_accuracy: 0.7200\n",
      "Epoch 139/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0275 - accuracy: 0.8450 - val_loss: 0.0423 - val_accuracy: 0.7200\n",
      "Epoch 140/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0272 - accuracy: 0.8500 - val_loss: 0.0421 - val_accuracy: 0.7200\n",
      "Epoch 141/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0269 - accuracy: 0.8567 - val_loss: 0.0418 - val_accuracy: 0.7200\n",
      "Epoch 142/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0267 - accuracy: 0.8567 - val_loss: 0.0416 - val_accuracy: 0.7200\n",
      "Epoch 143/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0264 - accuracy: 0.8583 - val_loss: 0.0413 - val_accuracy: 0.7200\n",
      "Epoch 144/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0261 - accuracy: 0.8617 - val_loss: 0.0411 - val_accuracy: 0.7200\n",
      "Epoch 145/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0259 - accuracy: 0.8633 - val_loss: 0.0408 - val_accuracy: 0.7300\n",
      "Epoch 146/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0256 - accuracy: 0.8667 - val_loss: 0.0406 - val_accuracy: 0.7300\n",
      "Epoch 147/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0254 - accuracy: 0.8683 - val_loss: 0.0403 - val_accuracy: 0.7300\n",
      "Epoch 148/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0251 - accuracy: 0.8700 - val_loss: 0.0400 - val_accuracy: 0.7400\n",
      "Epoch 149/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0248 - accuracy: 0.8750 - val_loss: 0.0398 - val_accuracy: 0.7400\n",
      "Epoch 150/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0246 - accuracy: 0.8767 - val_loss: 0.0395 - val_accuracy: 0.7400\n",
      "Epoch 151/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0243 - accuracy: 0.8767 - val_loss: 0.0393 - val_accuracy: 0.7400\n",
      "Epoch 152/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0241 - accuracy: 0.8800 - val_loss: 0.0391 - val_accuracy: 0.7400\n",
      "Epoch 153/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0239 - accuracy: 0.8783 - val_loss: 0.0389 - val_accuracy: 0.7400\n",
      "Epoch 154/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0237 - accuracy: 0.8850 - val_loss: 0.0386 - val_accuracy: 0.7400\n",
      "Epoch 155/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0234 - accuracy: 0.8817 - val_loss: 0.0384 - val_accuracy: 0.7400\n",
      "Epoch 156/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0232 - accuracy: 0.8850 - val_loss: 0.0382 - val_accuracy: 0.7400\n",
      "Epoch 157/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0230 - accuracy: 0.8917 - val_loss: 0.0380 - val_accuracy: 0.7400\n",
      "Epoch 158/240\n",
      "600/600 [==============================] - 0s 115us/sample - loss: 0.0228 - accuracy: 0.8900 - val_loss: 0.0377 - val_accuracy: 0.7400\n",
      "Epoch 159/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0226 - accuracy: 0.8900 - val_loss: 0.0375 - val_accuracy: 0.7400\n",
      "Epoch 160/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0224 - accuracy: 0.8917 - val_loss: 0.0374 - val_accuracy: 0.7400\n",
      "Epoch 161/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0221 - accuracy: 0.8917 - val_loss: 0.0372 - val_accuracy: 0.7500\n",
      "Epoch 162/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0219 - accuracy: 0.8917 - val_loss: 0.0370 - val_accuracy: 0.7500\n",
      "Epoch 163/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0217 - accuracy: 0.8917 - val_loss: 0.0367 - val_accuracy: 0.7500\n",
      "Epoch 164/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0215 - accuracy: 0.8917 - val_loss: 0.0366 - val_accuracy: 0.7500\n",
      "Epoch 165/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0213 - accuracy: 0.8950 - val_loss: 0.0364 - val_accuracy: 0.7500\n",
      "Epoch 166/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0211 - accuracy: 0.8933 - val_loss: 0.0362 - val_accuracy: 0.7700\n",
      "Epoch 167/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0209 - accuracy: 0.8950 - val_loss: 0.0360 - val_accuracy: 0.7800\n",
      "Epoch 168/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0208 - accuracy: 0.8950 - val_loss: 0.0358 - val_accuracy: 0.7800\n",
      "Epoch 169/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0206 - accuracy: 0.8950 - val_loss: 0.0357 - val_accuracy: 0.7800\n",
      "Epoch 170/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0204 - accuracy: 0.8967 - val_loss: 0.0355 - val_accuracy: 0.7800\n",
      "Epoch 171/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0202 - accuracy: 0.8967 - val_loss: 0.0353 - val_accuracy: 0.7800\n",
      "Epoch 172/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0200 - accuracy: 0.8967 - val_loss: 0.0352 - val_accuracy: 0.7900\n",
      "Epoch 173/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0199 - accuracy: 0.8967 - val_loss: 0.0350 - val_accuracy: 0.7900\n",
      "Epoch 174/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0197 - accuracy: 0.9000 - val_loss: 0.0348 - val_accuracy: 0.7900\n",
      "Epoch 175/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0195 - accuracy: 0.9000 - val_loss: 0.0347 - val_accuracy: 0.8000\n",
      "Epoch 176/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0193 - accuracy: 0.8983 - val_loss: 0.0345 - val_accuracy: 0.8000\n",
      "Epoch 177/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0192 - accuracy: 0.8967 - val_loss: 0.0344 - val_accuracy: 0.8000\n",
      "Epoch 178/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0190 - accuracy: 0.9017 - val_loss: 0.0342 - val_accuracy: 0.8000\n",
      "Epoch 179/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0188 - accuracy: 0.9033 - val_loss: 0.0341 - val_accuracy: 0.8000\n",
      "Epoch 180/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0187 - accuracy: 0.9050 - val_loss: 0.0339 - val_accuracy: 0.8000\n",
      "Epoch 181/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0185 - accuracy: 0.9017 - val_loss: 0.0337 - val_accuracy: 0.8100\n",
      "Epoch 182/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0184 - accuracy: 0.9033 - val_loss: 0.0336 - val_accuracy: 0.8100\n",
      "Epoch 183/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0182 - accuracy: 0.9067 - val_loss: 0.0335 - val_accuracy: 0.8100\n",
      "Epoch 184/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0180 - accuracy: 0.9050 - val_loss: 0.0333 - val_accuracy: 0.8100\n",
      "Epoch 185/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0179 - accuracy: 0.9017 - val_loss: 0.0332 - val_accuracy: 0.8100\n",
      "Epoch 186/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0177 - accuracy: 0.9067 - val_loss: 0.0332 - val_accuracy: 0.8100\n",
      "Epoch 187/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0176 - accuracy: 0.9033 - val_loss: 0.0331 - val_accuracy: 0.8100\n",
      "Epoch 188/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0174 - accuracy: 0.9067 - val_loss: 0.0329 - val_accuracy: 0.8100\n",
      "Epoch 189/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0173 - accuracy: 0.9050 - val_loss: 0.0328 - val_accuracy: 0.8100\n",
      "Epoch 190/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0172 - accuracy: 0.9083 - val_loss: 0.0326 - val_accuracy: 0.8100\n",
      "Epoch 191/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0170 - accuracy: 0.9083 - val_loss: 0.0325 - val_accuracy: 0.8100\n",
      "Epoch 192/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0169 - accuracy: 0.9083 - val_loss: 0.0323 - val_accuracy: 0.8100\n",
      "Epoch 193/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0167 - accuracy: 0.9067 - val_loss: 0.0322 - val_accuracy: 0.8100\n",
      "Epoch 194/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0166 - accuracy: 0.9100 - val_loss: 0.0321 - val_accuracy: 0.8100\n",
      "Epoch 195/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0165 - accuracy: 0.9067 - val_loss: 0.0319 - val_accuracy: 0.8100\n",
      "Epoch 196/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0163 - accuracy: 0.9100 - val_loss: 0.0319 - val_accuracy: 0.8100\n",
      "Epoch 197/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0162 - accuracy: 0.9083 - val_loss: 0.0318 - val_accuracy: 0.8100\n",
      "Epoch 198/240\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0161 - accuracy: 0.9117 - val_loss: 0.0317 - val_accuracy: 0.8100\n",
      "Epoch 199/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0160 - accuracy: 0.9100 - val_loss: 0.0315 - val_accuracy: 0.8100\n",
      "Epoch 200/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0158 - accuracy: 0.9133 - val_loss: 0.0314 - val_accuracy: 0.8100\n",
      "Epoch 201/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0157 - accuracy: 0.9150 - val_loss: 0.0313 - val_accuracy: 0.8100\n",
      "Epoch 202/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0156 - accuracy: 0.9133 - val_loss: 0.0312 - val_accuracy: 0.8100\n",
      "Epoch 203/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0155 - accuracy: 0.9167 - val_loss: 0.0310 - val_accuracy: 0.8100\n",
      "Epoch 204/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0153 - accuracy: 0.9183 - val_loss: 0.0309 - val_accuracy: 0.8100\n",
      "Epoch 205/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0152 - accuracy: 0.9183 - val_loss: 0.0309 - val_accuracy: 0.8100\n",
      "Epoch 206/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0151 - accuracy: 0.9200 - val_loss: 0.0308 - val_accuracy: 0.8100\n",
      "Epoch 207/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0149 - accuracy: 0.9183 - val_loss: 0.0306 - val_accuracy: 0.8100\n",
      "Epoch 208/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0149 - accuracy: 0.9200 - val_loss: 0.0306 - val_accuracy: 0.8100\n",
      "Epoch 209/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0148 - accuracy: 0.9300 - val_loss: 0.0305 - val_accuracy: 0.8100\n",
      "Epoch 210/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0146 - accuracy: 0.9283 - val_loss: 0.0304 - val_accuracy: 0.8100\n",
      "Epoch 211/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0145 - accuracy: 0.9267 - val_loss: 0.0303 - val_accuracy: 0.8100\n",
      "Epoch 212/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0144 - accuracy: 0.9300 - val_loss: 0.0302 - val_accuracy: 0.8100\n",
      "Epoch 213/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0143 - accuracy: 0.9300 - val_loss: 0.0301 - val_accuracy: 0.8100\n",
      "Epoch 214/240\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0142 - accuracy: 0.9300 - val_loss: 0.0301 - val_accuracy: 0.8100\n",
      "Epoch 215/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0141 - accuracy: 0.9333 - val_loss: 0.0300 - val_accuracy: 0.8100\n",
      "Epoch 216/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0140 - accuracy: 0.9333 - val_loss: 0.0299 - val_accuracy: 0.8100\n",
      "Epoch 217/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0139 - accuracy: 0.9333 - val_loss: 0.0298 - val_accuracy: 0.8100\n",
      "Epoch 218/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0138 - accuracy: 0.9317 - val_loss: 0.0298 - val_accuracy: 0.8100\n",
      "Epoch 219/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0137 - accuracy: 0.9333 - val_loss: 0.0297 - val_accuracy: 0.8100\n",
      "Epoch 220/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0136 - accuracy: 0.9350 - val_loss: 0.0297 - val_accuracy: 0.8100\n",
      "Epoch 221/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0135 - accuracy: 0.9350 - val_loss: 0.0295 - val_accuracy: 0.8100\n",
      "Epoch 222/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0134 - accuracy: 0.9350 - val_loss: 0.0295 - val_accuracy: 0.8100\n",
      "Epoch 223/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0133 - accuracy: 0.9367 - val_loss: 0.0294 - val_accuracy: 0.8100\n",
      "Epoch 224/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0132 - accuracy: 0.9383 - val_loss: 0.0292 - val_accuracy: 0.8100\n",
      "Epoch 225/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0131 - accuracy: 0.9383 - val_loss: 0.0292 - val_accuracy: 0.8100\n",
      "Epoch 226/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0130 - accuracy: 0.9383 - val_loss: 0.0291 - val_accuracy: 0.8100\n",
      "Epoch 227/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0129 - accuracy: 0.9367 - val_loss: 0.0291 - val_accuracy: 0.8100\n",
      "Epoch 228/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0128 - accuracy: 0.9417 - val_loss: 0.0290 - val_accuracy: 0.8100\n",
      "Epoch 229/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0127 - accuracy: 0.9400 - val_loss: 0.0290 - val_accuracy: 0.8100\n",
      "Epoch 230/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0126 - accuracy: 0.9417 - val_loss: 0.0288 - val_accuracy: 0.8100\n",
      "Epoch 231/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0125 - accuracy: 0.9450 - val_loss: 0.0288 - val_accuracy: 0.8100\n",
      "Epoch 232/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0124 - accuracy: 0.9417 - val_loss: 0.0288 - val_accuracy: 0.8100\n",
      "Epoch 233/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0124 - accuracy: 0.9433 - val_loss: 0.0287 - val_accuracy: 0.8100\n",
      "Epoch 234/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0123 - accuracy: 0.9433 - val_loss: 0.0287 - val_accuracy: 0.8100\n",
      "Epoch 235/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0122 - accuracy: 0.9483 - val_loss: 0.0286 - val_accuracy: 0.8100\n",
      "Epoch 236/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0121 - accuracy: 0.9450 - val_loss: 0.0285 - val_accuracy: 0.8100\n",
      "Epoch 237/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0120 - accuracy: 0.9467 - val_loss: 0.0285 - val_accuracy: 0.8100\n",
      "Epoch 238/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0119 - accuracy: 0.9483 - val_loss: 0.0284 - val_accuracy: 0.8100\n",
      "Epoch 239/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0118 - accuracy: 0.9450 - val_loss: 0.0284 - val_accuracy: 0.8100\n",
      "Epoch 240/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0118 - accuracy: 0.9483 - val_loss: 0.0283 - val_accuracy: 0.8100\n",
      "Training date and time : \n",
      "2020-04-09 21:05:06\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/240\n",
      "600/600 [==============================] - 0s 655us/sample - loss: 0.0899 - accuracy: 0.1800 - val_loss: 0.0899 - val_accuracy: 0.2300\n",
      "Epoch 2/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0898 - accuracy: 0.2033 - val_loss: 0.0898 - val_accuracy: 0.2300\n",
      "Epoch 3/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0896 - accuracy: 0.2117 - val_loss: 0.0897 - val_accuracy: 0.2300\n",
      "Epoch 4/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0895 - accuracy: 0.2183 - val_loss: 0.0897 - val_accuracy: 0.2300\n",
      "Epoch 5/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0894 - accuracy: 0.2317 - val_loss: 0.0896 - val_accuracy: 0.2300\n",
      "Epoch 6/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0893 - accuracy: 0.2483 - val_loss: 0.0895 - val_accuracy: 0.2400\n",
      "Epoch 7/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0892 - accuracy: 0.2583 - val_loss: 0.0894 - val_accuracy: 0.2400\n",
      "Epoch 8/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0891 - accuracy: 0.2683 - val_loss: 0.0893 - val_accuracy: 0.2300\n",
      "Epoch 9/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0890 - accuracy: 0.2700 - val_loss: 0.0892 - val_accuracy: 0.2300\n",
      "Epoch 10/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0889 - accuracy: 0.2750 - val_loss: 0.0891 - val_accuracy: 0.2300\n",
      "Epoch 11/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0887 - accuracy: 0.2783 - val_loss: 0.0890 - val_accuracy: 0.2400\n",
      "Epoch 12/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0886 - accuracy: 0.2800 - val_loss: 0.0889 - val_accuracy: 0.2400\n",
      "Epoch 13/240\n",
      "600/600 [==============================] - 0s 119us/sample - loss: 0.0885 - accuracy: 0.2883 - val_loss: 0.0888 - val_accuracy: 0.2400\n",
      "Epoch 14/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0884 - accuracy: 0.2917 - val_loss: 0.0887 - val_accuracy: 0.2500\n",
      "Epoch 15/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0882 - accuracy: 0.2950 - val_loss: 0.0886 - val_accuracy: 0.2800\n",
      "Epoch 16/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0881 - accuracy: 0.3100 - val_loss: 0.0885 - val_accuracy: 0.2900\n",
      "Epoch 17/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0880 - accuracy: 0.3250 - val_loss: 0.0884 - val_accuracy: 0.2900\n",
      "Epoch 18/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0878 - accuracy: 0.3367 - val_loss: 0.0883 - val_accuracy: 0.2900\n",
      "Epoch 19/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0877 - accuracy: 0.3533 - val_loss: 0.0882 - val_accuracy: 0.3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0875 - accuracy: 0.3700 - val_loss: 0.0881 - val_accuracy: 0.3000\n",
      "Epoch 21/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0874 - accuracy: 0.3783 - val_loss: 0.0879 - val_accuracy: 0.3100\n",
      "Epoch 22/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0872 - accuracy: 0.3933 - val_loss: 0.0878 - val_accuracy: 0.3100\n",
      "Epoch 23/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0871 - accuracy: 0.4000 - val_loss: 0.0877 - val_accuracy: 0.3200\n",
      "Epoch 24/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0869 - accuracy: 0.4117 - val_loss: 0.0875 - val_accuracy: 0.3300\n",
      "Epoch 25/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0867 - accuracy: 0.4233 - val_loss: 0.0874 - val_accuracy: 0.3400\n",
      "Epoch 26/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0865 - accuracy: 0.4333 - val_loss: 0.0873 - val_accuracy: 0.3600\n",
      "Epoch 27/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0864 - accuracy: 0.4383 - val_loss: 0.0871 - val_accuracy: 0.3500\n",
      "Epoch 28/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0862 - accuracy: 0.4450 - val_loss: 0.0869 - val_accuracy: 0.3700\n",
      "Epoch 29/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0860 - accuracy: 0.4433 - val_loss: 0.0868 - val_accuracy: 0.3700\n",
      "Epoch 30/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0857 - accuracy: 0.4467 - val_loss: 0.0866 - val_accuracy: 0.3700\n",
      "Epoch 31/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0855 - accuracy: 0.4467 - val_loss: 0.0864 - val_accuracy: 0.3700\n",
      "Epoch 32/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0853 - accuracy: 0.4550 - val_loss: 0.0862 - val_accuracy: 0.3600\n",
      "Epoch 33/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0850 - accuracy: 0.4550 - val_loss: 0.0860 - val_accuracy: 0.3600\n",
      "Epoch 34/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0848 - accuracy: 0.4667 - val_loss: 0.0858 - val_accuracy: 0.3600\n",
      "Epoch 35/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0845 - accuracy: 0.4650 - val_loss: 0.0855 - val_accuracy: 0.3500\n",
      "Epoch 36/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0842 - accuracy: 0.4700 - val_loss: 0.0853 - val_accuracy: 0.3500\n",
      "Epoch 37/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0839 - accuracy: 0.4683 - val_loss: 0.0850 - val_accuracy: 0.3400\n",
      "Epoch 38/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0836 - accuracy: 0.4667 - val_loss: 0.0848 - val_accuracy: 0.3300\n",
      "Epoch 39/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0832 - accuracy: 0.4683 - val_loss: 0.0845 - val_accuracy: 0.3300\n",
      "Epoch 40/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0829 - accuracy: 0.4667 - val_loss: 0.0842 - val_accuracy: 0.3200\n",
      "Epoch 41/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0825 - accuracy: 0.4633 - val_loss: 0.0839 - val_accuracy: 0.3200\n",
      "Epoch 42/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0821 - accuracy: 0.4583 - val_loss: 0.0835 - val_accuracy: 0.3300\n",
      "Epoch 43/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0817 - accuracy: 0.4583 - val_loss: 0.0832 - val_accuracy: 0.3300\n",
      "Epoch 44/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0813 - accuracy: 0.4617 - val_loss: 0.0828 - val_accuracy: 0.3300\n",
      "Epoch 45/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0808 - accuracy: 0.4633 - val_loss: 0.0825 - val_accuracy: 0.3300\n",
      "Epoch 46/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0804 - accuracy: 0.4617 - val_loss: 0.0821 - val_accuracy: 0.3300\n",
      "Epoch 47/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0799 - accuracy: 0.4667 - val_loss: 0.0817 - val_accuracy: 0.3300\n",
      "Epoch 48/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0794 - accuracy: 0.4633 - val_loss: 0.0813 - val_accuracy: 0.3400\n",
      "Epoch 49/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0789 - accuracy: 0.4683 - val_loss: 0.0809 - val_accuracy: 0.3500\n",
      "Epoch 50/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0784 - accuracy: 0.4733 - val_loss: 0.0805 - val_accuracy: 0.3600\n",
      "Epoch 51/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0779 - accuracy: 0.4767 - val_loss: 0.0801 - val_accuracy: 0.3700\n",
      "Epoch 52/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0774 - accuracy: 0.4800 - val_loss: 0.0797 - val_accuracy: 0.3900\n",
      "Epoch 53/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0769 - accuracy: 0.4800 - val_loss: 0.0793 - val_accuracy: 0.4000\n",
      "Epoch 54/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0763 - accuracy: 0.4933 - val_loss: 0.0789 - val_accuracy: 0.4100\n",
      "Epoch 55/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0758 - accuracy: 0.5017 - val_loss: 0.0785 - val_accuracy: 0.4200\n",
      "Epoch 56/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0752 - accuracy: 0.4983 - val_loss: 0.0780 - val_accuracy: 0.4300\n",
      "Epoch 57/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0747 - accuracy: 0.5100 - val_loss: 0.0776 - val_accuracy: 0.4400\n",
      "Epoch 58/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0741 - accuracy: 0.5183 - val_loss: 0.0772 - val_accuracy: 0.4400\n",
      "Epoch 59/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0735 - accuracy: 0.5350 - val_loss: 0.0767 - val_accuracy: 0.4500\n",
      "Epoch 60/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0729 - accuracy: 0.5383 - val_loss: 0.0763 - val_accuracy: 0.4700\n",
      "Epoch 61/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0723 - accuracy: 0.5450 - val_loss: 0.0758 - val_accuracy: 0.4800\n",
      "Epoch 62/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0717 - accuracy: 0.5617 - val_loss: 0.0753 - val_accuracy: 0.4900\n",
      "Epoch 63/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0711 - accuracy: 0.5683 - val_loss: 0.0748 - val_accuracy: 0.5000\n",
      "Epoch 64/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0704 - accuracy: 0.5750 - val_loss: 0.0744 - val_accuracy: 0.5100\n",
      "Epoch 65/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0698 - accuracy: 0.5783 - val_loss: 0.0739 - val_accuracy: 0.5100\n",
      "Epoch 66/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0691 - accuracy: 0.5900 - val_loss: 0.0734 - val_accuracy: 0.5300\n",
      "Epoch 67/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0684 - accuracy: 0.5883 - val_loss: 0.0729 - val_accuracy: 0.5400\n",
      "Epoch 68/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0678 - accuracy: 0.6050 - val_loss: 0.0723 - val_accuracy: 0.5600\n",
      "Epoch 69/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0671 - accuracy: 0.6183 - val_loss: 0.0718 - val_accuracy: 0.5600\n",
      "Epoch 70/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0664 - accuracy: 0.6200 - val_loss: 0.0713 - val_accuracy: 0.5600\n",
      "Epoch 71/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0657 - accuracy: 0.6267 - val_loss: 0.0708 - val_accuracy: 0.5600\n",
      "Epoch 72/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0649 - accuracy: 0.6333 - val_loss: 0.0702 - val_accuracy: 0.5600\n",
      "Epoch 73/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0642 - accuracy: 0.6450 - val_loss: 0.0697 - val_accuracy: 0.5800\n",
      "Epoch 74/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0635 - accuracy: 0.6500 - val_loss: 0.0691 - val_accuracy: 0.5900\n",
      "Epoch 75/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0627 - accuracy: 0.6550 - val_loss: 0.0686 - val_accuracy: 0.5900\n",
      "Epoch 76/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0619 - accuracy: 0.6683 - val_loss: 0.0680 - val_accuracy: 0.6200\n",
      "Epoch 77/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0612 - accuracy: 0.6717 - val_loss: 0.0674 - val_accuracy: 0.6400\n",
      "Epoch 78/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0604 - accuracy: 0.6883 - val_loss: 0.0669 - val_accuracy: 0.6400\n",
      "Epoch 79/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0596 - accuracy: 0.6900 - val_loss: 0.0663 - val_accuracy: 0.6400\n",
      "Epoch 80/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0588 - accuracy: 0.6967 - val_loss: 0.0657 - val_accuracy: 0.6500\n",
      "Epoch 81/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0580 - accuracy: 0.7000 - val_loss: 0.0651 - val_accuracy: 0.6500\n",
      "Epoch 82/240\n",
      "600/600 [==============================] - 0s 116us/sample - loss: 0.0571 - accuracy: 0.7133 - val_loss: 0.0645 - val_accuracy: 0.6600\n",
      "Epoch 83/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0563 - accuracy: 0.7183 - val_loss: 0.0640 - val_accuracy: 0.6600\n",
      "Epoch 84/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0555 - accuracy: 0.7233 - val_loss: 0.0634 - val_accuracy: 0.6600\n",
      "Epoch 85/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0546 - accuracy: 0.7267 - val_loss: 0.0628 - val_accuracy: 0.6600\n",
      "Epoch 86/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0538 - accuracy: 0.7267 - val_loss: 0.0622 - val_accuracy: 0.6600\n",
      "Epoch 87/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0530 - accuracy: 0.7367 - val_loss: 0.0616 - val_accuracy: 0.6600\n",
      "Epoch 88/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0522 - accuracy: 0.7417 - val_loss: 0.0610 - val_accuracy: 0.6600\n",
      "Epoch 89/240\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0513 - accuracy: 0.7417 - val_loss: 0.0605 - val_accuracy: 0.6600\n",
      "Epoch 90/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0505 - accuracy: 0.7467 - val_loss: 0.0599 - val_accuracy: 0.6700\n",
      "Epoch 91/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0497 - accuracy: 0.7517 - val_loss: 0.0593 - val_accuracy: 0.6600\n",
      "Epoch 92/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0489 - accuracy: 0.7517 - val_loss: 0.0588 - val_accuracy: 0.6600\n",
      "Epoch 93/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0481 - accuracy: 0.7550 - val_loss: 0.0582 - val_accuracy: 0.6600\n",
      "Epoch 94/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0473 - accuracy: 0.7583 - val_loss: 0.0577 - val_accuracy: 0.6600\n",
      "Epoch 95/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0465 - accuracy: 0.7683 - val_loss: 0.0572 - val_accuracy: 0.6500\n",
      "Epoch 96/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0458 - accuracy: 0.7700 - val_loss: 0.0567 - val_accuracy: 0.6600\n",
      "Epoch 97/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0450 - accuracy: 0.7717 - val_loss: 0.0562 - val_accuracy: 0.6600\n",
      "Epoch 98/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0443 - accuracy: 0.7767 - val_loss: 0.0557 - val_accuracy: 0.6700\n",
      "Epoch 99/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0436 - accuracy: 0.7767 - val_loss: 0.0552 - val_accuracy: 0.6700\n",
      "Epoch 100/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0429 - accuracy: 0.7800 - val_loss: 0.0547 - val_accuracy: 0.6700\n",
      "Epoch 101/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0422 - accuracy: 0.7783 - val_loss: 0.0543 - val_accuracy: 0.6700\n",
      "Epoch 102/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0415 - accuracy: 0.7833 - val_loss: 0.0539 - val_accuracy: 0.6600\n",
      "Epoch 103/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0409 - accuracy: 0.7817 - val_loss: 0.0534 - val_accuracy: 0.6600\n",
      "Epoch 104/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0402 - accuracy: 0.7883 - val_loss: 0.0530 - val_accuracy: 0.6600\n",
      "Epoch 105/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0396 - accuracy: 0.7917 - val_loss: 0.0525 - val_accuracy: 0.6600\n",
      "Epoch 106/240\n",
      "600/600 [==============================] - 0s 114us/sample - loss: 0.0390 - accuracy: 0.7900 - val_loss: 0.0522 - val_accuracy: 0.6600\n",
      "Epoch 107/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0385 - accuracy: 0.7933 - val_loss: 0.0518 - val_accuracy: 0.6600\n",
      "Epoch 108/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0379 - accuracy: 0.7933 - val_loss: 0.0513 - val_accuracy: 0.6600\n",
      "Epoch 109/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0374 - accuracy: 0.7950 - val_loss: 0.0509 - val_accuracy: 0.6600\n",
      "Epoch 110/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0368 - accuracy: 0.7933 - val_loss: 0.0505 - val_accuracy: 0.6600\n",
      "Epoch 111/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0363 - accuracy: 0.7950 - val_loss: 0.0501 - val_accuracy: 0.6600\n",
      "Epoch 112/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0358 - accuracy: 0.7933 - val_loss: 0.0497 - val_accuracy: 0.6600\n",
      "Epoch 113/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0353 - accuracy: 0.7967 - val_loss: 0.0494 - val_accuracy: 0.6600\n",
      "Epoch 114/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0348 - accuracy: 0.7967 - val_loss: 0.0490 - val_accuracy: 0.6600\n",
      "Epoch 115/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0344 - accuracy: 0.7983 - val_loss: 0.0486 - val_accuracy: 0.6600\n",
      "Epoch 116/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0339 - accuracy: 0.8050 - val_loss: 0.0483 - val_accuracy: 0.6600\n",
      "Epoch 117/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0335 - accuracy: 0.8033 - val_loss: 0.0480 - val_accuracy: 0.6600\n",
      "Epoch 118/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0331 - accuracy: 0.8050 - val_loss: 0.0476 - val_accuracy: 0.6700\n",
      "Epoch 119/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0327 - accuracy: 0.8067 - val_loss: 0.0472 - val_accuracy: 0.6800\n",
      "Epoch 120/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0323 - accuracy: 0.8067 - val_loss: 0.0468 - val_accuracy: 0.6900\n",
      "Epoch 121/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0319 - accuracy: 0.8100 - val_loss: 0.0464 - val_accuracy: 0.6900\n",
      "Epoch 122/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0315 - accuracy: 0.8100 - val_loss: 0.0461 - val_accuracy: 0.6900\n",
      "Epoch 123/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0311 - accuracy: 0.8150 - val_loss: 0.0458 - val_accuracy: 0.6900\n",
      "Epoch 124/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0307 - accuracy: 0.8167 - val_loss: 0.0455 - val_accuracy: 0.6900\n",
      "Epoch 125/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0304 - accuracy: 0.8233 - val_loss: 0.0451 - val_accuracy: 0.6900\n",
      "Epoch 126/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0300 - accuracy: 0.8233 - val_loss: 0.0448 - val_accuracy: 0.7000\n",
      "Epoch 127/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0296 - accuracy: 0.8283 - val_loss: 0.0445 - val_accuracy: 0.7100\n",
      "Epoch 128/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0293 - accuracy: 0.8333 - val_loss: 0.0441 - val_accuracy: 0.7100\n",
      "Epoch 129/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0290 - accuracy: 0.8350 - val_loss: 0.0437 - val_accuracy: 0.7100\n",
      "Epoch 130/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0286 - accuracy: 0.8367 - val_loss: 0.0434 - val_accuracy: 0.7100\n",
      "Epoch 131/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0283 - accuracy: 0.8383 - val_loss: 0.0431 - val_accuracy: 0.7100\n",
      "Epoch 132/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0280 - accuracy: 0.8467 - val_loss: 0.0428 - val_accuracy: 0.7100\n",
      "Epoch 133/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0277 - accuracy: 0.8500 - val_loss: 0.0425 - val_accuracy: 0.7100\n",
      "Epoch 134/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0274 - accuracy: 0.8567 - val_loss: 0.0422 - val_accuracy: 0.7100\n",
      "Epoch 135/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0271 - accuracy: 0.8600 - val_loss: 0.0419 - val_accuracy: 0.7200\n",
      "Epoch 136/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0268 - accuracy: 0.8633 - val_loss: 0.0416 - val_accuracy: 0.7300\n",
      "Epoch 137/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0265 - accuracy: 0.8667 - val_loss: 0.0413 - val_accuracy: 0.7300\n",
      "Epoch 138/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0262 - accuracy: 0.8633 - val_loss: 0.0410 - val_accuracy: 0.7300\n",
      "Epoch 139/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0259 - accuracy: 0.8650 - val_loss: 0.0408 - val_accuracy: 0.7300\n",
      "Epoch 140/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0256 - accuracy: 0.8683 - val_loss: 0.0406 - val_accuracy: 0.7300\n",
      "Epoch 141/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0254 - accuracy: 0.8717 - val_loss: 0.0403 - val_accuracy: 0.7400\n",
      "Epoch 142/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0251 - accuracy: 0.8700 - val_loss: 0.0401 - val_accuracy: 0.7400\n",
      "Epoch 143/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0249 - accuracy: 0.8733 - val_loss: 0.0399 - val_accuracy: 0.7300\n",
      "Epoch 144/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0246 - accuracy: 0.8767 - val_loss: 0.0396 - val_accuracy: 0.7300\n",
      "Epoch 145/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0243 - accuracy: 0.8800 - val_loss: 0.0393 - val_accuracy: 0.7400\n",
      "Epoch 146/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0241 - accuracy: 0.8833 - val_loss: 0.0391 - val_accuracy: 0.7300\n",
      "Epoch 147/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0238 - accuracy: 0.8800 - val_loss: 0.0389 - val_accuracy: 0.7400\n",
      "Epoch 148/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0236 - accuracy: 0.8833 - val_loss: 0.0386 - val_accuracy: 0.7400\n",
      "Epoch 149/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0234 - accuracy: 0.8850 - val_loss: 0.0384 - val_accuracy: 0.7400\n",
      "Epoch 150/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0232 - accuracy: 0.8850 - val_loss: 0.0382 - val_accuracy: 0.7400\n",
      "Epoch 151/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0229 - accuracy: 0.8883 - val_loss: 0.0379 - val_accuracy: 0.7500\n",
      "Epoch 152/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0227 - accuracy: 0.8883 - val_loss: 0.0377 - val_accuracy: 0.7500\n",
      "Epoch 153/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0225 - accuracy: 0.8883 - val_loss: 0.0376 - val_accuracy: 0.7600\n",
      "Epoch 154/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0223 - accuracy: 0.8917 - val_loss: 0.0373 - val_accuracy: 0.7700\n",
      "Epoch 155/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0220 - accuracy: 0.8917 - val_loss: 0.0371 - val_accuracy: 0.7700\n",
      "Epoch 156/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0218 - accuracy: 0.8917 - val_loss: 0.0369 - val_accuracy: 0.7700\n",
      "Epoch 157/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0216 - accuracy: 0.8933 - val_loss: 0.0367 - val_accuracy: 0.7700\n",
      "Epoch 158/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0214 - accuracy: 0.8950 - val_loss: 0.0365 - val_accuracy: 0.7700\n",
      "Epoch 159/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0212 - accuracy: 0.8933 - val_loss: 0.0363 - val_accuracy: 0.7800\n",
      "Epoch 160/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0210 - accuracy: 0.8933 - val_loss: 0.0361 - val_accuracy: 0.7800\n",
      "Epoch 161/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0208 - accuracy: 0.8950 - val_loss: 0.0360 - val_accuracy: 0.7800\n",
      "Epoch 162/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0206 - accuracy: 0.8967 - val_loss: 0.0358 - val_accuracy: 0.7800\n",
      "Epoch 163/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0204 - accuracy: 0.8933 - val_loss: 0.0356 - val_accuracy: 0.7900\n",
      "Epoch 164/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0202 - accuracy: 0.8983 - val_loss: 0.0355 - val_accuracy: 0.7800\n",
      "Epoch 165/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0200 - accuracy: 0.8967 - val_loss: 0.0353 - val_accuracy: 0.7900\n",
      "Epoch 166/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0199 - accuracy: 0.8967 - val_loss: 0.0351 - val_accuracy: 0.8000\n",
      "Epoch 167/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0197 - accuracy: 0.8967 - val_loss: 0.0349 - val_accuracy: 0.8000\n",
      "Epoch 168/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0195 - accuracy: 0.8983 - val_loss: 0.0348 - val_accuracy: 0.8000\n",
      "Epoch 169/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0193 - accuracy: 0.8983 - val_loss: 0.0347 - val_accuracy: 0.8000\n",
      "Epoch 170/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0191 - accuracy: 0.9000 - val_loss: 0.0345 - val_accuracy: 0.8000\n",
      "Epoch 171/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0190 - accuracy: 0.9033 - val_loss: 0.0343 - val_accuracy: 0.8000\n",
      "Epoch 172/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0188 - accuracy: 0.9000 - val_loss: 0.0342 - val_accuracy: 0.8000\n",
      "Epoch 173/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0187 - accuracy: 0.9033 - val_loss: 0.0340 - val_accuracy: 0.8000\n",
      "Epoch 174/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0185 - accuracy: 0.9017 - val_loss: 0.0339 - val_accuracy: 0.8000\n",
      "Epoch 175/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0184 - accuracy: 0.9067 - val_loss: 0.0337 - val_accuracy: 0.8000\n",
      "Epoch 176/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0182 - accuracy: 0.9000 - val_loss: 0.0336 - val_accuracy: 0.8000\n",
      "Epoch 177/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0180 - accuracy: 0.9033 - val_loss: 0.0335 - val_accuracy: 0.8000\n",
      "Epoch 178/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0179 - accuracy: 0.9067 - val_loss: 0.0333 - val_accuracy: 0.8100\n",
      "Epoch 179/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0177 - accuracy: 0.9050 - val_loss: 0.0332 - val_accuracy: 0.8100\n",
      "Epoch 180/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0175 - accuracy: 0.9050 - val_loss: 0.0330 - val_accuracy: 0.8100\n",
      "Epoch 181/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0174 - accuracy: 0.9067 - val_loss: 0.0328 - val_accuracy: 0.8100\n",
      "Epoch 182/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0173 - accuracy: 0.9067 - val_loss: 0.0328 - val_accuracy: 0.8100\n",
      "Epoch 183/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0171 - accuracy: 0.9067 - val_loss: 0.0326 - val_accuracy: 0.8100\n",
      "Epoch 184/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0170 - accuracy: 0.9067 - val_loss: 0.0325 - val_accuracy: 0.8100\n",
      "Epoch 185/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0168 - accuracy: 0.9100 - val_loss: 0.0324 - val_accuracy: 0.8100\n",
      "Epoch 186/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0167 - accuracy: 0.9100 - val_loss: 0.0324 - val_accuracy: 0.8100\n",
      "Epoch 187/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0166 - accuracy: 0.9083 - val_loss: 0.0322 - val_accuracy: 0.8100\n",
      "Epoch 188/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0164 - accuracy: 0.9133 - val_loss: 0.0321 - val_accuracy: 0.8100\n",
      "Epoch 189/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0163 - accuracy: 0.9117 - val_loss: 0.0320 - val_accuracy: 0.8100\n",
      "Epoch 190/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0162 - accuracy: 0.9167 - val_loss: 0.0319 - val_accuracy: 0.8100\n",
      "Epoch 191/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0160 - accuracy: 0.9150 - val_loss: 0.0317 - val_accuracy: 0.8100\n",
      "Epoch 192/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0159 - accuracy: 0.9167 - val_loss: 0.0316 - val_accuracy: 0.8100\n",
      "Epoch 193/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0158 - accuracy: 0.9167 - val_loss: 0.0315 - val_accuracy: 0.8100\n",
      "Epoch 194/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0157 - accuracy: 0.9167 - val_loss: 0.0314 - val_accuracy: 0.8100\n",
      "Epoch 195/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0155 - accuracy: 0.9217 - val_loss: 0.0312 - val_accuracy: 0.8100\n",
      "Epoch 196/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0154 - accuracy: 0.9200 - val_loss: 0.0312 - val_accuracy: 0.8100\n",
      "Epoch 197/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0153 - accuracy: 0.9200 - val_loss: 0.0312 - val_accuracy: 0.8100\n",
      "Epoch 198/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0152 - accuracy: 0.9217 - val_loss: 0.0310 - val_accuracy: 0.8100\n",
      "Epoch 199/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0151 - accuracy: 0.9200 - val_loss: 0.0309 - val_accuracy: 0.8100\n",
      "Epoch 200/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0149 - accuracy: 0.9200 - val_loss: 0.0308 - val_accuracy: 0.8100\n",
      "Epoch 201/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0148 - accuracy: 0.9233 - val_loss: 0.0307 - val_accuracy: 0.8100\n",
      "Epoch 202/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0147 - accuracy: 0.9233 - val_loss: 0.0306 - val_accuracy: 0.8100\n",
      "Epoch 203/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0146 - accuracy: 0.9250 - val_loss: 0.0304 - val_accuracy: 0.8100\n",
      "Epoch 204/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0145 - accuracy: 0.9283 - val_loss: 0.0303 - val_accuracy: 0.8100\n",
      "Epoch 205/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0144 - accuracy: 0.9317 - val_loss: 0.0304 - val_accuracy: 0.8100\n",
      "Epoch 206/240\n",
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0143 - accuracy: 0.9300 - val_loss: 0.0302 - val_accuracy: 0.8100\n",
      "Epoch 207/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0141 - accuracy: 0.9333 - val_loss: 0.0301 - val_accuracy: 0.8100\n",
      "Epoch 208/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0141 - accuracy: 0.9300 - val_loss: 0.0300 - val_accuracy: 0.8100\n",
      "Epoch 209/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0140 - accuracy: 0.9317 - val_loss: 0.0299 - val_accuracy: 0.8100\n",
      "Epoch 210/240\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0138 - accuracy: 0.9350 - val_loss: 0.0299 - val_accuracy: 0.8100\n",
      "Epoch 211/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0137 - accuracy: 0.9333 - val_loss: 0.0298 - val_accuracy: 0.8100\n",
      "Epoch 212/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0136 - accuracy: 0.9350 - val_loss: 0.0297 - val_accuracy: 0.8100\n",
      "Epoch 213/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0135 - accuracy: 0.9367 - val_loss: 0.0296 - val_accuracy: 0.8100\n",
      "Epoch 214/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0134 - accuracy: 0.9350 - val_loss: 0.0296 - val_accuracy: 0.8100\n",
      "Epoch 215/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0133 - accuracy: 0.9367 - val_loss: 0.0295 - val_accuracy: 0.8100\n",
      "Epoch 216/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0132 - accuracy: 0.9367 - val_loss: 0.0295 - val_accuracy: 0.8100\n",
      "Epoch 217/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0131 - accuracy: 0.9367 - val_loss: 0.0294 - val_accuracy: 0.8200\n",
      "Epoch 218/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0130 - accuracy: 0.9383 - val_loss: 0.0293 - val_accuracy: 0.8200\n",
      "Epoch 219/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0129 - accuracy: 0.9367 - val_loss: 0.0292 - val_accuracy: 0.8200\n",
      "Epoch 220/240\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0128 - accuracy: 0.9417 - val_loss: 0.0292 - val_accuracy: 0.8200\n",
      "Epoch 221/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0128 - accuracy: 0.9383 - val_loss: 0.0291 - val_accuracy: 0.8200\n",
      "Epoch 222/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0127 - accuracy: 0.9400 - val_loss: 0.0291 - val_accuracy: 0.8200\n",
      "Epoch 223/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0126 - accuracy: 0.9383 - val_loss: 0.0290 - val_accuracy: 0.8200\n",
      "Epoch 224/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0125 - accuracy: 0.9400 - val_loss: 0.0289 - val_accuracy: 0.8200\n",
      "Epoch 225/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0124 - accuracy: 0.9417 - val_loss: 0.0288 - val_accuracy: 0.8200\n",
      "Epoch 226/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0123 - accuracy: 0.9400 - val_loss: 0.0287 - val_accuracy: 0.8200\n",
      "Epoch 227/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0122 - accuracy: 0.9417 - val_loss: 0.0287 - val_accuracy: 0.8200\n",
      "Epoch 228/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0122 - accuracy: 0.9433 - val_loss: 0.0287 - val_accuracy: 0.8200\n",
      "Epoch 229/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0121 - accuracy: 0.9417 - val_loss: 0.0286 - val_accuracy: 0.8200\n",
      "Epoch 230/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0120 - accuracy: 0.9417 - val_loss: 0.0285 - val_accuracy: 0.8200\n",
      "Epoch 231/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0119 - accuracy: 0.9467 - val_loss: 0.0285 - val_accuracy: 0.8200\n",
      "Epoch 232/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0118 - accuracy: 0.9400 - val_loss: 0.0285 - val_accuracy: 0.8200\n",
      "Epoch 233/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0117 - accuracy: 0.9417 - val_loss: 0.0284 - val_accuracy: 0.8300\n",
      "Epoch 234/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0117 - accuracy: 0.9450 - val_loss: 0.0283 - val_accuracy: 0.8300\n",
      "Epoch 235/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0116 - accuracy: 0.9467 - val_loss: 0.0283 - val_accuracy: 0.8300\n",
      "Epoch 236/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0115 - accuracy: 0.9467 - val_loss: 0.0283 - val_accuracy: 0.8300\n",
      "Epoch 237/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0114 - accuracy: 0.9450 - val_loss: 0.0282 - val_accuracy: 0.8300\n",
      "Epoch 238/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0113 - accuracy: 0.9483 - val_loss: 0.0282 - val_accuracy: 0.8300\n",
      "Epoch 239/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0113 - accuracy: 0.9483 - val_loss: 0.0281 - val_accuracy: 0.8300\n",
      "Epoch 240/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0112 - accuracy: 0.9517 - val_loss: 0.0281 - val_accuracy: 0.8300\n",
      "Training date and time : \n",
      "2020-04-09 21:05:22\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/240\n",
      "600/600 [==============================] - 0s 669us/sample - loss: 0.0899 - accuracy: 0.1817 - val_loss: 0.0899 - val_accuracy: 0.1900\n",
      "Epoch 2/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0898 - accuracy: 0.1950 - val_loss: 0.0898 - val_accuracy: 0.2100\n",
      "Epoch 3/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0896 - accuracy: 0.2167 - val_loss: 0.0897 - val_accuracy: 0.2300\n",
      "Epoch 4/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0895 - accuracy: 0.2267 - val_loss: 0.0896 - val_accuracy: 0.2200\n",
      "Epoch 5/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0894 - accuracy: 0.2367 - val_loss: 0.0895 - val_accuracy: 0.2300\n",
      "Epoch 6/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0893 - accuracy: 0.2583 - val_loss: 0.0894 - val_accuracy: 0.2300\n",
      "Epoch 7/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0891 - accuracy: 0.2650 - val_loss: 0.0893 - val_accuracy: 0.2400\n",
      "Epoch 8/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0890 - accuracy: 0.2683 - val_loss: 0.0892 - val_accuracy: 0.2400\n",
      "Epoch 9/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0889 - accuracy: 0.2783 - val_loss: 0.0891 - val_accuracy: 0.2300\n",
      "Epoch 10/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0887 - accuracy: 0.2867 - val_loss: 0.0890 - val_accuracy: 0.2300\n",
      "Epoch 11/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0886 - accuracy: 0.2900 - val_loss: 0.0889 - val_accuracy: 0.2300\n",
      "Epoch 12/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0885 - accuracy: 0.2917 - val_loss: 0.0888 - val_accuracy: 0.2400\n",
      "Epoch 13/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0883 - accuracy: 0.2983 - val_loss: 0.0887 - val_accuracy: 0.2500\n",
      "Epoch 14/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0882 - accuracy: 0.3100 - val_loss: 0.0886 - val_accuracy: 0.2500\n",
      "Epoch 15/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0881 - accuracy: 0.3200 - val_loss: 0.0885 - val_accuracy: 0.2500\n",
      "Epoch 16/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0879 - accuracy: 0.3283 - val_loss: 0.0884 - val_accuracy: 0.2800\n",
      "Epoch 17/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0878 - accuracy: 0.3433 - val_loss: 0.0882 - val_accuracy: 0.2800\n",
      "Epoch 18/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0876 - accuracy: 0.3617 - val_loss: 0.0881 - val_accuracy: 0.2800\n",
      "Epoch 19/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0874 - accuracy: 0.3783 - val_loss: 0.0880 - val_accuracy: 0.2900\n",
      "Epoch 20/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0873 - accuracy: 0.3933 - val_loss: 0.0878 - val_accuracy: 0.2900\n",
      "Epoch 21/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0871 - accuracy: 0.4033 - val_loss: 0.0877 - val_accuracy: 0.3000\n",
      "Epoch 22/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0869 - accuracy: 0.4233 - val_loss: 0.0876 - val_accuracy: 0.3100\n",
      "Epoch 23/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0867 - accuracy: 0.4283 - val_loss: 0.0874 - val_accuracy: 0.3200\n",
      "Epoch 24/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0865 - accuracy: 0.4400 - val_loss: 0.0873 - val_accuracy: 0.3500\n",
      "Epoch 25/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0863 - accuracy: 0.4450 - val_loss: 0.0871 - val_accuracy: 0.3700\n",
      "Epoch 26/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0861 - accuracy: 0.4467 - val_loss: 0.0869 - val_accuracy: 0.3700\n",
      "Epoch 27/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0859 - accuracy: 0.4517 - val_loss: 0.0867 - val_accuracy: 0.3700\n",
      "Epoch 28/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0857 - accuracy: 0.4600 - val_loss: 0.0865 - val_accuracy: 0.3700\n",
      "Epoch 29/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0855 - accuracy: 0.4633 - val_loss: 0.0863 - val_accuracy: 0.3600\n",
      "Epoch 30/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0852 - accuracy: 0.4617 - val_loss: 0.0861 - val_accuracy: 0.3600\n",
      "Epoch 31/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0849 - accuracy: 0.4700 - val_loss: 0.0859 - val_accuracy: 0.3600\n",
      "Epoch 32/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0847 - accuracy: 0.4717 - val_loss: 0.0857 - val_accuracy: 0.3600\n",
      "Epoch 33/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0844 - accuracy: 0.4800 - val_loss: 0.0854 - val_accuracy: 0.3600\n",
      "Epoch 34/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0841 - accuracy: 0.4767 - val_loss: 0.0852 - val_accuracy: 0.3600\n",
      "Epoch 35/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0837 - accuracy: 0.4800 - val_loss: 0.0849 - val_accuracy: 0.3600\n",
      "Epoch 36/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0834 - accuracy: 0.4817 - val_loss: 0.0846 - val_accuracy: 0.3500\n",
      "Epoch 37/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0830 - accuracy: 0.4800 - val_loss: 0.0843 - val_accuracy: 0.3300\n",
      "Epoch 38/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0826 - accuracy: 0.4750 - val_loss: 0.0840 - val_accuracy: 0.3300\n",
      "Epoch 39/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0822 - accuracy: 0.4767 - val_loss: 0.0836 - val_accuracy: 0.3400\n",
      "Epoch 40/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0818 - accuracy: 0.4733 - val_loss: 0.0833 - val_accuracy: 0.3400\n",
      "Epoch 41/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0814 - accuracy: 0.4617 - val_loss: 0.0829 - val_accuracy: 0.3400\n",
      "Epoch 42/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0809 - accuracy: 0.4650 - val_loss: 0.0826 - val_accuracy: 0.3400\n",
      "Epoch 43/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0804 - accuracy: 0.4617 - val_loss: 0.0822 - val_accuracy: 0.3400\n",
      "Epoch 44/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0800 - accuracy: 0.4617 - val_loss: 0.0818 - val_accuracy: 0.3400\n",
      "Epoch 45/240\n",
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0795 - accuracy: 0.4750 - val_loss: 0.0814 - val_accuracy: 0.3400\n",
      "Epoch 46/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0789 - accuracy: 0.4733 - val_loss: 0.0810 - val_accuracy: 0.3500\n",
      "Epoch 47/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0784 - accuracy: 0.4783 - val_loss: 0.0805 - val_accuracy: 0.3600\n",
      "Epoch 48/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0779 - accuracy: 0.4800 - val_loss: 0.0801 - val_accuracy: 0.3700\n",
      "Epoch 49/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0774 - accuracy: 0.4917 - val_loss: 0.0797 - val_accuracy: 0.3700\n",
      "Epoch 50/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0768 - accuracy: 0.4950 - val_loss: 0.0793 - val_accuracy: 0.3900\n",
      "Epoch 51/240\n",
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0762 - accuracy: 0.4983 - val_loss: 0.0788 - val_accuracy: 0.4100\n",
      "Epoch 52/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0757 - accuracy: 0.5067 - val_loss: 0.0784 - val_accuracy: 0.4100\n",
      "Epoch 53/240\n",
      "600/600 [==============================] - 0s 114us/sample - loss: 0.0751 - accuracy: 0.5167 - val_loss: 0.0779 - val_accuracy: 0.4400\n",
      "Epoch 54/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0745 - accuracy: 0.5267 - val_loss: 0.0775 - val_accuracy: 0.4400\n",
      "Epoch 55/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0739 - accuracy: 0.5300 - val_loss: 0.0770 - val_accuracy: 0.4400\n",
      "Epoch 56/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0733 - accuracy: 0.5383 - val_loss: 0.0766 - val_accuracy: 0.4500\n",
      "Epoch 57/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0727 - accuracy: 0.5583 - val_loss: 0.0761 - val_accuracy: 0.4500\n",
      "Epoch 58/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0720 - accuracy: 0.5633 - val_loss: 0.0756 - val_accuracy: 0.4600\n",
      "Epoch 59/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0714 - accuracy: 0.5750 - val_loss: 0.0751 - val_accuracy: 0.4900\n",
      "Epoch 60/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0707 - accuracy: 0.5817 - val_loss: 0.0746 - val_accuracy: 0.4900\n",
      "Epoch 61/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0701 - accuracy: 0.5833 - val_loss: 0.0741 - val_accuracy: 0.5000\n",
      "Epoch 62/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0694 - accuracy: 0.5950 - val_loss: 0.0736 - val_accuracy: 0.5200\n",
      "Epoch 63/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0687 - accuracy: 0.6017 - val_loss: 0.0731 - val_accuracy: 0.5400\n",
      "Epoch 64/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0680 - accuracy: 0.6100 - val_loss: 0.0726 - val_accuracy: 0.5500\n",
      "Epoch 65/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0673 - accuracy: 0.6167 - val_loss: 0.0720 - val_accuracy: 0.5600\n",
      "Epoch 66/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0666 - accuracy: 0.6267 - val_loss: 0.0715 - val_accuracy: 0.5600\n",
      "Epoch 67/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0658 - accuracy: 0.6383 - val_loss: 0.0709 - val_accuracy: 0.5600\n",
      "Epoch 68/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0651 - accuracy: 0.6450 - val_loss: 0.0704 - val_accuracy: 0.5700\n",
      "Epoch 69/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0643 - accuracy: 0.6483 - val_loss: 0.0698 - val_accuracy: 0.5800\n",
      "Epoch 70/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0635 - accuracy: 0.6550 - val_loss: 0.0693 - val_accuracy: 0.5900\n",
      "Epoch 71/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0628 - accuracy: 0.6567 - val_loss: 0.0687 - val_accuracy: 0.5900\n",
      "Epoch 72/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0620 - accuracy: 0.6650 - val_loss: 0.0681 - val_accuracy: 0.6200\n",
      "Epoch 73/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0612 - accuracy: 0.6733 - val_loss: 0.0676 - val_accuracy: 0.6200\n",
      "Epoch 74/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0604 - accuracy: 0.6917 - val_loss: 0.0670 - val_accuracy: 0.6200\n",
      "Epoch 75/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0595 - accuracy: 0.6850 - val_loss: 0.0664 - val_accuracy: 0.6500\n",
      "Epoch 76/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0587 - accuracy: 0.6950 - val_loss: 0.0658 - val_accuracy: 0.6500\n",
      "Epoch 77/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0578 - accuracy: 0.6967 - val_loss: 0.0652 - val_accuracy: 0.6500\n",
      "Epoch 78/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0570 - accuracy: 0.7017 - val_loss: 0.0646 - val_accuracy: 0.6600\n",
      "Epoch 79/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0561 - accuracy: 0.7183 - val_loss: 0.0640 - val_accuracy: 0.6600\n",
      "Epoch 80/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0553 - accuracy: 0.7217 - val_loss: 0.0634 - val_accuracy: 0.6600\n",
      "Epoch 81/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0544 - accuracy: 0.7333 - val_loss: 0.0628 - val_accuracy: 0.6600\n",
      "Epoch 82/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0535 - accuracy: 0.7417 - val_loss: 0.0622 - val_accuracy: 0.6600\n",
      "Epoch 83/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0527 - accuracy: 0.7450 - val_loss: 0.0616 - val_accuracy: 0.6600\n",
      "Epoch 84/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0518 - accuracy: 0.7500 - val_loss: 0.0610 - val_accuracy: 0.6600\n",
      "Epoch 85/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0509 - accuracy: 0.7467 - val_loss: 0.0604 - val_accuracy: 0.6600\n",
      "Epoch 86/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0501 - accuracy: 0.7483 - val_loss: 0.0598 - val_accuracy: 0.6600\n",
      "Epoch 87/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0492 - accuracy: 0.7550 - val_loss: 0.0593 - val_accuracy: 0.6500\n",
      "Epoch 88/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0484 - accuracy: 0.7567 - val_loss: 0.0587 - val_accuracy: 0.6500\n",
      "Epoch 89/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0476 - accuracy: 0.7550 - val_loss: 0.0582 - val_accuracy: 0.6500\n",
      "Epoch 90/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0468 - accuracy: 0.7617 - val_loss: 0.0576 - val_accuracy: 0.6500\n",
      "Epoch 91/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0460 - accuracy: 0.7717 - val_loss: 0.0571 - val_accuracy: 0.6600\n",
      "Epoch 92/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0452 - accuracy: 0.7700 - val_loss: 0.0566 - val_accuracy: 0.6700\n",
      "Epoch 93/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0444 - accuracy: 0.7750 - val_loss: 0.0560 - val_accuracy: 0.6800\n",
      "Epoch 94/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0437 - accuracy: 0.7733 - val_loss: 0.0556 - val_accuracy: 0.6800\n",
      "Epoch 95/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0429 - accuracy: 0.7750 - val_loss: 0.0551 - val_accuracy: 0.6800\n",
      "Epoch 96/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0422 - accuracy: 0.7767 - val_loss: 0.0546 - val_accuracy: 0.6700\n",
      "Epoch 97/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0415 - accuracy: 0.7800 - val_loss: 0.0541 - val_accuracy: 0.6700\n",
      "Epoch 98/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0409 - accuracy: 0.7883 - val_loss: 0.0537 - val_accuracy: 0.6600\n",
      "Epoch 99/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0402 - accuracy: 0.7867 - val_loss: 0.0532 - val_accuracy: 0.6700\n",
      "Epoch 100/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0396 - accuracy: 0.7917 - val_loss: 0.0527 - val_accuracy: 0.6600\n",
      "Epoch 101/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0390 - accuracy: 0.7883 - val_loss: 0.0523 - val_accuracy: 0.6700\n",
      "Epoch 102/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0384 - accuracy: 0.7917 - val_loss: 0.0519 - val_accuracy: 0.6600\n",
      "Epoch 103/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0378 - accuracy: 0.7900 - val_loss: 0.0515 - val_accuracy: 0.6600\n",
      "Epoch 104/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0373 - accuracy: 0.7950 - val_loss: 0.0511 - val_accuracy: 0.6500\n",
      "Epoch 105/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0367 - accuracy: 0.7950 - val_loss: 0.0506 - val_accuracy: 0.6600\n",
      "Epoch 106/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0362 - accuracy: 0.7950 - val_loss: 0.0503 - val_accuracy: 0.6500\n",
      "Epoch 107/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0357 - accuracy: 0.7967 - val_loss: 0.0499 - val_accuracy: 0.6500\n",
      "Epoch 108/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0352 - accuracy: 0.7950 - val_loss: 0.0495 - val_accuracy: 0.6500\n",
      "Epoch 109/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0347 - accuracy: 0.7967 - val_loss: 0.0491 - val_accuracy: 0.6500\n",
      "Epoch 110/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0342 - accuracy: 0.8000 - val_loss: 0.0487 - val_accuracy: 0.6700\n",
      "Epoch 111/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0338 - accuracy: 0.8033 - val_loss: 0.0483 - val_accuracy: 0.6600\n",
      "Epoch 112/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0334 - accuracy: 0.8000 - val_loss: 0.0479 - val_accuracy: 0.6700\n",
      "Epoch 113/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0329 - accuracy: 0.8067 - val_loss: 0.0475 - val_accuracy: 0.6600\n",
      "Epoch 114/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0325 - accuracy: 0.8083 - val_loss: 0.0472 - val_accuracy: 0.6700\n",
      "Epoch 115/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0321 - accuracy: 0.8083 - val_loss: 0.0468 - val_accuracy: 0.6800\n",
      "Epoch 116/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0316 - accuracy: 0.8117 - val_loss: 0.0465 - val_accuracy: 0.6800\n",
      "Epoch 117/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0313 - accuracy: 0.8133 - val_loss: 0.0461 - val_accuracy: 0.6800\n",
      "Epoch 118/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0309 - accuracy: 0.8183 - val_loss: 0.0458 - val_accuracy: 0.6700\n",
      "Epoch 119/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0305 - accuracy: 0.8250 - val_loss: 0.0454 - val_accuracy: 0.6900\n",
      "Epoch 120/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0301 - accuracy: 0.8317 - val_loss: 0.0450 - val_accuracy: 0.7000\n",
      "Epoch 121/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0298 - accuracy: 0.8300 - val_loss: 0.0446 - val_accuracy: 0.7200\n",
      "Epoch 122/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0294 - accuracy: 0.8300 - val_loss: 0.0443 - val_accuracy: 0.7200\n",
      "Epoch 123/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0291 - accuracy: 0.8350 - val_loss: 0.0440 - val_accuracy: 0.7200\n",
      "Epoch 124/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0287 - accuracy: 0.8467 - val_loss: 0.0437 - val_accuracy: 0.7200\n",
      "Epoch 125/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0284 - accuracy: 0.8500 - val_loss: 0.0433 - val_accuracy: 0.7300\n",
      "Epoch 126/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0280 - accuracy: 0.8500 - val_loss: 0.0430 - val_accuracy: 0.7200\n",
      "Epoch 127/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0277 - accuracy: 0.8583 - val_loss: 0.0427 - val_accuracy: 0.7200\n",
      "Epoch 128/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0274 - accuracy: 0.8600 - val_loss: 0.0424 - val_accuracy: 0.7300\n",
      "Epoch 129/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0271 - accuracy: 0.8617 - val_loss: 0.0420 - val_accuracy: 0.7400\n",
      "Epoch 130/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0268 - accuracy: 0.8617 - val_loss: 0.0418 - val_accuracy: 0.7400\n",
      "Epoch 131/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0265 - accuracy: 0.8650 - val_loss: 0.0415 - val_accuracy: 0.7400\n",
      "Epoch 132/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0262 - accuracy: 0.8667 - val_loss: 0.0412 - val_accuracy: 0.7400\n",
      "Epoch 133/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0259 - accuracy: 0.8683 - val_loss: 0.0409 - val_accuracy: 0.7400\n",
      "Epoch 134/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0256 - accuracy: 0.8683 - val_loss: 0.0406 - val_accuracy: 0.7400\n",
      "Epoch 135/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0254 - accuracy: 0.8717 - val_loss: 0.0404 - val_accuracy: 0.7500\n",
      "Epoch 136/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0251 - accuracy: 0.8767 - val_loss: 0.0401 - val_accuracy: 0.7400\n",
      "Epoch 137/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0248 - accuracy: 0.8767 - val_loss: 0.0398 - val_accuracy: 0.7500\n",
      "Epoch 138/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0246 - accuracy: 0.8767 - val_loss: 0.0396 - val_accuracy: 0.7500\n",
      "Epoch 139/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0243 - accuracy: 0.8800 - val_loss: 0.0393 - val_accuracy: 0.7500\n",
      "Epoch 140/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0240 - accuracy: 0.8833 - val_loss: 0.0392 - val_accuracy: 0.7500\n",
      "Epoch 141/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0238 - accuracy: 0.8833 - val_loss: 0.0389 - val_accuracy: 0.7500\n",
      "Epoch 142/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0235 - accuracy: 0.8867 - val_loss: 0.0388 - val_accuracy: 0.7600\n",
      "Epoch 143/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0233 - accuracy: 0.8833 - val_loss: 0.0385 - val_accuracy: 0.7600\n",
      "Epoch 144/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0230 - accuracy: 0.8867 - val_loss: 0.0383 - val_accuracy: 0.7600\n",
      "Epoch 145/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0228 - accuracy: 0.8900 - val_loss: 0.0380 - val_accuracy: 0.7600\n",
      "Epoch 146/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0226 - accuracy: 0.8883 - val_loss: 0.0378 - val_accuracy: 0.7700\n",
      "Epoch 147/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0224 - accuracy: 0.8900 - val_loss: 0.0376 - val_accuracy: 0.7700\n",
      "Epoch 148/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0222 - accuracy: 0.8917 - val_loss: 0.0374 - val_accuracy: 0.7700\n",
      "Epoch 149/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0219 - accuracy: 0.8917 - val_loss: 0.0372 - val_accuracy: 0.7800\n",
      "Epoch 150/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0217 - accuracy: 0.8900 - val_loss: 0.0369 - val_accuracy: 0.7800\n",
      "Epoch 151/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0215 - accuracy: 0.8933 - val_loss: 0.0367 - val_accuracy: 0.7900\n",
      "Epoch 152/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0213 - accuracy: 0.8917 - val_loss: 0.0365 - val_accuracy: 0.7900\n",
      "Epoch 153/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0211 - accuracy: 0.8917 - val_loss: 0.0364 - val_accuracy: 0.7900\n",
      "Epoch 154/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0209 - accuracy: 0.8933 - val_loss: 0.0362 - val_accuracy: 0.8000\n",
      "Epoch 155/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0207 - accuracy: 0.8950 - val_loss: 0.0360 - val_accuracy: 0.8000\n",
      "Epoch 156/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0205 - accuracy: 0.8950 - val_loss: 0.0358 - val_accuracy: 0.8000\n",
      "Epoch 157/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0203 - accuracy: 0.8967 - val_loss: 0.0356 - val_accuracy: 0.8000\n",
      "Epoch 158/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0201 - accuracy: 0.8950 - val_loss: 0.0354 - val_accuracy: 0.8000\n",
      "Epoch 159/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0199 - accuracy: 0.8950 - val_loss: 0.0352 - val_accuracy: 0.8000\n",
      "Epoch 160/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0197 - accuracy: 0.8967 - val_loss: 0.0351 - val_accuracy: 0.8000\n",
      "Epoch 161/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0195 - accuracy: 0.8967 - val_loss: 0.0349 - val_accuracy: 0.8100\n",
      "Epoch 162/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0194 - accuracy: 0.8967 - val_loss: 0.0348 - val_accuracy: 0.8000\n",
      "Epoch 163/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0192 - accuracy: 0.9000 - val_loss: 0.0346 - val_accuracy: 0.8000\n",
      "Epoch 164/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0190 - accuracy: 0.9000 - val_loss: 0.0345 - val_accuracy: 0.8100\n",
      "Epoch 165/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0188 - accuracy: 0.8983 - val_loss: 0.0343 - val_accuracy: 0.8100\n",
      "Epoch 166/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0187 - accuracy: 0.9017 - val_loss: 0.0341 - val_accuracy: 0.8100\n",
      "Epoch 167/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0185 - accuracy: 0.9000 - val_loss: 0.0339 - val_accuracy: 0.8100\n",
      "Epoch 168/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0183 - accuracy: 0.9017 - val_loss: 0.0338 - val_accuracy: 0.8000\n",
      "Epoch 169/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0182 - accuracy: 0.9017 - val_loss: 0.0337 - val_accuracy: 0.8000\n",
      "Epoch 170/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0180 - accuracy: 0.9017 - val_loss: 0.0336 - val_accuracy: 0.8100\n",
      "Epoch 171/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0179 - accuracy: 0.9083 - val_loss: 0.0334 - val_accuracy: 0.8100\n",
      "Epoch 172/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0177 - accuracy: 0.9033 - val_loss: 0.0333 - val_accuracy: 0.8100\n",
      "Epoch 173/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0176 - accuracy: 0.9100 - val_loss: 0.0332 - val_accuracy: 0.8100\n",
      "Epoch 174/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0174 - accuracy: 0.9067 - val_loss: 0.0330 - val_accuracy: 0.8100\n",
      "Epoch 175/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0173 - accuracy: 0.9100 - val_loss: 0.0329 - val_accuracy: 0.8100\n",
      "Epoch 176/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0171 - accuracy: 0.9100 - val_loss: 0.0327 - val_accuracy: 0.8100\n",
      "Epoch 177/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0170 - accuracy: 0.9100 - val_loss: 0.0327 - val_accuracy: 0.8100\n",
      "Epoch 178/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0168 - accuracy: 0.9117 - val_loss: 0.0325 - val_accuracy: 0.8100\n",
      "Epoch 179/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0167 - accuracy: 0.9100 - val_loss: 0.0324 - val_accuracy: 0.8100\n",
      "Epoch 180/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0165 - accuracy: 0.9133 - val_loss: 0.0322 - val_accuracy: 0.8100\n",
      "Epoch 181/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0164 - accuracy: 0.9133 - val_loss: 0.0321 - val_accuracy: 0.8100\n",
      "Epoch 182/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0163 - accuracy: 0.9167 - val_loss: 0.0320 - val_accuracy: 0.8100\n",
      "Epoch 183/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0162 - accuracy: 0.9167 - val_loss: 0.0319 - val_accuracy: 0.8100\n",
      "Epoch 184/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0160 - accuracy: 0.9183 - val_loss: 0.0317 - val_accuracy: 0.8100\n",
      "Epoch 185/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0159 - accuracy: 0.9167 - val_loss: 0.0317 - val_accuracy: 0.8100\n",
      "Epoch 186/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0157 - accuracy: 0.9183 - val_loss: 0.0317 - val_accuracy: 0.8100\n",
      "Epoch 187/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0156 - accuracy: 0.9183 - val_loss: 0.0315 - val_accuracy: 0.8100\n",
      "Epoch 188/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0155 - accuracy: 0.9200 - val_loss: 0.0314 - val_accuracy: 0.8100\n",
      "Epoch 189/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0154 - accuracy: 0.9200 - val_loss: 0.0313 - val_accuracy: 0.8100\n",
      "Epoch 190/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0152 - accuracy: 0.9217 - val_loss: 0.0312 - val_accuracy: 0.8100\n",
      "Epoch 191/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0151 - accuracy: 0.9217 - val_loss: 0.0311 - val_accuracy: 0.8100\n",
      "Epoch 192/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0150 - accuracy: 0.9267 - val_loss: 0.0309 - val_accuracy: 0.8100\n",
      "Epoch 193/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0149 - accuracy: 0.9233 - val_loss: 0.0309 - val_accuracy: 0.8100\n",
      "Epoch 194/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0148 - accuracy: 0.9300 - val_loss: 0.0307 - val_accuracy: 0.8200\n",
      "Epoch 195/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0147 - accuracy: 0.9250 - val_loss: 0.0306 - val_accuracy: 0.8200\n",
      "Epoch 196/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0145 - accuracy: 0.9300 - val_loss: 0.0306 - val_accuracy: 0.8200\n",
      "Epoch 197/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0144 - accuracy: 0.9317 - val_loss: 0.0306 - val_accuracy: 0.8100\n",
      "Epoch 198/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0143 - accuracy: 0.9317 - val_loss: 0.0305 - val_accuracy: 0.8100\n",
      "Epoch 199/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0142 - accuracy: 0.9317 - val_loss: 0.0303 - val_accuracy: 0.8200\n",
      "Epoch 200/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0141 - accuracy: 0.9317 - val_loss: 0.0302 - val_accuracy: 0.8200\n",
      "Epoch 201/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0140 - accuracy: 0.9333 - val_loss: 0.0301 - val_accuracy: 0.8200\n",
      "Epoch 202/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0139 - accuracy: 0.9317 - val_loss: 0.0300 - val_accuracy: 0.8200\n",
      "Epoch 203/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0138 - accuracy: 0.9350 - val_loss: 0.0299 - val_accuracy: 0.8200\n",
      "Epoch 204/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0137 - accuracy: 0.9367 - val_loss: 0.0298 - val_accuracy: 0.8200\n",
      "Epoch 205/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0136 - accuracy: 0.9367 - val_loss: 0.0299 - val_accuracy: 0.8200\n",
      "Epoch 206/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0135 - accuracy: 0.9367 - val_loss: 0.0297 - val_accuracy: 0.8200\n",
      "Epoch 207/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0134 - accuracy: 0.9367 - val_loss: 0.0296 - val_accuracy: 0.8200\n",
      "Epoch 208/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0133 - accuracy: 0.9350 - val_loss: 0.0296 - val_accuracy: 0.8200\n",
      "Epoch 209/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0132 - accuracy: 0.9367 - val_loss: 0.0295 - val_accuracy: 0.8200\n",
      "Epoch 210/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0131 - accuracy: 0.9383 - val_loss: 0.0294 - val_accuracy: 0.8200\n",
      "Epoch 211/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0130 - accuracy: 0.9367 - val_loss: 0.0293 - val_accuracy: 0.8200\n",
      "Epoch 212/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0129 - accuracy: 0.9383 - val_loss: 0.0293 - val_accuracy: 0.8200\n",
      "Epoch 213/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0128 - accuracy: 0.9367 - val_loss: 0.0292 - val_accuracy: 0.8300\n",
      "Epoch 214/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0127 - accuracy: 0.9367 - val_loss: 0.0292 - val_accuracy: 0.8300\n",
      "Epoch 215/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0126 - accuracy: 0.9383 - val_loss: 0.0291 - val_accuracy: 0.8300\n",
      "Epoch 216/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0125 - accuracy: 0.9400 - val_loss: 0.0290 - val_accuracy: 0.8300\n",
      "Epoch 217/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0124 - accuracy: 0.9383 - val_loss: 0.0290 - val_accuracy: 0.8300\n",
      "Epoch 218/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0124 - accuracy: 0.9417 - val_loss: 0.0289 - val_accuracy: 0.8300\n",
      "Epoch 219/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0123 - accuracy: 0.9400 - val_loss: 0.0288 - val_accuracy: 0.8300\n",
      "Epoch 220/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0122 - accuracy: 0.9433 - val_loss: 0.0288 - val_accuracy: 0.8300\n",
      "Epoch 221/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0121 - accuracy: 0.9433 - val_loss: 0.0287 - val_accuracy: 0.8300\n",
      "Epoch 222/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0120 - accuracy: 0.9433 - val_loss: 0.0287 - val_accuracy: 0.8300\n",
      "Epoch 223/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0119 - accuracy: 0.9433 - val_loss: 0.0286 - val_accuracy: 0.8300\n",
      "Epoch 224/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0119 - accuracy: 0.9467 - val_loss: 0.0285 - val_accuracy: 0.8300\n",
      "Epoch 225/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0118 - accuracy: 0.9450 - val_loss: 0.0284 - val_accuracy: 0.8200\n",
      "Epoch 226/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0117 - accuracy: 0.9433 - val_loss: 0.0284 - val_accuracy: 0.8300\n",
      "Epoch 227/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0116 - accuracy: 0.9483 - val_loss: 0.0284 - val_accuracy: 0.8300\n",
      "Epoch 228/240\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0116 - accuracy: 0.9450 - val_loss: 0.0283 - val_accuracy: 0.8300\n",
      "Epoch 229/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0115 - accuracy: 0.9483 - val_loss: 0.0283 - val_accuracy: 0.8300\n",
      "Epoch 230/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0114 - accuracy: 0.9467 - val_loss: 0.0282 - val_accuracy: 0.8200\n",
      "Epoch 231/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0113 - accuracy: 0.9500 - val_loss: 0.0282 - val_accuracy: 0.8300\n",
      "Epoch 232/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0113 - accuracy: 0.9500 - val_loss: 0.0282 - val_accuracy: 0.8300\n",
      "Epoch 233/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0112 - accuracy: 0.9483 - val_loss: 0.0281 - val_accuracy: 0.8300\n",
      "Epoch 234/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0111 - accuracy: 0.9500 - val_loss: 0.0280 - val_accuracy: 0.8300\n",
      "Epoch 235/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0110 - accuracy: 0.9517 - val_loss: 0.0280 - val_accuracy: 0.8300\n",
      "Epoch 236/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0109 - accuracy: 0.9500 - val_loss: 0.0280 - val_accuracy: 0.8300\n",
      "Epoch 237/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0109 - accuracy: 0.9517 - val_loss: 0.0279 - val_accuracy: 0.8300\n",
      "Epoch 238/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0108 - accuracy: 0.9517 - val_loss: 0.0279 - val_accuracy: 0.8300\n",
      "Epoch 239/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0107 - accuracy: 0.9517 - val_loss: 0.0278 - val_accuracy: 0.8300\n",
      "Epoch 240/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0107 - accuracy: 0.9517 - val_loss: 0.0278 - val_accuracy: 0.8300\n",
      "Training date and time : \n",
      "2020-04-09 21:05:37\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/240\n",
      "600/600 [==============================] - 0s 667us/sample - loss: 0.0899 - accuracy: 0.1800 - val_loss: 0.0899 - val_accuracy: 0.1800\n",
      "Epoch 2/240\n",
      "600/600 [==============================] - 0s 114us/sample - loss: 0.0897 - accuracy: 0.1900 - val_loss: 0.0898 - val_accuracy: 0.2000\n",
      "Epoch 3/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0896 - accuracy: 0.2100 - val_loss: 0.0897 - val_accuracy: 0.2100\n",
      "Epoch 4/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0895 - accuracy: 0.2233 - val_loss: 0.0896 - val_accuracy: 0.2200\n",
      "Epoch 5/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0893 - accuracy: 0.2367 - val_loss: 0.0895 - val_accuracy: 0.2400\n",
      "Epoch 6/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0892 - accuracy: 0.2500 - val_loss: 0.0893 - val_accuracy: 0.2400\n",
      "Epoch 7/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0890 - accuracy: 0.2633 - val_loss: 0.0892 - val_accuracy: 0.2500\n",
      "Epoch 8/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0889 - accuracy: 0.2783 - val_loss: 0.0891 - val_accuracy: 0.2400\n",
      "Epoch 9/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0887 - accuracy: 0.2883 - val_loss: 0.0890 - val_accuracy: 0.2500\n",
      "Epoch 10/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0886 - accuracy: 0.2967 - val_loss: 0.0889 - val_accuracy: 0.2500\n",
      "Epoch 11/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0884 - accuracy: 0.3033 - val_loss: 0.0888 - val_accuracy: 0.2700\n",
      "Epoch 12/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0883 - accuracy: 0.3150 - val_loss: 0.0886 - val_accuracy: 0.2600\n",
      "Epoch 13/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0881 - accuracy: 0.3150 - val_loss: 0.0885 - val_accuracy: 0.2600\n",
      "Epoch 14/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0880 - accuracy: 0.3217 - val_loss: 0.0884 - val_accuracy: 0.2700\n",
      "Epoch 15/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0878 - accuracy: 0.3417 - val_loss: 0.0882 - val_accuracy: 0.2600\n",
      "Epoch 16/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0876 - accuracy: 0.3583 - val_loss: 0.0881 - val_accuracy: 0.2800\n",
      "Epoch 17/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0875 - accuracy: 0.3700 - val_loss: 0.0880 - val_accuracy: 0.2900\n",
      "Epoch 18/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0873 - accuracy: 0.3867 - val_loss: 0.0878 - val_accuracy: 0.2900\n",
      "Epoch 19/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0871 - accuracy: 0.4000 - val_loss: 0.0877 - val_accuracy: 0.3000\n",
      "Epoch 20/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0869 - accuracy: 0.4100 - val_loss: 0.0875 - val_accuracy: 0.3000\n",
      "Epoch 21/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0867 - accuracy: 0.4217 - val_loss: 0.0873 - val_accuracy: 0.3200\n",
      "Epoch 22/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0865 - accuracy: 0.4333 - val_loss: 0.0872 - val_accuracy: 0.3400\n",
      "Epoch 23/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0863 - accuracy: 0.4483 - val_loss: 0.0870 - val_accuracy: 0.3400\n",
      "Epoch 24/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0860 - accuracy: 0.4583 - val_loss: 0.0868 - val_accuracy: 0.3700\n",
      "Epoch 25/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0858 - accuracy: 0.4667 - val_loss: 0.0866 - val_accuracy: 0.3700\n",
      "Epoch 26/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0855 - accuracy: 0.4717 - val_loss: 0.0864 - val_accuracy: 0.3700\n",
      "Epoch 27/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0853 - accuracy: 0.4767 - val_loss: 0.0862 - val_accuracy: 0.3800\n",
      "Epoch 28/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0850 - accuracy: 0.4733 - val_loss: 0.0859 - val_accuracy: 0.3700\n",
      "Epoch 29/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0847 - accuracy: 0.4717 - val_loss: 0.0857 - val_accuracy: 0.3700\n",
      "Epoch 30/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0844 - accuracy: 0.4733 - val_loss: 0.0854 - val_accuracy: 0.3700\n",
      "Epoch 31/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0841 - accuracy: 0.4817 - val_loss: 0.0852 - val_accuracy: 0.3600\n",
      "Epoch 32/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0837 - accuracy: 0.4800 - val_loss: 0.0849 - val_accuracy: 0.3600\n",
      "Epoch 33/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0834 - accuracy: 0.4867 - val_loss: 0.0846 - val_accuracy: 0.3700\n",
      "Epoch 34/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0830 - accuracy: 0.4817 - val_loss: 0.0842 - val_accuracy: 0.3600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0826 - accuracy: 0.4817 - val_loss: 0.0839 - val_accuracy: 0.3600\n",
      "Epoch 36/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0821 - accuracy: 0.4867 - val_loss: 0.0836 - val_accuracy: 0.3600\n",
      "Epoch 37/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0817 - accuracy: 0.4833 - val_loss: 0.0832 - val_accuracy: 0.3500\n",
      "Epoch 38/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0812 - accuracy: 0.4817 - val_loss: 0.0828 - val_accuracy: 0.3500\n",
      "Epoch 39/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0807 - accuracy: 0.4817 - val_loss: 0.0824 - val_accuracy: 0.3500\n",
      "Epoch 40/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0802 - accuracy: 0.4817 - val_loss: 0.0820 - val_accuracy: 0.3500\n",
      "Epoch 41/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0797 - accuracy: 0.4750 - val_loss: 0.0816 - val_accuracy: 0.3500\n",
      "Epoch 42/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0792 - accuracy: 0.4767 - val_loss: 0.0811 - val_accuracy: 0.3600\n",
      "Epoch 43/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0786 - accuracy: 0.4817 - val_loss: 0.0807 - val_accuracy: 0.3500\n",
      "Epoch 44/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0781 - accuracy: 0.4850 - val_loss: 0.0803 - val_accuracy: 0.3700\n",
      "Epoch 45/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0775 - accuracy: 0.5000 - val_loss: 0.0798 - val_accuracy: 0.3800\n",
      "Epoch 46/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0769 - accuracy: 0.5000 - val_loss: 0.0794 - val_accuracy: 0.3900\n",
      "Epoch 47/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0763 - accuracy: 0.5067 - val_loss: 0.0789 - val_accuracy: 0.4100\n",
      "Epoch 48/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0757 - accuracy: 0.5133 - val_loss: 0.0784 - val_accuracy: 0.4100\n",
      "Epoch 49/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0751 - accuracy: 0.5217 - val_loss: 0.0780 - val_accuracy: 0.4200\n",
      "Epoch 50/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0745 - accuracy: 0.5317 - val_loss: 0.0775 - val_accuracy: 0.4300\n",
      "Epoch 51/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0739 - accuracy: 0.5400 - val_loss: 0.0770 - val_accuracy: 0.4600\n",
      "Epoch 52/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0732 - accuracy: 0.5450 - val_loss: 0.0765 - val_accuracy: 0.4600\n",
      "Epoch 53/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0726 - accuracy: 0.5550 - val_loss: 0.0760 - val_accuracy: 0.4700\n",
      "Epoch 54/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0719 - accuracy: 0.5667 - val_loss: 0.0755 - val_accuracy: 0.4700\n",
      "Epoch 55/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0713 - accuracy: 0.5767 - val_loss: 0.0750 - val_accuracy: 0.5000\n",
      "Epoch 56/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0706 - accuracy: 0.5817 - val_loss: 0.0745 - val_accuracy: 0.5000\n",
      "Epoch 57/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0699 - accuracy: 0.5900 - val_loss: 0.0740 - val_accuracy: 0.5200\n",
      "Epoch 58/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0691 - accuracy: 0.5983 - val_loss: 0.0734 - val_accuracy: 0.5300\n",
      "Epoch 59/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0684 - accuracy: 0.6083 - val_loss: 0.0729 - val_accuracy: 0.5500\n",
      "Epoch 60/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0677 - accuracy: 0.6200 - val_loss: 0.0723 - val_accuracy: 0.5600\n",
      "Epoch 61/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0669 - accuracy: 0.6233 - val_loss: 0.0718 - val_accuracy: 0.5600\n",
      "Epoch 62/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0662 - accuracy: 0.6333 - val_loss: 0.0712 - val_accuracy: 0.5600\n",
      "Epoch 63/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0654 - accuracy: 0.6367 - val_loss: 0.0707 - val_accuracy: 0.5600\n",
      "Epoch 64/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0646 - accuracy: 0.6500 - val_loss: 0.0701 - val_accuracy: 0.5600\n",
      "Epoch 65/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0638 - accuracy: 0.6650 - val_loss: 0.0695 - val_accuracy: 0.5600\n",
      "Epoch 66/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0630 - accuracy: 0.6683 - val_loss: 0.0689 - val_accuracy: 0.5800\n",
      "Epoch 67/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0622 - accuracy: 0.6800 - val_loss: 0.0684 - val_accuracy: 0.5900\n",
      "Epoch 68/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0614 - accuracy: 0.6850 - val_loss: 0.0678 - val_accuracy: 0.6200\n",
      "Epoch 69/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0605 - accuracy: 0.6933 - val_loss: 0.0672 - val_accuracy: 0.6300\n",
      "Epoch 70/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0597 - accuracy: 0.6950 - val_loss: 0.0666 - val_accuracy: 0.6400\n",
      "Epoch 71/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0588 - accuracy: 0.7000 - val_loss: 0.0660 - val_accuracy: 0.6500\n",
      "Epoch 72/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0580 - accuracy: 0.6983 - val_loss: 0.0654 - val_accuracy: 0.6500\n",
      "Epoch 73/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0571 - accuracy: 0.7117 - val_loss: 0.0648 - val_accuracy: 0.6500\n",
      "Epoch 74/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0562 - accuracy: 0.7217 - val_loss: 0.0642 - val_accuracy: 0.6500\n",
      "Epoch 75/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0553 - accuracy: 0.7283 - val_loss: 0.0635 - val_accuracy: 0.6600\n",
      "Epoch 76/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0544 - accuracy: 0.7383 - val_loss: 0.0629 - val_accuracy: 0.6600\n",
      "Epoch 77/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0535 - accuracy: 0.7383 - val_loss: 0.0623 - val_accuracy: 0.6600\n",
      "Epoch 78/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0526 - accuracy: 0.7467 - val_loss: 0.0617 - val_accuracy: 0.6600\n",
      "Epoch 79/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0518 - accuracy: 0.7467 - val_loss: 0.0611 - val_accuracy: 0.6700\n",
      "Epoch 80/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0509 - accuracy: 0.7567 - val_loss: 0.0605 - val_accuracy: 0.6700\n",
      "Epoch 81/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0500 - accuracy: 0.7633 - val_loss: 0.0599 - val_accuracy: 0.6700\n",
      "Epoch 82/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0491 - accuracy: 0.7667 - val_loss: 0.0593 - val_accuracy: 0.6600\n",
      "Epoch 83/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0483 - accuracy: 0.7717 - val_loss: 0.0588 - val_accuracy: 0.6600\n",
      "Epoch 84/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0474 - accuracy: 0.7683 - val_loss: 0.0582 - val_accuracy: 0.6600\n",
      "Epoch 85/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0466 - accuracy: 0.7717 - val_loss: 0.0577 - val_accuracy: 0.6600\n",
      "Epoch 86/240\n",
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0458 - accuracy: 0.7717 - val_loss: 0.0571 - val_accuracy: 0.6600\n",
      "Epoch 87/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0449 - accuracy: 0.7750 - val_loss: 0.0565 - val_accuracy: 0.6600\n",
      "Epoch 88/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0442 - accuracy: 0.7750 - val_loss: 0.0560 - val_accuracy: 0.6600\n",
      "Epoch 89/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0434 - accuracy: 0.7833 - val_loss: 0.0555 - val_accuracy: 0.6600\n",
      "Epoch 90/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0426 - accuracy: 0.7783 - val_loss: 0.0550 - val_accuracy: 0.6500\n",
      "Epoch 91/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0419 - accuracy: 0.7817 - val_loss: 0.0545 - val_accuracy: 0.6500\n",
      "Epoch 92/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0412 - accuracy: 0.7800 - val_loss: 0.0540 - val_accuracy: 0.6600\n",
      "Epoch 93/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0405 - accuracy: 0.7800 - val_loss: 0.0535 - val_accuracy: 0.6600\n",
      "Epoch 94/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0399 - accuracy: 0.7800 - val_loss: 0.0531 - val_accuracy: 0.6600\n",
      "Epoch 95/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0392 - accuracy: 0.7850 - val_loss: 0.0526 - val_accuracy: 0.6600\n",
      "Epoch 96/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0386 - accuracy: 0.7850 - val_loss: 0.0522 - val_accuracy: 0.6600\n",
      "Epoch 97/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0380 - accuracy: 0.7883 - val_loss: 0.0517 - val_accuracy: 0.6600\n",
      "Epoch 98/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0374 - accuracy: 0.7817 - val_loss: 0.0513 - val_accuracy: 0.6600\n",
      "Epoch 99/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0368 - accuracy: 0.7850 - val_loss: 0.0508 - val_accuracy: 0.6600\n",
      "Epoch 100/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0363 - accuracy: 0.7867 - val_loss: 0.0504 - val_accuracy: 0.6600\n",
      "Epoch 101/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0358 - accuracy: 0.7883 - val_loss: 0.0500 - val_accuracy: 0.6600\n",
      "Epoch 102/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0352 - accuracy: 0.7917 - val_loss: 0.0496 - val_accuracy: 0.6600\n",
      "Epoch 103/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0347 - accuracy: 0.7917 - val_loss: 0.0492 - val_accuracy: 0.6600\n",
      "Epoch 104/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0342 - accuracy: 0.7967 - val_loss: 0.0488 - val_accuracy: 0.6500\n",
      "Epoch 105/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0338 - accuracy: 0.8017 - val_loss: 0.0484 - val_accuracy: 0.6600\n",
      "Epoch 106/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0333 - accuracy: 0.8050 - val_loss: 0.0480 - val_accuracy: 0.6600\n",
      "Epoch 107/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0329 - accuracy: 0.8050 - val_loss: 0.0476 - val_accuracy: 0.6600\n",
      "Epoch 108/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0324 - accuracy: 0.8067 - val_loss: 0.0472 - val_accuracy: 0.6600\n",
      "Epoch 109/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0320 - accuracy: 0.8150 - val_loss: 0.0468 - val_accuracy: 0.6600\n",
      "Epoch 110/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0315 - accuracy: 0.8183 - val_loss: 0.0464 - val_accuracy: 0.6800\n",
      "Epoch 111/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0311 - accuracy: 0.8200 - val_loss: 0.0460 - val_accuracy: 0.6800\n",
      "Epoch 112/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0307 - accuracy: 0.8233 - val_loss: 0.0456 - val_accuracy: 0.6800\n",
      "Epoch 113/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0303 - accuracy: 0.8283 - val_loss: 0.0453 - val_accuracy: 0.6700\n",
      "Epoch 114/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0299 - accuracy: 0.8350 - val_loss: 0.0449 - val_accuracy: 0.6900\n",
      "Epoch 115/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0296 - accuracy: 0.8317 - val_loss: 0.0445 - val_accuracy: 0.7100\n",
      "Epoch 116/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0292 - accuracy: 0.8350 - val_loss: 0.0442 - val_accuracy: 0.7100\n",
      "Epoch 117/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0288 - accuracy: 0.8400 - val_loss: 0.0439 - val_accuracy: 0.7100\n",
      "Epoch 118/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0285 - accuracy: 0.8467 - val_loss: 0.0435 - val_accuracy: 0.7100\n",
      "Epoch 119/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0281 - accuracy: 0.8500 - val_loss: 0.0432 - val_accuracy: 0.7100\n",
      "Epoch 120/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0278 - accuracy: 0.8583 - val_loss: 0.0428 - val_accuracy: 0.7200\n",
      "Epoch 121/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0274 - accuracy: 0.8583 - val_loss: 0.0424 - val_accuracy: 0.7400\n",
      "Epoch 122/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0271 - accuracy: 0.8600 - val_loss: 0.0422 - val_accuracy: 0.7400\n",
      "Epoch 123/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0268 - accuracy: 0.8617 - val_loss: 0.0419 - val_accuracy: 0.7500\n",
      "Epoch 124/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0265 - accuracy: 0.8617 - val_loss: 0.0416 - val_accuracy: 0.7400\n",
      "Epoch 125/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0262 - accuracy: 0.8650 - val_loss: 0.0413 - val_accuracy: 0.7400\n",
      "Epoch 126/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0259 - accuracy: 0.8650 - val_loss: 0.0410 - val_accuracy: 0.7400\n",
      "Epoch 127/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0256 - accuracy: 0.8700 - val_loss: 0.0408 - val_accuracy: 0.7300\n",
      "Epoch 128/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0253 - accuracy: 0.8767 - val_loss: 0.0405 - val_accuracy: 0.7400\n",
      "Epoch 129/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0250 - accuracy: 0.8750 - val_loss: 0.0402 - val_accuracy: 0.7500\n",
      "Epoch 130/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0247 - accuracy: 0.8783 - val_loss: 0.0399 - val_accuracy: 0.7400\n",
      "Epoch 131/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0245 - accuracy: 0.8800 - val_loss: 0.0396 - val_accuracy: 0.7600\n",
      "Epoch 132/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0242 - accuracy: 0.8833 - val_loss: 0.0394 - val_accuracy: 0.7600\n",
      "Epoch 133/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0239 - accuracy: 0.8817 - val_loss: 0.0391 - val_accuracy: 0.7700\n",
      "Epoch 134/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0237 - accuracy: 0.8833 - val_loss: 0.0389 - val_accuracy: 0.7700\n",
      "Epoch 135/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0234 - accuracy: 0.8850 - val_loss: 0.0387 - val_accuracy: 0.7800\n",
      "Epoch 136/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0232 - accuracy: 0.8867 - val_loss: 0.0384 - val_accuracy: 0.7700\n",
      "Epoch 137/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0229 - accuracy: 0.8883 - val_loss: 0.0381 - val_accuracy: 0.7900\n",
      "Epoch 138/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0227 - accuracy: 0.8883 - val_loss: 0.0379 - val_accuracy: 0.8000\n",
      "Epoch 139/240\n",
      "600/600 [==============================] - 0s 114us/sample - loss: 0.0224 - accuracy: 0.8900 - val_loss: 0.0377 - val_accuracy: 0.8000\n",
      "Epoch 140/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0222 - accuracy: 0.8917 - val_loss: 0.0376 - val_accuracy: 0.8000\n",
      "Epoch 141/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0220 - accuracy: 0.8933 - val_loss: 0.0374 - val_accuracy: 0.8000\n",
      "Epoch 142/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0218 - accuracy: 0.8917 - val_loss: 0.0372 - val_accuracy: 0.8000\n",
      "Epoch 143/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0216 - accuracy: 0.8917 - val_loss: 0.0370 - val_accuracy: 0.7900\n",
      "Epoch 144/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0213 - accuracy: 0.8900 - val_loss: 0.0368 - val_accuracy: 0.8000\n",
      "Epoch 145/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0211 - accuracy: 0.8917 - val_loss: 0.0366 - val_accuracy: 0.8000\n",
      "Epoch 146/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0209 - accuracy: 0.8933 - val_loss: 0.0364 - val_accuracy: 0.8000\n",
      "Epoch 147/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0207 - accuracy: 0.8933 - val_loss: 0.0362 - val_accuracy: 0.7900\n",
      "Epoch 148/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0205 - accuracy: 0.8950 - val_loss: 0.0360 - val_accuracy: 0.8000\n",
      "Epoch 149/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0203 - accuracy: 0.8933 - val_loss: 0.0358 - val_accuracy: 0.7900\n",
      "Epoch 150/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0201 - accuracy: 0.8950 - val_loss: 0.0356 - val_accuracy: 0.8000\n",
      "Epoch 151/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0199 - accuracy: 0.8950 - val_loss: 0.0354 - val_accuracy: 0.7900\n",
      "Epoch 152/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0197 - accuracy: 0.9000 - val_loss: 0.0353 - val_accuracy: 0.8000\n",
      "Epoch 153/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0195 - accuracy: 0.8967 - val_loss: 0.0351 - val_accuracy: 0.7900\n",
      "Epoch 154/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0194 - accuracy: 0.8983 - val_loss: 0.0349 - val_accuracy: 0.7900\n",
      "Epoch 155/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0192 - accuracy: 0.9017 - val_loss: 0.0348 - val_accuracy: 0.7900\n",
      "Epoch 156/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0190 - accuracy: 0.9000 - val_loss: 0.0346 - val_accuracy: 0.7900\n",
      "Epoch 157/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0188 - accuracy: 0.9017 - val_loss: 0.0344 - val_accuracy: 0.7900\n",
      "Epoch 158/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0186 - accuracy: 0.9017 - val_loss: 0.0342 - val_accuracy: 0.7900\n",
      "Epoch 159/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0185 - accuracy: 0.9017 - val_loss: 0.0341 - val_accuracy: 0.7900\n",
      "Epoch 160/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0183 - accuracy: 0.9000 - val_loss: 0.0340 - val_accuracy: 0.8000\n",
      "Epoch 161/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0181 - accuracy: 0.9033 - val_loss: 0.0339 - val_accuracy: 0.8000\n",
      "Epoch 162/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0180 - accuracy: 0.9033 - val_loss: 0.0337 - val_accuracy: 0.7900\n",
      "Epoch 163/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0178 - accuracy: 0.9067 - val_loss: 0.0335 - val_accuracy: 0.7900\n",
      "Epoch 164/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0177 - accuracy: 0.9100 - val_loss: 0.0334 - val_accuracy: 0.8000\n",
      "Epoch 165/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0175 - accuracy: 0.9100 - val_loss: 0.0333 - val_accuracy: 0.8000\n",
      "Epoch 166/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0173 - accuracy: 0.9067 - val_loss: 0.0331 - val_accuracy: 0.8100\n",
      "Epoch 167/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0172 - accuracy: 0.9100 - val_loss: 0.0330 - val_accuracy: 0.8100\n",
      "Epoch 168/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0170 - accuracy: 0.9100 - val_loss: 0.0329 - val_accuracy: 0.8100\n",
      "Epoch 169/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0169 - accuracy: 0.9117 - val_loss: 0.0328 - val_accuracy: 0.8100\n",
      "Epoch 170/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0167 - accuracy: 0.9133 - val_loss: 0.0327 - val_accuracy: 0.8100\n",
      "Epoch 171/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0166 - accuracy: 0.9150 - val_loss: 0.0325 - val_accuracy: 0.8100\n",
      "Epoch 172/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0165 - accuracy: 0.9167 - val_loss: 0.0324 - val_accuracy: 0.8200\n",
      "Epoch 173/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0163 - accuracy: 0.9217 - val_loss: 0.0323 - val_accuracy: 0.8100\n",
      "Epoch 174/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0162 - accuracy: 0.9150 - val_loss: 0.0322 - val_accuracy: 0.8100\n",
      "Epoch 175/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0161 - accuracy: 0.9150 - val_loss: 0.0321 - val_accuracy: 0.8200\n",
      "Epoch 176/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0159 - accuracy: 0.9183 - val_loss: 0.0319 - val_accuracy: 0.8200\n",
      "Epoch 177/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0158 - accuracy: 0.9217 - val_loss: 0.0319 - val_accuracy: 0.8200\n",
      "Epoch 178/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0157 - accuracy: 0.9200 - val_loss: 0.0317 - val_accuracy: 0.8200\n",
      "Epoch 179/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0155 - accuracy: 0.9217 - val_loss: 0.0317 - val_accuracy: 0.8200\n",
      "Epoch 180/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0154 - accuracy: 0.9217 - val_loss: 0.0315 - val_accuracy: 0.8200\n",
      "Epoch 181/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0153 - accuracy: 0.9217 - val_loss: 0.0314 - val_accuracy: 0.8200\n",
      "Epoch 182/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0152 - accuracy: 0.9250 - val_loss: 0.0313 - val_accuracy: 0.8200\n",
      "Epoch 183/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0151 - accuracy: 0.9250 - val_loss: 0.0312 - val_accuracy: 0.8200\n",
      "Epoch 184/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0149 - accuracy: 0.9283 - val_loss: 0.0311 - val_accuracy: 0.8200\n",
      "Epoch 185/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0148 - accuracy: 0.9267 - val_loss: 0.0310 - val_accuracy: 0.8200\n",
      "Epoch 186/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0147 - accuracy: 0.9267 - val_loss: 0.0310 - val_accuracy: 0.8200\n",
      "Epoch 187/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0146 - accuracy: 0.9283 - val_loss: 0.0309 - val_accuracy: 0.8200\n",
      "Epoch 188/240\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0144 - accuracy: 0.9267 - val_loss: 0.0308 - val_accuracy: 0.8200\n",
      "Epoch 189/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0143 - accuracy: 0.9283 - val_loss: 0.0307 - val_accuracy: 0.8200\n",
      "Epoch 190/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0142 - accuracy: 0.9283 - val_loss: 0.0306 - val_accuracy: 0.8200\n",
      "Epoch 191/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0141 - accuracy: 0.9317 - val_loss: 0.0305 - val_accuracy: 0.8200\n",
      "Epoch 192/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0140 - accuracy: 0.9300 - val_loss: 0.0304 - val_accuracy: 0.8200\n",
      "Epoch 193/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0139 - accuracy: 0.9300 - val_loss: 0.0303 - val_accuracy: 0.8200\n",
      "Epoch 194/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0138 - accuracy: 0.9333 - val_loss: 0.0302 - val_accuracy: 0.8200\n",
      "Epoch 195/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0137 - accuracy: 0.9350 - val_loss: 0.0301 - val_accuracy: 0.8200\n",
      "Epoch 196/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0136 - accuracy: 0.9367 - val_loss: 0.0301 - val_accuracy: 0.8200\n",
      "Epoch 197/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0135 - accuracy: 0.9350 - val_loss: 0.0301 - val_accuracy: 0.8200\n",
      "Epoch 198/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0134 - accuracy: 0.9367 - val_loss: 0.0300 - val_accuracy: 0.8200\n",
      "Epoch 199/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0133 - accuracy: 0.9367 - val_loss: 0.0298 - val_accuracy: 0.8200\n",
      "Epoch 200/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0132 - accuracy: 0.9383 - val_loss: 0.0297 - val_accuracy: 0.8200\n",
      "Epoch 201/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0131 - accuracy: 0.9400 - val_loss: 0.0297 - val_accuracy: 0.8200\n",
      "Epoch 202/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0130 - accuracy: 0.9383 - val_loss: 0.0296 - val_accuracy: 0.8200\n",
      "Epoch 203/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0129 - accuracy: 0.9383 - val_loss: 0.0295 - val_accuracy: 0.8200\n",
      "Epoch 204/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0128 - accuracy: 0.9383 - val_loss: 0.0294 - val_accuracy: 0.8100\n",
      "Epoch 205/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0127 - accuracy: 0.9367 - val_loss: 0.0294 - val_accuracy: 0.8300\n",
      "Epoch 206/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0126 - accuracy: 0.9400 - val_loss: 0.0293 - val_accuracy: 0.8200\n",
      "Epoch 207/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0125 - accuracy: 0.9400 - val_loss: 0.0292 - val_accuracy: 0.8100\n",
      "Epoch 208/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0125 - accuracy: 0.9400 - val_loss: 0.0292 - val_accuracy: 0.8200\n",
      "Epoch 209/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0124 - accuracy: 0.9400 - val_loss: 0.0291 - val_accuracy: 0.8200\n",
      "Epoch 210/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0123 - accuracy: 0.9417 - val_loss: 0.0291 - val_accuracy: 0.8300\n",
      "Epoch 211/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0122 - accuracy: 0.9400 - val_loss: 0.0290 - val_accuracy: 0.8100\n",
      "Epoch 212/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0121 - accuracy: 0.9400 - val_loss: 0.0289 - val_accuracy: 0.8200\n",
      "Epoch 213/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0120 - accuracy: 0.9450 - val_loss: 0.0289 - val_accuracy: 0.8200\n",
      "Epoch 214/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0119 - accuracy: 0.9433 - val_loss: 0.0289 - val_accuracy: 0.8200\n",
      "Epoch 215/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0118 - accuracy: 0.9433 - val_loss: 0.0288 - val_accuracy: 0.8300\n",
      "Epoch 216/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0117 - accuracy: 0.9450 - val_loss: 0.0287 - val_accuracy: 0.8200\n",
      "Epoch 217/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0117 - accuracy: 0.9450 - val_loss: 0.0287 - val_accuracy: 0.8300\n",
      "Epoch 218/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0116 - accuracy: 0.9450 - val_loss: 0.0286 - val_accuracy: 0.8200\n",
      "Epoch 219/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0115 - accuracy: 0.9450 - val_loss: 0.0286 - val_accuracy: 0.8200\n",
      "Epoch 220/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0114 - accuracy: 0.9450 - val_loss: 0.0286 - val_accuracy: 0.8200\n",
      "Epoch 221/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0113 - accuracy: 0.9450 - val_loss: 0.0285 - val_accuracy: 0.8200\n",
      "Epoch 222/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0113 - accuracy: 0.9467 - val_loss: 0.0284 - val_accuracy: 0.8200\n",
      "Epoch 223/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0112 - accuracy: 0.9467 - val_loss: 0.0284 - val_accuracy: 0.8300\n",
      "Epoch 224/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0111 - accuracy: 0.9500 - val_loss: 0.0283 - val_accuracy: 0.8200\n",
      "Epoch 225/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0111 - accuracy: 0.9467 - val_loss: 0.0282 - val_accuracy: 0.8200\n",
      "Epoch 226/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0110 - accuracy: 0.9483 - val_loss: 0.0282 - val_accuracy: 0.8200\n",
      "Epoch 227/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0109 - accuracy: 0.9500 - val_loss: 0.0282 - val_accuracy: 0.8200\n",
      "Epoch 228/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0108 - accuracy: 0.9517 - val_loss: 0.0281 - val_accuracy: 0.8200\n",
      "Epoch 229/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0108 - accuracy: 0.9517 - val_loss: 0.0281 - val_accuracy: 0.8200\n",
      "Epoch 230/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0107 - accuracy: 0.9500 - val_loss: 0.0280 - val_accuracy: 0.8100\n",
      "Epoch 231/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0106 - accuracy: 0.9517 - val_loss: 0.0280 - val_accuracy: 0.8200\n",
      "Epoch 232/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0106 - accuracy: 0.9500 - val_loss: 0.0280 - val_accuracy: 0.8200\n",
      "Epoch 233/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0105 - accuracy: 0.9517 - val_loss: 0.0279 - val_accuracy: 0.8200\n",
      "Epoch 234/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0104 - accuracy: 0.9517 - val_loss: 0.0279 - val_accuracy: 0.8200\n",
      "Epoch 235/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0103 - accuracy: 0.9533 - val_loss: 0.0278 - val_accuracy: 0.8200\n",
      "Epoch 236/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0103 - accuracy: 0.9517 - val_loss: 0.0278 - val_accuracy: 0.8200\n",
      "Epoch 237/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0102 - accuracy: 0.9517 - val_loss: 0.0277 - val_accuracy: 0.8200\n",
      "Epoch 238/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0101 - accuracy: 0.9517 - val_loss: 0.0277 - val_accuracy: 0.8200\n",
      "Epoch 239/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0101 - accuracy: 0.9517 - val_loss: 0.0277 - val_accuracy: 0.8200\n",
      "Epoch 240/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0100 - accuracy: 0.9533 - val_loss: 0.0277 - val_accuracy: 0.8200\n",
      "Training date and time : \n",
      "2020-04-09 21:05:53\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/240\n",
      "600/600 [==============================] - 0s 660us/sample - loss: 0.0899 - accuracy: 0.1883 - val_loss: 0.0899 - val_accuracy: 0.1800\n",
      "Epoch 2/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0897 - accuracy: 0.1950 - val_loss: 0.0897 - val_accuracy: 0.1800\n",
      "Epoch 3/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0896 - accuracy: 0.2067 - val_loss: 0.0896 - val_accuracy: 0.1800\n",
      "Epoch 4/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0894 - accuracy: 0.2200 - val_loss: 0.0895 - val_accuracy: 0.2000\n",
      "Epoch 5/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0892 - accuracy: 0.2283 - val_loss: 0.0894 - val_accuracy: 0.2100\n",
      "Epoch 6/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0891 - accuracy: 0.2500 - val_loss: 0.0892 - val_accuracy: 0.2300\n",
      "Epoch 7/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0889 - accuracy: 0.2650 - val_loss: 0.0891 - val_accuracy: 0.2400\n",
      "Epoch 8/240\n",
      "600/600 [==============================] - 0s 203us/sample - loss: 0.0887 - accuracy: 0.2817 - val_loss: 0.0890 - val_accuracy: 0.2500\n",
      "Epoch 9/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0886 - accuracy: 0.2933 - val_loss: 0.0888 - val_accuracy: 0.2600\n",
      "Epoch 10/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0884 - accuracy: 0.3017 - val_loss: 0.0887 - val_accuracy: 0.2700\n",
      "Epoch 11/240\n",
      "600/600 [==============================] - 0s 118us/sample - loss: 0.0882 - accuracy: 0.3067 - val_loss: 0.0885 - val_accuracy: 0.2800\n",
      "Epoch 12/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0880 - accuracy: 0.3217 - val_loss: 0.0884 - val_accuracy: 0.2800\n",
      "Epoch 13/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0878 - accuracy: 0.3350 - val_loss: 0.0882 - val_accuracy: 0.2700\n",
      "Epoch 14/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0877 - accuracy: 0.3550 - val_loss: 0.0881 - val_accuracy: 0.2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0875 - accuracy: 0.3717 - val_loss: 0.0879 - val_accuracy: 0.2700\n",
      "Epoch 16/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0873 - accuracy: 0.3867 - val_loss: 0.0878 - val_accuracy: 0.2800\n",
      "Epoch 17/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0870 - accuracy: 0.3950 - val_loss: 0.0876 - val_accuracy: 0.2900\n",
      "Epoch 18/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0868 - accuracy: 0.4150 - val_loss: 0.0874 - val_accuracy: 0.3100\n",
      "Epoch 19/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0866 - accuracy: 0.4383 - val_loss: 0.0872 - val_accuracy: 0.3100\n",
      "Epoch 20/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0864 - accuracy: 0.4517 - val_loss: 0.0870 - val_accuracy: 0.3400\n",
      "Epoch 21/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0861 - accuracy: 0.4583 - val_loss: 0.0868 - val_accuracy: 0.3600\n",
      "Epoch 22/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0859 - accuracy: 0.4750 - val_loss: 0.0866 - val_accuracy: 0.3700\n",
      "Epoch 23/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0856 - accuracy: 0.4867 - val_loss: 0.0864 - val_accuracy: 0.3700\n",
      "Epoch 24/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0853 - accuracy: 0.4867 - val_loss: 0.0861 - val_accuracy: 0.3800\n",
      "Epoch 25/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0850 - accuracy: 0.4883 - val_loss: 0.0859 - val_accuracy: 0.3700\n",
      "Epoch 26/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0847 - accuracy: 0.4850 - val_loss: 0.0856 - val_accuracy: 0.3700\n",
      "Epoch 27/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0844 - accuracy: 0.4850 - val_loss: 0.0853 - val_accuracy: 0.3700\n",
      "Epoch 28/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0840 - accuracy: 0.4867 - val_loss: 0.0850 - val_accuracy: 0.3700\n",
      "Epoch 29/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0836 - accuracy: 0.4817 - val_loss: 0.0847 - val_accuracy: 0.3600\n",
      "Epoch 30/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0832 - accuracy: 0.4867 - val_loss: 0.0844 - val_accuracy: 0.3600\n",
      "Epoch 31/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0828 - accuracy: 0.4950 - val_loss: 0.0841 - val_accuracy: 0.3700\n",
      "Epoch 32/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0824 - accuracy: 0.4950 - val_loss: 0.0837 - val_accuracy: 0.3600\n",
      "Epoch 33/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0819 - accuracy: 0.5000 - val_loss: 0.0833 - val_accuracy: 0.3600\n",
      "Epoch 34/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0814 - accuracy: 0.4883 - val_loss: 0.0829 - val_accuracy: 0.3600\n",
      "Epoch 35/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0809 - accuracy: 0.4933 - val_loss: 0.0825 - val_accuracy: 0.3600\n",
      "Epoch 36/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0804 - accuracy: 0.4933 - val_loss: 0.0820 - val_accuracy: 0.3600\n",
      "Epoch 37/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0798 - accuracy: 0.4917 - val_loss: 0.0816 - val_accuracy: 0.3600\n",
      "Epoch 38/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0793 - accuracy: 0.4933 - val_loss: 0.0811 - val_accuracy: 0.3700\n",
      "Epoch 39/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0787 - accuracy: 0.4983 - val_loss: 0.0807 - val_accuracy: 0.3700\n",
      "Epoch 40/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0781 - accuracy: 0.5000 - val_loss: 0.0802 - val_accuracy: 0.3700\n",
      "Epoch 41/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0775 - accuracy: 0.5033 - val_loss: 0.0797 - val_accuracy: 0.3700\n",
      "Epoch 42/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0769 - accuracy: 0.5117 - val_loss: 0.0792 - val_accuracy: 0.3900\n",
      "Epoch 43/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0762 - accuracy: 0.5167 - val_loss: 0.0788 - val_accuracy: 0.4100\n",
      "Epoch 44/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0756 - accuracy: 0.5250 - val_loss: 0.0783 - val_accuracy: 0.4100\n",
      "Epoch 45/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0749 - accuracy: 0.5333 - val_loss: 0.0778 - val_accuracy: 0.4300\n",
      "Epoch 46/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0743 - accuracy: 0.5383 - val_loss: 0.0773 - val_accuracy: 0.4500\n",
      "Epoch 47/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0736 - accuracy: 0.5483 - val_loss: 0.0767 - val_accuracy: 0.4700\n",
      "Epoch 48/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0729 - accuracy: 0.5533 - val_loss: 0.0762 - val_accuracy: 0.4700\n",
      "Epoch 49/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0722 - accuracy: 0.5683 - val_loss: 0.0757 - val_accuracy: 0.4900\n",
      "Epoch 50/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0715 - accuracy: 0.5767 - val_loss: 0.0751 - val_accuracy: 0.4900\n",
      "Epoch 51/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0707 - accuracy: 0.5800 - val_loss: 0.0746 - val_accuracy: 0.5100\n",
      "Epoch 52/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0700 - accuracy: 0.5967 - val_loss: 0.0740 - val_accuracy: 0.5200\n",
      "Epoch 53/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0692 - accuracy: 0.6133 - val_loss: 0.0734 - val_accuracy: 0.5300\n",
      "Epoch 54/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0685 - accuracy: 0.6133 - val_loss: 0.0729 - val_accuracy: 0.5300\n",
      "Epoch 55/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0677 - accuracy: 0.6217 - val_loss: 0.0723 - val_accuracy: 0.5300\n",
      "Epoch 56/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0669 - accuracy: 0.6300 - val_loss: 0.0717 - val_accuracy: 0.5500\n",
      "Epoch 57/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0661 - accuracy: 0.6383 - val_loss: 0.0711 - val_accuracy: 0.5500\n",
      "Epoch 58/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0653 - accuracy: 0.6433 - val_loss: 0.0705 - val_accuracy: 0.5500\n",
      "Epoch 59/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0644 - accuracy: 0.6600 - val_loss: 0.0699 - val_accuracy: 0.5600\n",
      "Epoch 60/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0636 - accuracy: 0.6667 - val_loss: 0.0693 - val_accuracy: 0.5600\n",
      "Epoch 61/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0627 - accuracy: 0.6750 - val_loss: 0.0686 - val_accuracy: 0.5700\n",
      "Epoch 62/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0619 - accuracy: 0.6833 - val_loss: 0.0680 - val_accuracy: 0.5900\n",
      "Epoch 63/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0610 - accuracy: 0.6917 - val_loss: 0.0674 - val_accuracy: 0.6100\n",
      "Epoch 64/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0601 - accuracy: 0.6967 - val_loss: 0.0668 - val_accuracy: 0.6200\n",
      "Epoch 65/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0592 - accuracy: 0.7050 - val_loss: 0.0662 - val_accuracy: 0.6300\n",
      "Epoch 66/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0583 - accuracy: 0.7100 - val_loss: 0.0655 - val_accuracy: 0.6300\n",
      "Epoch 67/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0574 - accuracy: 0.7150 - val_loss: 0.0649 - val_accuracy: 0.6300\n",
      "Epoch 68/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0564 - accuracy: 0.7233 - val_loss: 0.0643 - val_accuracy: 0.6500\n",
      "Epoch 69/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0555 - accuracy: 0.7400 - val_loss: 0.0636 - val_accuracy: 0.6500\n",
      "Epoch 70/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0546 - accuracy: 0.7367 - val_loss: 0.0630 - val_accuracy: 0.6500\n",
      "Epoch 71/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0536 - accuracy: 0.7467 - val_loss: 0.0624 - val_accuracy: 0.6500\n",
      "Epoch 72/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0527 - accuracy: 0.7467 - val_loss: 0.0618 - val_accuracy: 0.6500\n",
      "Epoch 73/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0518 - accuracy: 0.7533 - val_loss: 0.0612 - val_accuracy: 0.6500\n",
      "Epoch 74/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0509 - accuracy: 0.7600 - val_loss: 0.0605 - val_accuracy: 0.6600\n",
      "Epoch 75/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0500 - accuracy: 0.7633 - val_loss: 0.0599 - val_accuracy: 0.6600\n",
      "Epoch 76/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0490 - accuracy: 0.7650 - val_loss: 0.0593 - val_accuracy: 0.6500\n",
      "Epoch 77/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0481 - accuracy: 0.7650 - val_loss: 0.0587 - val_accuracy: 0.6400\n",
      "Epoch 78/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0472 - accuracy: 0.7650 - val_loss: 0.0581 - val_accuracy: 0.6300\n",
      "Epoch 79/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0464 - accuracy: 0.7667 - val_loss: 0.0576 - val_accuracy: 0.6500\n",
      "Epoch 80/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0455 - accuracy: 0.7800 - val_loss: 0.0570 - val_accuracy: 0.6500\n",
      "Epoch 81/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0447 - accuracy: 0.7767 - val_loss: 0.0564 - val_accuracy: 0.6500\n",
      "Epoch 82/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0439 - accuracy: 0.7800 - val_loss: 0.0559 - val_accuracy: 0.6500\n",
      "Epoch 83/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0431 - accuracy: 0.7800 - val_loss: 0.0554 - val_accuracy: 0.6500\n",
      "Epoch 84/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0423 - accuracy: 0.7833 - val_loss: 0.0548 - val_accuracy: 0.6500\n",
      "Epoch 85/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0416 - accuracy: 0.7800 - val_loss: 0.0543 - val_accuracy: 0.6500\n",
      "Epoch 86/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0409 - accuracy: 0.7800 - val_loss: 0.0538 - val_accuracy: 0.6500\n",
      "Epoch 87/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0402 - accuracy: 0.7800 - val_loss: 0.0533 - val_accuracy: 0.6500\n",
      "Epoch 88/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0395 - accuracy: 0.7817 - val_loss: 0.0528 - val_accuracy: 0.6500\n",
      "Epoch 89/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0388 - accuracy: 0.7833 - val_loss: 0.0523 - val_accuracy: 0.6500\n",
      "Epoch 90/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0382 - accuracy: 0.7800 - val_loss: 0.0519 - val_accuracy: 0.6500\n",
      "Epoch 91/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0376 - accuracy: 0.7833 - val_loss: 0.0514 - val_accuracy: 0.6400\n",
      "Epoch 92/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0370 - accuracy: 0.7833 - val_loss: 0.0510 - val_accuracy: 0.6400\n",
      "Epoch 93/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0364 - accuracy: 0.7867 - val_loss: 0.0505 - val_accuracy: 0.6400\n",
      "Epoch 94/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0359 - accuracy: 0.7850 - val_loss: 0.0501 - val_accuracy: 0.6400\n",
      "Epoch 95/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0353 - accuracy: 0.7917 - val_loss: 0.0497 - val_accuracy: 0.6400\n",
      "Epoch 96/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0348 - accuracy: 0.7950 - val_loss: 0.0493 - val_accuracy: 0.6500\n",
      "Epoch 97/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0343 - accuracy: 0.7950 - val_loss: 0.0489 - val_accuracy: 0.6600\n",
      "Epoch 98/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0338 - accuracy: 0.7983 - val_loss: 0.0484 - val_accuracy: 0.6500\n",
      "Epoch 99/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0333 - accuracy: 0.8050 - val_loss: 0.0480 - val_accuracy: 0.6500\n",
      "Epoch 100/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0328 - accuracy: 0.8117 - val_loss: 0.0475 - val_accuracy: 0.6500\n",
      "Epoch 101/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0324 - accuracy: 0.8167 - val_loss: 0.0471 - val_accuracy: 0.6600\n",
      "Epoch 102/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0319 - accuracy: 0.8183 - val_loss: 0.0468 - val_accuracy: 0.6600\n",
      "Epoch 103/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0315 - accuracy: 0.8233 - val_loss: 0.0464 - val_accuracy: 0.6700\n",
      "Epoch 104/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0310 - accuracy: 0.8283 - val_loss: 0.0459 - val_accuracy: 0.6600\n",
      "Epoch 105/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0306 - accuracy: 0.8300 - val_loss: 0.0455 - val_accuracy: 0.6800\n",
      "Epoch 106/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0302 - accuracy: 0.8300 - val_loss: 0.0452 - val_accuracy: 0.6800\n",
      "Epoch 107/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0298 - accuracy: 0.8383 - val_loss: 0.0448 - val_accuracy: 0.6900\n",
      "Epoch 108/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0294 - accuracy: 0.8367 - val_loss: 0.0444 - val_accuracy: 0.7000\n",
      "Epoch 109/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0290 - accuracy: 0.8450 - val_loss: 0.0441 - val_accuracy: 0.7100\n",
      "Epoch 110/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0286 - accuracy: 0.8483 - val_loss: 0.0437 - val_accuracy: 0.7100\n",
      "Epoch 111/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0283 - accuracy: 0.8533 - val_loss: 0.0433 - val_accuracy: 0.7200\n",
      "Epoch 112/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0279 - accuracy: 0.8483 - val_loss: 0.0430 - val_accuracy: 0.7300\n",
      "Epoch 113/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0275 - accuracy: 0.8567 - val_loss: 0.0427 - val_accuracy: 0.7300\n",
      "Epoch 114/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0272 - accuracy: 0.8617 - val_loss: 0.0423 - val_accuracy: 0.7300\n",
      "Epoch 115/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0269 - accuracy: 0.8617 - val_loss: 0.0420 - val_accuracy: 0.7400\n",
      "Epoch 116/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0265 - accuracy: 0.8650 - val_loss: 0.0417 - val_accuracy: 0.7500\n",
      "Epoch 117/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0262 - accuracy: 0.8650 - val_loss: 0.0415 - val_accuracy: 0.7500\n",
      "Epoch 118/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0259 - accuracy: 0.8700 - val_loss: 0.0412 - val_accuracy: 0.7600\n",
      "Epoch 119/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0256 - accuracy: 0.8717 - val_loss: 0.0409 - val_accuracy: 0.7600\n",
      "Epoch 120/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0253 - accuracy: 0.8783 - val_loss: 0.0406 - val_accuracy: 0.7600\n",
      "Epoch 121/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0250 - accuracy: 0.8800 - val_loss: 0.0402 - val_accuracy: 0.7700\n",
      "Epoch 122/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0247 - accuracy: 0.8800 - val_loss: 0.0400 - val_accuracy: 0.7600\n",
      "Epoch 123/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0244 - accuracy: 0.8800 - val_loss: 0.0398 - val_accuracy: 0.7600\n",
      "Epoch 124/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0242 - accuracy: 0.8800 - val_loss: 0.0395 - val_accuracy: 0.7800\n",
      "Epoch 125/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0239 - accuracy: 0.8800 - val_loss: 0.0393 - val_accuracy: 0.7800\n",
      "Epoch 126/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0236 - accuracy: 0.8800 - val_loss: 0.0390 - val_accuracy: 0.7800\n",
      "Epoch 127/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0234 - accuracy: 0.8833 - val_loss: 0.0388 - val_accuracy: 0.7800\n",
      "Epoch 128/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0231 - accuracy: 0.8867 - val_loss: 0.0386 - val_accuracy: 0.7800\n",
      "Epoch 129/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0228 - accuracy: 0.8833 - val_loss: 0.0383 - val_accuracy: 0.7800\n",
      "Epoch 130/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0226 - accuracy: 0.8850 - val_loss: 0.0381 - val_accuracy: 0.7800\n",
      "Epoch 131/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0224 - accuracy: 0.8867 - val_loss: 0.0378 - val_accuracy: 0.7800\n",
      "Epoch 132/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0221 - accuracy: 0.8867 - val_loss: 0.0377 - val_accuracy: 0.7800\n",
      "Epoch 133/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0219 - accuracy: 0.8900 - val_loss: 0.0374 - val_accuracy: 0.7800\n",
      "Epoch 134/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0216 - accuracy: 0.8900 - val_loss: 0.0372 - val_accuracy: 0.7800\n",
      "Epoch 135/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0214 - accuracy: 0.8933 - val_loss: 0.0370 - val_accuracy: 0.7700\n",
      "Epoch 136/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0212 - accuracy: 0.8933 - val_loss: 0.0368 - val_accuracy: 0.7700\n",
      "Epoch 137/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0210 - accuracy: 0.8933 - val_loss: 0.0366 - val_accuracy: 0.7700\n",
      "Epoch 138/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0208 - accuracy: 0.8950 - val_loss: 0.0364 - val_accuracy: 0.7700\n",
      "Epoch 139/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0205 - accuracy: 0.8967 - val_loss: 0.0362 - val_accuracy: 0.7700\n",
      "Epoch 140/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0203 - accuracy: 0.8967 - val_loss: 0.0361 - val_accuracy: 0.7700\n",
      "Epoch 141/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0201 - accuracy: 0.8967 - val_loss: 0.0359 - val_accuracy: 0.7700\n",
      "Epoch 142/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0200 - accuracy: 0.8967 - val_loss: 0.0358 - val_accuracy: 0.7700\n",
      "Epoch 143/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0198 - accuracy: 0.8983 - val_loss: 0.0356 - val_accuracy: 0.7700\n",
      "Epoch 144/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0195 - accuracy: 0.9000 - val_loss: 0.0354 - val_accuracy: 0.7700\n",
      "Epoch 145/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0193 - accuracy: 0.9000 - val_loss: 0.0352 - val_accuracy: 0.7700\n",
      "Epoch 146/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0192 - accuracy: 0.9000 - val_loss: 0.0351 - val_accuracy: 0.7700\n",
      "Epoch 147/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0190 - accuracy: 0.8983 - val_loss: 0.0349 - val_accuracy: 0.7700\n",
      "Epoch 148/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0188 - accuracy: 0.9017 - val_loss: 0.0347 - val_accuracy: 0.7700\n",
      "Epoch 149/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0186 - accuracy: 0.9017 - val_loss: 0.0346 - val_accuracy: 0.7700\n",
      "Epoch 150/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0185 - accuracy: 0.9017 - val_loss: 0.0344 - val_accuracy: 0.7700\n",
      "Epoch 151/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0183 - accuracy: 0.9033 - val_loss: 0.0342 - val_accuracy: 0.7700\n",
      "Epoch 152/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0181 - accuracy: 0.9067 - val_loss: 0.0341 - val_accuracy: 0.7800\n",
      "Epoch 153/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0179 - accuracy: 0.9083 - val_loss: 0.0340 - val_accuracy: 0.7800\n",
      "Epoch 154/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0178 - accuracy: 0.9067 - val_loss: 0.0338 - val_accuracy: 0.7700\n",
      "Epoch 155/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0176 - accuracy: 0.9100 - val_loss: 0.0336 - val_accuracy: 0.7900\n",
      "Epoch 156/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0175 - accuracy: 0.9100 - val_loss: 0.0335 - val_accuracy: 0.7900\n",
      "Epoch 157/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0173 - accuracy: 0.9050 - val_loss: 0.0334 - val_accuracy: 0.7900\n",
      "Epoch 158/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0171 - accuracy: 0.9100 - val_loss: 0.0332 - val_accuracy: 0.7900\n",
      "Epoch 159/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0170 - accuracy: 0.9117 - val_loss: 0.0331 - val_accuracy: 0.8100\n",
      "Epoch 160/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0168 - accuracy: 0.9117 - val_loss: 0.0330 - val_accuracy: 0.8100\n",
      "Epoch 161/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0167 - accuracy: 0.9133 - val_loss: 0.0329 - val_accuracy: 0.7900\n",
      "Epoch 162/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0165 - accuracy: 0.9150 - val_loss: 0.0328 - val_accuracy: 0.7900\n",
      "Epoch 163/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0164 - accuracy: 0.9200 - val_loss: 0.0326 - val_accuracy: 0.8100\n",
      "Epoch 164/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0163 - accuracy: 0.9217 - val_loss: 0.0325 - val_accuracy: 0.8200\n",
      "Epoch 165/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0161 - accuracy: 0.9233 - val_loss: 0.0324 - val_accuracy: 0.8100\n",
      "Epoch 166/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0160 - accuracy: 0.9217 - val_loss: 0.0323 - val_accuracy: 0.8000\n",
      "Epoch 167/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0158 - accuracy: 0.9267 - val_loss: 0.0321 - val_accuracy: 0.8000\n",
      "Epoch 168/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0157 - accuracy: 0.9233 - val_loss: 0.0320 - val_accuracy: 0.8000\n",
      "Epoch 169/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0155 - accuracy: 0.9267 - val_loss: 0.0320 - val_accuracy: 0.8000\n",
      "Epoch 170/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0154 - accuracy: 0.9267 - val_loss: 0.0319 - val_accuracy: 0.8000\n",
      "Epoch 171/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0153 - accuracy: 0.9267 - val_loss: 0.0317 - val_accuracy: 0.8100\n",
      "Epoch 172/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0152 - accuracy: 0.9267 - val_loss: 0.0317 - val_accuracy: 0.8100\n",
      "Epoch 173/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0151 - accuracy: 0.9267 - val_loss: 0.0316 - val_accuracy: 0.8100\n",
      "Epoch 174/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0150 - accuracy: 0.9300 - val_loss: 0.0314 - val_accuracy: 0.8100\n",
      "Epoch 175/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0148 - accuracy: 0.9267 - val_loss: 0.0313 - val_accuracy: 0.8100\n",
      "Epoch 176/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0147 - accuracy: 0.9267 - val_loss: 0.0312 - val_accuracy: 0.8100\n",
      "Epoch 177/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0146 - accuracy: 0.9267 - val_loss: 0.0312 - val_accuracy: 0.8000\n",
      "Epoch 178/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0145 - accuracy: 0.9300 - val_loss: 0.0311 - val_accuracy: 0.8000\n",
      "Epoch 179/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0143 - accuracy: 0.9317 - val_loss: 0.0310 - val_accuracy: 0.8000\n",
      "Epoch 180/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0142 - accuracy: 0.9317 - val_loss: 0.0308 - val_accuracy: 0.8100\n",
      "Epoch 181/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0141 - accuracy: 0.9317 - val_loss: 0.0307 - val_accuracy: 0.8100\n",
      "Epoch 182/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0140 - accuracy: 0.9317 - val_loss: 0.0307 - val_accuracy: 0.8100\n",
      "Epoch 183/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0139 - accuracy: 0.9333 - val_loss: 0.0306 - val_accuracy: 0.8100\n",
      "Epoch 184/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0138 - accuracy: 0.9350 - val_loss: 0.0305 - val_accuracy: 0.8100\n",
      "Epoch 185/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0137 - accuracy: 0.9333 - val_loss: 0.0304 - val_accuracy: 0.8100\n",
      "Epoch 186/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0136 - accuracy: 0.9350 - val_loss: 0.0305 - val_accuracy: 0.8000\n",
      "Epoch 187/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0135 - accuracy: 0.9350 - val_loss: 0.0303 - val_accuracy: 0.8100\n",
      "Epoch 188/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0133 - accuracy: 0.9367 - val_loss: 0.0303 - val_accuracy: 0.8000\n",
      "Epoch 189/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0133 - accuracy: 0.9367 - val_loss: 0.0302 - val_accuracy: 0.8000\n",
      "Epoch 190/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0132 - accuracy: 0.9350 - val_loss: 0.0301 - val_accuracy: 0.8000\n",
      "Epoch 191/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0131 - accuracy: 0.9367 - val_loss: 0.0300 - val_accuracy: 0.8100\n",
      "Epoch 192/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0130 - accuracy: 0.9367 - val_loss: 0.0299 - val_accuracy: 0.8100\n",
      "Epoch 193/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0129 - accuracy: 0.9367 - val_loss: 0.0298 - val_accuracy: 0.8100\n",
      "Epoch 194/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0128 - accuracy: 0.9383 - val_loss: 0.0297 - val_accuracy: 0.8100\n",
      "Epoch 195/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0127 - accuracy: 0.9383 - val_loss: 0.0297 - val_accuracy: 0.8100\n",
      "Epoch 196/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0126 - accuracy: 0.9400 - val_loss: 0.0296 - val_accuracy: 0.8100\n",
      "Epoch 197/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0125 - accuracy: 0.9383 - val_loss: 0.0296 - val_accuracy: 0.8100\n",
      "Epoch 198/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0124 - accuracy: 0.9400 - val_loss: 0.0295 - val_accuracy: 0.8100\n",
      "Epoch 199/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0123 - accuracy: 0.9433 - val_loss: 0.0294 - val_accuracy: 0.8100\n",
      "Epoch 200/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0122 - accuracy: 0.9433 - val_loss: 0.0293 - val_accuracy: 0.8100\n",
      "Epoch 201/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0121 - accuracy: 0.9433 - val_loss: 0.0293 - val_accuracy: 0.8100\n",
      "Epoch 202/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0120 - accuracy: 0.9433 - val_loss: 0.0292 - val_accuracy: 0.8100\n",
      "Epoch 203/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0120 - accuracy: 0.9433 - val_loss: 0.0291 - val_accuracy: 0.8100\n",
      "Epoch 204/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0119 - accuracy: 0.9450 - val_loss: 0.0290 - val_accuracy: 0.8200\n",
      "Epoch 205/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0118 - accuracy: 0.9450 - val_loss: 0.0291 - val_accuracy: 0.8100\n",
      "Epoch 206/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0117 - accuracy: 0.9450 - val_loss: 0.0289 - val_accuracy: 0.8100\n",
      "Epoch 207/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0116 - accuracy: 0.9450 - val_loss: 0.0289 - val_accuracy: 0.8100\n",
      "Epoch 208/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0115 - accuracy: 0.9450 - val_loss: 0.0288 - val_accuracy: 0.8100\n",
      "Epoch 209/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0115 - accuracy: 0.9450 - val_loss: 0.0288 - val_accuracy: 0.8200\n",
      "Epoch 210/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0114 - accuracy: 0.9467 - val_loss: 0.0288 - val_accuracy: 0.8200\n",
      "Epoch 211/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0113 - accuracy: 0.9483 - val_loss: 0.0287 - val_accuracy: 0.8200\n",
      "Epoch 212/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0112 - accuracy: 0.9450 - val_loss: 0.0286 - val_accuracy: 0.8200\n",
      "Epoch 213/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0111 - accuracy: 0.9500 - val_loss: 0.0286 - val_accuracy: 0.8200\n",
      "Epoch 214/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0111 - accuracy: 0.9483 - val_loss: 0.0286 - val_accuracy: 0.8200\n",
      "Epoch 215/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0110 - accuracy: 0.9500 - val_loss: 0.0285 - val_accuracy: 0.8200\n",
      "Epoch 216/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0109 - accuracy: 0.9533 - val_loss: 0.0285 - val_accuracy: 0.8200\n",
      "Epoch 217/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0108 - accuracy: 0.9500 - val_loss: 0.0284 - val_accuracy: 0.8200\n",
      "Epoch 218/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0107 - accuracy: 0.9517 - val_loss: 0.0283 - val_accuracy: 0.8200\n",
      "Epoch 219/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0107 - accuracy: 0.9533 - val_loss: 0.0283 - val_accuracy: 0.8200\n",
      "Epoch 220/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0106 - accuracy: 0.9550 - val_loss: 0.0283 - val_accuracy: 0.8200\n",
      "Epoch 221/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0105 - accuracy: 0.9533 - val_loss: 0.0282 - val_accuracy: 0.8200\n",
      "Epoch 222/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0105 - accuracy: 0.9533 - val_loss: 0.0282 - val_accuracy: 0.8200\n",
      "Epoch 223/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0104 - accuracy: 0.9533 - val_loss: 0.0281 - val_accuracy: 0.8200\n",
      "Epoch 224/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0103 - accuracy: 0.9550 - val_loss: 0.0281 - val_accuracy: 0.8200\n",
      "Epoch 225/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0103 - accuracy: 0.9533 - val_loss: 0.0280 - val_accuracy: 0.8100\n",
      "Epoch 226/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0102 - accuracy: 0.9533 - val_loss: 0.0280 - val_accuracy: 0.8100\n",
      "Epoch 227/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0101 - accuracy: 0.9550 - val_loss: 0.0280 - val_accuracy: 0.8100\n",
      "Epoch 228/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0101 - accuracy: 0.9567 - val_loss: 0.0279 - val_accuracy: 0.8100\n",
      "Epoch 229/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0100 - accuracy: 0.9550 - val_loss: 0.0279 - val_accuracy: 0.8100\n",
      "Epoch 230/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0099 - accuracy: 0.9567 - val_loss: 0.0278 - val_accuracy: 0.8100\n",
      "Epoch 231/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0098 - accuracy: 0.9567 - val_loss: 0.0278 - val_accuracy: 0.8100\n",
      "Epoch 232/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0098 - accuracy: 0.9533 - val_loss: 0.0278 - val_accuracy: 0.8100\n",
      "Epoch 233/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0097 - accuracy: 0.9583 - val_loss: 0.0277 - val_accuracy: 0.8100\n",
      "Epoch 234/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0097 - accuracy: 0.9567 - val_loss: 0.0277 - val_accuracy: 0.8100\n",
      "Epoch 235/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0096 - accuracy: 0.9600 - val_loss: 0.0276 - val_accuracy: 0.8100\n",
      "Epoch 236/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0095 - accuracy: 0.9583 - val_loss: 0.0276 - val_accuracy: 0.8100\n",
      "Epoch 237/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0095 - accuracy: 0.9600 - val_loss: 0.0276 - val_accuracy: 0.8100\n",
      "Epoch 238/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0094 - accuracy: 0.9617 - val_loss: 0.0276 - val_accuracy: 0.8100\n",
      "Epoch 239/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0093 - accuracy: 0.9600 - val_loss: 0.0275 - val_accuracy: 0.8100\n",
      "Epoch 240/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0093 - accuracy: 0.9600 - val_loss: 0.0275 - val_accuracy: 0.8100\n",
      "Training date and time : \n",
      "2020-04-09 21:06:09\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/240\n",
      "600/600 [==============================] - 0s 656us/sample - loss: 0.0899 - accuracy: 0.1767 - val_loss: 0.0899 - val_accuracy: 0.1700\n",
      "Epoch 2/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0897 - accuracy: 0.1933 - val_loss: 0.0897 - val_accuracy: 0.1800\n",
      "Epoch 3/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0895 - accuracy: 0.2017 - val_loss: 0.0896 - val_accuracy: 0.1700\n",
      "Epoch 4/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0893 - accuracy: 0.2133 - val_loss: 0.0894 - val_accuracy: 0.1700\n",
      "Epoch 5/240\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0891 - accuracy: 0.2267 - val_loss: 0.0893 - val_accuracy: 0.2000\n",
      "Epoch 6/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0889 - accuracy: 0.2533 - val_loss: 0.0891 - val_accuracy: 0.2000\n",
      "Epoch 7/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0887 - accuracy: 0.2617 - val_loss: 0.0889 - val_accuracy: 0.2300\n",
      "Epoch 8/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0885 - accuracy: 0.2767 - val_loss: 0.0888 - val_accuracy: 0.2500\n",
      "Epoch 9/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0883 - accuracy: 0.2867 - val_loss: 0.0886 - val_accuracy: 0.2600\n",
      "Epoch 10/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0881 - accuracy: 0.3083 - val_loss: 0.0884 - val_accuracy: 0.2700\n",
      "Epoch 11/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0879 - accuracy: 0.3250 - val_loss: 0.0883 - val_accuracy: 0.2800\n",
      "Epoch 12/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0877 - accuracy: 0.3350 - val_loss: 0.0881 - val_accuracy: 0.2900\n",
      "Epoch 13/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0875 - accuracy: 0.3600 - val_loss: 0.0879 - val_accuracy: 0.2900\n",
      "Epoch 14/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0872 - accuracy: 0.3850 - val_loss: 0.0877 - val_accuracy: 0.2800\n",
      "Epoch 15/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0870 - accuracy: 0.4000 - val_loss: 0.0875 - val_accuracy: 0.3000\n",
      "Epoch 16/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0867 - accuracy: 0.4083 - val_loss: 0.0873 - val_accuracy: 0.3100\n",
      "Epoch 17/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0865 - accuracy: 0.4250 - val_loss: 0.0871 - val_accuracy: 0.3200\n",
      "Epoch 18/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0862 - accuracy: 0.4467 - val_loss: 0.0869 - val_accuracy: 0.3300\n",
      "Epoch 19/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0859 - accuracy: 0.4700 - val_loss: 0.0866 - val_accuracy: 0.3300\n",
      "Epoch 20/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0856 - accuracy: 0.4733 - val_loss: 0.0864 - val_accuracy: 0.3400\n",
      "Epoch 21/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0853 - accuracy: 0.4883 - val_loss: 0.0861 - val_accuracy: 0.3600\n",
      "Epoch 22/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0850 - accuracy: 0.5033 - val_loss: 0.0859 - val_accuracy: 0.3600\n",
      "Epoch 23/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0847 - accuracy: 0.5050 - val_loss: 0.0856 - val_accuracy: 0.3600\n",
      "Epoch 24/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0843 - accuracy: 0.5050 - val_loss: 0.0852 - val_accuracy: 0.3700\n",
      "Epoch 25/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0839 - accuracy: 0.5117 - val_loss: 0.0849 - val_accuracy: 0.3700\n",
      "Epoch 26/240\n",
      "600/600 [==============================] - 0s 117us/sample - loss: 0.0835 - accuracy: 0.5117 - val_loss: 0.0846 - val_accuracy: 0.3700\n",
      "Epoch 27/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0830 - accuracy: 0.5050 - val_loss: 0.0842 - val_accuracy: 0.3700\n",
      "Epoch 28/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0826 - accuracy: 0.5117 - val_loss: 0.0838 - val_accuracy: 0.3700\n",
      "Epoch 29/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0821 - accuracy: 0.5183 - val_loss: 0.0834 - val_accuracy: 0.3700\n",
      "Epoch 30/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0816 - accuracy: 0.5117 - val_loss: 0.0829 - val_accuracy: 0.3700\n",
      "Epoch 31/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0810 - accuracy: 0.5167 - val_loss: 0.0825 - val_accuracy: 0.3700\n",
      "Epoch 32/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0804 - accuracy: 0.5117 - val_loss: 0.0820 - val_accuracy: 0.3700\n",
      "Epoch 33/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0798 - accuracy: 0.5083 - val_loss: 0.0815 - val_accuracy: 0.3700\n",
      "Epoch 34/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0792 - accuracy: 0.5067 - val_loss: 0.0810 - val_accuracy: 0.3800\n",
      "Epoch 35/240\n",
      "600/600 [==============================] - 0s 114us/sample - loss: 0.0786 - accuracy: 0.5117 - val_loss: 0.0805 - val_accuracy: 0.3800\n",
      "Epoch 36/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0779 - accuracy: 0.5200 - val_loss: 0.0800 - val_accuracy: 0.3800\n",
      "Epoch 37/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0773 - accuracy: 0.5233 - val_loss: 0.0795 - val_accuracy: 0.3900\n",
      "Epoch 38/240\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0766 - accuracy: 0.5250 - val_loss: 0.0790 - val_accuracy: 0.4000\n",
      "Epoch 39/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0759 - accuracy: 0.5300 - val_loss: 0.0785 - val_accuracy: 0.4200\n",
      "Epoch 40/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0752 - accuracy: 0.5317 - val_loss: 0.0779 - val_accuracy: 0.4400\n",
      "Epoch 41/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0745 - accuracy: 0.5367 - val_loss: 0.0774 - val_accuracy: 0.4500\n",
      "Epoch 42/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0738 - accuracy: 0.5517 - val_loss: 0.0768 - val_accuracy: 0.4600\n",
      "Epoch 43/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0731 - accuracy: 0.5633 - val_loss: 0.0763 - val_accuracy: 0.4800\n",
      "Epoch 44/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0723 - accuracy: 0.5717 - val_loss: 0.0757 - val_accuracy: 0.4900\n",
      "Epoch 45/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0715 - accuracy: 0.5883 - val_loss: 0.0751 - val_accuracy: 0.4900\n",
      "Epoch 46/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0707 - accuracy: 0.5933 - val_loss: 0.0745 - val_accuracy: 0.4900\n",
      "Epoch 47/240\n",
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0699 - accuracy: 0.6000 - val_loss: 0.0739 - val_accuracy: 0.5000\n",
      "Epoch 48/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0691 - accuracy: 0.6067 - val_loss: 0.0733 - val_accuracy: 0.5100\n",
      "Epoch 49/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0683 - accuracy: 0.6183 - val_loss: 0.0727 - val_accuracy: 0.5200\n",
      "Epoch 50/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0675 - accuracy: 0.6300 - val_loss: 0.0720 - val_accuracy: 0.5200\n",
      "Epoch 51/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0666 - accuracy: 0.6350 - val_loss: 0.0714 - val_accuracy: 0.5300\n",
      "Epoch 52/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0657 - accuracy: 0.6483 - val_loss: 0.0708 - val_accuracy: 0.5400\n",
      "Epoch 53/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0648 - accuracy: 0.6567 - val_loss: 0.0701 - val_accuracy: 0.5500\n",
      "Epoch 54/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0639 - accuracy: 0.6633 - val_loss: 0.0695 - val_accuracy: 0.5500\n",
      "Epoch 55/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0630 - accuracy: 0.6717 - val_loss: 0.0688 - val_accuracy: 0.5500\n",
      "Epoch 56/240\n",
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0621 - accuracy: 0.6833 - val_loss: 0.0681 - val_accuracy: 0.5900\n",
      "Epoch 57/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0611 - accuracy: 0.6917 - val_loss: 0.0675 - val_accuracy: 0.5900\n",
      "Epoch 58/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0602 - accuracy: 0.6983 - val_loss: 0.0668 - val_accuracy: 0.6000\n",
      "Epoch 59/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0592 - accuracy: 0.7050 - val_loss: 0.0661 - val_accuracy: 0.6300\n",
      "Epoch 60/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0583 - accuracy: 0.7117 - val_loss: 0.0655 - val_accuracy: 0.6300\n",
      "Epoch 61/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0573 - accuracy: 0.7150 - val_loss: 0.0648 - val_accuracy: 0.6300\n",
      "Epoch 62/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0563 - accuracy: 0.7317 - val_loss: 0.0641 - val_accuracy: 0.6400\n",
      "Epoch 63/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0553 - accuracy: 0.7317 - val_loss: 0.0634 - val_accuracy: 0.6400\n",
      "Epoch 64/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0543 - accuracy: 0.7350 - val_loss: 0.0628 - val_accuracy: 0.6400\n",
      "Epoch 65/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0534 - accuracy: 0.7450 - val_loss: 0.0621 - val_accuracy: 0.6400\n",
      "Epoch 66/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0524 - accuracy: 0.7467 - val_loss: 0.0614 - val_accuracy: 0.6500\n",
      "Epoch 67/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0514 - accuracy: 0.7500 - val_loss: 0.0608 - val_accuracy: 0.6500\n",
      "Epoch 68/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0504 - accuracy: 0.7517 - val_loss: 0.0601 - val_accuracy: 0.6500\n",
      "Epoch 69/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0495 - accuracy: 0.7533 - val_loss: 0.0595 - val_accuracy: 0.6500\n",
      "Epoch 70/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0485 - accuracy: 0.7583 - val_loss: 0.0589 - val_accuracy: 0.6500\n",
      "Epoch 71/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0476 - accuracy: 0.7617 - val_loss: 0.0583 - val_accuracy: 0.6500\n",
      "Epoch 72/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0467 - accuracy: 0.7633 - val_loss: 0.0577 - val_accuracy: 0.6500\n",
      "Epoch 73/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0458 - accuracy: 0.7717 - val_loss: 0.0571 - val_accuracy: 0.6500\n",
      "Epoch 74/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0449 - accuracy: 0.7750 - val_loss: 0.0565 - val_accuracy: 0.6500\n",
      "Epoch 75/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0441 - accuracy: 0.7717 - val_loss: 0.0559 - val_accuracy: 0.6500\n",
      "Epoch 76/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0432 - accuracy: 0.7783 - val_loss: 0.0553 - val_accuracy: 0.6500\n",
      "Epoch 77/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0424 - accuracy: 0.7817 - val_loss: 0.0548 - val_accuracy: 0.6500\n",
      "Epoch 78/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0416 - accuracy: 0.7800 - val_loss: 0.0542 - val_accuracy: 0.6500\n",
      "Epoch 79/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0409 - accuracy: 0.7767 - val_loss: 0.0537 - val_accuracy: 0.6500\n",
      "Epoch 80/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0401 - accuracy: 0.7833 - val_loss: 0.0532 - val_accuracy: 0.6500\n",
      "Epoch 81/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0394 - accuracy: 0.7800 - val_loss: 0.0527 - val_accuracy: 0.6500\n",
      "Epoch 82/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0387 - accuracy: 0.7817 - val_loss: 0.0522 - val_accuracy: 0.6400\n",
      "Epoch 83/240\n",
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0381 - accuracy: 0.7850 - val_loss: 0.0517 - val_accuracy: 0.6400\n",
      "Epoch 84/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0375 - accuracy: 0.7833 - val_loss: 0.0512 - val_accuracy: 0.6400\n",
      "Epoch 85/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0368 - accuracy: 0.7883 - val_loss: 0.0508 - val_accuracy: 0.6400\n",
      "Epoch 86/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0363 - accuracy: 0.7917 - val_loss: 0.0503 - val_accuracy: 0.6400\n",
      "Epoch 87/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0356 - accuracy: 0.7950 - val_loss: 0.0498 - val_accuracy: 0.6500\n",
      "Epoch 88/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0351 - accuracy: 0.7950 - val_loss: 0.0494 - val_accuracy: 0.6500\n",
      "Epoch 89/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0346 - accuracy: 0.7950 - val_loss: 0.0489 - val_accuracy: 0.6500\n",
      "Epoch 90/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0340 - accuracy: 0.7967 - val_loss: 0.0485 - val_accuracy: 0.6500\n",
      "Epoch 91/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0335 - accuracy: 0.8067 - val_loss: 0.0480 - val_accuracy: 0.6500\n",
      "Epoch 92/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0330 - accuracy: 0.8117 - val_loss: 0.0476 - val_accuracy: 0.6500\n",
      "Epoch 93/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0325 - accuracy: 0.8100 - val_loss: 0.0472 - val_accuracy: 0.6500\n",
      "Epoch 94/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0321 - accuracy: 0.8133 - val_loss: 0.0468 - val_accuracy: 0.6500\n",
      "Epoch 95/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0316 - accuracy: 0.8217 - val_loss: 0.0463 - val_accuracy: 0.6600\n",
      "Epoch 96/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0311 - accuracy: 0.8250 - val_loss: 0.0459 - val_accuracy: 0.6600\n",
      "Epoch 97/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0307 - accuracy: 0.8317 - val_loss: 0.0455 - val_accuracy: 0.6700\n",
      "Epoch 98/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0302 - accuracy: 0.8350 - val_loss: 0.0451 - val_accuracy: 0.6700\n",
      "Epoch 99/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0298 - accuracy: 0.8350 - val_loss: 0.0447 - val_accuracy: 0.6800\n",
      "Epoch 100/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0294 - accuracy: 0.8400 - val_loss: 0.0443 - val_accuracy: 0.7000\n",
      "Epoch 101/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0290 - accuracy: 0.8500 - val_loss: 0.0439 - val_accuracy: 0.7100\n",
      "Epoch 102/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0286 - accuracy: 0.8517 - val_loss: 0.0436 - val_accuracy: 0.7100\n",
      "Epoch 103/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0282 - accuracy: 0.8533 - val_loss: 0.0433 - val_accuracy: 0.7100\n",
      "Epoch 104/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0278 - accuracy: 0.8567 - val_loss: 0.0429 - val_accuracy: 0.7200\n",
      "Epoch 105/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0275 - accuracy: 0.8550 - val_loss: 0.0425 - val_accuracy: 0.7300\n",
      "Epoch 106/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0271 - accuracy: 0.8650 - val_loss: 0.0422 - val_accuracy: 0.7400\n",
      "Epoch 107/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0268 - accuracy: 0.8617 - val_loss: 0.0419 - val_accuracy: 0.7400\n",
      "Epoch 108/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0265 - accuracy: 0.8667 - val_loss: 0.0416 - val_accuracy: 0.7500\n",
      "Epoch 109/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0261 - accuracy: 0.8683 - val_loss: 0.0413 - val_accuracy: 0.7500\n",
      "Epoch 110/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0258 - accuracy: 0.8700 - val_loss: 0.0409 - val_accuracy: 0.7500\n",
      "Epoch 111/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0255 - accuracy: 0.8717 - val_loss: 0.0406 - val_accuracy: 0.7600\n",
      "Epoch 112/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0252 - accuracy: 0.8733 - val_loss: 0.0403 - val_accuracy: 0.7600\n",
      "Epoch 113/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0248 - accuracy: 0.8750 - val_loss: 0.0401 - val_accuracy: 0.7600\n",
      "Epoch 114/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0245 - accuracy: 0.8767 - val_loss: 0.0398 - val_accuracy: 0.7600\n",
      "Epoch 115/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0243 - accuracy: 0.8750 - val_loss: 0.0396 - val_accuracy: 0.7700\n",
      "Epoch 116/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0240 - accuracy: 0.8800 - val_loss: 0.0393 - val_accuracy: 0.7700\n",
      "Epoch 117/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0237 - accuracy: 0.8783 - val_loss: 0.0391 - val_accuracy: 0.7700\n",
      "Epoch 118/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0234 - accuracy: 0.8833 - val_loss: 0.0389 - val_accuracy: 0.7700\n",
      "Epoch 119/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0232 - accuracy: 0.8850 - val_loss: 0.0386 - val_accuracy: 0.7700\n",
      "Epoch 120/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0229 - accuracy: 0.8867 - val_loss: 0.0383 - val_accuracy: 0.7700\n",
      "Epoch 121/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0226 - accuracy: 0.8883 - val_loss: 0.0381 - val_accuracy: 0.7800\n",
      "Epoch 122/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0224 - accuracy: 0.8883 - val_loss: 0.0379 - val_accuracy: 0.7600\n",
      "Epoch 123/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0221 - accuracy: 0.8850 - val_loss: 0.0377 - val_accuracy: 0.7600\n",
      "Epoch 124/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0219 - accuracy: 0.8917 - val_loss: 0.0375 - val_accuracy: 0.7600\n",
      "Epoch 125/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0217 - accuracy: 0.8900 - val_loss: 0.0373 - val_accuracy: 0.7700\n",
      "Epoch 126/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0214 - accuracy: 0.8933 - val_loss: 0.0371 - val_accuracy: 0.7700\n",
      "Epoch 127/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0212 - accuracy: 0.8933 - val_loss: 0.0369 - val_accuracy: 0.7700\n",
      "Epoch 128/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0210 - accuracy: 0.8950 - val_loss: 0.0367 - val_accuracy: 0.7700\n",
      "Epoch 129/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0207 - accuracy: 0.8950 - val_loss: 0.0364 - val_accuracy: 0.7700\n",
      "Epoch 130/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0205 - accuracy: 0.8950 - val_loss: 0.0363 - val_accuracy: 0.7700\n",
      "Epoch 131/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0203 - accuracy: 0.8950 - val_loss: 0.0360 - val_accuracy: 0.7800\n",
      "Epoch 132/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0201 - accuracy: 0.9000 - val_loss: 0.0359 - val_accuracy: 0.7800\n",
      "Epoch 133/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0199 - accuracy: 0.9017 - val_loss: 0.0357 - val_accuracy: 0.7700\n",
      "Epoch 134/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0197 - accuracy: 0.9000 - val_loss: 0.0355 - val_accuracy: 0.7700\n",
      "Epoch 135/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0195 - accuracy: 0.9000 - val_loss: 0.0354 - val_accuracy: 0.7700\n",
      "Epoch 136/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0193 - accuracy: 0.9000 - val_loss: 0.0352 - val_accuracy: 0.7700\n",
      "Epoch 137/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0191 - accuracy: 0.9017 - val_loss: 0.0350 - val_accuracy: 0.7700\n",
      "Epoch 138/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0189 - accuracy: 0.9050 - val_loss: 0.0348 - val_accuracy: 0.7700\n",
      "Epoch 139/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0187 - accuracy: 0.9033 - val_loss: 0.0347 - val_accuracy: 0.7700\n",
      "Epoch 140/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0185 - accuracy: 0.9000 - val_loss: 0.0346 - val_accuracy: 0.7700\n",
      "Epoch 141/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0183 - accuracy: 0.9067 - val_loss: 0.0344 - val_accuracy: 0.7800\n",
      "Epoch 142/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0182 - accuracy: 0.9083 - val_loss: 0.0343 - val_accuracy: 0.7800\n",
      "Epoch 143/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0180 - accuracy: 0.9083 - val_loss: 0.0342 - val_accuracy: 0.7700\n",
      "Epoch 144/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0178 - accuracy: 0.9083 - val_loss: 0.0340 - val_accuracy: 0.7800\n",
      "Epoch 145/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0176 - accuracy: 0.9117 - val_loss: 0.0338 - val_accuracy: 0.7900\n",
      "Epoch 146/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0175 - accuracy: 0.9100 - val_loss: 0.0337 - val_accuracy: 0.7800\n",
      "Epoch 147/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0173 - accuracy: 0.9117 - val_loss: 0.0336 - val_accuracy: 0.7800\n",
      "Epoch 148/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0172 - accuracy: 0.9117 - val_loss: 0.0334 - val_accuracy: 0.7800\n",
      "Epoch 149/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0170 - accuracy: 0.9100 - val_loss: 0.0333 - val_accuracy: 0.7800\n",
      "Epoch 150/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0169 - accuracy: 0.9133 - val_loss: 0.0331 - val_accuracy: 0.7900\n",
      "Epoch 151/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0167 - accuracy: 0.9133 - val_loss: 0.0330 - val_accuracy: 0.8000\n",
      "Epoch 152/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0165 - accuracy: 0.9200 - val_loss: 0.0328 - val_accuracy: 0.8000\n",
      "Epoch 153/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0164 - accuracy: 0.9200 - val_loss: 0.0328 - val_accuracy: 0.8000\n",
      "Epoch 154/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0163 - accuracy: 0.9150 - val_loss: 0.0326 - val_accuracy: 0.8000\n",
      "Epoch 155/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0161 - accuracy: 0.9217 - val_loss: 0.0325 - val_accuracy: 0.8000\n",
      "Epoch 156/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0160 - accuracy: 0.9217 - val_loss: 0.0324 - val_accuracy: 0.8000\n",
      "Epoch 157/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0158 - accuracy: 0.9233 - val_loss: 0.0323 - val_accuracy: 0.8000\n",
      "Epoch 158/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0157 - accuracy: 0.9267 - val_loss: 0.0321 - val_accuracy: 0.8000\n",
      "Epoch 159/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0156 - accuracy: 0.9233 - val_loss: 0.0320 - val_accuracy: 0.8000\n",
      "Epoch 160/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0154 - accuracy: 0.9267 - val_loss: 0.0319 - val_accuracy: 0.8000\n",
      "Epoch 161/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0153 - accuracy: 0.9300 - val_loss: 0.0318 - val_accuracy: 0.7900\n",
      "Epoch 162/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0151 - accuracy: 0.9300 - val_loss: 0.0317 - val_accuracy: 0.8000\n",
      "Epoch 163/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0150 - accuracy: 0.9317 - val_loss: 0.0316 - val_accuracy: 0.8000\n",
      "Epoch 164/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0149 - accuracy: 0.9317 - val_loss: 0.0315 - val_accuracy: 0.8100\n",
      "Epoch 165/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0148 - accuracy: 0.9300 - val_loss: 0.0314 - val_accuracy: 0.8000\n",
      "Epoch 166/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0146 - accuracy: 0.9317 - val_loss: 0.0313 - val_accuracy: 0.8000\n",
      "Epoch 167/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0145 - accuracy: 0.9317 - val_loss: 0.0312 - val_accuracy: 0.8000\n",
      "Epoch 168/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0144 - accuracy: 0.9333 - val_loss: 0.0311 - val_accuracy: 0.8000\n",
      "Epoch 169/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0143 - accuracy: 0.9317 - val_loss: 0.0310 - val_accuracy: 0.7900\n",
      "Epoch 170/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0141 - accuracy: 0.9333 - val_loss: 0.0309 - val_accuracy: 0.8000\n",
      "Epoch 171/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0141 - accuracy: 0.9350 - val_loss: 0.0308 - val_accuracy: 0.8100\n",
      "Epoch 172/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0139 - accuracy: 0.9333 - val_loss: 0.0307 - val_accuracy: 0.8100\n",
      "Epoch 173/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0138 - accuracy: 0.9333 - val_loss: 0.0307 - val_accuracy: 0.8100\n",
      "Epoch 174/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0137 - accuracy: 0.9333 - val_loss: 0.0305 - val_accuracy: 0.8100\n",
      "Epoch 175/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0136 - accuracy: 0.9350 - val_loss: 0.0305 - val_accuracy: 0.8100\n",
      "Epoch 176/240\n",
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0135 - accuracy: 0.9350 - val_loss: 0.0304 - val_accuracy: 0.8100\n",
      "Epoch 177/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0134 - accuracy: 0.9367 - val_loss: 0.0304 - val_accuracy: 0.8000\n",
      "Epoch 178/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0133 - accuracy: 0.9350 - val_loss: 0.0302 - val_accuracy: 0.8100\n",
      "Epoch 179/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0132 - accuracy: 0.9367 - val_loss: 0.0302 - val_accuracy: 0.8100\n",
      "Epoch 180/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0131 - accuracy: 0.9367 - val_loss: 0.0300 - val_accuracy: 0.8100\n",
      "Epoch 181/240\n",
      "600/600 [==============================] - 0s 117us/sample - loss: 0.0130 - accuracy: 0.9383 - val_loss: 0.0300 - val_accuracy: 0.8100\n",
      "Epoch 182/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0129 - accuracy: 0.9383 - val_loss: 0.0299 - val_accuracy: 0.8100\n",
      "Epoch 183/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0128 - accuracy: 0.9383 - val_loss: 0.0298 - val_accuracy: 0.8100\n",
      "Epoch 184/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0127 - accuracy: 0.9400 - val_loss: 0.0297 - val_accuracy: 0.8100\n",
      "Epoch 185/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0126 - accuracy: 0.9383 - val_loss: 0.0297 - val_accuracy: 0.8100\n",
      "Epoch 186/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0125 - accuracy: 0.9400 - val_loss: 0.0297 - val_accuracy: 0.8100\n",
      "Epoch 187/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0124 - accuracy: 0.9417 - val_loss: 0.0296 - val_accuracy: 0.8100\n",
      "Epoch 188/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0123 - accuracy: 0.9417 - val_loss: 0.0296 - val_accuracy: 0.8100\n",
      "Epoch 189/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0122 - accuracy: 0.9400 - val_loss: 0.0295 - val_accuracy: 0.8100\n",
      "Epoch 190/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0121 - accuracy: 0.9450 - val_loss: 0.0294 - val_accuracy: 0.8100\n",
      "Epoch 191/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0120 - accuracy: 0.9433 - val_loss: 0.0293 - val_accuracy: 0.8100\n",
      "Epoch 192/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0119 - accuracy: 0.9433 - val_loss: 0.0293 - val_accuracy: 0.8200\n",
      "Epoch 193/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0118 - accuracy: 0.9450 - val_loss: 0.0292 - val_accuracy: 0.8100\n",
      "Epoch 194/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0117 - accuracy: 0.9433 - val_loss: 0.0291 - val_accuracy: 0.8100\n",
      "Epoch 195/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0116 - accuracy: 0.9450 - val_loss: 0.0290 - val_accuracy: 0.8200\n",
      "Epoch 196/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0116 - accuracy: 0.9483 - val_loss: 0.0290 - val_accuracy: 0.8200\n",
      "Epoch 197/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0115 - accuracy: 0.9467 - val_loss: 0.0290 - val_accuracy: 0.8200\n",
      "Epoch 198/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0114 - accuracy: 0.9483 - val_loss: 0.0290 - val_accuracy: 0.8200\n",
      "Epoch 199/240\n",
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0113 - accuracy: 0.9483 - val_loss: 0.0289 - val_accuracy: 0.8200\n",
      "Epoch 200/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0113 - accuracy: 0.9483 - val_loss: 0.0288 - val_accuracy: 0.8200\n",
      "Epoch 201/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0112 - accuracy: 0.9500 - val_loss: 0.0287 - val_accuracy: 0.8100\n",
      "Epoch 202/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0111 - accuracy: 0.9517 - val_loss: 0.0286 - val_accuracy: 0.8200\n",
      "Epoch 203/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0110 - accuracy: 0.9517 - val_loss: 0.0286 - val_accuracy: 0.8200\n",
      "Epoch 204/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0109 - accuracy: 0.9533 - val_loss: 0.0285 - val_accuracy: 0.8200\n",
      "Epoch 205/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0108 - accuracy: 0.9533 - val_loss: 0.0286 - val_accuracy: 0.8200\n",
      "Epoch 206/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0108 - accuracy: 0.9533 - val_loss: 0.0285 - val_accuracy: 0.8100\n",
      "Epoch 207/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0107 - accuracy: 0.9533 - val_loss: 0.0284 - val_accuracy: 0.8100\n",
      "Epoch 208/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0106 - accuracy: 0.9517 - val_loss: 0.0284 - val_accuracy: 0.8100\n",
      "Epoch 209/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0106 - accuracy: 0.9550 - val_loss: 0.0283 - val_accuracy: 0.8100\n",
      "Epoch 210/240\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0105 - accuracy: 0.9533 - val_loss: 0.0283 - val_accuracy: 0.8100\n",
      "Epoch 211/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0104 - accuracy: 0.9550 - val_loss: 0.0283 - val_accuracy: 0.8100\n",
      "Epoch 212/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0103 - accuracy: 0.9550 - val_loss: 0.0282 - val_accuracy: 0.8100\n",
      "Epoch 213/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0103 - accuracy: 0.9550 - val_loss: 0.0282 - val_accuracy: 0.8100\n",
      "Epoch 214/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0102 - accuracy: 0.9550 - val_loss: 0.0282 - val_accuracy: 0.8000\n",
      "Epoch 215/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 115us/sample - loss: 0.0101 - accuracy: 0.9583 - val_loss: 0.0281 - val_accuracy: 0.8100\n",
      "Epoch 216/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0100 - accuracy: 0.9550 - val_loss: 0.0281 - val_accuracy: 0.8100\n",
      "Epoch 217/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0100 - accuracy: 0.9600 - val_loss: 0.0280 - val_accuracy: 0.8100\n",
      "Epoch 218/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0099 - accuracy: 0.9600 - val_loss: 0.0280 - val_accuracy: 0.8100\n",
      "Epoch 219/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0099 - accuracy: 0.9600 - val_loss: 0.0279 - val_accuracy: 0.8100\n",
      "Epoch 220/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0098 - accuracy: 0.9617 - val_loss: 0.0280 - val_accuracy: 0.8000\n",
      "Epoch 221/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0097 - accuracy: 0.9600 - val_loss: 0.0279 - val_accuracy: 0.8100\n",
      "Epoch 222/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0097 - accuracy: 0.9600 - val_loss: 0.0278 - val_accuracy: 0.8000\n",
      "Epoch 223/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0096 - accuracy: 0.9600 - val_loss: 0.0278 - val_accuracy: 0.8100\n",
      "Epoch 224/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0095 - accuracy: 0.9617 - val_loss: 0.0277 - val_accuracy: 0.8000\n",
      "Epoch 225/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0095 - accuracy: 0.9617 - val_loss: 0.0277 - val_accuracy: 0.8000\n",
      "Epoch 226/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0094 - accuracy: 0.9617 - val_loss: 0.0277 - val_accuracy: 0.8000\n",
      "Epoch 227/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0093 - accuracy: 0.9617 - val_loss: 0.0277 - val_accuracy: 0.8000\n",
      "Epoch 228/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0093 - accuracy: 0.9617 - val_loss: 0.0276 - val_accuracy: 0.8100\n",
      "Epoch 229/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0092 - accuracy: 0.9617 - val_loss: 0.0276 - val_accuracy: 0.8000\n",
      "Epoch 230/240\n",
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0092 - accuracy: 0.9617 - val_loss: 0.0275 - val_accuracy: 0.8000\n",
      "Epoch 231/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0091 - accuracy: 0.9633 - val_loss: 0.0275 - val_accuracy: 0.8000\n",
      "Epoch 232/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0091 - accuracy: 0.9650 - val_loss: 0.0275 - val_accuracy: 0.8000\n",
      "Epoch 233/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0090 - accuracy: 0.9633 - val_loss: 0.0275 - val_accuracy: 0.8000\n",
      "Epoch 234/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0089 - accuracy: 0.9650 - val_loss: 0.0274 - val_accuracy: 0.8000\n",
      "Epoch 235/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0089 - accuracy: 0.9650 - val_loss: 0.0274 - val_accuracy: 0.8000\n",
      "Epoch 236/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0088 - accuracy: 0.9650 - val_loss: 0.0274 - val_accuracy: 0.8000\n",
      "Epoch 237/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0088 - accuracy: 0.9650 - val_loss: 0.0274 - val_accuracy: 0.8000\n",
      "Epoch 238/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0087 - accuracy: 0.9650 - val_loss: 0.0273 - val_accuracy: 0.8000\n",
      "Epoch 239/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0086 - accuracy: 0.9650 - val_loss: 0.0273 - val_accuracy: 0.8000\n",
      "Epoch 240/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0086 - accuracy: 0.9667 - val_loss: 0.0273 - val_accuracy: 0.8000\n",
      "Training date and time : \n",
      "2020-04-09 21:06:25\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/240\n",
      "600/600 [==============================] - 0s 663us/sample - loss: 0.0900 - accuracy: 0.1650 - val_loss: 0.0899 - val_accuracy: 0.1600\n",
      "Epoch 2/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0897 - accuracy: 0.1817 - val_loss: 0.0897 - val_accuracy: 0.1600\n",
      "Epoch 3/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0895 - accuracy: 0.1967 - val_loss: 0.0895 - val_accuracy: 0.1700\n",
      "Epoch 4/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0892 - accuracy: 0.2133 - val_loss: 0.0893 - val_accuracy: 0.1800\n",
      "Epoch 5/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0890 - accuracy: 0.2183 - val_loss: 0.0891 - val_accuracy: 0.1900\n",
      "Epoch 6/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0888 - accuracy: 0.2383 - val_loss: 0.0889 - val_accuracy: 0.2000\n",
      "Epoch 7/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0885 - accuracy: 0.2617 - val_loss: 0.0887 - val_accuracy: 0.2000\n",
      "Epoch 8/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0883 - accuracy: 0.2783 - val_loss: 0.0885 - val_accuracy: 0.2200\n",
      "Epoch 9/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0880 - accuracy: 0.2983 - val_loss: 0.0883 - val_accuracy: 0.2600\n",
      "Epoch 10/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0878 - accuracy: 0.3183 - val_loss: 0.0881 - val_accuracy: 0.2800\n",
      "Epoch 11/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0875 - accuracy: 0.3400 - val_loss: 0.0879 - val_accuracy: 0.2900\n",
      "Epoch 12/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0872 - accuracy: 0.3650 - val_loss: 0.0877 - val_accuracy: 0.3000\n",
      "Epoch 13/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0870 - accuracy: 0.3833 - val_loss: 0.0875 - val_accuracy: 0.3000\n",
      "Epoch 14/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0867 - accuracy: 0.4017 - val_loss: 0.0872 - val_accuracy: 0.3200\n",
      "Epoch 15/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0864 - accuracy: 0.4183 - val_loss: 0.0870 - val_accuracy: 0.3200\n",
      "Epoch 16/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0861 - accuracy: 0.4367 - val_loss: 0.0867 - val_accuracy: 0.3300\n",
      "Epoch 17/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0857 - accuracy: 0.4533 - val_loss: 0.0864 - val_accuracy: 0.3400\n",
      "Epoch 18/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0854 - accuracy: 0.4717 - val_loss: 0.0861 - val_accuracy: 0.3700\n",
      "Epoch 19/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0850 - accuracy: 0.4983 - val_loss: 0.0858 - val_accuracy: 0.3600\n",
      "Epoch 20/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0846 - accuracy: 0.5017 - val_loss: 0.0855 - val_accuracy: 0.3800\n",
      "Epoch 21/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0842 - accuracy: 0.5167 - val_loss: 0.0852 - val_accuracy: 0.3700\n",
      "Epoch 22/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0838 - accuracy: 0.5133 - val_loss: 0.0848 - val_accuracy: 0.3700\n",
      "Epoch 23/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0833 - accuracy: 0.5267 - val_loss: 0.0844 - val_accuracy: 0.3900\n",
      "Epoch 24/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0828 - accuracy: 0.5233 - val_loss: 0.0840 - val_accuracy: 0.4000\n",
      "Epoch 25/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0823 - accuracy: 0.5367 - val_loss: 0.0835 - val_accuracy: 0.4000\n",
      "Epoch 26/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0818 - accuracy: 0.5350 - val_loss: 0.0831 - val_accuracy: 0.4000\n",
      "Epoch 27/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0812 - accuracy: 0.5267 - val_loss: 0.0826 - val_accuracy: 0.4100\n",
      "Epoch 28/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0806 - accuracy: 0.5283 - val_loss: 0.0820 - val_accuracy: 0.4200\n",
      "Epoch 29/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0799 - accuracy: 0.5283 - val_loss: 0.0815 - val_accuracy: 0.4300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0792 - accuracy: 0.5250 - val_loss: 0.0810 - val_accuracy: 0.4300\n",
      "Epoch 31/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0785 - accuracy: 0.5367 - val_loss: 0.0804 - val_accuracy: 0.4300\n",
      "Epoch 32/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0778 - accuracy: 0.5383 - val_loss: 0.0798 - val_accuracy: 0.4300\n",
      "Epoch 33/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0771 - accuracy: 0.5467 - val_loss: 0.0793 - val_accuracy: 0.4300\n",
      "Epoch 34/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0764 - accuracy: 0.5500 - val_loss: 0.0787 - val_accuracy: 0.4300\n",
      "Epoch 35/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0756 - accuracy: 0.5500 - val_loss: 0.0781 - val_accuracy: 0.4400\n",
      "Epoch 36/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0749 - accuracy: 0.5550 - val_loss: 0.0775 - val_accuracy: 0.4500\n",
      "Epoch 37/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0741 - accuracy: 0.5567 - val_loss: 0.0769 - val_accuracy: 0.4500\n",
      "Epoch 38/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0733 - accuracy: 0.5667 - val_loss: 0.0763 - val_accuracy: 0.4600\n",
      "Epoch 39/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0725 - accuracy: 0.5767 - val_loss: 0.0757 - val_accuracy: 0.4600\n",
      "Epoch 40/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0716 - accuracy: 0.5867 - val_loss: 0.0751 - val_accuracy: 0.4800\n",
      "Epoch 41/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0708 - accuracy: 0.5900 - val_loss: 0.0744 - val_accuracy: 0.4800\n",
      "Epoch 42/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0699 - accuracy: 0.5967 - val_loss: 0.0738 - val_accuracy: 0.4800\n",
      "Epoch 43/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0690 - accuracy: 0.6100 - val_loss: 0.0731 - val_accuracy: 0.4900\n",
      "Epoch 44/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0681 - accuracy: 0.6167 - val_loss: 0.0725 - val_accuracy: 0.4900\n",
      "Epoch 45/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0672 - accuracy: 0.6267 - val_loss: 0.0718 - val_accuracy: 0.4900\n",
      "Epoch 46/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0663 - accuracy: 0.6433 - val_loss: 0.0711 - val_accuracy: 0.4900\n",
      "Epoch 47/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0653 - accuracy: 0.6450 - val_loss: 0.0704 - val_accuracy: 0.5100\n",
      "Epoch 48/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0644 - accuracy: 0.6633 - val_loss: 0.0697 - val_accuracy: 0.5300\n",
      "Epoch 49/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0634 - accuracy: 0.6783 - val_loss: 0.0690 - val_accuracy: 0.5500\n",
      "Epoch 50/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0624 - accuracy: 0.6800 - val_loss: 0.0683 - val_accuracy: 0.5600\n",
      "Epoch 51/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0614 - accuracy: 0.6933 - val_loss: 0.0676 - val_accuracy: 0.5700\n",
      "Epoch 52/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0604 - accuracy: 0.7000 - val_loss: 0.0669 - val_accuracy: 0.6100\n",
      "Epoch 53/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0594 - accuracy: 0.7050 - val_loss: 0.0662 - val_accuracy: 0.6200\n",
      "Epoch 54/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0584 - accuracy: 0.7117 - val_loss: 0.0654 - val_accuracy: 0.6300\n",
      "Epoch 55/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0573 - accuracy: 0.7117 - val_loss: 0.0647 - val_accuracy: 0.6400\n",
      "Epoch 56/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0563 - accuracy: 0.7250 - val_loss: 0.0640 - val_accuracy: 0.6400\n",
      "Epoch 57/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0552 - accuracy: 0.7350 - val_loss: 0.0633 - val_accuracy: 0.6400\n",
      "Epoch 58/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0542 - accuracy: 0.7283 - val_loss: 0.0626 - val_accuracy: 0.6400\n",
      "Epoch 59/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0531 - accuracy: 0.7417 - val_loss: 0.0619 - val_accuracy: 0.6400\n",
      "Epoch 60/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0521 - accuracy: 0.7433 - val_loss: 0.0611 - val_accuracy: 0.6500\n",
      "Epoch 61/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0511 - accuracy: 0.7450 - val_loss: 0.0605 - val_accuracy: 0.6500\n",
      "Epoch 62/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0501 - accuracy: 0.7467 - val_loss: 0.0598 - val_accuracy: 0.6500\n",
      "Epoch 63/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0490 - accuracy: 0.7550 - val_loss: 0.0591 - val_accuracy: 0.6500\n",
      "Epoch 64/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0481 - accuracy: 0.7567 - val_loss: 0.0585 - val_accuracy: 0.6500\n",
      "Epoch 65/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0471 - accuracy: 0.7600 - val_loss: 0.0578 - val_accuracy: 0.6500\n",
      "Epoch 66/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0461 - accuracy: 0.7650 - val_loss: 0.0572 - val_accuracy: 0.6400\n",
      "Epoch 67/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0452 - accuracy: 0.7617 - val_loss: 0.0566 - val_accuracy: 0.6400\n",
      "Epoch 68/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0443 - accuracy: 0.7667 - val_loss: 0.0560 - val_accuracy: 0.6400\n",
      "Epoch 69/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0434 - accuracy: 0.7717 - val_loss: 0.0554 - val_accuracy: 0.6400\n",
      "Epoch 70/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0425 - accuracy: 0.7767 - val_loss: 0.0548 - val_accuracy: 0.6400\n",
      "Epoch 71/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0417 - accuracy: 0.7750 - val_loss: 0.0543 - val_accuracy: 0.6400\n",
      "Epoch 72/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0409 - accuracy: 0.7783 - val_loss: 0.0537 - val_accuracy: 0.6400\n",
      "Epoch 73/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0402 - accuracy: 0.7783 - val_loss: 0.0532 - val_accuracy: 0.6300\n",
      "Epoch 74/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0394 - accuracy: 0.7817 - val_loss: 0.0527 - val_accuracy: 0.6400\n",
      "Epoch 75/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0387 - accuracy: 0.7833 - val_loss: 0.0521 - val_accuracy: 0.6400\n",
      "Epoch 76/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0380 - accuracy: 0.7867 - val_loss: 0.0516 - val_accuracy: 0.6400\n",
      "Epoch 77/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0373 - accuracy: 0.7917 - val_loss: 0.0511 - val_accuracy: 0.6400\n",
      "Epoch 78/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0367 - accuracy: 0.7950 - val_loss: 0.0506 - val_accuracy: 0.6400\n",
      "Epoch 79/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0361 - accuracy: 0.7933 - val_loss: 0.0501 - val_accuracy: 0.6400\n",
      "Epoch 80/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0354 - accuracy: 0.7950 - val_loss: 0.0496 - val_accuracy: 0.6500\n",
      "Epoch 81/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0349 - accuracy: 0.7983 - val_loss: 0.0491 - val_accuracy: 0.6500\n",
      "Epoch 82/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0343 - accuracy: 0.8000 - val_loss: 0.0487 - val_accuracy: 0.6500\n",
      "Epoch 83/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0338 - accuracy: 0.8050 - val_loss: 0.0482 - val_accuracy: 0.6500\n",
      "Epoch 84/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0332 - accuracy: 0.8050 - val_loss: 0.0477 - val_accuracy: 0.6500\n",
      "Epoch 85/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0327 - accuracy: 0.8100 - val_loss: 0.0473 - val_accuracy: 0.6500\n",
      "Epoch 86/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0322 - accuracy: 0.8150 - val_loss: 0.0468 - val_accuracy: 0.6500\n",
      "Epoch 87/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0316 - accuracy: 0.8200 - val_loss: 0.0463 - val_accuracy: 0.6500\n",
      "Epoch 88/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0312 - accuracy: 0.8217 - val_loss: 0.0459 - val_accuracy: 0.6600\n",
      "Epoch 89/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0307 - accuracy: 0.8267 - val_loss: 0.0454 - val_accuracy: 0.6700\n",
      "Epoch 90/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0302 - accuracy: 0.8300 - val_loss: 0.0450 - val_accuracy: 0.6800\n",
      "Epoch 91/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0298 - accuracy: 0.8367 - val_loss: 0.0446 - val_accuracy: 0.6900\n",
      "Epoch 92/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0293 - accuracy: 0.8417 - val_loss: 0.0442 - val_accuracy: 0.6900\n",
      "Epoch 93/240\n",
      "600/600 [==============================] - 0s 114us/sample - loss: 0.0289 - accuracy: 0.8433 - val_loss: 0.0438 - val_accuracy: 0.7000\n",
      "Epoch 94/240\n",
      "600/600 [==============================] - 0s 190us/sample - loss: 0.0285 - accuracy: 0.8450 - val_loss: 0.0434 - val_accuracy: 0.7200\n",
      "Epoch 95/240\n",
      "600/600 [==============================] - 0s 249us/sample - loss: 0.0281 - accuracy: 0.8517 - val_loss: 0.0431 - val_accuracy: 0.7200\n",
      "Epoch 96/240\n",
      "600/600 [==============================] - 0s 260us/sample - loss: 0.0277 - accuracy: 0.8567 - val_loss: 0.0427 - val_accuracy: 0.7300\n",
      "Epoch 97/240\n",
      "600/600 [==============================] - 0s 212us/sample - loss: 0.0273 - accuracy: 0.8583 - val_loss: 0.0424 - val_accuracy: 0.7300\n",
      "Epoch 98/240\n",
      "600/600 [==============================] - 0s 137us/sample - loss: 0.0269 - accuracy: 0.8633 - val_loss: 0.0420 - val_accuracy: 0.7300\n",
      "Epoch 99/240\n",
      "600/600 [==============================] - 0s 216us/sample - loss: 0.0266 - accuracy: 0.8633 - val_loss: 0.0417 - val_accuracy: 0.7300\n",
      "Epoch 100/240\n",
      "600/600 [==============================] - 0s 237us/sample - loss: 0.0262 - accuracy: 0.8633 - val_loss: 0.0413 - val_accuracy: 0.7400\n",
      "Epoch 101/240\n",
      "600/600 [==============================] - 0s 196us/sample - loss: 0.0259 - accuracy: 0.8667 - val_loss: 0.0410 - val_accuracy: 0.7400\n",
      "Epoch 102/240\n",
      "600/600 [==============================] - 0s 199us/sample - loss: 0.0255 - accuracy: 0.8717 - val_loss: 0.0407 - val_accuracy: 0.7400\n",
      "Epoch 103/240\n",
      "600/600 [==============================] - 0s 284us/sample - loss: 0.0252 - accuracy: 0.8700 - val_loss: 0.0405 - val_accuracy: 0.7400\n",
      "Epoch 104/240\n",
      "600/600 [==============================] - 0s 176us/sample - loss: 0.0249 - accuracy: 0.8733 - val_loss: 0.0401 - val_accuracy: 0.7500\n",
      "Epoch 105/240\n",
      "600/600 [==============================] - 0s 285us/sample - loss: 0.0246 - accuracy: 0.8783 - val_loss: 0.0398 - val_accuracy: 0.7500\n",
      "Epoch 106/240\n",
      "600/600 [==============================] - 0s 119us/sample - loss: 0.0243 - accuracy: 0.8783 - val_loss: 0.0395 - val_accuracy: 0.7500\n",
      "Epoch 107/240\n",
      "600/600 [==============================] - 0s 173us/sample - loss: 0.0240 - accuracy: 0.8783 - val_loss: 0.0393 - val_accuracy: 0.7500\n",
      "Epoch 108/240\n",
      "600/600 [==============================] - 0s 128us/sample - loss: 0.0237 - accuracy: 0.8800 - val_loss: 0.0390 - val_accuracy: 0.7600\n",
      "Epoch 109/240\n",
      "600/600 [==============================] - 0s 126us/sample - loss: 0.0234 - accuracy: 0.8800 - val_loss: 0.0387 - val_accuracy: 0.7600\n",
      "Epoch 110/240\n",
      "600/600 [==============================] - 0s 131us/sample - loss: 0.0231 - accuracy: 0.8833 - val_loss: 0.0384 - val_accuracy: 0.7700\n",
      "Epoch 111/240\n",
      "600/600 [==============================] - 0s 204us/sample - loss: 0.0228 - accuracy: 0.8867 - val_loss: 0.0382 - val_accuracy: 0.7700\n",
      "Epoch 112/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0226 - accuracy: 0.8850 - val_loss: 0.0379 - val_accuracy: 0.7700\n",
      "Epoch 113/240\n",
      "600/600 [==============================] - 0s 161us/sample - loss: 0.0223 - accuracy: 0.8850 - val_loss: 0.0377 - val_accuracy: 0.7700\n",
      "Epoch 114/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0220 - accuracy: 0.8867 - val_loss: 0.0375 - val_accuracy: 0.7700\n",
      "Epoch 115/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0218 - accuracy: 0.8867 - val_loss: 0.0373 - val_accuracy: 0.7700\n",
      "Epoch 116/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0215 - accuracy: 0.8883 - val_loss: 0.0371 - val_accuracy: 0.7600\n",
      "Epoch 117/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0213 - accuracy: 0.8900 - val_loss: 0.0369 - val_accuracy: 0.7600\n",
      "Epoch 118/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0210 - accuracy: 0.8967 - val_loss: 0.0367 - val_accuracy: 0.7600\n",
      "Epoch 119/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0208 - accuracy: 0.8950 - val_loss: 0.0364 - val_accuracy: 0.7600\n",
      "Epoch 120/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0206 - accuracy: 0.8967 - val_loss: 0.0362 - val_accuracy: 0.7600\n",
      "Epoch 121/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0203 - accuracy: 0.8983 - val_loss: 0.0360 - val_accuracy: 0.7600\n",
      "Epoch 122/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0201 - accuracy: 0.9000 - val_loss: 0.0358 - val_accuracy: 0.7600\n",
      "Epoch 123/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0199 - accuracy: 0.8967 - val_loss: 0.0356 - val_accuracy: 0.7600\n",
      "Epoch 124/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0197 - accuracy: 0.9033 - val_loss: 0.0355 - val_accuracy: 0.7600\n",
      "Epoch 125/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0195 - accuracy: 0.9017 - val_loss: 0.0353 - val_accuracy: 0.7600\n",
      "Epoch 126/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0193 - accuracy: 0.9017 - val_loss: 0.0351 - val_accuracy: 0.7600\n",
      "Epoch 127/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0191 - accuracy: 0.9050 - val_loss: 0.0350 - val_accuracy: 0.7600\n",
      "Epoch 128/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0189 - accuracy: 0.9083 - val_loss: 0.0348 - val_accuracy: 0.7600\n",
      "Epoch 129/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0187 - accuracy: 0.9050 - val_loss: 0.0346 - val_accuracy: 0.7600\n",
      "Epoch 130/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0185 - accuracy: 0.9050 - val_loss: 0.0344 - val_accuracy: 0.7600\n",
      "Epoch 131/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0183 - accuracy: 0.9083 - val_loss: 0.0342 - val_accuracy: 0.7700\n",
      "Epoch 132/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0181 - accuracy: 0.9117 - val_loss: 0.0341 - val_accuracy: 0.7700\n",
      "Epoch 133/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0180 - accuracy: 0.9117 - val_loss: 0.0340 - val_accuracy: 0.7700\n",
      "Epoch 134/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0178 - accuracy: 0.9117 - val_loss: 0.0338 - val_accuracy: 0.7700\n",
      "Epoch 135/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0176 - accuracy: 0.9117 - val_loss: 0.0337 - val_accuracy: 0.7700\n",
      "Epoch 136/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0174 - accuracy: 0.9150 - val_loss: 0.0335 - val_accuracy: 0.7700\n",
      "Epoch 137/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0173 - accuracy: 0.9167 - val_loss: 0.0333 - val_accuracy: 0.7700\n",
      "Epoch 138/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0171 - accuracy: 0.9133 - val_loss: 0.0332 - val_accuracy: 0.7800\n",
      "Epoch 139/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0169 - accuracy: 0.9200 - val_loss: 0.0331 - val_accuracy: 0.7800\n",
      "Epoch 140/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0168 - accuracy: 0.9200 - val_loss: 0.0331 - val_accuracy: 0.7700\n",
      "Epoch 141/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0166 - accuracy: 0.9217 - val_loss: 0.0329 - val_accuracy: 0.7700\n",
      "Epoch 142/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0165 - accuracy: 0.9217 - val_loss: 0.0328 - val_accuracy: 0.7700\n",
      "Epoch 143/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0163 - accuracy: 0.9233 - val_loss: 0.0327 - val_accuracy: 0.7800\n",
      "Epoch 144/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0161 - accuracy: 0.9217 - val_loss: 0.0325 - val_accuracy: 0.7800\n",
      "Epoch 145/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0160 - accuracy: 0.9217 - val_loss: 0.0324 - val_accuracy: 0.7800\n",
      "Epoch 146/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0158 - accuracy: 0.9217 - val_loss: 0.0323 - val_accuracy: 0.7800\n",
      "Epoch 147/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0157 - accuracy: 0.9217 - val_loss: 0.0322 - val_accuracy: 0.7800\n",
      "Epoch 148/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0156 - accuracy: 0.9250 - val_loss: 0.0320 - val_accuracy: 0.7800\n",
      "Epoch 149/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0154 - accuracy: 0.9250 - val_loss: 0.0319 - val_accuracy: 0.7800\n",
      "Epoch 150/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0153 - accuracy: 0.9250 - val_loss: 0.0318 - val_accuracy: 0.7800\n",
      "Epoch 151/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0151 - accuracy: 0.9267 - val_loss: 0.0316 - val_accuracy: 0.7800\n",
      "Epoch 152/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0150 - accuracy: 0.9317 - val_loss: 0.0315 - val_accuracy: 0.7800\n",
      "Epoch 153/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0149 - accuracy: 0.9300 - val_loss: 0.0315 - val_accuracy: 0.7800\n",
      "Epoch 154/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0148 - accuracy: 0.9317 - val_loss: 0.0314 - val_accuracy: 0.7800\n",
      "Epoch 155/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0146 - accuracy: 0.9333 - val_loss: 0.0312 - val_accuracy: 0.7900\n",
      "Epoch 156/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0145 - accuracy: 0.9333 - val_loss: 0.0311 - val_accuracy: 0.7900\n",
      "Epoch 157/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0144 - accuracy: 0.9333 - val_loss: 0.0311 - val_accuracy: 0.7900\n",
      "Epoch 158/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0143 - accuracy: 0.9333 - val_loss: 0.0309 - val_accuracy: 0.7900\n",
      "Epoch 159/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0142 - accuracy: 0.9350 - val_loss: 0.0308 - val_accuracy: 0.7900\n",
      "Epoch 160/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0140 - accuracy: 0.9350 - val_loss: 0.0308 - val_accuracy: 0.7900\n",
      "Epoch 161/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0139 - accuracy: 0.9350 - val_loss: 0.0307 - val_accuracy: 0.7800\n",
      "Epoch 162/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0138 - accuracy: 0.9367 - val_loss: 0.0306 - val_accuracy: 0.7800\n",
      "Epoch 163/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0137 - accuracy: 0.9350 - val_loss: 0.0305 - val_accuracy: 0.7900\n",
      "Epoch 164/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0136 - accuracy: 0.9383 - val_loss: 0.0304 - val_accuracy: 0.7900\n",
      "Epoch 165/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0134 - accuracy: 0.9350 - val_loss: 0.0303 - val_accuracy: 0.7800\n",
      "Epoch 166/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0133 - accuracy: 0.9367 - val_loss: 0.0303 - val_accuracy: 0.7800\n",
      "Epoch 167/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0132 - accuracy: 0.9367 - val_loss: 0.0302 - val_accuracy: 0.7800\n",
      "Epoch 168/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0131 - accuracy: 0.9383 - val_loss: 0.0301 - val_accuracy: 0.7800\n",
      "Epoch 169/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0130 - accuracy: 0.9400 - val_loss: 0.0300 - val_accuracy: 0.7800\n",
      "Epoch 170/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0129 - accuracy: 0.9400 - val_loss: 0.0300 - val_accuracy: 0.7800\n",
      "Epoch 171/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0128 - accuracy: 0.9383 - val_loss: 0.0299 - val_accuracy: 0.7900\n",
      "Epoch 172/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0127 - accuracy: 0.9433 - val_loss: 0.0298 - val_accuracy: 0.7900\n",
      "Epoch 173/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0126 - accuracy: 0.9417 - val_loss: 0.0297 - val_accuracy: 0.7900\n",
      "Epoch 174/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0125 - accuracy: 0.9417 - val_loss: 0.0296 - val_accuracy: 0.7900\n",
      "Epoch 175/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0124 - accuracy: 0.9417 - val_loss: 0.0296 - val_accuracy: 0.7900\n",
      "Epoch 176/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0123 - accuracy: 0.9450 - val_loss: 0.0295 - val_accuracy: 0.7900\n",
      "Epoch 177/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0122 - accuracy: 0.9450 - val_loss: 0.0295 - val_accuracy: 0.7900\n",
      "Epoch 178/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0121 - accuracy: 0.9417 - val_loss: 0.0294 - val_accuracy: 0.7800\n",
      "Epoch 179/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0120 - accuracy: 0.9450 - val_loss: 0.0293 - val_accuracy: 0.7900\n",
      "Epoch 180/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0119 - accuracy: 0.9450 - val_loss: 0.0292 - val_accuracy: 0.8100\n",
      "Epoch 181/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0119 - accuracy: 0.9450 - val_loss: 0.0291 - val_accuracy: 0.8000\n",
      "Epoch 182/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0118 - accuracy: 0.9467 - val_loss: 0.0291 - val_accuracy: 0.8100\n",
      "Epoch 183/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0117 - accuracy: 0.9433 - val_loss: 0.0290 - val_accuracy: 0.8000\n",
      "Epoch 184/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0116 - accuracy: 0.9467 - val_loss: 0.0289 - val_accuracy: 0.8000\n",
      "Epoch 185/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0115 - accuracy: 0.9517 - val_loss: 0.0289 - val_accuracy: 0.8100\n",
      "Epoch 186/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0114 - accuracy: 0.9483 - val_loss: 0.0289 - val_accuracy: 0.8000\n",
      "Epoch 187/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0113 - accuracy: 0.9500 - val_loss: 0.0288 - val_accuracy: 0.8100\n",
      "Epoch 188/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0112 - accuracy: 0.9500 - val_loss: 0.0288 - val_accuracy: 0.8000\n",
      "Epoch 189/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0112 - accuracy: 0.9517 - val_loss: 0.0287 - val_accuracy: 0.8000\n",
      "Epoch 190/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0111 - accuracy: 0.9517 - val_loss: 0.0287 - val_accuracy: 0.8000\n",
      "Epoch 191/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0110 - accuracy: 0.9533 - val_loss: 0.0286 - val_accuracy: 0.8100\n",
      "Epoch 192/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0109 - accuracy: 0.9533 - val_loss: 0.0285 - val_accuracy: 0.8100\n",
      "Epoch 193/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0108 - accuracy: 0.9517 - val_loss: 0.0284 - val_accuracy: 0.8100\n",
      "Epoch 194/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0108 - accuracy: 0.9533 - val_loss: 0.0283 - val_accuracy: 0.8100\n",
      "Epoch 195/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0107 - accuracy: 0.9533 - val_loss: 0.0283 - val_accuracy: 0.8100\n",
      "Epoch 196/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0106 - accuracy: 0.9533 - val_loss: 0.0283 - val_accuracy: 0.8100\n",
      "Epoch 197/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0105 - accuracy: 0.9533 - val_loss: 0.0283 - val_accuracy: 0.8100\n",
      "Epoch 198/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0105 - accuracy: 0.9533 - val_loss: 0.0283 - val_accuracy: 0.8100\n",
      "Epoch 199/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0104 - accuracy: 0.9550 - val_loss: 0.0282 - val_accuracy: 0.8100\n",
      "Epoch 200/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0103 - accuracy: 0.9533 - val_loss: 0.0281 - val_accuracy: 0.8100\n",
      "Epoch 201/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0102 - accuracy: 0.9550 - val_loss: 0.0280 - val_accuracy: 0.8000\n",
      "Epoch 202/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0101 - accuracy: 0.9567 - val_loss: 0.0280 - val_accuracy: 0.8100\n",
      "Epoch 203/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0101 - accuracy: 0.9600 - val_loss: 0.0279 - val_accuracy: 0.8100\n",
      "Epoch 204/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0100 - accuracy: 0.9600 - val_loss: 0.0279 - val_accuracy: 0.8100\n",
      "Epoch 205/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0099 - accuracy: 0.9600 - val_loss: 0.0279 - val_accuracy: 0.8100\n",
      "Epoch 206/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0099 - accuracy: 0.9583 - val_loss: 0.0278 - val_accuracy: 0.8000\n",
      "Epoch 207/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0098 - accuracy: 0.9583 - val_loss: 0.0278 - val_accuracy: 0.8000\n",
      "Epoch 208/240\n",
      "600/600 [==============================] - 0s 87us/sample - loss: 0.0097 - accuracy: 0.9583 - val_loss: 0.0277 - val_accuracy: 0.8000\n",
      "Epoch 209/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0097 - accuracy: 0.9600 - val_loss: 0.0277 - val_accuracy: 0.8000\n",
      "Epoch 210/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0096 - accuracy: 0.9600 - val_loss: 0.0277 - val_accuracy: 0.8000\n",
      "Epoch 211/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0095 - accuracy: 0.9600 - val_loss: 0.0276 - val_accuracy: 0.8000\n",
      "Epoch 212/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0095 - accuracy: 0.9600 - val_loss: 0.0276 - val_accuracy: 0.8000\n",
      "Epoch 213/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0094 - accuracy: 0.9600 - val_loss: 0.0276 - val_accuracy: 0.8000\n",
      "Epoch 214/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0093 - accuracy: 0.9617 - val_loss: 0.0276 - val_accuracy: 0.8000\n",
      "Epoch 215/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0093 - accuracy: 0.9600 - val_loss: 0.0275 - val_accuracy: 0.8000\n",
      "Epoch 216/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0092 - accuracy: 0.9617 - val_loss: 0.0275 - val_accuracy: 0.8000\n",
      "Epoch 217/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0091 - accuracy: 0.9600 - val_loss: 0.0274 - val_accuracy: 0.8000\n",
      "Epoch 218/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0091 - accuracy: 0.9633 - val_loss: 0.0274 - val_accuracy: 0.8000\n",
      "Epoch 219/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0090 - accuracy: 0.9633 - val_loss: 0.0273 - val_accuracy: 0.8000\n",
      "Epoch 220/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0090 - accuracy: 0.9633 - val_loss: 0.0274 - val_accuracy: 0.8000\n",
      "Epoch 221/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0089 - accuracy: 0.9650 - val_loss: 0.0273 - val_accuracy: 0.8000\n",
      "Epoch 222/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0088 - accuracy: 0.9650 - val_loss: 0.0273 - val_accuracy: 0.8100\n",
      "Epoch 223/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0088 - accuracy: 0.9650 - val_loss: 0.0272 - val_accuracy: 0.8100\n",
      "Epoch 224/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0087 - accuracy: 0.9650 - val_loss: 0.0272 - val_accuracy: 0.8100\n",
      "Epoch 225/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0087 - accuracy: 0.9650 - val_loss: 0.0271 - val_accuracy: 0.8100\n",
      "Epoch 226/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0086 - accuracy: 0.9650 - val_loss: 0.0271 - val_accuracy: 0.8100\n",
      "Epoch 227/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0086 - accuracy: 0.9667 - val_loss: 0.0271 - val_accuracy: 0.8100\n",
      "Epoch 228/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0085 - accuracy: 0.9667 - val_loss: 0.0271 - val_accuracy: 0.8100\n",
      "Epoch 229/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0085 - accuracy: 0.9667 - val_loss: 0.0271 - val_accuracy: 0.8100\n",
      "Epoch 230/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0084 - accuracy: 0.9667 - val_loss: 0.0270 - val_accuracy: 0.8100\n",
      "Epoch 231/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0083 - accuracy: 0.9667 - val_loss: 0.0270 - val_accuracy: 0.8100\n",
      "Epoch 232/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0083 - accuracy: 0.9667 - val_loss: 0.0270 - val_accuracy: 0.8000\n",
      "Epoch 233/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0082 - accuracy: 0.9667 - val_loss: 0.0269 - val_accuracy: 0.8100\n",
      "Epoch 234/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0082 - accuracy: 0.9683 - val_loss: 0.0269 - val_accuracy: 0.8100\n",
      "Epoch 235/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0081 - accuracy: 0.9683 - val_loss: 0.0269 - val_accuracy: 0.8100\n",
      "Epoch 236/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0081 - accuracy: 0.9683 - val_loss: 0.0269 - val_accuracy: 0.8000\n",
      "Epoch 237/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0080 - accuracy: 0.9683 - val_loss: 0.0268 - val_accuracy: 0.8100\n",
      "Epoch 238/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0080 - accuracy: 0.9683 - val_loss: 0.0268 - val_accuracy: 0.8000\n",
      "Epoch 239/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0079 - accuracy: 0.9683 - val_loss: 0.0268 - val_accuracy: 0.8100\n",
      "Epoch 240/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0079 - accuracy: 0.9683 - val_loss: 0.0268 - val_accuracy: 0.8000\n",
      "Training date and time : \n",
      "2020-04-09 21:06:42\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/240\n",
      "600/600 [==============================] - 0s 673us/sample - loss: 0.0900 - accuracy: 0.1617 - val_loss: 0.0899 - val_accuracy: 0.1900\n",
      "Epoch 2/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0897 - accuracy: 0.1750 - val_loss: 0.0896 - val_accuracy: 0.1900\n",
      "Epoch 3/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0894 - accuracy: 0.1900 - val_loss: 0.0894 - val_accuracy: 0.1900\n",
      "Epoch 4/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0891 - accuracy: 0.2150 - val_loss: 0.0892 - val_accuracy: 0.1900\n",
      "Epoch 5/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0888 - accuracy: 0.2217 - val_loss: 0.0889 - val_accuracy: 0.1800\n",
      "Epoch 6/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0885 - accuracy: 0.2483 - val_loss: 0.0887 - val_accuracy: 0.2100\n",
      "Epoch 7/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0882 - accuracy: 0.2717 - val_loss: 0.0885 - val_accuracy: 0.2300\n",
      "Epoch 8/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0879 - accuracy: 0.2967 - val_loss: 0.0882 - val_accuracy: 0.2500\n",
      "Epoch 9/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0876 - accuracy: 0.3083 - val_loss: 0.0880 - val_accuracy: 0.2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0873 - accuracy: 0.3367 - val_loss: 0.0877 - val_accuracy: 0.2800\n",
      "Epoch 11/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0870 - accuracy: 0.3667 - val_loss: 0.0874 - val_accuracy: 0.2900\n",
      "Epoch 12/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0866 - accuracy: 0.3917 - val_loss: 0.0872 - val_accuracy: 0.3100\n",
      "Epoch 13/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0863 - accuracy: 0.4133 - val_loss: 0.0869 - val_accuracy: 0.3400\n",
      "Epoch 14/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0859 - accuracy: 0.4400 - val_loss: 0.0866 - val_accuracy: 0.3500\n",
      "Epoch 15/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0855 - accuracy: 0.4633 - val_loss: 0.0862 - val_accuracy: 0.3800\n",
      "Epoch 16/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0851 - accuracy: 0.4800 - val_loss: 0.0859 - val_accuracy: 0.3900\n",
      "Epoch 17/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0847 - accuracy: 0.4967 - val_loss: 0.0855 - val_accuracy: 0.4100\n",
      "Epoch 18/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0842 - accuracy: 0.5133 - val_loss: 0.0851 - val_accuracy: 0.4100\n",
      "Epoch 19/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0837 - accuracy: 0.5283 - val_loss: 0.0847 - val_accuracy: 0.4300\n",
      "Epoch 20/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0832 - accuracy: 0.5367 - val_loss: 0.0843 - val_accuracy: 0.4300\n",
      "Epoch 21/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0827 - accuracy: 0.5333 - val_loss: 0.0838 - val_accuracy: 0.4300\n",
      "Epoch 22/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0821 - accuracy: 0.5367 - val_loss: 0.0833 - val_accuracy: 0.4400\n",
      "Epoch 23/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0814 - accuracy: 0.5433 - val_loss: 0.0827 - val_accuracy: 0.4400\n",
      "Epoch 24/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0808 - accuracy: 0.5450 - val_loss: 0.0822 - val_accuracy: 0.4300\n",
      "Epoch 25/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0801 - accuracy: 0.5467 - val_loss: 0.0816 - val_accuracy: 0.4300\n",
      "Epoch 26/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0793 - accuracy: 0.5433 - val_loss: 0.0810 - val_accuracy: 0.4200\n",
      "Epoch 27/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0786 - accuracy: 0.5417 - val_loss: 0.0804 - val_accuracy: 0.4200\n",
      "Epoch 28/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0778 - accuracy: 0.5483 - val_loss: 0.0797 - val_accuracy: 0.4200\n",
      "Epoch 29/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0770 - accuracy: 0.5667 - val_loss: 0.0791 - val_accuracy: 0.4300\n",
      "Epoch 30/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0762 - accuracy: 0.5717 - val_loss: 0.0785 - val_accuracy: 0.4300\n",
      "Epoch 31/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0753 - accuracy: 0.5783 - val_loss: 0.0778 - val_accuracy: 0.4300\n",
      "Epoch 32/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0745 - accuracy: 0.5800 - val_loss: 0.0772 - val_accuracy: 0.4300\n",
      "Epoch 33/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0736 - accuracy: 0.5817 - val_loss: 0.0765 - val_accuracy: 0.4500\n",
      "Epoch 34/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0727 - accuracy: 0.5850 - val_loss: 0.0759 - val_accuracy: 0.4600\n",
      "Epoch 35/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0718 - accuracy: 0.5967 - val_loss: 0.0752 - val_accuracy: 0.4600\n",
      "Epoch 36/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0709 - accuracy: 0.6083 - val_loss: 0.0745 - val_accuracy: 0.4600\n",
      "Epoch 37/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0700 - accuracy: 0.6067 - val_loss: 0.0738 - val_accuracy: 0.4700\n",
      "Epoch 38/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0690 - accuracy: 0.6150 - val_loss: 0.0731 - val_accuracy: 0.4800\n",
      "Epoch 39/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0680 - accuracy: 0.6300 - val_loss: 0.0723 - val_accuracy: 0.4800\n",
      "Epoch 40/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0670 - accuracy: 0.6283 - val_loss: 0.0716 - val_accuracy: 0.4800\n",
      "Epoch 41/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0660 - accuracy: 0.6417 - val_loss: 0.0709 - val_accuracy: 0.4800\n",
      "Epoch 42/240\n",
      "600/600 [==============================] - 0s 113us/sample - loss: 0.0650 - accuracy: 0.6500 - val_loss: 0.0701 - val_accuracy: 0.5000\n",
      "Epoch 43/240\n",
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0639 - accuracy: 0.6667 - val_loss: 0.0694 - val_accuracy: 0.5200\n",
      "Epoch 44/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0629 - accuracy: 0.6750 - val_loss: 0.0686 - val_accuracy: 0.5300\n",
      "Epoch 45/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0618 - accuracy: 0.6867 - val_loss: 0.0678 - val_accuracy: 0.5500\n",
      "Epoch 46/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0607 - accuracy: 0.6967 - val_loss: 0.0671 - val_accuracy: 0.5700\n",
      "Epoch 47/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0596 - accuracy: 0.6967 - val_loss: 0.0663 - val_accuracy: 0.6200\n",
      "Epoch 48/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0585 - accuracy: 0.7100 - val_loss: 0.0656 - val_accuracy: 0.6300\n",
      "Epoch 49/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0574 - accuracy: 0.7183 - val_loss: 0.0648 - val_accuracy: 0.6400\n",
      "Epoch 50/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0563 - accuracy: 0.7200 - val_loss: 0.0640 - val_accuracy: 0.6400\n",
      "Epoch 51/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0551 - accuracy: 0.7267 - val_loss: 0.0633 - val_accuracy: 0.6400\n",
      "Epoch 52/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0540 - accuracy: 0.7317 - val_loss: 0.0625 - val_accuracy: 0.6500\n",
      "Epoch 53/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0529 - accuracy: 0.7333 - val_loss: 0.0618 - val_accuracy: 0.6500\n",
      "Epoch 54/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0518 - accuracy: 0.7417 - val_loss: 0.0610 - val_accuracy: 0.6500\n",
      "Epoch 55/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0507 - accuracy: 0.7433 - val_loss: 0.0603 - val_accuracy: 0.6500\n",
      "Epoch 56/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0496 - accuracy: 0.7467 - val_loss: 0.0596 - val_accuracy: 0.6500\n",
      "Epoch 57/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0486 - accuracy: 0.7550 - val_loss: 0.0589 - val_accuracy: 0.6600\n",
      "Epoch 58/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0475 - accuracy: 0.7550 - val_loss: 0.0582 - val_accuracy: 0.6600\n",
      "Epoch 59/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0465 - accuracy: 0.7600 - val_loss: 0.0575 - val_accuracy: 0.6500\n",
      "Epoch 60/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0455 - accuracy: 0.7717 - val_loss: 0.0568 - val_accuracy: 0.6500\n",
      "Epoch 61/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0445 - accuracy: 0.7733 - val_loss: 0.0562 - val_accuracy: 0.6500\n",
      "Epoch 62/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0436 - accuracy: 0.7700 - val_loss: 0.0556 - val_accuracy: 0.6500\n",
      "Epoch 63/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0427 - accuracy: 0.7783 - val_loss: 0.0549 - val_accuracy: 0.6500\n",
      "Epoch 64/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0418 - accuracy: 0.7750 - val_loss: 0.0543 - val_accuracy: 0.6500\n",
      "Epoch 65/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0410 - accuracy: 0.7750 - val_loss: 0.0537 - val_accuracy: 0.6400\n",
      "Epoch 66/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0402 - accuracy: 0.7800 - val_loss: 0.0532 - val_accuracy: 0.6300\n",
      "Epoch 67/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0394 - accuracy: 0.7800 - val_loss: 0.0526 - val_accuracy: 0.6400\n",
      "Epoch 68/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0387 - accuracy: 0.7817 - val_loss: 0.0521 - val_accuracy: 0.6400\n",
      "Epoch 69/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0379 - accuracy: 0.7867 - val_loss: 0.0515 - val_accuracy: 0.6400\n",
      "Epoch 70/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0372 - accuracy: 0.7850 - val_loss: 0.0510 - val_accuracy: 0.6400\n",
      "Epoch 71/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0366 - accuracy: 0.7867 - val_loss: 0.0505 - val_accuracy: 0.6400\n",
      "Epoch 72/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0359 - accuracy: 0.7900 - val_loss: 0.0500 - val_accuracy: 0.6400\n",
      "Epoch 73/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0353 - accuracy: 0.7883 - val_loss: 0.0495 - val_accuracy: 0.6400\n",
      "Epoch 74/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0347 - accuracy: 0.7933 - val_loss: 0.0490 - val_accuracy: 0.6400\n",
      "Epoch 75/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0341 - accuracy: 0.7983 - val_loss: 0.0484 - val_accuracy: 0.6400\n",
      "Epoch 76/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0335 - accuracy: 0.8033 - val_loss: 0.0479 - val_accuracy: 0.6400\n",
      "Epoch 77/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0330 - accuracy: 0.8100 - val_loss: 0.0474 - val_accuracy: 0.6500\n",
      "Epoch 78/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0324 - accuracy: 0.8117 - val_loss: 0.0469 - val_accuracy: 0.6400\n",
      "Epoch 79/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0319 - accuracy: 0.8183 - val_loss: 0.0465 - val_accuracy: 0.6400\n",
      "Epoch 80/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0314 - accuracy: 0.8233 - val_loss: 0.0460 - val_accuracy: 0.6400\n",
      "Epoch 81/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0309 - accuracy: 0.8217 - val_loss: 0.0455 - val_accuracy: 0.6600\n",
      "Epoch 82/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0304 - accuracy: 0.8283 - val_loss: 0.0451 - val_accuracy: 0.6700\n",
      "Epoch 83/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0299 - accuracy: 0.8350 - val_loss: 0.0446 - val_accuracy: 0.6900\n",
      "Epoch 84/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0294 - accuracy: 0.8383 - val_loss: 0.0442 - val_accuracy: 0.7000\n",
      "Epoch 85/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0290 - accuracy: 0.8417 - val_loss: 0.0438 - val_accuracy: 0.7100\n",
      "Epoch 86/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0286 - accuracy: 0.8467 - val_loss: 0.0434 - val_accuracy: 0.7200\n",
      "Epoch 87/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0281 - accuracy: 0.8467 - val_loss: 0.0430 - val_accuracy: 0.7200\n",
      "Epoch 88/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0277 - accuracy: 0.8500 - val_loss: 0.0426 - val_accuracy: 0.7200\n",
      "Epoch 89/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0273 - accuracy: 0.8517 - val_loss: 0.0422 - val_accuracy: 0.7300\n",
      "Epoch 90/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0269 - accuracy: 0.8550 - val_loss: 0.0419 - val_accuracy: 0.7300\n",
      "Epoch 91/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0265 - accuracy: 0.8567 - val_loss: 0.0415 - val_accuracy: 0.7300\n",
      "Epoch 92/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0262 - accuracy: 0.8650 - val_loss: 0.0412 - val_accuracy: 0.7300\n",
      "Epoch 93/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0258 - accuracy: 0.8650 - val_loss: 0.0409 - val_accuracy: 0.7300\n",
      "Epoch 94/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0255 - accuracy: 0.8667 - val_loss: 0.0406 - val_accuracy: 0.7400\n",
      "Epoch 95/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0251 - accuracy: 0.8717 - val_loss: 0.0403 - val_accuracy: 0.7400\n",
      "Epoch 96/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0248 - accuracy: 0.8667 - val_loss: 0.0400 - val_accuracy: 0.7500\n",
      "Epoch 97/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0245 - accuracy: 0.8750 - val_loss: 0.0397 - val_accuracy: 0.7500\n",
      "Epoch 98/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0241 - accuracy: 0.8817 - val_loss: 0.0394 - val_accuracy: 0.7500\n",
      "Epoch 99/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0238 - accuracy: 0.8783 - val_loss: 0.0391 - val_accuracy: 0.7500\n",
      "Epoch 100/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0235 - accuracy: 0.8817 - val_loss: 0.0388 - val_accuracy: 0.7500\n",
      "Epoch 101/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0232 - accuracy: 0.8850 - val_loss: 0.0385 - val_accuracy: 0.7600\n",
      "Epoch 102/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0229 - accuracy: 0.8833 - val_loss: 0.0384 - val_accuracy: 0.7600\n",
      "Epoch 103/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0227 - accuracy: 0.8850 - val_loss: 0.0381 - val_accuracy: 0.7600\n",
      "Epoch 104/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0224 - accuracy: 0.8850 - val_loss: 0.0378 - val_accuracy: 0.7600\n",
      "Epoch 105/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0221 - accuracy: 0.8900 - val_loss: 0.0375 - val_accuracy: 0.7500\n",
      "Epoch 106/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0218 - accuracy: 0.8917 - val_loss: 0.0373 - val_accuracy: 0.7400\n",
      "Epoch 107/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0216 - accuracy: 0.8883 - val_loss: 0.0371 - val_accuracy: 0.7600\n",
      "Epoch 108/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0213 - accuracy: 0.8917 - val_loss: 0.0369 - val_accuracy: 0.7600\n",
      "Epoch 109/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0211 - accuracy: 0.8933 - val_loss: 0.0367 - val_accuracy: 0.7600\n",
      "Epoch 110/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0208 - accuracy: 0.9000 - val_loss: 0.0364 - val_accuracy: 0.7600\n",
      "Epoch 111/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0206 - accuracy: 0.9000 - val_loss: 0.0362 - val_accuracy: 0.7600\n",
      "Epoch 112/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0204 - accuracy: 0.8983 - val_loss: 0.0360 - val_accuracy: 0.7600\n",
      "Epoch 113/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0201 - accuracy: 0.9000 - val_loss: 0.0358 - val_accuracy: 0.7600\n",
      "Epoch 114/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0199 - accuracy: 0.9033 - val_loss: 0.0356 - val_accuracy: 0.7600\n",
      "Epoch 115/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0197 - accuracy: 0.9033 - val_loss: 0.0354 - val_accuracy: 0.7600\n",
      "Epoch 116/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0195 - accuracy: 0.9050 - val_loss: 0.0353 - val_accuracy: 0.7600\n",
      "Epoch 117/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0193 - accuracy: 0.9033 - val_loss: 0.0351 - val_accuracy: 0.7600\n",
      "Epoch 118/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0190 - accuracy: 0.9067 - val_loss: 0.0350 - val_accuracy: 0.7600\n",
      "Epoch 119/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0189 - accuracy: 0.9083 - val_loss: 0.0347 - val_accuracy: 0.7700\n",
      "Epoch 120/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0187 - accuracy: 0.9100 - val_loss: 0.0345 - val_accuracy: 0.7700\n",
      "Epoch 121/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0184 - accuracy: 0.9100 - val_loss: 0.0343 - val_accuracy: 0.7700\n",
      "Epoch 122/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0182 - accuracy: 0.9100 - val_loss: 0.0342 - val_accuracy: 0.7700\n",
      "Epoch 123/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0181 - accuracy: 0.9100 - val_loss: 0.0340 - val_accuracy: 0.7700\n",
      "Epoch 124/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0179 - accuracy: 0.9117 - val_loss: 0.0339 - val_accuracy: 0.7700\n",
      "Epoch 125/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0177 - accuracy: 0.9133 - val_loss: 0.0337 - val_accuracy: 0.7700\n",
      "Epoch 126/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0175 - accuracy: 0.9133 - val_loss: 0.0336 - val_accuracy: 0.7700\n",
      "Epoch 127/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0173 - accuracy: 0.9133 - val_loss: 0.0335 - val_accuracy: 0.7700\n",
      "Epoch 128/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0172 - accuracy: 0.9150 - val_loss: 0.0333 - val_accuracy: 0.7700\n",
      "Epoch 129/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0170 - accuracy: 0.9200 - val_loss: 0.0331 - val_accuracy: 0.7700\n",
      "Epoch 130/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0168 - accuracy: 0.9183 - val_loss: 0.0330 - val_accuracy: 0.7700\n",
      "Epoch 131/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0167 - accuracy: 0.9167 - val_loss: 0.0328 - val_accuracy: 0.7800\n",
      "Epoch 132/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0165 - accuracy: 0.9200 - val_loss: 0.0327 - val_accuracy: 0.7800\n",
      "Epoch 133/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0163 - accuracy: 0.9233 - val_loss: 0.0326 - val_accuracy: 0.7800\n",
      "Epoch 134/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0162 - accuracy: 0.9233 - val_loss: 0.0324 - val_accuracy: 0.7800\n",
      "Epoch 135/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0160 - accuracy: 0.9217 - val_loss: 0.0323 - val_accuracy: 0.7800\n",
      "Epoch 136/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0159 - accuracy: 0.9267 - val_loss: 0.0322 - val_accuracy: 0.7800\n",
      "Epoch 137/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0157 - accuracy: 0.9217 - val_loss: 0.0320 - val_accuracy: 0.7800\n",
      "Epoch 138/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0156 - accuracy: 0.9250 - val_loss: 0.0319 - val_accuracy: 0.7800\n",
      "Epoch 139/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0154 - accuracy: 0.9250 - val_loss: 0.0318 - val_accuracy: 0.7800\n",
      "Epoch 140/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0153 - accuracy: 0.9233 - val_loss: 0.0318 - val_accuracy: 0.7800\n",
      "Epoch 141/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0151 - accuracy: 0.9283 - val_loss: 0.0317 - val_accuracy: 0.7800\n",
      "Epoch 142/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0150 - accuracy: 0.9233 - val_loss: 0.0316 - val_accuracy: 0.7800\n",
      "Epoch 143/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0149 - accuracy: 0.9267 - val_loss: 0.0315 - val_accuracy: 0.7800\n",
      "Epoch 144/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0147 - accuracy: 0.9283 - val_loss: 0.0313 - val_accuracy: 0.7800\n",
      "Epoch 145/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0146 - accuracy: 0.9300 - val_loss: 0.0312 - val_accuracy: 0.7800\n",
      "Epoch 146/240\n",
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0145 - accuracy: 0.9267 - val_loss: 0.0311 - val_accuracy: 0.7800\n",
      "Epoch 147/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0144 - accuracy: 0.9300 - val_loss: 0.0310 - val_accuracy: 0.7800\n",
      "Epoch 148/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0142 - accuracy: 0.9300 - val_loss: 0.0309 - val_accuracy: 0.7800\n",
      "Epoch 149/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0141 - accuracy: 0.9317 - val_loss: 0.0308 - val_accuracy: 0.7800\n",
      "Epoch 150/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0140 - accuracy: 0.9333 - val_loss: 0.0306 - val_accuracy: 0.7800\n",
      "Epoch 151/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0138 - accuracy: 0.9333 - val_loss: 0.0305 - val_accuracy: 0.7800\n",
      "Epoch 152/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0137 - accuracy: 0.9350 - val_loss: 0.0304 - val_accuracy: 0.7900\n",
      "Epoch 153/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0136 - accuracy: 0.9350 - val_loss: 0.0304 - val_accuracy: 0.7900\n",
      "Epoch 154/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0135 - accuracy: 0.9350 - val_loss: 0.0303 - val_accuracy: 0.7800\n",
      "Epoch 155/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0134 - accuracy: 0.9367 - val_loss: 0.0302 - val_accuracy: 0.7900\n",
      "Epoch 156/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0133 - accuracy: 0.9367 - val_loss: 0.0301 - val_accuracy: 0.7900\n",
      "Epoch 157/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0132 - accuracy: 0.9367 - val_loss: 0.0300 - val_accuracy: 0.7900\n",
      "Epoch 158/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0130 - accuracy: 0.9383 - val_loss: 0.0299 - val_accuracy: 0.7900\n",
      "Epoch 159/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0130 - accuracy: 0.9383 - val_loss: 0.0298 - val_accuracy: 0.7900\n",
      "Epoch 160/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0128 - accuracy: 0.9367 - val_loss: 0.0298 - val_accuracy: 0.7900\n",
      "Epoch 161/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0127 - accuracy: 0.9383 - val_loss: 0.0297 - val_accuracy: 0.7800\n",
      "Epoch 162/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0126 - accuracy: 0.9383 - val_loss: 0.0296 - val_accuracy: 0.7800\n",
      "Epoch 163/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0125 - accuracy: 0.9383 - val_loss: 0.0295 - val_accuracy: 0.7900\n",
      "Epoch 164/240\n",
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0124 - accuracy: 0.9417 - val_loss: 0.0294 - val_accuracy: 0.7900\n",
      "Epoch 165/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0123 - accuracy: 0.9400 - val_loss: 0.0294 - val_accuracy: 0.7800\n",
      "Epoch 166/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0122 - accuracy: 0.9400 - val_loss: 0.0293 - val_accuracy: 0.7800\n",
      "Epoch 167/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0121 - accuracy: 0.9417 - val_loss: 0.0292 - val_accuracy: 0.7800\n",
      "Epoch 168/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0120 - accuracy: 0.9433 - val_loss: 0.0292 - val_accuracy: 0.7800\n",
      "Epoch 169/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0119 - accuracy: 0.9450 - val_loss: 0.0291 - val_accuracy: 0.7800\n",
      "Epoch 170/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0118 - accuracy: 0.9467 - val_loss: 0.0290 - val_accuracy: 0.7800\n",
      "Epoch 171/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0117 - accuracy: 0.9467 - val_loss: 0.0290 - val_accuracy: 0.7900\n",
      "Epoch 172/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0116 - accuracy: 0.9467 - val_loss: 0.0289 - val_accuracy: 0.7900\n",
      "Epoch 173/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0115 - accuracy: 0.9483 - val_loss: 0.0289 - val_accuracy: 0.7900\n",
      "Epoch 174/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0115 - accuracy: 0.9467 - val_loss: 0.0288 - val_accuracy: 0.7900\n",
      "Epoch 175/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0114 - accuracy: 0.9467 - val_loss: 0.0287 - val_accuracy: 0.7900\n",
      "Epoch 176/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0113 - accuracy: 0.9500 - val_loss: 0.0286 - val_accuracy: 0.7900\n",
      "Epoch 177/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0112 - accuracy: 0.9517 - val_loss: 0.0287 - val_accuracy: 0.7900\n",
      "Epoch 178/240\n",
      "600/600 [==============================] - 0s 108us/sample - loss: 0.0111 - accuracy: 0.9517 - val_loss: 0.0286 - val_accuracy: 0.7800\n",
      "Epoch 179/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0110 - accuracy: 0.9500 - val_loss: 0.0285 - val_accuracy: 0.7900\n",
      "Epoch 180/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0109 - accuracy: 0.9517 - val_loss: 0.0284 - val_accuracy: 0.8000\n",
      "Epoch 181/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0108 - accuracy: 0.9517 - val_loss: 0.0283 - val_accuracy: 0.8000\n",
      "Epoch 182/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0108 - accuracy: 0.9550 - val_loss: 0.0283 - val_accuracy: 0.8000\n",
      "Epoch 183/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0107 - accuracy: 0.9550 - val_loss: 0.0282 - val_accuracy: 0.8000\n",
      "Epoch 184/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0106 - accuracy: 0.9533 - val_loss: 0.0282 - val_accuracy: 0.8100\n",
      "Epoch 185/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0105 - accuracy: 0.9567 - val_loss: 0.0282 - val_accuracy: 0.8200\n",
      "Epoch 186/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0104 - accuracy: 0.9550 - val_loss: 0.0282 - val_accuracy: 0.8000\n",
      "Epoch 187/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0104 - accuracy: 0.9533 - val_loss: 0.0281 - val_accuracy: 0.8100\n",
      "Epoch 188/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0103 - accuracy: 0.9567 - val_loss: 0.0281 - val_accuracy: 0.8100\n",
      "Epoch 189/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0102 - accuracy: 0.9550 - val_loss: 0.0280 - val_accuracy: 0.8200\n",
      "Epoch 190/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0101 - accuracy: 0.9550 - val_loss: 0.0280 - val_accuracy: 0.8200\n",
      "Epoch 191/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0101 - accuracy: 0.9583 - val_loss: 0.0279 - val_accuracy: 0.8200\n",
      "Epoch 192/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0100 - accuracy: 0.9583 - val_loss: 0.0278 - val_accuracy: 0.8200\n",
      "Epoch 193/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0099 - accuracy: 0.9567 - val_loss: 0.0278 - val_accuracy: 0.8200\n",
      "Epoch 194/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0098 - accuracy: 0.9583 - val_loss: 0.0277 - val_accuracy: 0.8200\n",
      "Epoch 195/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0097 - accuracy: 0.9617 - val_loss: 0.0277 - val_accuracy: 0.8200\n",
      "Epoch 196/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0097 - accuracy: 0.9617 - val_loss: 0.0277 - val_accuracy: 0.8200\n",
      "Epoch 197/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0096 - accuracy: 0.9617 - val_loss: 0.0277 - val_accuracy: 0.8200\n",
      "Epoch 198/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0095 - accuracy: 0.9617 - val_loss: 0.0276 - val_accuracy: 0.8200\n",
      "Epoch 199/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0095 - accuracy: 0.9600 - val_loss: 0.0276 - val_accuracy: 0.8200\n",
      "Epoch 200/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0094 - accuracy: 0.9617 - val_loss: 0.0275 - val_accuracy: 0.8200\n",
      "Epoch 201/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0093 - accuracy: 0.9617 - val_loss: 0.0274 - val_accuracy: 0.8200\n",
      "Epoch 202/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0093 - accuracy: 0.9633 - val_loss: 0.0274 - val_accuracy: 0.8200\n",
      "Epoch 203/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0092 - accuracy: 0.9633 - val_loss: 0.0273 - val_accuracy: 0.8200\n",
      "Epoch 204/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0091 - accuracy: 0.9650 - val_loss: 0.0273 - val_accuracy: 0.8200\n",
      "Epoch 205/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0091 - accuracy: 0.9650 - val_loss: 0.0274 - val_accuracy: 0.8200\n",
      "Epoch 206/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0090 - accuracy: 0.9650 - val_loss: 0.0272 - val_accuracy: 0.8200\n",
      "Epoch 207/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0089 - accuracy: 0.9650 - val_loss: 0.0272 - val_accuracy: 0.8100\n",
      "Epoch 208/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0089 - accuracy: 0.9650 - val_loss: 0.0272 - val_accuracy: 0.8100\n",
      "Epoch 209/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0088 - accuracy: 0.9650 - val_loss: 0.0272 - val_accuracy: 0.8100\n",
      "Epoch 210/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0088 - accuracy: 0.9650 - val_loss: 0.0271 - val_accuracy: 0.8100\n",
      "Epoch 211/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0087 - accuracy: 0.9650 - val_loss: 0.0271 - val_accuracy: 0.8100\n",
      "Epoch 212/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0086 - accuracy: 0.9650 - val_loss: 0.0270 - val_accuracy: 0.8100\n",
      "Epoch 213/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0086 - accuracy: 0.9650 - val_loss: 0.0270 - val_accuracy: 0.8100\n",
      "Epoch 214/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0085 - accuracy: 0.9650 - val_loss: 0.0270 - val_accuracy: 0.8100\n",
      "Epoch 215/240\n",
      "600/600 [==============================] - 0s 115us/sample - loss: 0.0085 - accuracy: 0.9650 - val_loss: 0.0270 - val_accuracy: 0.8100\n",
      "Epoch 216/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0084 - accuracy: 0.9650 - val_loss: 0.0270 - val_accuracy: 0.8100\n",
      "Epoch 217/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0083 - accuracy: 0.9650 - val_loss: 0.0269 - val_accuracy: 0.8100\n",
      "Epoch 218/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0083 - accuracy: 0.9650 - val_loss: 0.0269 - val_accuracy: 0.8100\n",
      "Epoch 219/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0082 - accuracy: 0.9650 - val_loss: 0.0269 - val_accuracy: 0.8100\n",
      "Epoch 220/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0082 - accuracy: 0.9650 - val_loss: 0.0269 - val_accuracy: 0.8100\n",
      "Epoch 221/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0081 - accuracy: 0.9650 - val_loss: 0.0268 - val_accuracy: 0.8100\n",
      "Epoch 222/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0081 - accuracy: 0.9650 - val_loss: 0.0268 - val_accuracy: 0.8100\n",
      "Epoch 223/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0080 - accuracy: 0.9650 - val_loss: 0.0267 - val_accuracy: 0.8100\n",
      "Epoch 224/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0080 - accuracy: 0.9667 - val_loss: 0.0267 - val_accuracy: 0.8100\n",
      "Epoch 225/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0079 - accuracy: 0.9683 - val_loss: 0.0267 - val_accuracy: 0.8100\n",
      "Epoch 226/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0079 - accuracy: 0.9683 - val_loss: 0.0267 - val_accuracy: 0.8100\n",
      "Epoch 227/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0078 - accuracy: 0.9683 - val_loss: 0.0266 - val_accuracy: 0.8100\n",
      "Epoch 228/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0078 - accuracy: 0.9683 - val_loss: 0.0266 - val_accuracy: 0.8100\n",
      "Epoch 229/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0077 - accuracy: 0.9700 - val_loss: 0.0266 - val_accuracy: 0.8100\n",
      "Epoch 230/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0077 - accuracy: 0.9700 - val_loss: 0.0265 - val_accuracy: 0.8100\n",
      "Epoch 231/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0076 - accuracy: 0.9717 - val_loss: 0.0265 - val_accuracy: 0.8100\n",
      "Epoch 232/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0076 - accuracy: 0.9717 - val_loss: 0.0266 - val_accuracy: 0.8100\n",
      "Epoch 233/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0075 - accuracy: 0.9717 - val_loss: 0.0265 - val_accuracy: 0.8100\n",
      "Epoch 234/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0075 - accuracy: 0.9717 - val_loss: 0.0265 - val_accuracy: 0.8100\n",
      "Epoch 235/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0074 - accuracy: 0.9717 - val_loss: 0.0264 - val_accuracy: 0.8100\n",
      "Epoch 236/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0074 - accuracy: 0.9717 - val_loss: 0.0264 - val_accuracy: 0.8100\n",
      "Epoch 237/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0073 - accuracy: 0.9717 - val_loss: 0.0264 - val_accuracy: 0.8100\n",
      "Epoch 238/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0073 - accuracy: 0.9717 - val_loss: 0.0264 - val_accuracy: 0.8100\n",
      "Epoch 239/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0072 - accuracy: 0.9717 - val_loss: 0.0264 - val_accuracy: 0.8100\n",
      "Epoch 240/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0072 - accuracy: 0.9717 - val_loss: 0.0264 - val_accuracy: 0.8100\n",
      "Training date and time : \n",
      "2020-04-09 21:06:57\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/240\n",
      "600/600 [==============================] - 0s 650us/sample - loss: 0.0901 - accuracy: 0.1533 - val_loss: 0.0899 - val_accuracy: 0.1900\n",
      "Epoch 2/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0897 - accuracy: 0.1700 - val_loss: 0.0896 - val_accuracy: 0.1900\n",
      "Epoch 3/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0893 - accuracy: 0.1867 - val_loss: 0.0893 - val_accuracy: 0.2000\n",
      "Epoch 4/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0890 - accuracy: 0.2150 - val_loss: 0.0890 - val_accuracy: 0.1900\n",
      "Epoch 5/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0886 - accuracy: 0.2333 - val_loss: 0.0887 - val_accuracy: 0.2100\n",
      "Epoch 6/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0882 - accuracy: 0.2633 - val_loss: 0.0884 - val_accuracy: 0.2500\n",
      "Epoch 7/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0879 - accuracy: 0.2800 - val_loss: 0.0881 - val_accuracy: 0.2500\n",
      "Epoch 8/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0875 - accuracy: 0.3050 - val_loss: 0.0878 - val_accuracy: 0.2600\n",
      "Epoch 9/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0871 - accuracy: 0.3367 - val_loss: 0.0875 - val_accuracy: 0.2800\n",
      "Epoch 10/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0867 - accuracy: 0.3600 - val_loss: 0.0872 - val_accuracy: 0.3100\n",
      "Epoch 11/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0863 - accuracy: 0.3850 - val_loss: 0.0868 - val_accuracy: 0.3000\n",
      "Epoch 12/240\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0858 - accuracy: 0.4250 - val_loss: 0.0865 - val_accuracy: 0.3400\n",
      "Epoch 13/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0854 - accuracy: 0.4450 - val_loss: 0.0861 - val_accuracy: 0.3800\n",
      "Epoch 14/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0849 - accuracy: 0.4667 - val_loss: 0.0857 - val_accuracy: 0.4200\n",
      "Epoch 15/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0844 - accuracy: 0.4900 - val_loss: 0.0852 - val_accuracy: 0.4500\n",
      "Epoch 16/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0838 - accuracy: 0.5017 - val_loss: 0.0848 - val_accuracy: 0.4400\n",
      "Epoch 17/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0832 - accuracy: 0.5283 - val_loss: 0.0843 - val_accuracy: 0.4300\n",
      "Epoch 18/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0826 - accuracy: 0.5383 - val_loss: 0.0837 - val_accuracy: 0.4300\n",
      "Epoch 19/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0819 - accuracy: 0.5483 - val_loss: 0.0831 - val_accuracy: 0.4400\n",
      "Epoch 20/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0812 - accuracy: 0.5500 - val_loss: 0.0825 - val_accuracy: 0.4400\n",
      "Epoch 21/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0804 - accuracy: 0.5567 - val_loss: 0.0819 - val_accuracy: 0.4500\n",
      "Epoch 22/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0796 - accuracy: 0.5533 - val_loss: 0.0812 - val_accuracy: 0.4400\n",
      "Epoch 23/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0787 - accuracy: 0.5533 - val_loss: 0.0805 - val_accuracy: 0.4400\n",
      "Epoch 24/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0779 - accuracy: 0.5550 - val_loss: 0.0798 - val_accuracy: 0.4300\n",
      "Epoch 25/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0770 - accuracy: 0.5617 - val_loss: 0.0791 - val_accuracy: 0.4200\n",
      "Epoch 26/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0761 - accuracy: 0.5650 - val_loss: 0.0784 - val_accuracy: 0.4300\n",
      "Epoch 27/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0752 - accuracy: 0.5717 - val_loss: 0.0777 - val_accuracy: 0.4400\n",
      "Epoch 28/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0742 - accuracy: 0.5867 - val_loss: 0.0770 - val_accuracy: 0.4400\n",
      "Epoch 29/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0733 - accuracy: 0.5883 - val_loss: 0.0762 - val_accuracy: 0.4400\n",
      "Epoch 30/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0723 - accuracy: 0.5950 - val_loss: 0.0755 - val_accuracy: 0.4500\n",
      "Epoch 31/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0713 - accuracy: 0.6050 - val_loss: 0.0747 - val_accuracy: 0.4500\n",
      "Epoch 32/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0702 - accuracy: 0.6167 - val_loss: 0.0739 - val_accuracy: 0.4500\n",
      "Epoch 33/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0692 - accuracy: 0.6267 - val_loss: 0.0732 - val_accuracy: 0.4500\n",
      "Epoch 34/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0681 - accuracy: 0.6333 - val_loss: 0.0724 - val_accuracy: 0.4700\n",
      "Epoch 35/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0670 - accuracy: 0.6417 - val_loss: 0.0716 - val_accuracy: 0.4900\n",
      "Epoch 36/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0659 - accuracy: 0.6467 - val_loss: 0.0708 - val_accuracy: 0.4900\n",
      "Epoch 37/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0648 - accuracy: 0.6533 - val_loss: 0.0700 - val_accuracy: 0.5000\n",
      "Epoch 38/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0636 - accuracy: 0.6733 - val_loss: 0.0692 - val_accuracy: 0.5100\n",
      "Epoch 39/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0625 - accuracy: 0.6833 - val_loss: 0.0684 - val_accuracy: 0.5300\n",
      "Epoch 40/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0613 - accuracy: 0.6917 - val_loss: 0.0676 - val_accuracy: 0.5300\n",
      "Epoch 41/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0601 - accuracy: 0.7033 - val_loss: 0.0668 - val_accuracy: 0.5500\n",
      "Epoch 42/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0590 - accuracy: 0.7050 - val_loss: 0.0659 - val_accuracy: 0.6000\n",
      "Epoch 43/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0578 - accuracy: 0.7133 - val_loss: 0.0651 - val_accuracy: 0.6200\n",
      "Epoch 44/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0566 - accuracy: 0.7183 - val_loss: 0.0643 - val_accuracy: 0.6400\n",
      "Epoch 45/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0554 - accuracy: 0.7217 - val_loss: 0.0635 - val_accuracy: 0.6500\n",
      "Epoch 46/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0542 - accuracy: 0.7233 - val_loss: 0.0627 - val_accuracy: 0.6500\n",
      "Epoch 47/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0530 - accuracy: 0.7317 - val_loss: 0.0619 - val_accuracy: 0.6500\n",
      "Epoch 48/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0519 - accuracy: 0.7350 - val_loss: 0.0612 - val_accuracy: 0.6500\n",
      "Epoch 49/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0507 - accuracy: 0.7417 - val_loss: 0.0604 - val_accuracy: 0.6500\n",
      "Epoch 50/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0496 - accuracy: 0.7483 - val_loss: 0.0597 - val_accuracy: 0.6600\n",
      "Epoch 51/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0484 - accuracy: 0.7517 - val_loss: 0.0590 - val_accuracy: 0.6500\n",
      "Epoch 52/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0473 - accuracy: 0.7567 - val_loss: 0.0582 - val_accuracy: 0.6500\n",
      "Epoch 53/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0463 - accuracy: 0.7567 - val_loss: 0.0575 - val_accuracy: 0.6500\n",
      "Epoch 54/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0452 - accuracy: 0.7600 - val_loss: 0.0569 - val_accuracy: 0.6500\n",
      "Epoch 55/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0442 - accuracy: 0.7700 - val_loss: 0.0562 - val_accuracy: 0.6500\n",
      "Epoch 56/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0433 - accuracy: 0.7683 - val_loss: 0.0555 - val_accuracy: 0.6500\n",
      "Epoch 57/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0423 - accuracy: 0.7733 - val_loss: 0.0549 - val_accuracy: 0.6400\n",
      "Epoch 58/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0414 - accuracy: 0.7717 - val_loss: 0.0543 - val_accuracy: 0.6300\n",
      "Epoch 59/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0406 - accuracy: 0.7733 - val_loss: 0.0536 - val_accuracy: 0.6500\n",
      "Epoch 60/240\n",
      "600/600 [==============================] - 0s 110us/sample - loss: 0.0397 - accuracy: 0.7767 - val_loss: 0.0530 - val_accuracy: 0.6400\n",
      "Epoch 61/240\n",
      "600/600 [==============================] - 0s 109us/sample - loss: 0.0390 - accuracy: 0.7800 - val_loss: 0.0524 - val_accuracy: 0.6400\n",
      "Epoch 62/240\n",
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0382 - accuracy: 0.7833 - val_loss: 0.0519 - val_accuracy: 0.6400\n",
      "Epoch 63/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0374 - accuracy: 0.7883 - val_loss: 0.0513 - val_accuracy: 0.6400\n",
      "Epoch 64/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0368 - accuracy: 0.7900 - val_loss: 0.0508 - val_accuracy: 0.6400\n",
      "Epoch 65/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0361 - accuracy: 0.7883 - val_loss: 0.0502 - val_accuracy: 0.6400\n",
      "Epoch 66/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0354 - accuracy: 0.7917 - val_loss: 0.0497 - val_accuracy: 0.6400\n",
      "Epoch 67/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0348 - accuracy: 0.7933 - val_loss: 0.0492 - val_accuracy: 0.6400\n",
      "Epoch 68/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0342 - accuracy: 0.7950 - val_loss: 0.0486 - val_accuracy: 0.6400\n",
      "Epoch 69/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0336 - accuracy: 0.8050 - val_loss: 0.0481 - val_accuracy: 0.6400\n",
      "Epoch 70/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0330 - accuracy: 0.8033 - val_loss: 0.0475 - val_accuracy: 0.6400\n",
      "Epoch 71/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0324 - accuracy: 0.8100 - val_loss: 0.0470 - val_accuracy: 0.6400\n",
      "Epoch 72/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0319 - accuracy: 0.8183 - val_loss: 0.0465 - val_accuracy: 0.6400\n",
      "Epoch 73/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0313 - accuracy: 0.8233 - val_loss: 0.0460 - val_accuracy: 0.6400\n",
      "Epoch 74/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0308 - accuracy: 0.8250 - val_loss: 0.0455 - val_accuracy: 0.6500\n",
      "Epoch 75/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0303 - accuracy: 0.8300 - val_loss: 0.0450 - val_accuracy: 0.6700\n",
      "Epoch 76/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0298 - accuracy: 0.8333 - val_loss: 0.0445 - val_accuracy: 0.6800\n",
      "Epoch 77/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0293 - accuracy: 0.8400 - val_loss: 0.0440 - val_accuracy: 0.6900\n",
      "Epoch 78/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0288 - accuracy: 0.8417 - val_loss: 0.0436 - val_accuracy: 0.6900\n",
      "Epoch 79/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0284 - accuracy: 0.8483 - val_loss: 0.0432 - val_accuracy: 0.6900\n",
      "Epoch 80/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0279 - accuracy: 0.8500 - val_loss: 0.0428 - val_accuracy: 0.7100\n",
      "Epoch 81/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0275 - accuracy: 0.8500 - val_loss: 0.0423 - val_accuracy: 0.7100\n",
      "Epoch 82/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0270 - accuracy: 0.8533 - val_loss: 0.0420 - val_accuracy: 0.7200\n",
      "Epoch 83/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0267 - accuracy: 0.8550 - val_loss: 0.0416 - val_accuracy: 0.7200\n",
      "Epoch 84/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0262 - accuracy: 0.8617 - val_loss: 0.0413 - val_accuracy: 0.7200\n",
      "Epoch 85/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0259 - accuracy: 0.8633 - val_loss: 0.0410 - val_accuracy: 0.7200\n",
      "Epoch 86/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0255 - accuracy: 0.8667 - val_loss: 0.0406 - val_accuracy: 0.7300\n",
      "Epoch 87/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0251 - accuracy: 0.8650 - val_loss: 0.0402 - val_accuracy: 0.7300\n",
      "Epoch 88/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0248 - accuracy: 0.8717 - val_loss: 0.0398 - val_accuracy: 0.7300\n",
      "Epoch 89/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0244 - accuracy: 0.8783 - val_loss: 0.0396 - val_accuracy: 0.7400\n",
      "Epoch 90/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0241 - accuracy: 0.8767 - val_loss: 0.0393 - val_accuracy: 0.7400\n",
      "Epoch 91/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0237 - accuracy: 0.8817 - val_loss: 0.0390 - val_accuracy: 0.7400\n",
      "Epoch 92/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0234 - accuracy: 0.8833 - val_loss: 0.0387 - val_accuracy: 0.7400\n",
      "Epoch 93/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0231 - accuracy: 0.8817 - val_loss: 0.0384 - val_accuracy: 0.7500\n",
      "Epoch 94/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0228 - accuracy: 0.8817 - val_loss: 0.0382 - val_accuracy: 0.7500\n",
      "Epoch 95/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0225 - accuracy: 0.8867 - val_loss: 0.0379 - val_accuracy: 0.7400\n",
      "Epoch 96/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0222 - accuracy: 0.8850 - val_loss: 0.0377 - val_accuracy: 0.7400\n",
      "Epoch 97/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0219 - accuracy: 0.8900 - val_loss: 0.0374 - val_accuracy: 0.7500\n",
      "Epoch 98/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0217 - accuracy: 0.8967 - val_loss: 0.0372 - val_accuracy: 0.7600\n",
      "Epoch 99/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0214 - accuracy: 0.8933 - val_loss: 0.0369 - val_accuracy: 0.7600\n",
      "Epoch 100/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0211 - accuracy: 0.8950 - val_loss: 0.0367 - val_accuracy: 0.7700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0209 - accuracy: 0.8950 - val_loss: 0.0364 - val_accuracy: 0.7700\n",
      "Epoch 102/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0206 - accuracy: 0.8967 - val_loss: 0.0363 - val_accuracy: 0.7600\n",
      "Epoch 103/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0204 - accuracy: 0.9000 - val_loss: 0.0361 - val_accuracy: 0.7700\n",
      "Epoch 104/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0201 - accuracy: 0.9017 - val_loss: 0.0358 - val_accuracy: 0.7700\n",
      "Epoch 105/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0199 - accuracy: 0.9033 - val_loss: 0.0356 - val_accuracy: 0.7600\n",
      "Epoch 106/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0197 - accuracy: 0.9017 - val_loss: 0.0354 - val_accuracy: 0.7600\n",
      "Epoch 107/240\n",
      "600/600 [==============================] - 0s 112us/sample - loss: 0.0194 - accuracy: 0.9033 - val_loss: 0.0352 - val_accuracy: 0.7600\n",
      "Epoch 108/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0192 - accuracy: 0.9067 - val_loss: 0.0350 - val_accuracy: 0.7600\n",
      "Epoch 109/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0190 - accuracy: 0.9050 - val_loss: 0.0348 - val_accuracy: 0.7600\n",
      "Epoch 110/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0188 - accuracy: 0.9100 - val_loss: 0.0346 - val_accuracy: 0.7600\n",
      "Epoch 111/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0186 - accuracy: 0.9117 - val_loss: 0.0345 - val_accuracy: 0.7600\n",
      "Epoch 112/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0184 - accuracy: 0.9083 - val_loss: 0.0343 - val_accuracy: 0.7700\n",
      "Epoch 113/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0182 - accuracy: 0.9067 - val_loss: 0.0342 - val_accuracy: 0.7700\n",
      "Epoch 114/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0180 - accuracy: 0.9117 - val_loss: 0.0340 - val_accuracy: 0.7700\n",
      "Epoch 115/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0178 - accuracy: 0.9100 - val_loss: 0.0338 - val_accuracy: 0.7700\n",
      "Epoch 116/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0176 - accuracy: 0.9133 - val_loss: 0.0337 - val_accuracy: 0.7700\n",
      "Epoch 117/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0174 - accuracy: 0.9133 - val_loss: 0.0336 - val_accuracy: 0.7700\n",
      "Epoch 118/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0172 - accuracy: 0.9150 - val_loss: 0.0334 - val_accuracy: 0.7700\n",
      "Epoch 119/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0171 - accuracy: 0.9167 - val_loss: 0.0332 - val_accuracy: 0.7700\n",
      "Epoch 120/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0169 - accuracy: 0.9150 - val_loss: 0.0330 - val_accuracy: 0.7700\n",
      "Epoch 121/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0167 - accuracy: 0.9217 - val_loss: 0.0329 - val_accuracy: 0.7700\n",
      "Epoch 122/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0165 - accuracy: 0.9200 - val_loss: 0.0328 - val_accuracy: 0.7700\n",
      "Epoch 123/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0164 - accuracy: 0.9233 - val_loss: 0.0326 - val_accuracy: 0.7700\n",
      "Epoch 124/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0162 - accuracy: 0.9250 - val_loss: 0.0326 - val_accuracy: 0.7700\n",
      "Epoch 125/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0160 - accuracy: 0.9217 - val_loss: 0.0324 - val_accuracy: 0.7700\n",
      "Epoch 126/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0159 - accuracy: 0.9250 - val_loss: 0.0323 - val_accuracy: 0.7700\n",
      "Epoch 127/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0157 - accuracy: 0.9250 - val_loss: 0.0322 - val_accuracy: 0.7700\n",
      "Epoch 128/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0156 - accuracy: 0.9250 - val_loss: 0.0321 - val_accuracy: 0.7800\n",
      "Epoch 129/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0154 - accuracy: 0.9250 - val_loss: 0.0319 - val_accuracy: 0.7800\n",
      "Epoch 130/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0153 - accuracy: 0.9250 - val_loss: 0.0318 - val_accuracy: 0.7800\n",
      "Epoch 131/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0151 - accuracy: 0.9250 - val_loss: 0.0316 - val_accuracy: 0.7800\n",
      "Epoch 132/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0150 - accuracy: 0.9250 - val_loss: 0.0316 - val_accuracy: 0.7800\n",
      "Epoch 133/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0148 - accuracy: 0.9250 - val_loss: 0.0315 - val_accuracy: 0.7800\n",
      "Epoch 134/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0147 - accuracy: 0.9267 - val_loss: 0.0313 - val_accuracy: 0.7800\n",
      "Epoch 135/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0146 - accuracy: 0.9267 - val_loss: 0.0313 - val_accuracy: 0.7800\n",
      "Epoch 136/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0144 - accuracy: 0.9267 - val_loss: 0.0311 - val_accuracy: 0.7800\n",
      "Epoch 137/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0143 - accuracy: 0.9267 - val_loss: 0.0310 - val_accuracy: 0.7800\n",
      "Epoch 138/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0142 - accuracy: 0.9267 - val_loss: 0.0309 - val_accuracy: 0.7800\n",
      "Epoch 139/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0140 - accuracy: 0.9283 - val_loss: 0.0308 - val_accuracy: 0.7800\n",
      "Epoch 140/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0139 - accuracy: 0.9300 - val_loss: 0.0308 - val_accuracy: 0.7800\n",
      "Epoch 141/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0138 - accuracy: 0.9350 - val_loss: 0.0307 - val_accuracy: 0.7800\n",
      "Epoch 142/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0137 - accuracy: 0.9333 - val_loss: 0.0306 - val_accuracy: 0.7800\n",
      "Epoch 143/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0135 - accuracy: 0.9333 - val_loss: 0.0305 - val_accuracy: 0.7800\n",
      "Epoch 144/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0134 - accuracy: 0.9350 - val_loss: 0.0304 - val_accuracy: 0.7800\n",
      "Epoch 145/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0133 - accuracy: 0.9350 - val_loss: 0.0303 - val_accuracy: 0.7800\n",
      "Epoch 146/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0132 - accuracy: 0.9350 - val_loss: 0.0302 - val_accuracy: 0.7800\n",
      "Epoch 147/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0131 - accuracy: 0.9367 - val_loss: 0.0301 - val_accuracy: 0.7800\n",
      "Epoch 148/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0130 - accuracy: 0.9367 - val_loss: 0.0300 - val_accuracy: 0.7800\n",
      "Epoch 149/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0128 - accuracy: 0.9383 - val_loss: 0.0300 - val_accuracy: 0.7800\n",
      "Epoch 150/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0127 - accuracy: 0.9383 - val_loss: 0.0298 - val_accuracy: 0.7800\n",
      "Epoch 151/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0126 - accuracy: 0.9383 - val_loss: 0.0297 - val_accuracy: 0.7900\n",
      "Epoch 152/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0125 - accuracy: 0.9383 - val_loss: 0.0296 - val_accuracy: 0.7800\n",
      "Epoch 153/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0124 - accuracy: 0.9417 - val_loss: 0.0296 - val_accuracy: 0.7800\n",
      "Epoch 154/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0123 - accuracy: 0.9400 - val_loss: 0.0295 - val_accuracy: 0.7800\n",
      "Epoch 155/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0122 - accuracy: 0.9400 - val_loss: 0.0294 - val_accuracy: 0.7800\n",
      "Epoch 156/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0121 - accuracy: 0.9433 - val_loss: 0.0294 - val_accuracy: 0.7800\n",
      "Epoch 157/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0120 - accuracy: 0.9433 - val_loss: 0.0293 - val_accuracy: 0.7800\n",
      "Epoch 158/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0119 - accuracy: 0.9417 - val_loss: 0.0292 - val_accuracy: 0.7800\n",
      "Epoch 159/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0118 - accuracy: 0.9450 - val_loss: 0.0291 - val_accuracy: 0.7900\n",
      "Epoch 160/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0117 - accuracy: 0.9450 - val_loss: 0.0291 - val_accuracy: 0.7900\n",
      "Epoch 161/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0116 - accuracy: 0.9467 - val_loss: 0.0291 - val_accuracy: 0.7900\n",
      "Epoch 162/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0115 - accuracy: 0.9467 - val_loss: 0.0290 - val_accuracy: 0.7900\n",
      "Epoch 163/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0114 - accuracy: 0.9467 - val_loss: 0.0289 - val_accuracy: 0.7900\n",
      "Epoch 164/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0113 - accuracy: 0.9483 - val_loss: 0.0288 - val_accuracy: 0.7900\n",
      "Epoch 165/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0112 - accuracy: 0.9483 - val_loss: 0.0288 - val_accuracy: 0.7900\n",
      "Epoch 166/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0111 - accuracy: 0.9467 - val_loss: 0.0287 - val_accuracy: 0.7900\n",
      "Epoch 167/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0110 - accuracy: 0.9517 - val_loss: 0.0286 - val_accuracy: 0.7900\n",
      "Epoch 168/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0109 - accuracy: 0.9517 - val_loss: 0.0286 - val_accuracy: 0.7900\n",
      "Epoch 169/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0108 - accuracy: 0.9533 - val_loss: 0.0286 - val_accuracy: 0.7900\n",
      "Epoch 170/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0108 - accuracy: 0.9550 - val_loss: 0.0285 - val_accuracy: 0.7900\n",
      "Epoch 171/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0107 - accuracy: 0.9567 - val_loss: 0.0284 - val_accuracy: 0.7900\n",
      "Epoch 172/240\n",
      "600/600 [==============================] - 0s 111us/sample - loss: 0.0106 - accuracy: 0.9583 - val_loss: 0.0284 - val_accuracy: 0.7900\n",
      "Epoch 173/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0105 - accuracy: 0.9583 - val_loss: 0.0283 - val_accuracy: 0.7900\n",
      "Epoch 174/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0105 - accuracy: 0.9583 - val_loss: 0.0282 - val_accuracy: 0.7900\n",
      "Epoch 175/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0104 - accuracy: 0.9567 - val_loss: 0.0282 - val_accuracy: 0.7900\n",
      "Epoch 176/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0103 - accuracy: 0.9583 - val_loss: 0.0281 - val_accuracy: 0.7900\n",
      "Epoch 177/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0102 - accuracy: 0.9583 - val_loss: 0.0282 - val_accuracy: 0.8000\n",
      "Epoch 178/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0101 - accuracy: 0.9583 - val_loss: 0.0281 - val_accuracy: 0.7900\n",
      "Epoch 179/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0100 - accuracy: 0.9600 - val_loss: 0.0281 - val_accuracy: 0.8000\n",
      "Epoch 180/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0100 - accuracy: 0.9600 - val_loss: 0.0279 - val_accuracy: 0.7900\n",
      "Epoch 181/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0099 - accuracy: 0.9600 - val_loss: 0.0279 - val_accuracy: 0.7900\n",
      "Epoch 182/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0098 - accuracy: 0.9600 - val_loss: 0.0279 - val_accuracy: 0.8000\n",
      "Epoch 183/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0097 - accuracy: 0.9600 - val_loss: 0.0278 - val_accuracy: 0.7900\n",
      "Epoch 184/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0097 - accuracy: 0.9600 - val_loss: 0.0277 - val_accuracy: 0.8000\n",
      "Epoch 185/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0096 - accuracy: 0.9617 - val_loss: 0.0277 - val_accuracy: 0.8000\n",
      "Epoch 186/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0095 - accuracy: 0.9617 - val_loss: 0.0278 - val_accuracy: 0.8000\n",
      "Epoch 187/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0095 - accuracy: 0.9600 - val_loss: 0.0277 - val_accuracy: 0.8000\n",
      "Epoch 188/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0094 - accuracy: 0.9650 - val_loss: 0.0277 - val_accuracy: 0.8000\n",
      "Epoch 189/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0093 - accuracy: 0.9617 - val_loss: 0.0276 - val_accuracy: 0.8000\n",
      "Epoch 190/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0092 - accuracy: 0.9617 - val_loss: 0.0276 - val_accuracy: 0.8000\n",
      "Epoch 191/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0092 - accuracy: 0.9617 - val_loss: 0.0275 - val_accuracy: 0.8000\n",
      "Epoch 192/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0091 - accuracy: 0.9650 - val_loss: 0.0275 - val_accuracy: 0.8100\n",
      "Epoch 193/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0090 - accuracy: 0.9633 - val_loss: 0.0274 - val_accuracy: 0.8100\n",
      "Epoch 194/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0090 - accuracy: 0.9650 - val_loss: 0.0273 - val_accuracy: 0.8100\n",
      "Epoch 195/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0089 - accuracy: 0.9650 - val_loss: 0.0273 - val_accuracy: 0.8100\n",
      "Epoch 196/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0088 - accuracy: 0.9650 - val_loss: 0.0273 - val_accuracy: 0.8000\n",
      "Epoch 197/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0088 - accuracy: 0.9650 - val_loss: 0.0273 - val_accuracy: 0.8000\n",
      "Epoch 198/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0087 - accuracy: 0.9650 - val_loss: 0.0273 - val_accuracy: 0.8000\n",
      "Epoch 199/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0087 - accuracy: 0.9650 - val_loss: 0.0272 - val_accuracy: 0.8000\n",
      "Epoch 200/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0086 - accuracy: 0.9650 - val_loss: 0.0272 - val_accuracy: 0.8100\n",
      "Epoch 201/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0085 - accuracy: 0.9650 - val_loss: 0.0271 - val_accuracy: 0.8100\n",
      "Epoch 202/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0085 - accuracy: 0.9650 - val_loss: 0.0271 - val_accuracy: 0.8200\n",
      "Epoch 203/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0084 - accuracy: 0.9650 - val_loss: 0.0270 - val_accuracy: 0.8200\n",
      "Epoch 204/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0083 - accuracy: 0.9650 - val_loss: 0.0270 - val_accuracy: 0.8100\n",
      "Epoch 205/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0083 - accuracy: 0.9667 - val_loss: 0.0271 - val_accuracy: 0.8000\n",
      "Epoch 206/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0082 - accuracy: 0.9667 - val_loss: 0.0270 - val_accuracy: 0.8100\n",
      "Epoch 207/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0082 - accuracy: 0.9650 - val_loss: 0.0269 - val_accuracy: 0.8100\n",
      "Epoch 208/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0081 - accuracy: 0.9667 - val_loss: 0.0269 - val_accuracy: 0.8100\n",
      "Epoch 209/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0081 - accuracy: 0.9667 - val_loss: 0.0269 - val_accuracy: 0.8100\n",
      "Epoch 210/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0080 - accuracy: 0.9683 - val_loss: 0.0269 - val_accuracy: 0.8100\n",
      "Epoch 211/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0079 - accuracy: 0.9683 - val_loss: 0.0268 - val_accuracy: 0.8100\n",
      "Epoch 212/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0079 - accuracy: 0.9683 - val_loss: 0.0268 - val_accuracy: 0.8100\n",
      "Epoch 213/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0078 - accuracy: 0.9700 - val_loss: 0.0268 - val_accuracy: 0.8100\n",
      "Epoch 214/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0078 - accuracy: 0.9700 - val_loss: 0.0268 - val_accuracy: 0.8100\n",
      "Epoch 215/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0077 - accuracy: 0.9683 - val_loss: 0.0267 - val_accuracy: 0.8100\n",
      "Epoch 216/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0077 - accuracy: 0.9700 - val_loss: 0.0267 - val_accuracy: 0.8100\n",
      "Epoch 217/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0076 - accuracy: 0.9700 - val_loss: 0.0267 - val_accuracy: 0.8100\n",
      "Epoch 218/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0076 - accuracy: 0.9700 - val_loss: 0.0267 - val_accuracy: 0.8100\n",
      "Epoch 219/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0075 - accuracy: 0.9700 - val_loss: 0.0267 - val_accuracy: 0.8100\n",
      "Epoch 220/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0075 - accuracy: 0.9700 - val_loss: 0.0267 - val_accuracy: 0.8100\n",
      "Epoch 221/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0074 - accuracy: 0.9700 - val_loss: 0.0266 - val_accuracy: 0.8100\n",
      "Epoch 222/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0074 - accuracy: 0.9700 - val_loss: 0.0266 - val_accuracy: 0.8100\n",
      "Epoch 223/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0073 - accuracy: 0.9700 - val_loss: 0.0265 - val_accuracy: 0.8100\n",
      "Epoch 224/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0073 - accuracy: 0.9700 - val_loss: 0.0265 - val_accuracy: 0.8100\n",
      "Epoch 225/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0073 - accuracy: 0.9700 - val_loss: 0.0265 - val_accuracy: 0.8100\n",
      "Epoch 226/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0072 - accuracy: 0.9700 - val_loss: 0.0265 - val_accuracy: 0.8100\n",
      "Epoch 227/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0072 - accuracy: 0.9717 - val_loss: 0.0265 - val_accuracy: 0.8100\n",
      "Epoch 228/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0071 - accuracy: 0.9717 - val_loss: 0.0264 - val_accuracy: 0.8100\n",
      "Epoch 229/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0071 - accuracy: 0.9717 - val_loss: 0.0264 - val_accuracy: 0.8100\n",
      "Epoch 230/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0070 - accuracy: 0.9717 - val_loss: 0.0264 - val_accuracy: 0.8100\n",
      "Epoch 231/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0070 - accuracy: 0.9717 - val_loss: 0.0264 - val_accuracy: 0.8100\n",
      "Epoch 232/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0069 - accuracy: 0.9733 - val_loss: 0.0264 - val_accuracy: 0.8100\n",
      "Epoch 233/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0069 - accuracy: 0.9717 - val_loss: 0.0263 - val_accuracy: 0.8100\n",
      "Epoch 234/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0069 - accuracy: 0.9717 - val_loss: 0.0263 - val_accuracy: 0.8100\n",
      "Epoch 235/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0068 - accuracy: 0.9717 - val_loss: 0.0263 - val_accuracy: 0.8100\n",
      "Epoch 236/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0068 - accuracy: 0.9733 - val_loss: 0.0263 - val_accuracy: 0.8100\n",
      "Epoch 237/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0067 - accuracy: 0.9733 - val_loss: 0.0263 - val_accuracy: 0.8100\n",
      "Epoch 238/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0067 - accuracy: 0.9717 - val_loss: 0.0263 - val_accuracy: 0.8100\n",
      "Epoch 239/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0066 - accuracy: 0.9733 - val_loss: 0.0262 - val_accuracy: 0.8100\n",
      "Epoch 240/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0066 - accuracy: 0.9733 - val_loss: 0.0262 - val_accuracy: 0.8100\n",
      "Training date and time : \n",
      "2020-04-09 21:07:13\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/240\n",
      "600/600 [==============================] - 0s 659us/sample - loss: 0.0902 - accuracy: 0.1450 - val_loss: 0.0899 - val_accuracy: 0.2000\n",
      "Epoch 2/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0897 - accuracy: 0.1650 - val_loss: 0.0895 - val_accuracy: 0.2000\n",
      "Epoch 3/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0892 - accuracy: 0.1817 - val_loss: 0.0892 - val_accuracy: 0.1900\n",
      "Epoch 4/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0888 - accuracy: 0.2133 - val_loss: 0.0888 - val_accuracy: 0.2400\n",
      "Epoch 5/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0883 - accuracy: 0.2317 - val_loss: 0.0885 - val_accuracy: 0.2400\n",
      "Epoch 6/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0879 - accuracy: 0.2717 - val_loss: 0.0881 - val_accuracy: 0.2600\n",
      "Epoch 7/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0874 - accuracy: 0.3017 - val_loss: 0.0877 - val_accuracy: 0.2700\n",
      "Epoch 8/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0870 - accuracy: 0.3133 - val_loss: 0.0874 - val_accuracy: 0.3000\n",
      "Epoch 9/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0865 - accuracy: 0.3417 - val_loss: 0.0870 - val_accuracy: 0.3200\n",
      "Epoch 10/240\n",
      "600/600 [==============================] - 0s 88us/sample - loss: 0.0859 - accuracy: 0.3733 - val_loss: 0.0865 - val_accuracy: 0.3300\n",
      "Epoch 11/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0854 - accuracy: 0.4183 - val_loss: 0.0861 - val_accuracy: 0.3800\n",
      "Epoch 12/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0848 - accuracy: 0.4450 - val_loss: 0.0856 - val_accuracy: 0.4000\n",
      "Epoch 13/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0842 - accuracy: 0.4633 - val_loss: 0.0851 - val_accuracy: 0.4200\n",
      "Epoch 14/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0835 - accuracy: 0.4850 - val_loss: 0.0845 - val_accuracy: 0.4100\n",
      "Epoch 15/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0828 - accuracy: 0.5100 - val_loss: 0.0839 - val_accuracy: 0.4300\n",
      "Epoch 16/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0820 - accuracy: 0.5267 - val_loss: 0.0833 - val_accuracy: 0.4300\n",
      "Epoch 17/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0812 - accuracy: 0.5467 - val_loss: 0.0826 - val_accuracy: 0.4300\n",
      "Epoch 18/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0803 - accuracy: 0.5483 - val_loss: 0.0819 - val_accuracy: 0.4300\n",
      "Epoch 19/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0794 - accuracy: 0.5517 - val_loss: 0.0811 - val_accuracy: 0.4400\n",
      "Epoch 20/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0784 - accuracy: 0.5633 - val_loss: 0.0803 - val_accuracy: 0.4300\n",
      "Epoch 21/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0774 - accuracy: 0.5683 - val_loss: 0.0795 - val_accuracy: 0.4300\n",
      "Epoch 22/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0764 - accuracy: 0.5683 - val_loss: 0.0787 - val_accuracy: 0.4300\n",
      "Epoch 23/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0754 - accuracy: 0.5733 - val_loss: 0.0779 - val_accuracy: 0.4300\n",
      "Epoch 24/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0743 - accuracy: 0.5850 - val_loss: 0.0771 - val_accuracy: 0.4300\n",
      "Epoch 25/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0733 - accuracy: 0.5933 - val_loss: 0.0763 - val_accuracy: 0.4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0722 - accuracy: 0.5983 - val_loss: 0.0755 - val_accuracy: 0.4500\n",
      "Epoch 27/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0710 - accuracy: 0.6167 - val_loss: 0.0746 - val_accuracy: 0.4500\n",
      "Epoch 28/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0699 - accuracy: 0.6217 - val_loss: 0.0738 - val_accuracy: 0.4500\n",
      "Epoch 29/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0687 - accuracy: 0.6333 - val_loss: 0.0729 - val_accuracy: 0.4600\n",
      "Epoch 30/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0675 - accuracy: 0.6383 - val_loss: 0.0720 - val_accuracy: 0.4600\n",
      "Epoch 31/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0663 - accuracy: 0.6450 - val_loss: 0.0712 - val_accuracy: 0.5000\n",
      "Epoch 32/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0651 - accuracy: 0.6633 - val_loss: 0.0703 - val_accuracy: 0.5000\n",
      "Epoch 33/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0638 - accuracy: 0.6783 - val_loss: 0.0694 - val_accuracy: 0.5000\n",
      "Epoch 34/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0626 - accuracy: 0.6833 - val_loss: 0.0686 - val_accuracy: 0.5100\n",
      "Epoch 35/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0613 - accuracy: 0.6950 - val_loss: 0.0677 - val_accuracy: 0.5300\n",
      "Epoch 36/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0600 - accuracy: 0.7000 - val_loss: 0.0668 - val_accuracy: 0.5400\n",
      "Epoch 37/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0588 - accuracy: 0.7117 - val_loss: 0.0660 - val_accuracy: 0.5700\n",
      "Epoch 38/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0575 - accuracy: 0.7200 - val_loss: 0.0651 - val_accuracy: 0.5800\n",
      "Epoch 39/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0562 - accuracy: 0.7150 - val_loss: 0.0642 - val_accuracy: 0.6100\n",
      "Epoch 40/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0550 - accuracy: 0.7233 - val_loss: 0.0634 - val_accuracy: 0.6400\n",
      "Epoch 41/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0537 - accuracy: 0.7317 - val_loss: 0.0626 - val_accuracy: 0.6400\n",
      "Epoch 42/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0524 - accuracy: 0.7333 - val_loss: 0.0618 - val_accuracy: 0.6500\n",
      "Epoch 43/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0512 - accuracy: 0.7450 - val_loss: 0.0610 - val_accuracy: 0.6600\n",
      "Epoch 44/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0500 - accuracy: 0.7450 - val_loss: 0.0602 - val_accuracy: 0.6600\n",
      "Epoch 45/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0488 - accuracy: 0.7517 - val_loss: 0.0594 - val_accuracy: 0.6500\n",
      "Epoch 46/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0477 - accuracy: 0.7567 - val_loss: 0.0587 - val_accuracy: 0.6400\n",
      "Epoch 47/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0465 - accuracy: 0.7583 - val_loss: 0.0580 - val_accuracy: 0.6400\n",
      "Epoch 48/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0455 - accuracy: 0.7583 - val_loss: 0.0573 - val_accuracy: 0.6400\n",
      "Epoch 49/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0444 - accuracy: 0.7650 - val_loss: 0.0566 - val_accuracy: 0.6400\n",
      "Epoch 50/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0434 - accuracy: 0.7650 - val_loss: 0.0559 - val_accuracy: 0.6500\n",
      "Epoch 51/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0424 - accuracy: 0.7667 - val_loss: 0.0552 - val_accuracy: 0.6500\n",
      "Epoch 52/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0415 - accuracy: 0.7700 - val_loss: 0.0546 - val_accuracy: 0.6500\n",
      "Epoch 53/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0407 - accuracy: 0.7733 - val_loss: 0.0540 - val_accuracy: 0.6400\n",
      "Epoch 54/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0398 - accuracy: 0.7733 - val_loss: 0.0534 - val_accuracy: 0.6400\n",
      "Epoch 55/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0390 - accuracy: 0.7783 - val_loss: 0.0527 - val_accuracy: 0.6400\n",
      "Epoch 56/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0382 - accuracy: 0.7767 - val_loss: 0.0522 - val_accuracy: 0.6400\n",
      "Epoch 57/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0375 - accuracy: 0.7783 - val_loss: 0.0516 - val_accuracy: 0.6400\n",
      "Epoch 58/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0368 - accuracy: 0.7833 - val_loss: 0.0510 - val_accuracy: 0.6400\n",
      "Epoch 59/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0361 - accuracy: 0.7883 - val_loss: 0.0505 - val_accuracy: 0.6400\n",
      "Epoch 60/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0354 - accuracy: 0.7900 - val_loss: 0.0499 - val_accuracy: 0.6400\n",
      "Epoch 61/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0348 - accuracy: 0.7900 - val_loss: 0.0494 - val_accuracy: 0.6400\n",
      "Epoch 62/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0342 - accuracy: 0.7950 - val_loss: 0.0488 - val_accuracy: 0.6400\n",
      "Epoch 63/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0336 - accuracy: 0.8000 - val_loss: 0.0483 - val_accuracy: 0.6400\n",
      "Epoch 64/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0330 - accuracy: 0.8017 - val_loss: 0.0477 - val_accuracy: 0.6400\n",
      "Epoch 65/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0324 - accuracy: 0.8017 - val_loss: 0.0471 - val_accuracy: 0.6400\n",
      "Epoch 66/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0318 - accuracy: 0.8067 - val_loss: 0.0466 - val_accuracy: 0.6400\n",
      "Epoch 67/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0313 - accuracy: 0.8167 - val_loss: 0.0461 - val_accuracy: 0.6500\n",
      "Epoch 68/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0308 - accuracy: 0.8233 - val_loss: 0.0456 - val_accuracy: 0.6500\n",
      "Epoch 69/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0302 - accuracy: 0.8283 - val_loss: 0.0450 - val_accuracy: 0.6600\n",
      "Epoch 70/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0297 - accuracy: 0.8300 - val_loss: 0.0444 - val_accuracy: 0.6800\n",
      "Epoch 71/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0292 - accuracy: 0.8417 - val_loss: 0.0440 - val_accuracy: 0.6800\n",
      "Epoch 72/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0287 - accuracy: 0.8417 - val_loss: 0.0435 - val_accuracy: 0.7100\n",
      "Epoch 73/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0282 - accuracy: 0.8467 - val_loss: 0.0431 - val_accuracy: 0.7100\n",
      "Epoch 74/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0278 - accuracy: 0.8500 - val_loss: 0.0426 - val_accuracy: 0.7200\n",
      "Epoch 75/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0273 - accuracy: 0.8550 - val_loss: 0.0422 - val_accuracy: 0.7200\n",
      "Epoch 76/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0269 - accuracy: 0.8567 - val_loss: 0.0417 - val_accuracy: 0.7300\n",
      "Epoch 77/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0264 - accuracy: 0.8567 - val_loss: 0.0413 - val_accuracy: 0.7200\n",
      "Epoch 78/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0260 - accuracy: 0.8583 - val_loss: 0.0410 - val_accuracy: 0.7200\n",
      "Epoch 79/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0257 - accuracy: 0.8633 - val_loss: 0.0407 - val_accuracy: 0.7200\n",
      "Epoch 80/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0252 - accuracy: 0.8650 - val_loss: 0.0403 - val_accuracy: 0.7200\n",
      "Epoch 81/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0248 - accuracy: 0.8667 - val_loss: 0.0399 - val_accuracy: 0.7300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0245 - accuracy: 0.8750 - val_loss: 0.0396 - val_accuracy: 0.7300\n",
      "Epoch 83/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0242 - accuracy: 0.8750 - val_loss: 0.0393 - val_accuracy: 0.7300\n",
      "Epoch 84/240\n",
      "600/600 [==============================] - 0s 89us/sample - loss: 0.0238 - accuracy: 0.8750 - val_loss: 0.0390 - val_accuracy: 0.7300\n",
      "Epoch 85/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0234 - accuracy: 0.8767 - val_loss: 0.0387 - val_accuracy: 0.7400\n",
      "Epoch 86/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0231 - accuracy: 0.8783 - val_loss: 0.0384 - val_accuracy: 0.7400\n",
      "Epoch 87/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0228 - accuracy: 0.8800 - val_loss: 0.0381 - val_accuracy: 0.7400\n",
      "Epoch 88/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0225 - accuracy: 0.8800 - val_loss: 0.0378 - val_accuracy: 0.7400\n",
      "Epoch 89/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0222 - accuracy: 0.8850 - val_loss: 0.0375 - val_accuracy: 0.7400\n",
      "Epoch 90/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0219 - accuracy: 0.8817 - val_loss: 0.0373 - val_accuracy: 0.7400\n",
      "Epoch 91/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0216 - accuracy: 0.8883 - val_loss: 0.0370 - val_accuracy: 0.7400\n",
      "Epoch 92/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0213 - accuracy: 0.8900 - val_loss: 0.0368 - val_accuracy: 0.7500\n",
      "Epoch 93/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0210 - accuracy: 0.8883 - val_loss: 0.0366 - val_accuracy: 0.7500\n",
      "Epoch 94/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0208 - accuracy: 0.8933 - val_loss: 0.0364 - val_accuracy: 0.7500\n",
      "Epoch 95/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0205 - accuracy: 0.8917 - val_loss: 0.0362 - val_accuracy: 0.7600\n",
      "Epoch 96/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0203 - accuracy: 0.8900 - val_loss: 0.0359 - val_accuracy: 0.7500\n",
      "Epoch 97/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0200 - accuracy: 0.8983 - val_loss: 0.0358 - val_accuracy: 0.7600\n",
      "Epoch 98/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0198 - accuracy: 0.9050 - val_loss: 0.0355 - val_accuracy: 0.7600\n",
      "Epoch 99/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0195 - accuracy: 0.9033 - val_loss: 0.0353 - val_accuracy: 0.7600\n",
      "Epoch 100/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0193 - accuracy: 0.9067 - val_loss: 0.0351 - val_accuracy: 0.7600\n",
      "Epoch 101/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0191 - accuracy: 0.9033 - val_loss: 0.0349 - val_accuracy: 0.7700\n",
      "Epoch 102/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0188 - accuracy: 0.9083 - val_loss: 0.0348 - val_accuracy: 0.7700\n",
      "Epoch 103/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0186 - accuracy: 0.9083 - val_loss: 0.0346 - val_accuracy: 0.7800\n",
      "Epoch 104/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0184 - accuracy: 0.9083 - val_loss: 0.0344 - val_accuracy: 0.7600\n",
      "Epoch 105/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0182 - accuracy: 0.9117 - val_loss: 0.0341 - val_accuracy: 0.7600\n",
      "Epoch 106/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0180 - accuracy: 0.9100 - val_loss: 0.0340 - val_accuracy: 0.7700\n",
      "Epoch 107/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0178 - accuracy: 0.9117 - val_loss: 0.0339 - val_accuracy: 0.7700\n",
      "Epoch 108/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0176 - accuracy: 0.9117 - val_loss: 0.0337 - val_accuracy: 0.7700\n",
      "Epoch 109/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0174 - accuracy: 0.9150 - val_loss: 0.0335 - val_accuracy: 0.7700\n",
      "Epoch 110/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0172 - accuracy: 0.9167 - val_loss: 0.0333 - val_accuracy: 0.7700\n",
      "Epoch 111/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0170 - accuracy: 0.9150 - val_loss: 0.0332 - val_accuracy: 0.7700\n",
      "Epoch 112/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0168 - accuracy: 0.9183 - val_loss: 0.0330 - val_accuracy: 0.7700\n",
      "Epoch 113/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0166 - accuracy: 0.9200 - val_loss: 0.0329 - val_accuracy: 0.7800\n",
      "Epoch 114/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0164 - accuracy: 0.9200 - val_loss: 0.0328 - val_accuracy: 0.7700\n",
      "Epoch 115/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0163 - accuracy: 0.9200 - val_loss: 0.0326 - val_accuracy: 0.7700\n",
      "Epoch 116/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0161 - accuracy: 0.9233 - val_loss: 0.0325 - val_accuracy: 0.7700\n",
      "Epoch 117/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0160 - accuracy: 0.9233 - val_loss: 0.0324 - val_accuracy: 0.7700\n",
      "Epoch 118/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0158 - accuracy: 0.9250 - val_loss: 0.0323 - val_accuracy: 0.7700\n",
      "Epoch 119/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0156 - accuracy: 0.9250 - val_loss: 0.0321 - val_accuracy: 0.7700\n",
      "Epoch 120/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0155 - accuracy: 0.9267 - val_loss: 0.0320 - val_accuracy: 0.7700\n",
      "Epoch 121/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0153 - accuracy: 0.9267 - val_loss: 0.0318 - val_accuracy: 0.7700\n",
      "Epoch 122/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0151 - accuracy: 0.9267 - val_loss: 0.0317 - val_accuracy: 0.7800\n",
      "Epoch 123/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0150 - accuracy: 0.9267 - val_loss: 0.0316 - val_accuracy: 0.7800\n",
      "Epoch 124/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0148 - accuracy: 0.9267 - val_loss: 0.0315 - val_accuracy: 0.7800\n",
      "Epoch 125/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0147 - accuracy: 0.9267 - val_loss: 0.0314 - val_accuracy: 0.7800\n",
      "Epoch 126/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0146 - accuracy: 0.9267 - val_loss: 0.0313 - val_accuracy: 0.7800\n",
      "Epoch 127/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0144 - accuracy: 0.9267 - val_loss: 0.0312 - val_accuracy: 0.7800\n",
      "Epoch 128/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0143 - accuracy: 0.9283 - val_loss: 0.0311 - val_accuracy: 0.7800\n",
      "Epoch 129/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0141 - accuracy: 0.9283 - val_loss: 0.0310 - val_accuracy: 0.7800\n",
      "Epoch 130/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0140 - accuracy: 0.9283 - val_loss: 0.0309 - val_accuracy: 0.7800\n",
      "Epoch 131/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0139 - accuracy: 0.9283 - val_loss: 0.0307 - val_accuracy: 0.7800\n",
      "Epoch 132/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0137 - accuracy: 0.9317 - val_loss: 0.0307 - val_accuracy: 0.7800\n",
      "Epoch 133/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0136 - accuracy: 0.9333 - val_loss: 0.0306 - val_accuracy: 0.7800\n",
      "Epoch 134/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0135 - accuracy: 0.9350 - val_loss: 0.0305 - val_accuracy: 0.7800\n",
      "Epoch 135/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0134 - accuracy: 0.9333 - val_loss: 0.0304 - val_accuracy: 0.7800\n",
      "Epoch 136/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0132 - accuracy: 0.9350 - val_loss: 0.0303 - val_accuracy: 0.7800\n",
      "Epoch 137/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0131 - accuracy: 0.9367 - val_loss: 0.0302 - val_accuracy: 0.7800\n",
      "Epoch 138/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0130 - accuracy: 0.9350 - val_loss: 0.0301 - val_accuracy: 0.7800\n",
      "Epoch 139/240\n",
      "600/600 [==============================] - 0s 102us/sample - loss: 0.0129 - accuracy: 0.9350 - val_loss: 0.0300 - val_accuracy: 0.7800\n",
      "Epoch 140/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0128 - accuracy: 0.9367 - val_loss: 0.0301 - val_accuracy: 0.7800\n",
      "Epoch 141/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0126 - accuracy: 0.9367 - val_loss: 0.0300 - val_accuracy: 0.7800\n",
      "Epoch 142/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0125 - accuracy: 0.9367 - val_loss: 0.0299 - val_accuracy: 0.7800\n",
      "Epoch 143/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0124 - accuracy: 0.9367 - val_loss: 0.0298 - val_accuracy: 0.7800\n",
      "Epoch 144/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0123 - accuracy: 0.9367 - val_loss: 0.0297 - val_accuracy: 0.7800\n",
      "Epoch 145/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0122 - accuracy: 0.9383 - val_loss: 0.0296 - val_accuracy: 0.7800\n",
      "Epoch 146/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0121 - accuracy: 0.9400 - val_loss: 0.0296 - val_accuracy: 0.7800\n",
      "Epoch 147/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0120 - accuracy: 0.9400 - val_loss: 0.0295 - val_accuracy: 0.7800\n",
      "Epoch 148/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0119 - accuracy: 0.9417 - val_loss: 0.0293 - val_accuracy: 0.7800\n",
      "Epoch 149/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0118 - accuracy: 0.9450 - val_loss: 0.0293 - val_accuracy: 0.7800\n",
      "Epoch 150/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0117 - accuracy: 0.9450 - val_loss: 0.0292 - val_accuracy: 0.7800\n",
      "Epoch 151/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0116 - accuracy: 0.9450 - val_loss: 0.0291 - val_accuracy: 0.7800\n",
      "Epoch 152/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0115 - accuracy: 0.9450 - val_loss: 0.0290 - val_accuracy: 0.7800\n",
      "Epoch 153/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0114 - accuracy: 0.9500 - val_loss: 0.0290 - val_accuracy: 0.7800\n",
      "Epoch 154/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0113 - accuracy: 0.9483 - val_loss: 0.0289 - val_accuracy: 0.7800\n",
      "Epoch 155/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0112 - accuracy: 0.9500 - val_loss: 0.0289 - val_accuracy: 0.7800\n",
      "Epoch 156/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0111 - accuracy: 0.9500 - val_loss: 0.0288 - val_accuracy: 0.7800\n",
      "Epoch 157/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0110 - accuracy: 0.9517 - val_loss: 0.0287 - val_accuracy: 0.7800\n",
      "Epoch 158/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0109 - accuracy: 0.9517 - val_loss: 0.0287 - val_accuracy: 0.7800\n",
      "Epoch 159/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0108 - accuracy: 0.9533 - val_loss: 0.0286 - val_accuracy: 0.7800\n",
      "Epoch 160/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0107 - accuracy: 0.9533 - val_loss: 0.0286 - val_accuracy: 0.7800\n",
      "Epoch 161/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0106 - accuracy: 0.9517 - val_loss: 0.0286 - val_accuracy: 0.7900\n",
      "Epoch 162/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0105 - accuracy: 0.9550 - val_loss: 0.0285 - val_accuracy: 0.7900\n",
      "Epoch 163/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0105 - accuracy: 0.9550 - val_loss: 0.0284 - val_accuracy: 0.7800\n",
      "Epoch 164/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0104 - accuracy: 0.9567 - val_loss: 0.0283 - val_accuracy: 0.7800\n",
      "Epoch 165/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0103 - accuracy: 0.9550 - val_loss: 0.0283 - val_accuracy: 0.7900\n",
      "Epoch 166/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0102 - accuracy: 0.9583 - val_loss: 0.0283 - val_accuracy: 0.7900\n",
      "Epoch 167/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0101 - accuracy: 0.9567 - val_loss: 0.0282 - val_accuracy: 0.7800\n",
      "Epoch 168/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0100 - accuracy: 0.9583 - val_loss: 0.0281 - val_accuracy: 0.7900\n",
      "Epoch 169/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0100 - accuracy: 0.9583 - val_loss: 0.0281 - val_accuracy: 0.7900\n",
      "Epoch 170/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0099 - accuracy: 0.9583 - val_loss: 0.0281 - val_accuracy: 0.7900\n",
      "Epoch 171/240\n",
      "600/600 [==============================] - 0s 107us/sample - loss: 0.0098 - accuracy: 0.9583 - val_loss: 0.0280 - val_accuracy: 0.7900\n",
      "Epoch 172/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0097 - accuracy: 0.9583 - val_loss: 0.0280 - val_accuracy: 0.7900\n",
      "Epoch 173/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0097 - accuracy: 0.9583 - val_loss: 0.0279 - val_accuracy: 0.7900\n",
      "Epoch 174/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0096 - accuracy: 0.9583 - val_loss: 0.0279 - val_accuracy: 0.7900\n",
      "Epoch 175/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0095 - accuracy: 0.9583 - val_loss: 0.0278 - val_accuracy: 0.7900\n",
      "Epoch 176/240\n",
      "600/600 [==============================] - 0s 105us/sample - loss: 0.0094 - accuracy: 0.9583 - val_loss: 0.0278 - val_accuracy: 0.7900\n",
      "Epoch 177/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0094 - accuracy: 0.9600 - val_loss: 0.0278 - val_accuracy: 0.7900\n",
      "Epoch 178/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0093 - accuracy: 0.9583 - val_loss: 0.0277 - val_accuracy: 0.7900\n",
      "Epoch 179/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0092 - accuracy: 0.9617 - val_loss: 0.0277 - val_accuracy: 0.7900\n",
      "Epoch 180/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0091 - accuracy: 0.9583 - val_loss: 0.0276 - val_accuracy: 0.7900\n",
      "Epoch 181/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0091 - accuracy: 0.9600 - val_loss: 0.0276 - val_accuracy: 0.7900\n",
      "Epoch 182/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0090 - accuracy: 0.9583 - val_loss: 0.0276 - val_accuracy: 0.7900\n",
      "Epoch 183/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0090 - accuracy: 0.9600 - val_loss: 0.0275 - val_accuracy: 0.7900\n",
      "Epoch 184/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0089 - accuracy: 0.9633 - val_loss: 0.0274 - val_accuracy: 0.7900\n",
      "Epoch 185/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0088 - accuracy: 0.9650 - val_loss: 0.0275 - val_accuracy: 0.7900\n",
      "Epoch 186/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0087 - accuracy: 0.9650 - val_loss: 0.0275 - val_accuracy: 0.7900\n",
      "Epoch 187/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0087 - accuracy: 0.9667 - val_loss: 0.0274 - val_accuracy: 0.7900\n",
      "Epoch 188/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0086 - accuracy: 0.9667 - val_loss: 0.0274 - val_accuracy: 0.7900\n",
      "Epoch 189/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0086 - accuracy: 0.9667 - val_loss: 0.0274 - val_accuracy: 0.7900\n",
      "Epoch 190/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0085 - accuracy: 0.9667 - val_loss: 0.0273 - val_accuracy: 0.7900\n",
      "Epoch 191/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0084 - accuracy: 0.9667 - val_loss: 0.0273 - val_accuracy: 0.7900\n",
      "Epoch 192/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0084 - accuracy: 0.9667 - val_loss: 0.0272 - val_accuracy: 0.7900\n",
      "Epoch 193/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0083 - accuracy: 0.9667 - val_loss: 0.0272 - val_accuracy: 0.7900\n",
      "Epoch 194/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0082 - accuracy: 0.9667 - val_loss: 0.0271 - val_accuracy: 0.7900\n",
      "Epoch 195/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0082 - accuracy: 0.9667 - val_loss: 0.0271 - val_accuracy: 0.7900\n",
      "Epoch 196/240\n",
      "600/600 [==============================] - 0s 103us/sample - loss: 0.0081 - accuracy: 0.9683 - val_loss: 0.0271 - val_accuracy: 0.7900\n",
      "Epoch 197/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0081 - accuracy: 0.9683 - val_loss: 0.0271 - val_accuracy: 0.7900\n",
      "Epoch 198/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0080 - accuracy: 0.9683 - val_loss: 0.0271 - val_accuracy: 0.7900\n",
      "Epoch 199/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0080 - accuracy: 0.9683 - val_loss: 0.0271 - val_accuracy: 0.7900\n",
      "Epoch 200/240\n",
      "600/600 [==============================] - 0s 106us/sample - loss: 0.0079 - accuracy: 0.9683 - val_loss: 0.0270 - val_accuracy: 0.7900\n",
      "Epoch 201/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0078 - accuracy: 0.9683 - val_loss: 0.0269 - val_accuracy: 0.7900\n",
      "Epoch 202/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0078 - accuracy: 0.9683 - val_loss: 0.0269 - val_accuracy: 0.7900\n",
      "Epoch 203/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0077 - accuracy: 0.9683 - val_loss: 0.0269 - val_accuracy: 0.7900\n",
      "Epoch 204/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0077 - accuracy: 0.9683 - val_loss: 0.0269 - val_accuracy: 0.7800\n",
      "Epoch 205/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0076 - accuracy: 0.9700 - val_loss: 0.0269 - val_accuracy: 0.7800\n",
      "Epoch 206/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0076 - accuracy: 0.9683 - val_loss: 0.0268 - val_accuracy: 0.7800\n",
      "Epoch 207/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0075 - accuracy: 0.9700 - val_loss: 0.0268 - val_accuracy: 0.7800\n",
      "Epoch 208/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0075 - accuracy: 0.9700 - val_loss: 0.0268 - val_accuracy: 0.7800\n",
      "Epoch 209/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0074 - accuracy: 0.9700 - val_loss: 0.0268 - val_accuracy: 0.7700\n",
      "Epoch 210/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0074 - accuracy: 0.9700 - val_loss: 0.0268 - val_accuracy: 0.7800\n",
      "Epoch 211/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0073 - accuracy: 0.9700 - val_loss: 0.0267 - val_accuracy: 0.7700\n",
      "Epoch 212/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0073 - accuracy: 0.9717 - val_loss: 0.0267 - val_accuracy: 0.7800\n",
      "Epoch 213/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0072 - accuracy: 0.9717 - val_loss: 0.0267 - val_accuracy: 0.7700\n",
      "Epoch 214/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0072 - accuracy: 0.9717 - val_loss: 0.0267 - val_accuracy: 0.7700\n",
      "Epoch 215/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0071 - accuracy: 0.9717 - val_loss: 0.0266 - val_accuracy: 0.7700\n",
      "Epoch 216/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0071 - accuracy: 0.9717 - val_loss: 0.0266 - val_accuracy: 0.7700\n",
      "Epoch 217/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0070 - accuracy: 0.9717 - val_loss: 0.0266 - val_accuracy: 0.7800\n",
      "Epoch 218/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0070 - accuracy: 0.9717 - val_loss: 0.0266 - val_accuracy: 0.7700\n",
      "Epoch 219/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0069 - accuracy: 0.9717 - val_loss: 0.0266 - val_accuracy: 0.7700\n",
      "Epoch 220/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0069 - accuracy: 0.9717 - val_loss: 0.0266 - val_accuracy: 0.7700\n",
      "Epoch 221/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0068 - accuracy: 0.9717 - val_loss: 0.0265 - val_accuracy: 0.7700\n",
      "Epoch 222/240\n",
      "600/600 [==============================] - 0s 96us/sample - loss: 0.0068 - accuracy: 0.9717 - val_loss: 0.0265 - val_accuracy: 0.7700\n",
      "Epoch 223/240\n",
      "600/600 [==============================] - 0s 99us/sample - loss: 0.0068 - accuracy: 0.9717 - val_loss: 0.0265 - val_accuracy: 0.7700\n",
      "Epoch 224/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0067 - accuracy: 0.9750 - val_loss: 0.0265 - val_accuracy: 0.7700\n",
      "Epoch 225/240\n",
      "600/600 [==============================] - 0s 104us/sample - loss: 0.0067 - accuracy: 0.9750 - val_loss: 0.0265 - val_accuracy: 0.7700\n",
      "Epoch 226/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0066 - accuracy: 0.9750 - val_loss: 0.0265 - val_accuracy: 0.7700\n",
      "Epoch 227/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0066 - accuracy: 0.9750 - val_loss: 0.0264 - val_accuracy: 0.7700\n",
      "Epoch 228/240\n",
      "600/600 [==============================] - 0s 90us/sample - loss: 0.0065 - accuracy: 0.9750 - val_loss: 0.0264 - val_accuracy: 0.7700\n",
      "Epoch 229/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0065 - accuracy: 0.9750 - val_loss: 0.0264 - val_accuracy: 0.7700\n",
      "Epoch 230/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0065 - accuracy: 0.9767 - val_loss: 0.0264 - val_accuracy: 0.7800\n",
      "Epoch 231/240\n",
      "600/600 [==============================] - 0s 98us/sample - loss: 0.0064 - accuracy: 0.9767 - val_loss: 0.0264 - val_accuracy: 0.7700\n",
      "Epoch 232/240\n",
      "600/600 [==============================] - 0s 92us/sample - loss: 0.0064 - accuracy: 0.9767 - val_loss: 0.0264 - val_accuracy: 0.7700\n",
      "Epoch 233/240\n",
      "600/600 [==============================] - 0s 94us/sample - loss: 0.0063 - accuracy: 0.9767 - val_loss: 0.0264 - val_accuracy: 0.7800\n",
      "Epoch 234/240\n",
      "600/600 [==============================] - 0s 101us/sample - loss: 0.0063 - accuracy: 0.9767 - val_loss: 0.0263 - val_accuracy: 0.7800\n",
      "Epoch 235/240\n",
      "600/600 [==============================] - 0s 97us/sample - loss: 0.0063 - accuracy: 0.9767 - val_loss: 0.0263 - val_accuracy: 0.7800\n",
      "Epoch 236/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0062 - accuracy: 0.9767 - val_loss: 0.0263 - val_accuracy: 0.7700\n",
      "Epoch 237/240\n",
      "600/600 [==============================] - 0s 95us/sample - loss: 0.0062 - accuracy: 0.9767 - val_loss: 0.0263 - val_accuracy: 0.7800\n",
      "Epoch 238/240\n",
      "600/600 [==============================] - 0s 93us/sample - loss: 0.0061 - accuracy: 0.9767 - val_loss: 0.0263 - val_accuracy: 0.7700\n",
      "Epoch 239/240\n",
      "600/600 [==============================] - 0s 91us/sample - loss: 0.0061 - accuracy: 0.9767 - val_loss: 0.0263 - val_accuracy: 0.7800\n",
      "Epoch 240/240\n",
      "600/600 [==============================] - 0s 100us/sample - loss: 0.0061 - accuracy: 0.9767 - val_loss: 0.0263 - val_accuracy: 0.7800\n"
     ]
    }
   ],
   "source": [
    "compile_model(model1)\n",
    "fit_model1(model1, 240)\n",
    "\n",
    "for m in model_list:\n",
    "    compile_model(m)\n",
    "    fit_model2(m, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_list = list(np.arange(0, 1.05, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_weights = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_weights_list_per_pi = list()\n",
    "for model_comp in model_list:\n",
    "    weights = [model1.get_weights(), model_comp.get_weights()]\n",
    "    agg_weights_list = list()\n",
    "    for theta in theta_list:\n",
    "        agg_weights = list()\n",
    "        for weights_list_tuple in zip(*weights):\n",
    "            agg_weights.append(np.array([np.average(np.array(w), axis=0, weights=[1. - theta, theta]) for w in zip(*weights_list_tuple)]))\n",
    "        agg_weights_list.append(agg_weights)\n",
    "    agg_weights_list_per_pi.append(agg_weights_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y = np.meshgrid(np.array(pi_list), np.array(theta_list))\n",
    "X, Y = np.meshgrid(np.array(theta_list), np.array(dist_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.02986117,  0.04316036, -0.01210911, ...,  0.07561368,\n",
       "         -0.0527647 , -0.04415964],\n",
       "        [-0.03667645,  0.05753742,  0.05212331, ..., -0.05153497,\n",
       "         -0.07470006, -0.00142   ],\n",
       "        [-0.04506178,  0.04306922, -0.03672078, ..., -0.04365882,\n",
       "          0.06915371, -0.06021708],\n",
       "        ...,\n",
       "        [-0.06554753, -0.01371761,  0.06625354, ..., -0.06544591,\n",
       "          0.05488627,  0.03811066],\n",
       "        [ 0.01981778, -0.02859065,  0.00619854, ..., -0.06173892,\n",
       "         -0.05130823, -0.04297249],\n",
       "        [ 0.03375495,  0.04143161,  0.00207567, ..., -0.02181715,\n",
       "          0.0173167 , -0.00831042]]),\n",
       " array([ 2.66553042e-03,  1.12337349e-02, -3.46943596e-03, -4.51730751e-03,\n",
       "         1.65902041e-02, -1.89069088e-03,  2.17705243e-03,  7.78011803e-04,\n",
       "         2.37092860e-02,  4.16239649e-02,  1.32374074e-02,  1.41867371e-02,\n",
       "        -2.15103704e-04,  5.43664629e-03,  5.75736072e-03,  3.81434831e-04,\n",
       "         1.81434434e-02,  1.03400154e-02,  8.84340517e-03,  1.27392577e-03,\n",
       "         1.91782601e-03,  1.55067062e-02,  1.95630025e-02,  1.85923278e-02,\n",
       "         5.74963912e-03, -1.26730534e-03,  7.74085708e-03,  8.76366068e-03,\n",
       "         2.45346944e-03,  3.96215133e-02,  1.57083687e-03,  1.96823012e-02,\n",
       "         2.11271737e-02,  1.29431086e-02,  3.58803826e-03,  1.90918092e-02,\n",
       "         4.46871342e-03,  1.05539185e-03,  2.38834731e-02,  1.51011171e-02,\n",
       "         0.00000000e+00,  1.55103644e-02,  1.56723149e-02, -3.24783078e-03,\n",
       "         2.08019558e-02,  9.82637331e-03,  1.41306277e-02,  2.66240612e-02,\n",
       "        -3.10971460e-04, -3.95161659e-03, -5.94816695e-04,  1.81758625e-03,\n",
       "         1.52484281e-02,  1.22838803e-02,  3.82099580e-03,  9.21215210e-03,\n",
       "         3.40788672e-03,  3.54234618e-03,  3.16282026e-02, -4.81918594e-03,\n",
       "         4.84482385e-03,  4.51627607e-03,  2.30190028e-02, -9.11746547e-03,\n",
       "         1.91656109e-02, -4.13508527e-03,  2.99803521e-02, -1.21612556e-03,\n",
       "         1.91538204e-02,  9.15518403e-03,  1.37738958e-02,  5.16846823e-03,\n",
       "         1.03656976e-02,  3.89708579e-03, -1.13275321e-03, -5.30472305e-03,\n",
       "        -2.30751769e-03,  1.14533817e-02,  2.29231711e-03,  1.19669838e-02,\n",
       "        -2.49362644e-03,  2.35318989e-02,  1.13212010e-02, -1.06551580e-03,\n",
       "         1.09881759e-02,  2.05756295e-02,  2.23933365e-02,  7.27935694e-04,\n",
       "         2.25014109e-02,  8.49416666e-03,  2.68208552e-02,  2.16015126e-03,\n",
       "         2.85457098e-03,  1.61847640e-02,  8.69627390e-03,  1.88813335e-03,\n",
       "        -2.36603641e-03,  2.10864879e-02,  3.37393110e-04, -1.21734675e-03,\n",
       "        -2.94180214e-03,  2.43342738e-03,  1.84743723e-03, -1.33924987e-04,\n",
       "         1.24305869e-02,  9.22845770e-03,  7.99507834e-03,  1.11058271e-02,\n",
       "         5.02710091e-03, -1.60078795e-04,  1.13353347e-02,  2.19533332e-02,\n",
       "         1.00180544e-02, -4.52340627e-03, -4.07758029e-03,  8.44508503e-03,\n",
       "        -2.83760624e-03,  1.55049609e-02,  4.02402878e-03,  2.22443510e-02,\n",
       "         1.68469399e-02,  2.64822156e-03,  2.86923610e-02,  9.96281672e-03,\n",
       "         5.28800488e-03,  7.38049718e-03,  9.78961494e-03,  1.30214235e-02,\n",
       "         3.95395383e-02, -3.45908129e-03,  6.67488668e-03,  2.39718352e-02,\n",
       "         1.81324035e-02,  1.10309087e-02, -8.98342914e-05,  4.47724340e-03,\n",
       "         2.53484724e-03,  3.11549637e-03,  5.94532443e-03,  1.92771945e-02,\n",
       "         4.04191390e-03,  3.03561939e-03,  2.56329942e-02, -1.08503585e-03,\n",
       "         2.87067425e-03,  1.18821179e-02, -4.56712767e-03,  1.16249325e-03,\n",
       "         2.36735046e-02,  8.58220039e-04,  2.01209970e-02, -7.92680029e-03,\n",
       "        -6.89207285e-04,  1.02824233e-02,  1.03477631e-02,  2.54169237e-02,\n",
       "         1.72022823e-02, -3.49028851e-04,  1.22739058e-02, -4.36405512e-03,\n",
       "         2.59077940e-02,  8.39505997e-03,  2.32731272e-02,  3.68569512e-03,\n",
       "         6.48128008e-03,  1.02837533e-02,  2.23607998e-02,  3.91995162e-03,\n",
       "         8.15642811e-03,  3.93566350e-03,  1.90496743e-02, -8.58807657e-03,\n",
       "         1.82579667e-03, -3.30507843e-04,  5.25758485e-04,  4.20819828e-03,\n",
       "         9.17726196e-03,  2.01475434e-02,  1.17113544e-02,  7.04959035e-03,\n",
       "         2.22723112e-02,  2.10101549e-02,  2.25497391e-02, -3.59346834e-03,\n",
       "         1.10083632e-02, -3.86233296e-04,  1.24639980e-02, -5.88276470e-03,\n",
       "        -1.02713238e-02,  1.72348116e-02, -3.78677738e-04,  2.24534655e-03,\n",
       "         1.06019014e-02,  4.17805219e-04, -1.42312981e-03,  6.61182450e-03,\n",
       "         2.70060934e-02,  1.57739073e-02,  1.42569216e-02,  2.22974876e-03]),\n",
       " array([[ 0.01322561,  0.10259784, -0.03478704, ...,  0.10510609,\n",
       "         -0.10220375,  0.11008061],\n",
       "        [-0.03827222,  0.08188026,  0.10676522, ...,  0.0437827 ,\n",
       "          0.13025296, -0.09842511],\n",
       "        [ 0.05423858, -0.050718  ,  0.000204  , ...,  0.03425437,\n",
       "          0.0199347 ,  0.10639954],\n",
       "        ...,\n",
       "        [-0.09478254, -0.03463449, -0.09785014, ..., -0.0980133 ,\n",
       "          0.09720992, -0.09676269],\n",
       "        [ 0.05905443,  0.00954522,  0.04009145, ..., -0.07459133,\n",
       "         -0.0378527 ,  0.09207408],\n",
       "        [ 0.07708334,  0.08680617, -0.11474133, ...,  0.0284464 ,\n",
       "          0.07628739, -0.05578227]]),\n",
       " array([-2.25754664e-03, -3.00283893e-04,  3.68456878e-02,  1.45679191e-02,\n",
       "         6.27508038e-04,  3.21374298e-03, -8.66221264e-03, -1.06381939e-03,\n",
       "         2.40132343e-02,  6.13980461e-03, -9.97472834e-03,  8.96629319e-03,\n",
       "         2.14187894e-02,  9.38439462e-03,  1.59227885e-02,  1.63451694e-02,\n",
       "         1.82346907e-02,  9.45382193e-03,  3.05956267e-02,  5.09183481e-03,\n",
       "         1.59538281e-03, -1.67157478e-03,  1.50737241e-02,  2.26423685e-02,\n",
       "         1.47045143e-02,  6.50892965e-03,  4.61559044e-03,  1.04624480e-02,\n",
       "         2.80155744e-02, -1.54643124e-02, -9.49163642e-03, -9.18859057e-03,\n",
       "         2.35911962e-02,  2.49148104e-02,  7.99411535e-03,  1.11045614e-02,\n",
       "         4.81106574e-03, -2.24577409e-04,  7.29398197e-03, -1.38737513e-02,\n",
       "        -5.20586967e-03,  2.27927640e-02,  1.94126472e-03,  1.78821720e-02,\n",
       "         2.19251793e-02,  3.03810406e-02,  8.09117570e-04,  1.64765015e-03,\n",
       "        -2.93903751e-03,  2.09560022e-02,  5.35528088e-05,  2.57968972e-03,\n",
       "        -3.00274882e-03,  6.08196296e-03,  3.81688662e-02, -3.27338185e-03,\n",
       "         5.07368986e-03,  1.21329697e-02, -7.40537187e-03, -1.26470625e-03,\n",
       "        -3.04240326e-04,  8.34085513e-03,  8.89537204e-03,  5.20883303e-04,\n",
       "         2.81737670e-02,  2.63697412e-02, -8.75531603e-03,  9.37965978e-03,\n",
       "        -3.76858911e-03,  3.44074145e-02,  1.92829501e-02, -2.93711154e-03,\n",
       "        -5.14082052e-03,  7.07744202e-03,  5.79433935e-03,  2.79468708e-02,\n",
       "        -7.00786384e-03,  6.58888952e-04,  1.19334869e-02, -8.76730960e-03,\n",
       "        -3.44048429e-04,  1.62570272e-03,  9.24155675e-03,  1.33876931e-02,\n",
       "        -1.12606364e-03,  0.00000000e+00,  1.34522291e-02,  2.55631916e-02,\n",
       "         4.45559900e-03, -9.97169875e-04,  2.71352734e-02,  5.62100811e-03,\n",
       "        -1.00879688e-02, -1.40813238e-03, -2.01646495e-03, -2.16519530e-03,\n",
       "         5.51014527e-05,  1.29513089e-02, -1.54567584e-02,  1.55685382e-04,\n",
       "        -2.63644685e-03,  2.11484618e-02,  1.54612139e-02,  2.92306188e-02,\n",
       "        -4.97222366e-03,  1.53151415e-02,  7.64135737e-03,  1.75409596e-02,\n",
       "         1.40381162e-03, -3.31555307e-03,  1.30649908e-02,  5.64216496e-03,\n",
       "        -1.66097726e-03,  2.45369934e-02,  2.07092706e-02,  1.13084111e-02,\n",
       "         1.83282420e-02,  1.22904941e-03, -1.99828087e-03,  6.16733171e-03,\n",
       "         1.68110919e-03,  6.32130716e-04,  1.06482720e-02,  1.08518153e-02,\n",
       "         1.53329233e-02,  2.47267564e-03, -3.72315350e-04, -8.01468920e-03,\n",
       "         5.11447340e-03,  7.60941580e-03,  3.25847999e-03,  1.42256916e-03,\n",
       "         5.46348887e-03, -6.20152615e-03,  6.47158083e-03, -4.18465026e-03,\n",
       "         6.87105628e-03, -6.63564715e-05,  1.59533881e-02,  2.22426504e-02,\n",
       "         2.06666850e-02,  2.03051511e-03,  1.40553694e-02, -5.13964798e-04,\n",
       "         0.00000000e+00,  1.38421301e-02,  1.92417186e-02,  4.18762825e-02,\n",
       "         6.29425421e-03,  1.04762819e-02,  5.08070085e-03,  1.31110344e-02,\n",
       "         1.53609440e-02, -6.78917347e-03,  4.94837388e-03,  1.03632994e-02,\n",
       "         3.26830298e-02, -7.45235739e-05,  8.78374092e-03,  2.05633158e-04,\n",
       "         1.64027675e-03,  2.45371796e-02,  7.32145272e-04,  2.06243824e-02,\n",
       "         1.23887509e-02, -1.01127084e-02,  4.44933248e-04,  1.22603131e-02,\n",
       "         4.15471935e-04,  5.83600812e-03,  2.65821256e-02, -2.72529270e-03,\n",
       "        -9.71796270e-03,  2.16666842e-03,  8.90586525e-03,  2.15230277e-03,\n",
       "         8.32761079e-03, -3.07685672e-03, -1.31728372e-03,  5.48416143e-03,\n",
       "        -2.34939950e-03,  5.78542147e-03,  3.01986234e-03,  1.88343339e-02,\n",
       "         1.88696347e-02,  1.53002637e-02,  1.51087325e-02,  1.86323057e-04,\n",
       "         1.04924869e-02, -2.30487948e-03,  6.05378486e-03,  1.27105257e-02,\n",
       "         1.09950621e-02, -5.65646729e-03,  7.17685907e-04,  1.05039552e-02,\n",
       "        -5.67098614e-03,  3.92647739e-03,  1.80297010e-02,  7.15253782e-03]),\n",
       " array([[-0.02783877, -0.17809768, -0.09993228, ...,  0.00714055,\n",
       "         -0.06505409, -0.0500605 ],\n",
       "        [ 0.00482578, -0.04497221,  0.08732826, ..., -0.03800859,\n",
       "          0.08717001,  0.07331482],\n",
       "        [-0.23291163,  0.21637204,  0.07205094, ..., -0.21405418,\n",
       "          0.1113095 ,  0.13362481],\n",
       "        ...,\n",
       "        [ 0.14478417,  0.06192863,  0.07235549, ..., -0.16251051,\n",
       "          0.0678719 ,  0.17852576],\n",
       "        [ 0.24340791,  0.16424273,  0.008875  , ...,  0.05376198,\n",
       "         -0.1149772 , -0.11342014],\n",
       "        [-0.03025464,  0.03136425,  0.02337944, ...,  0.12568502,\n",
       "          0.07262526,  0.09464167]]),\n",
       " array([-0.03958469,  0.02731168, -0.02439844,  0.00844536,  0.03774892,\n",
       "         0.01753458, -0.0315586 ,  0.00807188, -0.05539865,  0.051828  ])]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_weights_list_per_pi[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.zeros(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0257 - accuracy: 0.8251\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0251 - accuracy: 0.8302\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0245 - accuracy: 0.8347\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0240 - accuracy: 0.8406\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0235 - accuracy: 0.8456\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0230 - accuracy: 0.8485\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0226 - accuracy: 0.8534\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0222 - accuracy: 0.8568\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0219 - accuracy: 0.8590\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0216 - accuracy: 0.8607\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0214 - accuracy: 0.8634\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0212 - accuracy: 0.8653\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0210 - accuracy: 0.8656\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0209 - accuracy: 0.8644\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0209 - accuracy: 0.8642\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0209 - accuracy: 0.8639\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0209 - accuracy: 0.8633\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0210 - accuracy: 0.8620\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0212 - accuracy: 0.8605\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0214 - accuracy: 0.8582\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0217 - accuracy: 0.8561\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0257 - accuracy: 0.8251\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0251 - accuracy: 0.8301\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0246 - accuracy: 0.8345\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0240 - accuracy: 0.8406\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0236 - accuracy: 0.8448\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0231 - accuracy: 0.8483\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0227 - accuracy: 0.8529\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0224 - accuracy: 0.8561\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0220 - accuracy: 0.8577\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0217 - accuracy: 0.8600\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0215 - accuracy: 0.8623\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0213 - accuracy: 0.8643\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0212 - accuracy: 0.8649\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0211 - accuracy: 0.8644\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0210 - accuracy: 0.8645\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0210 - accuracy: 0.8635\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0211 - accuracy: 0.8638\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0212 - accuracy: 0.8625\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0213 - accuracy: 0.8603\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0216 - accuracy: 0.8576\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0218 - accuracy: 0.8556\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0257 - accuracy: 0.8251\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0252 - accuracy: 0.8303\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0246 - accuracy: 0.8341\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0241 - accuracy: 0.8397\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0237 - accuracy: 0.8440\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0233 - accuracy: 0.8482\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0229 - accuracy: 0.8519\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0225 - accuracy: 0.8542\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0222 - accuracy: 0.8568\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0220 - accuracy: 0.8589\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0218 - accuracy: 0.8613\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0216 - accuracy: 0.8622\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0214 - accuracy: 0.8629\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0213 - accuracy: 0.8634\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0213 - accuracy: 0.8645\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0213 - accuracy: 0.8643\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0213 - accuracy: 0.8634\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0214 - accuracy: 0.8612\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0216 - accuracy: 0.8595\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0218 - accuracy: 0.8563\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0221 - accuracy: 0.8533\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0257 - accuracy: 0.8251\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0252 - accuracy: 0.8289\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0247 - accuracy: 0.8341\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0243 - accuracy: 0.8379\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0239 - accuracy: 0.8430\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0235 - accuracy: 0.8475\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0231 - accuracy: 0.8505\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0228 - accuracy: 0.8522\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0226 - accuracy: 0.8548\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0223 - accuracy: 0.8572\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0221 - accuracy: 0.8597\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0220 - accuracy: 0.8615\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0218 - accuracy: 0.8613\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0218 - accuracy: 0.8624\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0217 - accuracy: 0.8640\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0217 - accuracy: 0.8629\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0218 - accuracy: 0.8619\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0219 - accuracy: 0.8608\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0220 - accuracy: 0.8585\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0222 - accuracy: 0.8553\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0225 - accuracy: 0.8524\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0257 - accuracy: 0.8251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0253 - accuracy: 0.8287\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0248 - accuracy: 0.8339\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0244 - accuracy: 0.8384\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0241 - accuracy: 0.8428\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0238 - accuracy: 0.8459\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0235 - accuracy: 0.8497\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0232 - accuracy: 0.8518\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0230 - accuracy: 0.8549\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0228 - accuracy: 0.8566\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0226 - accuracy: 0.8588\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0225 - accuracy: 0.8602\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0224 - accuracy: 0.8608\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0223 - accuracy: 0.8612\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0223 - accuracy: 0.8611\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0223 - accuracy: 0.8613\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0223 - accuracy: 0.8609\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0224 - accuracy: 0.8581\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0226 - accuracy: 0.8558\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0228 - accuracy: 0.8521\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0230 - accuracy: 0.8492\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0257 - accuracy: 0.8251\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0253 - accuracy: 0.8289\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0250 - accuracy: 0.8330\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0247 - accuracy: 0.8375\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0244 - accuracy: 0.8420\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0242 - accuracy: 0.8456\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0240 - accuracy: 0.8473\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0238 - accuracy: 0.8497\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0236 - accuracy: 0.8521\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0235 - accuracy: 0.8544\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0233 - accuracy: 0.8577\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0232 - accuracy: 0.8583\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0231 - accuracy: 0.8584\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0231 - accuracy: 0.8591\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0230 - accuracy: 0.8598\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0230 - accuracy: 0.8585\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0230 - accuracy: 0.8576\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0231 - accuracy: 0.8550\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0232 - accuracy: 0.8528\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0234 - accuracy: 0.8490\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0236 - accuracy: 0.8455\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0257 - accuracy: 0.8251\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0254 - accuracy: 0.8286\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0252 - accuracy: 0.8331\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0250 - accuracy: 0.8371\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0248 - accuracy: 0.8408\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0247 - accuracy: 0.8432\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0246 - accuracy: 0.8454\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0245 - accuracy: 0.8473\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0244 - accuracy: 0.8505\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0244 - accuracy: 0.8500\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0243 - accuracy: 0.8525\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0242 - accuracy: 0.8546\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0241 - accuracy: 0.8547\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0240 - accuracy: 0.8556\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0240 - accuracy: 0.8548\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0239 - accuracy: 0.8548\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0239 - accuracy: 0.8538\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0239 - accuracy: 0.8517\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0239 - accuracy: 0.8490\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0240 - accuracy: 0.8455\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0242 - accuracy: 0.8410\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0257 - accuracy: 0.8251\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0255 - accuracy: 0.8281\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0254 - accuracy: 0.8329\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0253 - accuracy: 0.8364\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0253 - accuracy: 0.8396\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0253 - accuracy: 0.8412\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0253 - accuracy: 0.8438\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0253 - accuracy: 0.8458\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0253 - accuracy: 0.8481\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0254 - accuracy: 0.8484\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0253 - accuracy: 0.8512\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0253 - accuracy: 0.8517\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0252 - accuracy: 0.8524\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0251 - accuracy: 0.8545\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0249 - accuracy: 0.8547\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0247 - accuracy: 0.8537\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0246 - accuracy: 0.8527\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0245 - accuracy: 0.8498\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0244 - accuracy: 0.8464\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0245 - accuracy: 0.8431\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0245 - accuracy: 0.8398\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0257 - accuracy: 0.8251\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0256 - accuracy: 0.8276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0256 - accuracy: 0.8327\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0257 - accuracy: 0.8352\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0258 - accuracy: 0.8376\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0260 - accuracy: 0.8398\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0263 - accuracy: 0.8417\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0265 - accuracy: 0.8435\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0267 - accuracy: 0.8452\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.0268 - accuracy: 0.8460\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0269 - accuracy: 0.8479\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0268 - accuracy: 0.8491\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0267 - accuracy: 0.8497\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0264 - accuracy: 0.8511\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0261 - accuracy: 0.8520\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0258 - accuracy: 0.8512\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0255 - accuracy: 0.8502\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0252 - accuracy: 0.8471\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0250 - accuracy: 0.8440\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0249 - accuracy: 0.8411\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0248 - accuracy: 0.8385\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0257 - accuracy: 0.8251\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0258 - accuracy: 0.8271\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0259 - accuracy: 0.8305\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0262 - accuracy: 0.8334\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0266 - accuracy: 0.8348\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0271 - accuracy: 0.8359\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0276 - accuracy: 0.8368\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0281 - accuracy: 0.8389\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0285 - accuracy: 0.8401\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0288 - accuracy: 0.8399\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0289 - accuracy: 0.8422\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0288 - accuracy: 0.8446\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0285 - accuracy: 0.8462\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0281 - accuracy: 0.8469\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0276 - accuracy: 0.8477\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0270 - accuracy: 0.8464\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0264 - accuracy: 0.8462\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0259 - accuracy: 0.8449\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0255 - accuracy: 0.8419\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0251 - accuracy: 0.8390\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0249 - accuracy: 0.8377\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0257 - accuracy: 0.8251\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0259 - accuracy: 0.8277\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0263 - accuracy: 0.8288\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0269 - accuracy: 0.8299\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0276 - accuracy: 0.8298\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0285 - accuracy: 0.8293\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0294 - accuracy: 0.8291\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0302 - accuracy: 0.8292\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0309 - accuracy: 0.8297\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0314 - accuracy: 0.8303\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0315 - accuracy: 0.8322\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0314 - accuracy: 0.8344\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0309 - accuracy: 0.8371\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0302 - accuracy: 0.8391\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0293 - accuracy: 0.8405\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0284 - accuracy: 0.8425\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0274 - accuracy: 0.8444\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0265 - accuracy: 0.8427\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0258 - accuracy: 0.8396\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0252 - accuracy: 0.8383\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0249 - accuracy: 0.8370\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0257 - accuracy: 0.8251\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0261 - accuracy: 0.8271\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0267 - accuracy: 0.8281\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0275 - accuracy: 0.8274\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0286 - accuracy: 0.8254\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0298 - accuracy: 0.8241\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0311 - accuracy: 0.8223\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0323 - accuracy: 0.8220\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0333 - accuracy: 0.8225\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0339 - accuracy: 0.8230\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0342 - accuracy: 0.8259\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0339 - accuracy: 0.8277\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0333 - accuracy: 0.8314\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0323 - accuracy: 0.8317\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0310 - accuracy: 0.8366\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0297 - accuracy: 0.8395\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0283 - accuracy: 0.8406\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0271 - accuracy: 0.8413\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0261 - accuracy: 0.8394\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0253 - accuracy: 0.8386\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0248 - accuracy: 0.8375\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0257 - accuracy: 0.8251\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0262 - accuracy: 0.8268\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0270 - accuracy: 0.8266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0281 - accuracy: 0.8256\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0295 - accuracy: 0.8239\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0311 - accuracy: 0.8215\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0329 - accuracy: 0.8180\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0345 - accuracy: 0.8160\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0358 - accuracy: 0.8145\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0367 - accuracy: 0.8158\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0370 - accuracy: 0.8180\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0367 - accuracy: 0.8206\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0358 - accuracy: 0.8253\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0344 - accuracy: 0.8300\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0326 - accuracy: 0.8350\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0308 - accuracy: 0.8381\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0289 - accuracy: 0.8400\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0273 - accuracy: 0.8409\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0260 - accuracy: 0.8404\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0251 - accuracy: 0.8408\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0244 - accuracy: 0.8394\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0257 - accuracy: 0.8251\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0263 - accuracy: 0.8256\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0273 - accuracy: 0.8252\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0287 - accuracy: 0.8235\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0305 - accuracy: 0.8197\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0327 - accuracy: 0.8176\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0349 - accuracy: 0.8127\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0370 - accuracy: 0.8076\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0388 - accuracy: 0.8026\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0400 - accuracy: 0.8009\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0403 - accuracy: 0.8010\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0399 - accuracy: 0.8055\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0387 - accuracy: 0.8122\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0368 - accuracy: 0.8202\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0345 - accuracy: 0.8283\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0321 - accuracy: 0.8345\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0297 - accuracy: 0.8377\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0277 - accuracy: 0.8408\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0261 - accuracy: 0.8410\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0249 - accuracy: 0.8416\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0242 - accuracy: 0.8408\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0257 - accuracy: 0.8251\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0264 - accuracy: 0.8249\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0276 - accuracy: 0.8236\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0293 - accuracy: 0.8211\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0315 - accuracy: 0.8176\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0340 - accuracy: 0.8119\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.0368 - accuracy: 0.8078\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0394 - accuracy: 0.7998\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0416 - accuracy: 0.7918\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.0431 - accuracy: 0.7885\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.0436 - accuracy: 0.7906\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0430 - accuracy: 0.7963\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0414 - accuracy: 0.8033\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0391 - accuracy: 0.8141\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0362 - accuracy: 0.8238\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0332 - accuracy: 0.8296\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0304 - accuracy: 0.8350\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0280 - accuracy: 0.8386\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0261 - accuracy: 0.8404\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0247 - accuracy: 0.8421\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0238 - accuracy: 0.8429\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0257 - accuracy: 0.8251\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0265 - accuracy: 0.8240\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0279 - accuracy: 0.8231\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0298 - accuracy: 0.8208\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.0324 - accuracy: 0.8159\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0354 - accuracy: 0.8099\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0387 - accuracy: 0.8023\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0419 - accuracy: 0.7937\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0446 - accuracy: 0.7856\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0463 - accuracy: 0.7782\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0469 - accuracy: 0.7812\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0462 - accuracy: 0.7874\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0443 - accuracy: 0.7968\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0414 - accuracy: 0.8103\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0380 - accuracy: 0.8192\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0344 - accuracy: 0.8280\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0310 - accuracy: 0.8353\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0282 - accuracy: 0.8384\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0260 - accuracy: 0.8423\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0245 - accuracy: 0.8444\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0235 - accuracy: 0.8444\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0257 - accuracy: 0.8251\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0266 - accuracy: 0.8235\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0282 - accuracy: 0.8226\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0303 - accuracy: 0.8194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0333 - accuracy: 0.8141\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0368 - accuracy: 0.8070\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0407 - accuracy: 0.7983\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0444 - accuracy: 0.7867\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0476 - accuracy: 0.7750\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0496 - accuracy: 0.7675\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0503 - accuracy: 0.7660\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0495 - accuracy: 0.7732\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0472 - accuracy: 0.7884\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0438 - accuracy: 0.8035\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0397 - accuracy: 0.8162\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0354 - accuracy: 0.8249\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0316 - accuracy: 0.8325\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0284 - accuracy: 0.8394\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0259 - accuracy: 0.8427\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0243 - accuracy: 0.8450\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0232 - accuracy: 0.8453\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0257 - accuracy: 0.8251\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0267 - accuracy: 0.8235\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0284 - accuracy: 0.8217\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0309 - accuracy: 0.8182\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0342 - accuracy: 0.8117\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0383 - accuracy: 0.8046\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0427 - accuracy: 0.7924\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0471 - accuracy: 0.7742\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0507 - accuracy: 0.7618\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0530 - accuracy: 0.7518\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0537 - accuracy: 0.7498\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0528 - accuracy: 0.7593\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0501 - accuracy: 0.7776\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0461 - accuracy: 0.7985\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0414 - accuracy: 0.8128\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0364 - accuracy: 0.8231\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0320 - accuracy: 0.8332\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0284 - accuracy: 0.8402\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0258 - accuracy: 0.8435\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0240 - accuracy: 0.8449\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0229 - accuracy: 0.8470\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0257 - accuracy: 0.8251\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0268 - accuracy: 0.8236\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0286 - accuracy: 0.8213\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0314 - accuracy: 0.8163\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0351 - accuracy: 0.8098\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0397 - accuracy: 0.8007\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0448 - accuracy: 0.7828\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0496 - accuracy: 0.7645\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0536 - accuracy: 0.7438\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0562 - accuracy: 0.7343\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0570 - accuracy: 0.7309\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0558 - accuracy: 0.7405\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0528 - accuracy: 0.7616\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0483 - accuracy: 0.7894\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0429 - accuracy: 0.8086\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0373 - accuracy: 0.8222\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0324 - accuracy: 0.8331\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0284 - accuracy: 0.8398\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0256 - accuracy: 0.8428\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0238 - accuracy: 0.8461\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0227 - accuracy: 0.8486\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0257 - accuracy: 0.8251\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0269 - accuracy: 0.8229\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0289 - accuracy: 0.8208\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0319 - accuracy: 0.8152\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0360 - accuracy: 0.8075\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0411 - accuracy: 0.7947\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0467 - accuracy: 0.7740\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0520 - accuracy: 0.7525\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0564 - accuracy: 0.7289\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0591 - accuracy: 0.7118\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0599 - accuracy: 0.7062\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0585 - accuracy: 0.7183\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0552 - accuracy: 0.7478\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0502 - accuracy: 0.7803\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0441 - accuracy: 0.8044\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0380 - accuracy: 0.8210\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0326 - accuracy: 0.8336\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0283 - accuracy: 0.8410\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0254 - accuracy: 0.8453\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0235 - accuracy: 0.8487\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0224 - accuracy: 0.8497\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0257 - accuracy: 0.8251\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0269 - accuracy: 0.8227\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0291 - accuracy: 0.8209\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0323 - accuracy: 0.8146\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0369 - accuracy: 0.8059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0424 - accuracy: 0.7896\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0485 - accuracy: 0.7657\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0542 - accuracy: 0.7389\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0588 - accuracy: 0.7099\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0616 - accuracy: 0.6861\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0623 - accuracy: 0.6784\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0608 - accuracy: 0.6969\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0572 - accuracy: 0.7337\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0517 - accuracy: 0.7745\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0452 - accuracy: 0.8027\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0385 - accuracy: 0.8214\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0327 - accuracy: 0.8343\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0282 - accuracy: 0.8409\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0252 - accuracy: 0.8473\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0232 - accuracy: 0.8493\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0222 - accuracy: 0.8513\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for agg_weights_list in agg_weights_list_per_pi:\n",
    "    j = 0\n",
    "    for agg_weights in agg_weights_list:\n",
    "        aggr_model = keras.models.clone_model(model1)\n",
    "        aggr_model.set_weights(agg_weights)\n",
    "        compile_model(aggr_model)\n",
    "        score = aggr_model.evaluate(x_test, y_test, batch_size=1000, steps=10);\n",
    "        Z[i][j] = score[0]\n",
    "        j += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=cm.tab20,\n",
    "                       linewidth=0, antialiased=False)\n",
    "ax.set_xlabel('$theta$')\n",
    "ax.set_ylabel('$\\pi$')\n",
    "ax.set_zlabel('$loss$')\n",
    "# Customize the z axis.\n",
    "# ax.set_zlim(-1.01, 1.01)\n",
    "# ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "# ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "# ax.view_init(0, 180)\n",
    "# ax.view_init(0, 0)\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "plt.savefig('fig1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How much are they similar to each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_distance(model1, model2):\n",
    "    w = zip(model1.get_weights(), model2.get_weights())\n",
    "    lw = list(w)\n",
    "    sums = 0\n",
    "    i = 0\n",
    "    for ww in lw:\n",
    "        i += 1\n",
    "        sums += np.average(np.absolute(ww[0] - ww[1]))\n",
    "    return sums / i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05077916461353501"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_distance(model1, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_max = 0\n",
    "i = 0\n",
    "for ww in lw:\n",
    "    i += 1\n",
    "    cur_max = max(np.max(np.absolute(ww[0] - ww[1])), cur_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13698825"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pi_list = list(np.arange(0, 1.05, 0.05)) # P for perturbations\n",
    "\n",
    "weights = [model1.get_weights(), model2.get_weights()]\n",
    "model_weights_list = list()\n",
    "for pi in pi_list:\n",
    "    agg_weights = list()\n",
    "    for weights_list_tuple in zip(*weights):\n",
    "        agg_weights.append(np.array([np.average(np.array(w), axis=0, weights=[1. - pi, pi]) for w in zip(*weights_list_tuple)]))\n",
    "    model_weights_list.append(agg_weights)\n",
    "    \n",
    "model_list2 = list()\n",
    "for _ in range(len(pi_list)):\n",
    "    model_list2.append(tf.keras.models.clone_model(model1))\n",
    "    \n",
    "for i in range(len(model_list)):\n",
    "    model_list2[i].set_weights(model_weights_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([average_distance(model1, m) for m in model_list2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### backup results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## @TODO Experiment with pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model1 = tf.keras.models.clone_model(model1)\n",
    "pretrained_model2 = tf.keras.models.clone_model(model1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "personalized.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
